<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    
    <link rel="shortcut icon" href="/img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>Without pip install - BigDL Project</title>
    <link href="/css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="/css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="/css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="/css/highlight.css">
    <link href="../../extra.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="/js/jquery-3.2.1.min.js"></script>
    <script src="/js/bootstrap-3.3.7.min.js"></script>
    <script src="/js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "Precondition", url: "#precondition", children: [
          ]},
          {title: "Remark", url: "#remark", children: [
          ]},
          {title: "Set Environment Variables", url: "#set-environment-variables", children: [
          ]},
          {title: "Update spark-bigdl.conf (Optional)", url: "#update-spark-bigdlconf-optional", children: [
          ]},
          {title: "Run with pyspark", url: "#run-with-pyspark", children: [
          ]},
          {title: "Run with spark-submit", url: "#run-with-spark-submit", children: [
          ]},
          {title: "Run with Jupyter", url: "#run-with-jupyter", children: [
          ]},
          {title: "Run with virtual environment in Yarn", url: "#run-with-virtual-environment-in-yarn", children: [
          ]},
          {title: "BigDL Configuration", url: "#bigdl-configuration", children: [
          ]},
        ];

    </script>
    <script src="/js/base.js"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
    
    <h1><strong>Without pip install</strong></h1>
    <hr>
    <h2 id="precondition"><strong>Precondition</strong></h2>
<p>First of all, you need to obtain the BigDL libs. Refer to <a href="../../ScalaUserGuide/install-pre-built/">Install from pre built</a>
or <a href="../../ScalaUserGuide/install-build-src/">Install from source code</a> for more details</p>
<h2 id="remark"><strong>Remark</strong></h2>
<ul>
<li>Only <strong>Python 2.7</strong>, <strong>Python 3.5</strong> and <strong>Python 3.6</strong> are supported for now.</li>
<li>Note that <strong>Python 3.6</strong> is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and 2.2.0. See <a href="https://issues.apache.org/jira/browse/SPARK-19019">this issue</a> for more discussion.</li>
</ul>
<h2 id="set-environment-variables"><strong>Set Environment Variables</strong></h2>
<p>Set <strong>BIGDL_HOME</strong> and <strong>SPARK_HOME</strong>:</p>
<ul>
<li>If you download BigDL from the <a href="../../release-download/">Release Page</a></li>
</ul>
<pre><code class="bash">export SPARK_HOME=folder path where you extract the spark package
export BIGDL_HOME=folder path where you extract the bigdl package
</code></pre>

<ul>
<li>If you build BigDL by yourself</li>
</ul>
<pre><code class="bash">export SPARK_HOME=folder path where you extract the spark package
export BIGDL_HOME=the dist folder generated by the build process, which is under the top level of the source folder
</code></pre>

<h2 id="update-spark-bigdlconf-optional"><strong>Update spark-bigdl.conf (Optional)</strong></h2>
<p>If you have some customized properties in some files, which is used with the <strong>--properties-file</strong> option
in spark-submit/pyspark, add these customized properties into ${BIGDL_HOME}/conf/spark-bigdl.conf.</p>
<h2 id="run-with-pyspark"><strong>Run with pyspark</strong></h2>
<pre><code class="bash">${BIGDL_HOME}/bin/pyspark-with-bigdl.sh --master local[*]
</code></pre>

<ul>
<li><code>--master</code> set the master URL to connect to</li>
<li><code>--jars</code> if there are extra jars needed.</li>
<li><code>--py-files</code> if there are extra python packages needed.</li>
</ul>
<p>You can also specify other options available for pyspark in the above command if needed.</p>
<p><a href="../run-from-pip/#code.verification">Example code to verify if BigDL can run successfully</a></p>
<h2 id="run-with-spark-submit"><strong>Run with spark-submit</strong></h2>
<p>A BigDL Python program runs as a standard pyspark program, which requires all Python dependencies
(e.g., NumPy) used by the program to be installed on each node in the Spark cluster. You can try
running the BigDL <a href="https://github.com/intel-analytics/BigDL/tree/master/pyspark/bigdl/models/lenet">lenet Python example</a>
as follows:</p>
<pre><code class="bash">${BIGDL_HOME}/bin/spark-submit-with-bigdl.sh --master local[4] lenet5.py
</code></pre>

<h2 id="run-with-jupyter"><strong>Run with Jupyter</strong></h2>
<p>With the full Python API support in BigDL, users can use BigDL together with powerful notebooks
(such as Jupyter notebook) in a distributed fashion across the cluster, combining Python libraries,
Spark SQL / dataframes and MLlib, deep learning models in BigDL, as well as interactive
visualization tools.</p>
<p><strong>Prerequisites</strong>: Install all the necessary libraries on the local node where you will run Jupyter, e.g., </p>
<pre><code class="bash">sudo apt install python
sudo apt install python-pip
sudo pip install numpy scipy pandas scikit-learn matplotlib seaborn wordcloud
</code></pre>

<p>Launch the Jupyter notebook as follows:</p>
<pre><code class="bash">${BIGDL_HOME}/bin/jupyter-with-bigdl.sh --master local[*]
</code></pre>

<ul>
<li><code>--master</code> set the master URL to connect to</li>
<li><code>--jars</code> if there are extra jars needed.</li>
<li><code>--py-files</code> if there are extra python packages needed.</li>
</ul>
<p>You can also specify other options available for pyspark in the above command if needed.</p>
<p>After successfully launching Jupyter, you will be able to navigate to the notebook dashboard using
your browser. You can find the exact URL in the console output when you started Jupyter; by default,
the dashboard URL is http://your_node:8888/</p>
<p><a href="../run-from-pip/#code.verification">Example code to verify if BigDL can run successfully</a></p>
<p><a name="yarn.example"></a></p>
<h2 id="run-with-virtual-environment-in-yarn"><strong>Run with virtual environment in Yarn</strong></h2>
<p>If you already created BigDL dependency virtual environment according to <a href="../install-without-pip/#yarn.cluster">Yarn cluster guide in install without pip </a>, you can run python program using BigDL as following examples.</p>
<ul>
<li>Note: please set BigDL_HOME, SPARK_HOME environment. Set VENV_HOME to the parent directory of venv.zip and venv directory. Replace VERSION with your BigDL version, like 0.5.0. If you don't install BigDL from source, replace ${BigDL_HOME}/pyspark/bigdl/examples/lenet/lenet.py with your python program which is using BigDL.</li>
<li>Yarn cluster mode</li>
</ul>
<pre><code>    BigDL_HOME=
    SPARK_HOME=
    PYTHON_API_PATH=${BigDL_HOME}/dist/lib/bigdl-VERSION-python-api.zip
    BigDL_JAR_PATH=${BigDL_HOME}/dist/lib/bigdl-VERSION-jar-with-dependencies.jar
    PYTHONPATH=${PYTHON_API_PATH}:$PYTHONPATH
    VENV_HOME=

    PYSPARK_PYTHON=./venv.zip/venv/bin/python ${SPARK_HOME}/bin/spark-submit \
    --conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=./venv.zip/venv/bin/python \
    --master yarn-cluster \
    --executor-memory 10g \
    --driver-memory 10g \
    --executor-cores 8 \
    --num-executors 2 \
    --properties-file ${BigDL_HOME}/dist/conf/spark-bigdl.conf \
    --jars ${BigDL_JAR_PATH} \
    --py-files ${PYTHON_API_PATH} \
    --archives ${VENV_HOME}/venv.zip \
    --conf spark.driver.extraClassPath=bigdl-VERSION-jar-with-dependencies.jar \
    --conf spark.executor.extraClassPath=bigdl-VERSION-jar-with-dependencies.jar \
    ${BigDL_HOME}/pyspark/bigdl/examples/lenet/lenet.py
</code></pre>

<ul>
<li>
<p>Yarn client mode
```
    BigDL_HOME=
    SPARK_HOME=
    PYTHON_API_PATH=${BigDL_HOME}/dist/lib/bigdl-VERSION-python-api.zip
    BigDL_JAR_PATH=${BigDL_HOME}/dist/lib/bigdl-VERSION-jar-with-dependencies.jar
    PYTHONPATH=${PYTHON_API_PATH}:$PYTHONPATH
    VENV_HOME=</p>
<p>PYSPARK_DRIVER_PYTHON=${VENV_HOME}/venv/bin/python PYSPARK_PYTHON=./venv.zip/venv/bin/python ${SPARK_HOME}/bin/spark-submit \
--master yarn \
--deploy-mode client \
--executor-memory 10g \
--driver-memory 10g \
--executor-cores 16 \
--num-executors 2 \
--properties-file ${BigDL_HOME}/dist/conf/spark-bigdl.conf \
--jars ${BigDL_JAR_PATH} \
--py-files ${PYTHON_API_PATH} \
--archives ${VENV_HOME}/venv.zip \
--conf spark.driver.extraClassPath=${BigDL_JAR_PATH} \
--conf spark.executor.extraClassPath=bigdl-VERSION-jar-with-dependencies.jar \
${BigDL_HOME}/pyspark/bigdl/examples/lenet/lenet.py
 ```</p>
</li>
</ul>
<h2 id="bigdl-configuration"><strong>BigDL Configuration</strong></h2>
<p>Please check <a href="../../ScalaUserGuide/configuration/">this page</a></p>

  <br>
</div>

<footer class="col-md-12 wm-page-content">
  <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>