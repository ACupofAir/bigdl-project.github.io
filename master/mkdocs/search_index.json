{
    "docs": [
        {
            "location": "/", 
            "text": "What is BigDL\n\n\nBigDL\n is a distributed deep learning library for Apache Spark; with BigDL, users can write their deep learning applications as standard Spark programs, which can directly run on top of existing Spark or Hadoop clusters.\n\n\n\n\n\n\nRich deep learning support.\n Modeled after \nTorch\n, BigDL provides comprehensive support for deep learning, including numeric computing (via \nTensor\n) and high level \nneural networks\n; in addition, users can load pre-trained \nCaffe\n or \nTorch\n or \nKeras\n models into Spark programs using BigDL.\n\n\n\n\n\n\nExtremely high performance.\n To achieve high performance, BigDL uses \nIntel MKL\n and multi-threaded programming in each Spark task. Consequently, it is orders of magnitude faster than out-of-box open source \nCaffe\n, \nTorch\n or \nTensorFlow\n on a single-node Xeon (i.e., comparable with mainstream GPU).\n\n\n\n\n\n\nEfficiently scale-out.\n BigDL can efficiently scale out to perform data analytics at \"Big Data scale\", by leveraging \nApache Spark\n (a lightning fast distributed data processing framework), as well as efficient implementations of synchronous SGD and all-reduce communications on Spark. \n\n\n\n\n\n\n\n\nWhy BigDL?\n\n\nYou may want to write your deep learning programs using BigDL if:\n\n\n\n\n\n\nYou want to analyze a large amount of data on the same Big Data (Hadoop/Spark) cluster where the data are stored (in, say, HDFS, HBase, Hive, etc.).\n\n\n\n\n\n\nYou want to add deep learning functionalities (either training or prediction) to your Big Data (Spark) programs and/or workflow.\n\n\n\n\n\n\nYou want to leverage existing Hadoop/Spark clusters to run your deep learning applications, which can be then dynamically shared with other workloads (e.g., ETL, data warehouse, feature engineering, classical machine learning, graph analytics, etc.)\n\n\n\n\n\n\n\n\nGetting Help\n\n\n\n\n\n\nFor the technical overview of BigDL, please refer to the \nBigDL white paper\n\n\n\n\n\n\nYou can check out the \nGetting Started page\n for a quick overview of how to use BigDL, and the \nBigDL Tutorials project\n for step-by-step deep leaning tutorials on BigDL (using Python). \n\n\n\n\n\n\nYou can join the \nBigDL Google Group\n (or subscribe to the \nMail List\n) for more questions and discussions on BigDL\n\n\n\n\n\n\nYou can post bug reports and feature requests at the \nIssue Page", 
            "title": "ReadMe"
        }, 
        {
            "location": "/#what-is-bigdl", 
            "text": "BigDL  is a distributed deep learning library for Apache Spark; with BigDL, users can write their deep learning applications as standard Spark programs, which can directly run on top of existing Spark or Hadoop clusters.    Rich deep learning support.  Modeled after  Torch , BigDL provides comprehensive support for deep learning, including numeric computing (via  Tensor ) and high level  neural networks ; in addition, users can load pre-trained  Caffe  or  Torch  or  Keras  models into Spark programs using BigDL.    Extremely high performance.  To achieve high performance, BigDL uses  Intel MKL  and multi-threaded programming in each Spark task. Consequently, it is orders of magnitude faster than out-of-box open source  Caffe ,  Torch  or  TensorFlow  on a single-node Xeon (i.e., comparable with mainstream GPU).    Efficiently scale-out.  BigDL can efficiently scale out to perform data analytics at \"Big Data scale\", by leveraging  Apache Spark  (a lightning fast distributed data processing framework), as well as efficient implementations of synchronous SGD and all-reduce communications on Spark.", 
            "title": "What is BigDL"
        }, 
        {
            "location": "/#why-bigdl", 
            "text": "You may want to write your deep learning programs using BigDL if:    You want to analyze a large amount of data on the same Big Data (Hadoop/Spark) cluster where the data are stored (in, say, HDFS, HBase, Hive, etc.).    You want to add deep learning functionalities (either training or prediction) to your Big Data (Spark) programs and/or workflow.    You want to leverage existing Hadoop/Spark clusters to run your deep learning applications, which can be then dynamically shared with other workloads (e.g., ETL, data warehouse, feature engineering, classical machine learning, graph analytics, etc.)", 
            "title": "Why BigDL?"
        }, 
        {
            "location": "/#getting-help", 
            "text": "For the technical overview of BigDL, please refer to the  BigDL white paper    You can check out the  Getting Started page  for a quick overview of how to use BigDL, and the  BigDL Tutorials project  for step-by-step deep leaning tutorials on BigDL (using Python).     You can join the  BigDL Google Group  (or subscribe to the  Mail List ) for more questions and discussions on BigDL    You can post bug reports and feature requests at the  Issue Page", 
            "title": "Getting Help"
        }, 
        {
            "location": "/whitepaper/", 
            "text": "BigDL: A Distributed Deep Learning Framework for Big Data\n\n\nJason (Jinquan) Dai\n1\n, Yiheng Wang\n1\n, Xin Qiu\n1\n, Ding Ding\n1\n, Yao Zhang\n2 \u01c2\n, Yanzhang Wang\n1\n, Xianyan Jia\n2 \u01c2\n, Cherry (Li) Zhang\n1\n, Yan Wan\n3 \u01c2\n, Zhichao Li\n1\n, Jiao Wang\n1\n, Shengsheng Huang\n1\n, Zhongyuan Wu\n1\n, Yang Wang\n1\n, Yuhao Yang\n1\n, Bowen She\n1\n, Dongjie Shi\n1\n, Qi Lu\n1\n, Kai Huang\n1\n, Guoqiong Song\n1\n\n\n1\nIntel Corporation,    \n2\nTencent Inc.,    \n3\nAlibaba Group\n\n\n\u01c2\nWork was done when the author worked at Intel\n\n\n\n\nAbstract\n\n\nIn this paper, we present BigDL, a distributed deep learning framework for Big Data platforms and workflows. It is implemented on top of Apache Spark, and allows users to write their deep learning applications as standard Spark programs (running directly on large-scale big data clusters in a distributed fashion). It provides an expressive, \u201cdata-analytics integrated\u201d deep learning programming model, so that users can easily build the end-to-end analytics + AI pipelines under a unified programing paradigm; by implementing an \nAllReduce\n like operation using existing primitives in Spark (e.g., shuffle, broadcast, and in-memory data persistence), it also provides a highly efficient \u201cparameter server\u201d style architecture, so as to achieve highly scalable, data-parallel distributed training. Since its initial open source release, BigDL users have built many analytics and deep learning applications (e.g., object detection, sequence-to-sequence generation, neural recommendations, fraud detection, etc.) on Spark.\n\n\n1. Introduction\n\n\nRecent breakthroughs in artificial intelligence have brought deep learning to the forefront of new generations of data analytics; as the requirements and usage models expand, new systems and architecture beyond existing deep learning frameworks (e.g., Caffe [1], Torch [2], TensorFlow [3], MXNet [4], Chainer [5], etc.) have inevitably emerged. In particular, there is increasing demand from organizations to apply deep learning technologies (such as computer vision, natural language processing, generative adversary networks, etc.) to their big data platforms and pipelines. This emerging convergence of deep learning and big data analytics is driven by several important technology and industry trends:\n\n\n\n\n\n\nData scale drives deep learning process.\n Today users are building even deeper, more complex neural networks to take advantage of the massive amount of data that they have access to. In practice, big data (e.g., Apache Hadoop [6] or Apache Spark [7]) clusters are ubiquitously deployed as the global data platform, where all the production data are stored and made available to all the users. Therefore, it is usually much more efficient to run the algorithm directly on the big data cluster where the data are stored and shared (than copying data to a separate infrastructure).\n\n\n\n\n\n\nReal-world deep learning applications are complex big data pipelines,\n which require a lot of data processing (such as cleaning, transformation, augmentation, feature extraction, etc.) beyond model training/inference. Therefore, it is much simpler and more efficient (for development and workflow management) to seamlessly integrate deep learning functionalities into existing big data workflow running on the same infrastructure, especially given the recent improvements that reduce deep learning training time from weeks to hours [9] or even minutes [10].\n\n\n\n\n\n\nDeep learning is increasingly adopted by the big data and data science community.\n Unfortunately, mainstream data engineers and data scientists are usually not deep learning experts; as the usages of deep learning expand and scale to larger deployment, it will be much more easier if these users can continue the use of familiar software tools and programming models (e.g., Spark [8] or even SQL) and existing big data cluster infrastructures to build their deep learning applications.\n\n\n\n\n\n\nWe have developed \nBigDL\n [11], a distributed deep learning framework for big data platforms and workflows. It is implemented as a library on top of Apache Spark, and allows users to write their large-scale deep learning applications (including model training, fine-tuning and inference) as standard Spark programs, which can run directly on existing big data (Hadoop or Spark) clusters. BigDL provides comprehensive support of deep learning technologies (neural network operations, layers, losses and optimizers); in particular, users can directly run existing models defined in other frameworks (such as TensorFlow, Keras [12], Caffe and Torch) on Spark in a distributed fashion.\n\n\nBigDL also provides seamless integrations of deep learning technologies into the big data ecosystem. Not only can a BigDL program directly interact with different components in the Spark framework (e.g., DataFrames [13], Spark Streaming [14], ML Pipelines [15], etc.), it can also directly run in a variety of big data frameworks (such as Apache Storm [17], Apache Flink [18], Apache Kafka [19], etc.). Since its initial open source on Dec 30, 2016, BigDL has enabled many community users to build their deep learning applications (e.g., object detection, sequence-to-sequence generation, neural recommendations, fraud detection, etc.) on Spark and big data platforms.\n\n\n2. Programming Model\n\n\nBigDL is implemented on Apache Spark, a widely used cluster computing engine for big data analysis. Spark provides a comprehensive set of libraries for relational processing, streaming, graph processing [16] and machine learning (in Python, Scala or Java); as a result, one can easily build the end-to-end, \u201cdata-analytics integrated\u201d deep learning and AI pipelines (under a unified programing paradigm) using Spark and BigDL, as illustrated in Figure 1.\n\n\n1    spark = SparkContext(appName=\ntext_classifier\n, \u2026)\n2    //load input data: (text, label) pairs\n3    texts_rdd = spark.textFile(\nhdfs://...\n)\n4    //convert text to list of words\n5    words_rdd = texts_rdd.map(lambda text, label: \n6                               ([w for w in to_words(text)], label))\n7    //load GloVe embedding\n8    w2v = news20.get_glove_w2v(dim=\u2026)\n9    //convert word list to list of vertors using GloVe embeddings\n10   vector_rdd = words_rdd.map(lambda word_list, label:\n11                              ([to_vec(w, w2v) for w in word_list], label))\n12   //convert (list of vertors, label) pair to Sample\n13   sample_rdd = vector_rdd.map(lambda vector_list, label: \n14                                 to_sample(vector_list, label))\n15   //construct neural network model  \n16   model = Sequential().add(Recurrent().add(LSTM(\u2026)))\n17                       .add(Linear(\u2026))\n18                       .add(LogSoftMax())\n19   //train the model \n20   loss = ClassNLLCriterion()\n21   optim_method = Adagrad()\n22   optimizer = Optimizer(model=model, training_rdd=sample_rdd, \n23                         criterion=loss, optim_method= optim_method, \u2026)\n24   trained_model =optimizer.optimize()\n25   //model prediction\n26   test_rdd = \u2026\n27   prediction_rdd = trained_model.predict(test_rdd)\n\n\n\n\nFigure 1. The end-to-end text classification pipeline (including data loading, tokenization, word vectorization, training, prediction, etc.) on Spark and BigDL.\n\n\n2.1. Spark\n\n\nSpark provides the \nResilient Distributed Dataset\n (RDD) [8] in-memory storage abstraction, which is an immutable collection of Python or Scala/Java objects partitioned across a cluster, and can be transformed to derive new RDDs through data-parallel functional operators like \nmap, filter and reduce.\n Consequently, users can efficiently load very large dataset and process the loaded data in a distributed fashion using Spark, and then feed the processed data into the analytics and AI pipeline. For example, lines 1 ~ 6 in Figure 1 illustrates how to load the input data (article texts and their associated labels) from the Hadoop Distributed File System (HDFS) [20], and transforms each text string into a list of words.\n\n\n2.2. Data transformation\n\n\nSpark supports general dataflow DAGs [8] by composing multiple data-parallel operators on RDD, where each vertex represents an RDD and each edge represents the transformation by the RDD operator. By constructing the dataflow DAG in Spark, users can easily transform the input data (for, e.g., image augmentations, word vectorizations, etc.), which can then be used by the neural network models. For example, lines 7 ~ 11 in Figure 1 illustrates how to apply GloVe word embedding [21] to transform each word to a vector. \n\n\n\n\n\n\nN-dimensional array:\n In BigDL, we model the basic data elements used in neural network computations as N-dimensional numeric (int8, float32, etc.) arrays. These arrays are represented by \nnumpy.ndarry\n [22] and \nBigDL.Tensor\n (similar to \nTorch.Tensor\n [23]) for BigDL Python and Scala/Java APIs respectively.\n\n\n\n\n\n\nSample:\n Each record used in BigDL model training and prediction is modelled as a Sample, which contains an input feature and an optional label. Each input feature is one or more N-dimensional arrays, while each label is either a scalar (float32) value, or one or more \nN-dimensional arrays.\n For instance, lines 12 ~ 14 in Figure 1 shows how to turn the transformed data into an RDD of \nSamples,\n which will later be used by BigDL model training.\n\n\n\n\n\n\n2.3. Model Construction\n\n\nSimilar to Torch and Keras, BigDL uses a dataflow representation for the neural network model, where each vertex in the dataflow graph represents a neural network layer (such as \nReLu, Spatial Convolution and LSTM\n). BigDL then uses the semantics of the layers for model evaluation (\nforward\n) and gradient computation (\nbackward\n). For example, lines 15 ~ 18 in Figure 1 illustrates the model definition used in the text classification example.\n\n\n2.4. Model training\n\n\nThe transformed input data (RDD of Samples) and the constructed model can then be passed over to the \nOptimizer\n in BigDL, which automatically performs distributed model training across the cluster, as illustrated by lines 19 ~ 24 in \nFigure 1.\n\n\n\n\nOptimizer:\n In BigDL, the distributed training process is modelled by an Optimizer abstraction, which runs iterative Spark jobs to minimize the loss (as defined by the user specified Criterion) using specific optimization method (such as \nSGD, AdaGrad [24], Adam [25], etc.\n).\n\n\n\n\n2.5. Model Inference\n\n\nBigDL also allows users to directly use existing models (pre-trained by Caffe, Keras, TensorFlow, Torch or BigDL) in Spark, so as to directly perform model prediction in a distributed fashion (using RDD transformations), as illustrated by lines 25 ~ 27 in Figure 1. \n\n\n\n\nModelBroadcast:\n BigDL provides the \nModelBroadcast\n abstraction to manage the deployment of the pre-trained model across the cluster in a Spark job; the model prediction operation (\npredict\n) in BigDL uses \nModelBroadcast\n to cache a single copy of the model on each machine (by leveraging the \nbroadcast\n [26] mechanism in Spark), and manage the model cloning and weight sharing among different tasks in the same machine.\n\n\n\n\n2.6. Spark DataFrame and ML Pipeline\n\n\nBesides RDD, Spark provides a high level \nDataFrame\n abstraction [13], which is a distributed collection of rows with a specific schema (similar to a table in a relational database), and implements data-parallel relational operators like \nfilter\n and \njoin\n for efficient structured data analysis. On top of DataFrame, Spark introduces a high level ML \n(machine learning) pipeline\n [15] similar to SciKit-Learn [27], which allows users to construct the machine learning workflow as a graph of transformations on data (e.g., feature extraction, normalization, model training, etc.). BigDL also provides native integration with the high level Spark DataFrame and ML Pipeline APIs (using its \nDLModel\n and \nDLEstimator\n abstractions). \n\n\n3. Execution Model\n\n\nSimilar to other Big Data systems (such as MapReduce [28]), a Spark cluster consists of a single driver node and multiple worker nodes, as shown in Figure 2.  The driver node is responsible for coordinating the tasks in a Spark job (e.g., scheduling and dispatching), while the worker nodes are responsible for the actual computation and physical data storage. To automatically parallelize the large-scale data processing across the cluster in a fault-tolerant fashion, Spark provides a functional compute model where immutable RDDs are transformed through coarse-grained operators (i.e., applying the same operation to all data items). \n\n\n \n\n\nFigure 2. A Spark job contains many Spark tasks; the driver node is responsible for scheduling and dispatching the tasks to worker nodes, which runs the actual Spark tasks.\n\n\nOn the other hand, efficient and distributed training of deep neural networks would necessitate very different operations (such as fine-grained data access and in-place data mutation [3]). In this section, we describe in details how BigDL supports highly efficient and scalable distributed training, directly on top of the data parallel and functional compute model of Spark (in addition to various optimizations for model inference).\n\n\n3.1. Data-parallel training\n\n\nTo train a deep neural network model across the cluster, BigDL provides data-parallel training on Spark using synchronous mini-batch SGD, which is shown to achieve better scalability and efficiency (in terms of time-to-quality) compared to asynchronous training [29][30]. The distributed training in BigDL is implemented as an iterative process, as illustrated in Figure 3; each iteration runs a couple of Spark jobs to first compute the gradients using the current mini-batch, and then make a single update to the parameters of the neural network model.\n\n\nfor (i \n- 1 to N) {\n  //\nmodel forward-backward\n job\n  for each task in the Spark job:\n     read the latest weights\n     get a random batch of data from local sample partition\n     compute errors (forward on local model replica)\n     compute gradients (backward on local model replica)\n  //\nparameter synchronization\n job\n  aggregate (sum) all the gradients\n  update the weights per specified optimization method\n}\n\n\n\n\nFigure 3. BigDL provides efficient, data-parallel, synchronous mini-batch SGD, where each iteration runs two Spark jobs for \u201cmodel forward-backward\u201d and \u201cparameter synchronization\u201d.\n\n\nAs described in Section 2, BigDL models the training data as an RDD of Samples, which are automatically partitioned and potentially cached in memory across the Spark cluster. In addition, to implement the data-parallel training, BigDL also constructs an RDD of models, each of which is a replica of the original neural network model. The model and sample RDDs are co-partitioned and co-located [14] across the cluster, as shown in Figure 4; consequently, in each iteration of the model training, a single \u201cmodel forward-backward\u201d Spark job can apply the functional zip operator to the partitions of model and sample RDDs, and compute the gradients in parallel for each model replica (using a small batch of data in the co-located sample partition), as illustrated in Figure 4.\n\n\n \n\n\nFigure 4. The \u201cmodel forward-backward\u201d spark job, which computes the local gradients for each model replica in parallel.\n\n\n3.2. Parameter synchronization\n\n\nParameter synchronization is a performance critical operation for data-parallel training (in terms of speed and scalability). To support efficient parameter synchronization, existing deep learning frameworks usually implement the parameter server [31][32][33] architecture or AllReduce [34] operation, which unfortunately cannot be directly supported by the functional compute model provided by the Big Data systems.\nIn BigDL, we have adapted the primitives available in the Spark (e.g., shuffle, broadcast, in-memory cache, etc.) to implement an efficient AllReduce-like operation, so as to mimic the functionality of a parameter server architecture (as illustrated in Figure 5).\n\n\n \n\n\nFigure 5. Parameter synchronization in BigDL. Each local gradient (computed by a task in the \u201cmodel forward-backward\u201d job) is evenly divided into N partitions; then each task n in the \u201cparameter synchronization\u201d job aggregates these local gradients and update the weights for the nth partition.\n\n\n\n\n\n\nA Spark job has \nN\n tasks, each of which is assigned a unique Id ranging from \n1\n to \nN\n in BigDL. After each task in the \u201c\nmodel forward-backward\n\u201d job computes the local gradients (as described in section 3.1), it evenly divides the local gradients into \nN\n partitions, as shown in Figure 5.\n\n\n\n\n\n\nNext, another \u201c\nparameter synchronization\n\u201d job is launched; each task \nn\n in the \u201c\nparameter synchronization\n\u201d job is responsible for managing the n\nth\n partition of the parameters, just like a parameter server (as shown in Figure 6). Specifically, the n\nth\n partition of the gradients (from all the tasks of the previous \u201c\nmodel forward-backward\n\u201d job) are first \nshuffled\n to task n, which then aggregates (sums) these gradients, and applies the updates to the n\nth\n partition of the weights (using the specific optimization method), as illustrated in Figure 5.\n\n\n\n\n\n\nFor each task n in the \nparameter synchronization\n job\n   shuffle the nth partition of all gradients to this task\n   aggregate (sum) the gradients\n   updates the nth partition of the weights\n   broadcast the nth partition of the updated weights\n\n\n\n\nFigure 6. The \u201cparameter synchronization\u201d Spark job, manages the n\nth\n partition of the parameters (similar to a parameter server).\n\n\n\n\n\n\nAfter that, each task \nn\n in the \u201c\nparameter synchronization\n\u201d job \nbroadcasts\n the n\nth\n partition of the updated weights; consequently, tasks in the \u201c\nmodel forward-backward\n\u201d job in the next iteration can read the latest value of all the weights before the next training step begins.\n\n\n\n\n\n\nThe \nshuffle\n and \ntask-side broadcast\n operations described above are implemented on top of the distributed \nin-memory\n storage in Spark: both the shuffled gradients and broadcasted weights are materialized in memory, which can be read remotely by the Spark tasks with extremely low latency.\n\n\n\n\n\n\nBy implementing the AllReduce operation using primitives in Spark, BigDL provides a highly efficient \u201cparameter server\u201d style architecture directly on top of Big Data frameworks. As a result, it is demonstrated to support highly scalable distributed training on up to 256-node, as reported by Cray [35] and shown in Figure 7. \n\n\n \n\n\nFigure 7. Throughput of ImageNet Inception v1 training reported by Cary [35] (using BigDL 0.3.0 and dual-socket Intel Broadwell 2.1 GHz); the training throughput scales almost linear up to 128 nodes (and continue to scale reasonably up to 256 nodes).\n\n\n3.3. Task scheduling\n\n\nWhile BigDL provides a highly efficient \u201cparameter server\u201d style architecture, it has a fundamentally different implementation than existing deep learning frameworks. In particular, existing deep learning frameworks are typically deployed as multiple long-running, potentially stateful tasks [3], which interact with each other (in a blocking fashion to support synchronous mini-batch SGD) for model computation and/or parameter synchronization.\n\n\nIn contrast, BigDL runs a series of short-lived Spark jobs (e.g., two jobs per mini-batch as described in earlier sections), and each task in the job is stateless and non-blocking. As a result, BigDL programs can automatically adapt to the dynamic resource changes (e.g., preemption, failures, incremental scaling, resource sharing, etc.) in a timely fashion. On the other hand, task scheduling in Spark can become a potential bottleneck of the distributed training on a large cluster. For instance, Figure 8 shows that, for ImageNet Inception v1 training, the overhead of launching tasks (as a fraction of average compute time) in BigDL, while low for 100~200 tasks, can grows to over 10% when there are close to 500 tasks [37]. To address this issue, BigDL will launch a single, multi-threaded task on each worker, so as to achieve high scalability (e.g., up to 256 servers as shown in Figure 7 above). \n\n\nTo scale to an even larger number (e.g., 500) of workers, one can potentially leverages the iterative nature of the model training (in which the same operations are executed repeatedly). For instance, group scheduling introduced by Drizzle [36] (a low latency execution engine for Spark) can help schedule multiple iterations (or a group) of computations at once, so as to greatly reduce scheduling overheads even if there are a large number of tasks, as benchmarked by RISELab [37] and shown in Figure 8.\n\n\n \n\n\nFigure 8. Overheads of task scheduling and dispatch (as a fraction of average compute time) for ImageNet Inception v1 training in BigDL [37].\n\n\n3.4. Model quantization\n\n\nQuantization refers to using technologies that store numbers and perform calculations on them in more compact and lower precision form (than their original format such as 32-bit floating point). BigDL takes advantage of this type of low precision computing to quantize existing models (which can be pre-trained by various frameworks such as Caffe, Keras, TensorFlow, Torch or BigDL) for optimized inference.\n\n\nBigDL first loads existing models and then quantizes the parameters of some selected layers (e.g., Spatial Convolution) into 8-bit integer (using the equation shown in Figure 9) to produce a quantized model. During model inference, each quantized layer quantizes the input (float32) data into 8-bit integer on the fly, applies the 8-bit calculations (such as GEMM) using the quantized parameters and data, and dequantizes the results to 32-bit floating point. Many of these operations can be fused in the implementation, and consequently the quantization and dequantization overheads are very low at inference time.\n\n\nMath.round(1.0 * value \n           / Math.max(Math.abs(max), Math.abs(min)) \n           * Byte.MaxValue).toByte\n\n\n\n\nFigure 9. Equation for quantizing 32-bit floating point to 8-bit integer.\n\n\nUnlike many existing quantization implementations, BigDL adopts a new local quantization scheme. That is, it performs the quantization and dequantization operations (as described above) in each small local quantization window, a small sub-block (such as a patch or kernel in convolution) of the parameters or input data. As a result, BigDL can use very low bit integers, such as 8-bit, in model quantization with extremely low model accuracy drop (less than 0.1%), 4x model size reduction, and up to 2x inference speedup, as benchmarked on AWS EC2 [38] and shown in Figure 10.\n\n\n\n\nFigure 10. Model quantization results (accuracy, inference speed and model size) for SSD, VGG16 and VGG19 (using BigDL 0.3.0 and AWS EC2 C5.18xlarge instances) [38].\n\n\n3.5. Local execution\n\n\nIn addition to being a standard Spark program, BigDL also provide support to run the model training and inference on a local JVM (without Spark). This helps improve the efficiency when running BigDL on a single node, as there are no overheads such as parameter synchronizations or task scheduling. More importantly, it makes it easy to directly integrate BigDL models (for either inference or fine-tuning) with various big data frameworks, such as Apache Storm, Apache Flink or Apache Kafka, which are usually JVM based.\n\n\n4. Applications\n\n\nSince its initial open source release (on Dec 30, 2016), BigDL users have built many deep learning applications on Spark and Big Data platforms. In this section, we describes two typical use cases for both model inference and training using BigDL.\n\n\n4.1. Image feature extraction\n\n\nJD.com [39] is one of the largest online retailers in the world. It has built an end-to-end \nobject detection and image feature extraction\n pipeline [40] on top of BigDL and Spark, as illustrated in Figure 11.\n\n\n \n\n\nFigure 11. End-to-end object detection and image feature extraction pipeline (using SSD and DeepBit models) on top of Spark and BigDL [40].\n\n\n\n\n\n\nThe pipeline first reads hundreds of millions of pictures from a distributed database into Spark (as an RDD of pictures), and then pre-processes the RDD of pictures (including \nresizing\n, \nnormalization\n, and \nbatching\n) in a distributed fashion using Spark.\n\n\n\n\n\n\nAfter that, it uses BigDL to load a \nSSD\n [41] model (pre-trained in Caffe) for large scale, distributed object detection on Spark, which generates the coordinates and scores for the detected objects in each of the pictures.\n\n\n\n\n\n\nIt then generates the target images (by keeping the object with highest score as the target, and cropping the original picture based on the coordinates of the target), and further pre-processes the RDD of target images (including \nresizing\n and \nbatching\n).\n\n\n\n\n\n\nFinally it uses BigDL to load a \nDeepBit\n [42] model (again pre-trained in Caffe) for distributed feature extraction of the target images to generate the corresponding features, and stores the results (RDD of extracted object features) in the Hadoop Distributed File System (HDFS).\n\n\n\n\n\n\nThe entire data analytics and deep learning pipeline, including data loading, partitioning, preprocessing, model inference, and storing the results, can be easily implemented under a unified programming paradigm (using Spark and BigDL). In addition, the end-to-end pipeline also delivers ~3.83x speedup compared to running the same solution on a GPU cluster, as reported by JD [40] and shown in Figure 12.\n\n\n \n\n\nFigure 12. Throughput of GPU clusters and Xeon clusters for the image feature extraction pipeline benchmarked by JD [40]; the GPU throughput is tested on 20 NVIDIA Tesla K40 cards, and the Xeon throughput is tested on 1200 logical cores (where each dual-socket Intel Xeon E5-2650 v4 server runs 50 logical cores).\n\n\n4.2. Precipitation Nowcasting\n\n\nCray has integrated BigDL to their Urika-XC analytics software suite, and built an end-to-end precipitation nowcasting (\npredicting short-term precipitation\n) workflow [35] on spark and BigDL, including data preparation, model training and inference, as illustrated in Figure 13. \n\n\n \n\n\nFigure 13. End-to-end precipitation nowcasting workflow (using sequence-to-sequence model) [35] on Spark and BigDL.\n\n\n\n\n\n\nThe application first reads over a terabyte of raw radar scan data into Spark (as an RDD of radar images), and then converts it into an RDD of \nNumPy ndarrays\n.\n\n\n\n\n\n\nIt then trains a \nsequence-to-sequence\n model [43][44] (as illustrated in Figure 13), using a sequence of images leading up to the current time as the input, and a sequence of predicted images arbitrarily far in the future as the output.\n\n\n\n\n\n\nAfter the model is trained, it can be used to predict, say, precipitation patterns for the next hour, as illustrated in Figure 14.\n\n\n\n\n\n\n \n\n\nFigure 14. Predicting precipitation patterns for the next hour [35] on Spark and BigDL (i.e., a sequence of images for the future time steps of the next hour).\n\n\n5. Summary\n\n\nWe have described BigDL, including its programming model, execution model and typical use cases. It combines the benefits of big data and HPC (high performance computing) architecture, so as to provide both an expressive, \u201cdata-analytics integrated\u201d deep learning programing model for users to build their analytics + AI pipelines, and a highly efficient \u201cparameter server\u201d style architecture directly on top of Big Data platforms for scalable data-parallel training. \n\n\nBigDL is a work in progress, but our initial experience is encouraging. Since its initial open source release (on Dec 30, 2016), it has received over 2300 stars on Github; and it have enabled many users to build new analytics and deep learning applications, which can directly run on top of existing Hadoop and/or Spark clusters.\n\n\n6. Acknowledgement\n\n\nWe gratefully acknowledge contributions from our (current and former) colleagues at Intel (including Jun Wang, Liangying Lv, Andy Chen, Sergey Ermolin, Zewei Chen, Ning Wang, Yulia Tell, Pengfei Yue, Wesley Du, Erjin Ren, Xiao Dong Wang, Radhika Rangarajan, Jack Chen, Milind Damle and Dave Nielsen), and numerous users and collaborators from the open source community (including Shivaram Venkataraman, Zhenhua Wang, Alex Heye, Omid Khanmohamadi, Mike Ringenburg, Gopi Kumar, Xiao Xu, Suqiang Song, etc.) to the BigDL project.\n\n\n7. Reference\n\n\n[1] Caffe. \nhttp://caffe.berkeleyvision.org\n\n\n[2] Torch. \nhttp://torch.ch\n\n\n[3] Mart\u00edn Abadi, et al. \u201cTensorFlow: A System for Large-Scale Machine Learning\u201d, OSDI 2016.\n\n\n[4] Tianqi Chen, et al. \u201cMXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems\u201d, LearningSys 2015.\n\n\n[5] Seiya Tokui, et al. \u201cChainer: a Next-Generation Open Source Framework for Deep Learning\u201d. LearningSys 2015.\n\n\n[6] Apache Hadoop. \nhttp://hadoop.apache.org\n\n\n[7] Apache Spark. \nhttps://spark.apache.org\n\n\n[8] Matei Zaharia , et al. \u201cResilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing\u201d, NSDI 2012.\n\n\n[9] Priya Goyal, et al. \u201cAccurate, Large Minibatch SGD: Training ImageNet in 1 Hour\u201d, arXiv: 1706.02677 [cs.CV]\n\n\n[10] Yang You, et al. \u201cImageNet Training in Minutes\u201d, arXiv:1709.05011 [cs.CV]\n\n\n[11] BigDL. \nhttps://github.com/intel-analytics/BigDL/\n\n\n[12] Keras. \nhttps://keras.io\n\n\n[13] Michael Armbrust, et al. \u201cSpark SQL: Relational Data Processing in Spark\u201d, SIGMOD 2015.\n\n\n[14] Matei Zaharia, et al. \u201cDiscretized Streams: Fault-Tolerant Streaming Computation at Scale\u201d, SOSP 2013.\n\n\n[15] Xiangrui Meng, et al. \u201cMLlib: Machine Learning in Apache Spark\u201d, Journal of Machine Learning Research (JMLR) 2016.\n\n\n[16] Reynold S. Xin, et al. \u201cGraphX: Unifying Data-Parallel and Graph-Parallel Analytics\u201d, OSDI 2014.\n\n\n[17] Apache Storm. \nhttp://storm.apache.org\n\n\n[18] Apache Flink. \nhttps://flink.apache.org\n\n\n[19] Apache Kafka. \nhttps://kafka.apache.org\n\n\n[20] Konstantin Shvachko, et al. \u201cThe Hadoop Distributed File System\u201d, MSST 2010.\n\n\n[21] Jeffrey Pennington, et al. \u201cGloVe: Global Vectors for Word Representation\u201d, EMNLP 2014.\n\n\n[22] Numpy. \nhttp://www.numpy.org\n\n\n[23] Torch7. \nhttps://github.com/torch/torch7\n\n\n[24] J. Duchi, et al. \u201cAdaptive subgradient methods for online learning and stochastic optimization.\u201d Journal of Machine Learning Research (JMLR) 2011.\n\n\n[25] Diederik P. Kingma, et al. \u201cAdam: A Method for Stochastic Optimization\u201d, ICLR 2015.\n\n\n[26] Reynold Xin, et al. \u201cShark: SQL and Rich Analytics at Scale\u201d, SIGMOD 2013.\n\n\n[27] SciKit-Learn. \nhttp://scikit-learn.org/stable/\n\n\n[28] Jeffrey Dean, et al. \u201cMapReduce: simplified data processing on large clusters\u201d, OSDI 2014.\n\n\n[29] J. Chen, et al. \u201cRevisiting distributed synchronous SGD\u201d, ICLR Workshop 2016.\n\n\n[30] H. Cui, et al. \u201cGeePS: Scalable deep learning on distributed GPUs with a GPU specialized parameter server\u201d, EuroSys 2016.\n\n\n[31] J. Dean, et al. \u201cLarge scale distributed deep networks\u201d, NIPS 2012.\n\n\n[32] T. Chilimbi, et al. \u201cProject Adam: Building an efficient and scalable deep learning training system\u201d, OSDI 2014.\n\n\n[33] M. Li, et al. \u201cScaling distributed machine learning with the Parameter Server\u201d, OSDI 2014.\n\n\n[34] Andrew Gibiansky. \nBringing HPC Techniques to Deep Learning\n\n\n[35] Alex Heye, et al. \nScalable Deep Learning with BigDL on the Urika-XC Software Suite\n\n\n[36] Shivaram Venkataraman, et al. \u201cDrizzle: Fast and Adaptable Stream Processing at Scale\u201d, SOSP 2017.\n\n\n[37] Shivaram Venkataraman, et al. \nAccelerating Deep Learning Training with BigDL and Drizzle on Apache Spark\n\n\n[38] Jason (Jinquan) Dai, et al. \nLeveraging Low Precision and Quantization for Deep Learning Using the Amazon EC2 C5 Instance and BigDL\n\n\n[39] JD. \nhttps://en.wikipedia.org/wiki/JD.com\n\n\n[40] Jason (Jinquan) Dai, et al. \nBuilding Large-Scale Image Feature Extraction with BigDL at JD.com\n\n\n[41] Wei Liu, et al. \u201cSSD: Single Shot MultiBox Detector\u201d, ECCV 2016.\n\n\n[42] Kevin Lin, et al. \u201cLearning Compact Binary Descriptors with Unsupervised Deep Neural Networks\u201d, CVPR 2016.\n\n\n[43] I. Sutskever, et al. \u201cSequence to sequence learning with neural networks\u201d, NIPS 2014. \n\n\n[44] Xingjian Shi, et al. \u201cConvolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting\u201d, NIPS 2015.", 
            "title": "White Paper"
        }, 
        {
            "location": "/whitepaper/#bigdl-a-distributed-deep-learning-framework-for-big-data", 
            "text": "Jason (Jinquan) Dai 1 , Yiheng Wang 1 , Xin Qiu 1 , Ding Ding 1 , Yao Zhang 2 \u01c2 , Yanzhang Wang 1 , Xianyan Jia 2 \u01c2 , Cherry (Li) Zhang 1 , Yan Wan 3 \u01c2 , Zhichao Li 1 , Jiao Wang 1 , Shengsheng Huang 1 , Zhongyuan Wu 1 , Yang Wang 1 , Yuhao Yang 1 , Bowen She 1 , Dongjie Shi 1 , Qi Lu 1 , Kai Huang 1 , Guoqiong Song 1  1 Intel Corporation,     2 Tencent Inc.,     3 Alibaba Group  \u01c2 Work was done when the author worked at Intel", 
            "title": "BigDL: A Distributed Deep Learning Framework for Big Data"
        }, 
        {
            "location": "/whitepaper/#abstract", 
            "text": "In this paper, we present BigDL, a distributed deep learning framework for Big Data platforms and workflows. It is implemented on top of Apache Spark, and allows users to write their deep learning applications as standard Spark programs (running directly on large-scale big data clusters in a distributed fashion). It provides an expressive, \u201cdata-analytics integrated\u201d deep learning programming model, so that users can easily build the end-to-end analytics + AI pipelines under a unified programing paradigm; by implementing an  AllReduce  like operation using existing primitives in Spark (e.g., shuffle, broadcast, and in-memory data persistence), it also provides a highly efficient \u201cparameter server\u201d style architecture, so as to achieve highly scalable, data-parallel distributed training. Since its initial open source release, BigDL users have built many analytics and deep learning applications (e.g., object detection, sequence-to-sequence generation, neural recommendations, fraud detection, etc.) on Spark.", 
            "title": "Abstract"
        }, 
        {
            "location": "/whitepaper/#1-introduction", 
            "text": "Recent breakthroughs in artificial intelligence have brought deep learning to the forefront of new generations of data analytics; as the requirements and usage models expand, new systems and architecture beyond existing deep learning frameworks (e.g., Caffe [1], Torch [2], TensorFlow [3], MXNet [4], Chainer [5], etc.) have inevitably emerged. In particular, there is increasing demand from organizations to apply deep learning technologies (such as computer vision, natural language processing, generative adversary networks, etc.) to their big data platforms and pipelines. This emerging convergence of deep learning and big data analytics is driven by several important technology and industry trends:    Data scale drives deep learning process.  Today users are building even deeper, more complex neural networks to take advantage of the massive amount of data that they have access to. In practice, big data (e.g., Apache Hadoop [6] or Apache Spark [7]) clusters are ubiquitously deployed as the global data platform, where all the production data are stored and made available to all the users. Therefore, it is usually much more efficient to run the algorithm directly on the big data cluster where the data are stored and shared (than copying data to a separate infrastructure).    Real-world deep learning applications are complex big data pipelines,  which require a lot of data processing (such as cleaning, transformation, augmentation, feature extraction, etc.) beyond model training/inference. Therefore, it is much simpler and more efficient (for development and workflow management) to seamlessly integrate deep learning functionalities into existing big data workflow running on the same infrastructure, especially given the recent improvements that reduce deep learning training time from weeks to hours [9] or even minutes [10].    Deep learning is increasingly adopted by the big data and data science community.  Unfortunately, mainstream data engineers and data scientists are usually not deep learning experts; as the usages of deep learning expand and scale to larger deployment, it will be much more easier if these users can continue the use of familiar software tools and programming models (e.g., Spark [8] or even SQL) and existing big data cluster infrastructures to build their deep learning applications.    We have developed  BigDL  [11], a distributed deep learning framework for big data platforms and workflows. It is implemented as a library on top of Apache Spark, and allows users to write their large-scale deep learning applications (including model training, fine-tuning and inference) as standard Spark programs, which can run directly on existing big data (Hadoop or Spark) clusters. BigDL provides comprehensive support of deep learning technologies (neural network operations, layers, losses and optimizers); in particular, users can directly run existing models defined in other frameworks (such as TensorFlow, Keras [12], Caffe and Torch) on Spark in a distributed fashion.  BigDL also provides seamless integrations of deep learning technologies into the big data ecosystem. Not only can a BigDL program directly interact with different components in the Spark framework (e.g., DataFrames [13], Spark Streaming [14], ML Pipelines [15], etc.), it can also directly run in a variety of big data frameworks (such as Apache Storm [17], Apache Flink [18], Apache Kafka [19], etc.). Since its initial open source on Dec 30, 2016, BigDL has enabled many community users to build their deep learning applications (e.g., object detection, sequence-to-sequence generation, neural recommendations, fraud detection, etc.) on Spark and big data platforms.", 
            "title": "1. Introduction"
        }, 
        {
            "location": "/whitepaper/#2-programming-model", 
            "text": "BigDL is implemented on Apache Spark, a widely used cluster computing engine for big data analysis. Spark provides a comprehensive set of libraries for relational processing, streaming, graph processing [16] and machine learning (in Python, Scala or Java); as a result, one can easily build the end-to-end, \u201cdata-analytics integrated\u201d deep learning and AI pipelines (under a unified programing paradigm) using Spark and BigDL, as illustrated in Figure 1.  1    spark = SparkContext(appName= text_classifier , \u2026)\n2    //load input data: (text, label) pairs\n3    texts_rdd = spark.textFile( hdfs://... )\n4    //convert text to list of words\n5    words_rdd = texts_rdd.map(lambda text, label: \n6                               ([w for w in to_words(text)], label))\n7    //load GloVe embedding\n8    w2v = news20.get_glove_w2v(dim=\u2026)\n9    //convert word list to list of vertors using GloVe embeddings\n10   vector_rdd = words_rdd.map(lambda word_list, label:\n11                              ([to_vec(w, w2v) for w in word_list], label))\n12   //convert (list of vertors, label) pair to Sample\n13   sample_rdd = vector_rdd.map(lambda vector_list, label: \n14                                 to_sample(vector_list, label))\n15   //construct neural network model  \n16   model = Sequential().add(Recurrent().add(LSTM(\u2026)))\n17                       .add(Linear(\u2026))\n18                       .add(LogSoftMax())\n19   //train the model \n20   loss = ClassNLLCriterion()\n21   optim_method = Adagrad()\n22   optimizer = Optimizer(model=model, training_rdd=sample_rdd, \n23                         criterion=loss, optim_method= optim_method, \u2026)\n24   trained_model =optimizer.optimize()\n25   //model prediction\n26   test_rdd = \u2026\n27   prediction_rdd = trained_model.predict(test_rdd)  Figure 1. The end-to-end text classification pipeline (including data loading, tokenization, word vectorization, training, prediction, etc.) on Spark and BigDL.", 
            "title": "2. Programming Model"
        }, 
        {
            "location": "/whitepaper/#21-spark", 
            "text": "Spark provides the  Resilient Distributed Dataset  (RDD) [8] in-memory storage abstraction, which is an immutable collection of Python or Scala/Java objects partitioned across a cluster, and can be transformed to derive new RDDs through data-parallel functional operators like  map, filter and reduce.  Consequently, users can efficiently load very large dataset and process the loaded data in a distributed fashion using Spark, and then feed the processed data into the analytics and AI pipeline. For example, lines 1 ~ 6 in Figure 1 illustrates how to load the input data (article texts and their associated labels) from the Hadoop Distributed File System (HDFS) [20], and transforms each text string into a list of words.", 
            "title": "2.1. Spark"
        }, 
        {
            "location": "/whitepaper/#22-data-transformation", 
            "text": "Spark supports general dataflow DAGs [8] by composing multiple data-parallel operators on RDD, where each vertex represents an RDD and each edge represents the transformation by the RDD operator. By constructing the dataflow DAG in Spark, users can easily transform the input data (for, e.g., image augmentations, word vectorizations, etc.), which can then be used by the neural network models. For example, lines 7 ~ 11 in Figure 1 illustrates how to apply GloVe word embedding [21] to transform each word to a vector.     N-dimensional array:  In BigDL, we model the basic data elements used in neural network computations as N-dimensional numeric (int8, float32, etc.) arrays. These arrays are represented by  numpy.ndarry  [22] and  BigDL.Tensor  (similar to  Torch.Tensor  [23]) for BigDL Python and Scala/Java APIs respectively.    Sample:  Each record used in BigDL model training and prediction is modelled as a Sample, which contains an input feature and an optional label. Each input feature is one or more N-dimensional arrays, while each label is either a scalar (float32) value, or one or more  N-dimensional arrays.  For instance, lines 12 ~ 14 in Figure 1 shows how to turn the transformed data into an RDD of  Samples,  which will later be used by BigDL model training.", 
            "title": "2.2. Data transformation"
        }, 
        {
            "location": "/whitepaper/#23-model-construction", 
            "text": "Similar to Torch and Keras, BigDL uses a dataflow representation for the neural network model, where each vertex in the dataflow graph represents a neural network layer (such as  ReLu, Spatial Convolution and LSTM ). BigDL then uses the semantics of the layers for model evaluation ( forward ) and gradient computation ( backward ). For example, lines 15 ~ 18 in Figure 1 illustrates the model definition used in the text classification example.", 
            "title": "2.3. Model Construction"
        }, 
        {
            "location": "/whitepaper/#24-model-training", 
            "text": "The transformed input data (RDD of Samples) and the constructed model can then be passed over to the  Optimizer  in BigDL, which automatically performs distributed model training across the cluster, as illustrated by lines 19 ~ 24 in  Figure 1.   Optimizer:  In BigDL, the distributed training process is modelled by an Optimizer abstraction, which runs iterative Spark jobs to minimize the loss (as defined by the user specified Criterion) using specific optimization method (such as  SGD, AdaGrad [24], Adam [25], etc. ).", 
            "title": "2.4. Model training"
        }, 
        {
            "location": "/whitepaper/#25-model-inference", 
            "text": "BigDL also allows users to directly use existing models (pre-trained by Caffe, Keras, TensorFlow, Torch or BigDL) in Spark, so as to directly perform model prediction in a distributed fashion (using RDD transformations), as illustrated by lines 25 ~ 27 in Figure 1.    ModelBroadcast:  BigDL provides the  ModelBroadcast  abstraction to manage the deployment of the pre-trained model across the cluster in a Spark job; the model prediction operation ( predict ) in BigDL uses  ModelBroadcast  to cache a single copy of the model on each machine (by leveraging the  broadcast  [26] mechanism in Spark), and manage the model cloning and weight sharing among different tasks in the same machine.", 
            "title": "2.5. Model Inference"
        }, 
        {
            "location": "/whitepaper/#26-spark-dataframe-and-ml-pipeline", 
            "text": "Besides RDD, Spark provides a high level  DataFrame  abstraction [13], which is a distributed collection of rows with a specific schema (similar to a table in a relational database), and implements data-parallel relational operators like  filter  and  join  for efficient structured data analysis. On top of DataFrame, Spark introduces a high level ML  (machine learning) pipeline  [15] similar to SciKit-Learn [27], which allows users to construct the machine learning workflow as a graph of transformations on data (e.g., feature extraction, normalization, model training, etc.). BigDL also provides native integration with the high level Spark DataFrame and ML Pipeline APIs (using its  DLModel  and  DLEstimator  abstractions).", 
            "title": "2.6. Spark DataFrame and ML Pipeline"
        }, 
        {
            "location": "/whitepaper/#3-execution-model", 
            "text": "Similar to other Big Data systems (such as MapReduce [28]), a Spark cluster consists of a single driver node and multiple worker nodes, as shown in Figure 2.  The driver node is responsible for coordinating the tasks in a Spark job (e.g., scheduling and dispatching), while the worker nodes are responsible for the actual computation and physical data storage. To automatically parallelize the large-scale data processing across the cluster in a fault-tolerant fashion, Spark provides a functional compute model where immutable RDDs are transformed through coarse-grained operators (i.e., applying the same operation to all data items).      Figure 2. A Spark job contains many Spark tasks; the driver node is responsible for scheduling and dispatching the tasks to worker nodes, which runs the actual Spark tasks.  On the other hand, efficient and distributed training of deep neural networks would necessitate very different operations (such as fine-grained data access and in-place data mutation [3]). In this section, we describe in details how BigDL supports highly efficient and scalable distributed training, directly on top of the data parallel and functional compute model of Spark (in addition to various optimizations for model inference).", 
            "title": "3. Execution Model"
        }, 
        {
            "location": "/whitepaper/#31-data-parallel-training", 
            "text": "To train a deep neural network model across the cluster, BigDL provides data-parallel training on Spark using synchronous mini-batch SGD, which is shown to achieve better scalability and efficiency (in terms of time-to-quality) compared to asynchronous training [29][30]. The distributed training in BigDL is implemented as an iterative process, as illustrated in Figure 3; each iteration runs a couple of Spark jobs to first compute the gradients using the current mini-batch, and then make a single update to the parameters of the neural network model.  for (i  - 1 to N) {\n  // model forward-backward  job\n  for each task in the Spark job:\n     read the latest weights\n     get a random batch of data from local sample partition\n     compute errors (forward on local model replica)\n     compute gradients (backward on local model replica)\n  // parameter synchronization  job\n  aggregate (sum) all the gradients\n  update the weights per specified optimization method\n}  Figure 3. BigDL provides efficient, data-parallel, synchronous mini-batch SGD, where each iteration runs two Spark jobs for \u201cmodel forward-backward\u201d and \u201cparameter synchronization\u201d.  As described in Section 2, BigDL models the training data as an RDD of Samples, which are automatically partitioned and potentially cached in memory across the Spark cluster. In addition, to implement the data-parallel training, BigDL also constructs an RDD of models, each of which is a replica of the original neural network model. The model and sample RDDs are co-partitioned and co-located [14] across the cluster, as shown in Figure 4; consequently, in each iteration of the model training, a single \u201cmodel forward-backward\u201d Spark job can apply the functional zip operator to the partitions of model and sample RDDs, and compute the gradients in parallel for each model replica (using a small batch of data in the co-located sample partition), as illustrated in Figure 4.     Figure 4. The \u201cmodel forward-backward\u201d spark job, which computes the local gradients for each model replica in parallel.", 
            "title": "3.1. Data-parallel training"
        }, 
        {
            "location": "/whitepaper/#32-parameter-synchronization", 
            "text": "Parameter synchronization is a performance critical operation for data-parallel training (in terms of speed and scalability). To support efficient parameter synchronization, existing deep learning frameworks usually implement the parameter server [31][32][33] architecture or AllReduce [34] operation, which unfortunately cannot be directly supported by the functional compute model provided by the Big Data systems.\nIn BigDL, we have adapted the primitives available in the Spark (e.g., shuffle, broadcast, in-memory cache, etc.) to implement an efficient AllReduce-like operation, so as to mimic the functionality of a parameter server architecture (as illustrated in Figure 5).     Figure 5. Parameter synchronization in BigDL. Each local gradient (computed by a task in the \u201cmodel forward-backward\u201d job) is evenly divided into N partitions; then each task n in the \u201cparameter synchronization\u201d job aggregates these local gradients and update the weights for the nth partition.    A Spark job has  N  tasks, each of which is assigned a unique Id ranging from  1  to  N  in BigDL. After each task in the \u201c model forward-backward \u201d job computes the local gradients (as described in section 3.1), it evenly divides the local gradients into  N  partitions, as shown in Figure 5.    Next, another \u201c parameter synchronization \u201d job is launched; each task  n  in the \u201c parameter synchronization \u201d job is responsible for managing the n th  partition of the parameters, just like a parameter server (as shown in Figure 6). Specifically, the n th  partition of the gradients (from all the tasks of the previous \u201c model forward-backward \u201d job) are first  shuffled  to task n, which then aggregates (sums) these gradients, and applies the updates to the n th  partition of the weights (using the specific optimization method), as illustrated in Figure 5.    For each task n in the  parameter synchronization  job\n   shuffle the nth partition of all gradients to this task\n   aggregate (sum) the gradients\n   updates the nth partition of the weights\n   broadcast the nth partition of the updated weights  Figure 6. The \u201cparameter synchronization\u201d Spark job, manages the n th  partition of the parameters (similar to a parameter server).    After that, each task  n  in the \u201c parameter synchronization \u201d job  broadcasts  the n th  partition of the updated weights; consequently, tasks in the \u201c model forward-backward \u201d job in the next iteration can read the latest value of all the weights before the next training step begins.    The  shuffle  and  task-side broadcast  operations described above are implemented on top of the distributed  in-memory  storage in Spark: both the shuffled gradients and broadcasted weights are materialized in memory, which can be read remotely by the Spark tasks with extremely low latency.    By implementing the AllReduce operation using primitives in Spark, BigDL provides a highly efficient \u201cparameter server\u201d style architecture directly on top of Big Data frameworks. As a result, it is demonstrated to support highly scalable distributed training on up to 256-node, as reported by Cray [35] and shown in Figure 7.      Figure 7. Throughput of ImageNet Inception v1 training reported by Cary [35] (using BigDL 0.3.0 and dual-socket Intel Broadwell 2.1 GHz); the training throughput scales almost linear up to 128 nodes (and continue to scale reasonably up to 256 nodes).", 
            "title": "3.2. Parameter synchronization"
        }, 
        {
            "location": "/whitepaper/#33-task-scheduling", 
            "text": "While BigDL provides a highly efficient \u201cparameter server\u201d style architecture, it has a fundamentally different implementation than existing deep learning frameworks. In particular, existing deep learning frameworks are typically deployed as multiple long-running, potentially stateful tasks [3], which interact with each other (in a blocking fashion to support synchronous mini-batch SGD) for model computation and/or parameter synchronization.  In contrast, BigDL runs a series of short-lived Spark jobs (e.g., two jobs per mini-batch as described in earlier sections), and each task in the job is stateless and non-blocking. As a result, BigDL programs can automatically adapt to the dynamic resource changes (e.g., preemption, failures, incremental scaling, resource sharing, etc.) in a timely fashion. On the other hand, task scheduling in Spark can become a potential bottleneck of the distributed training on a large cluster. For instance, Figure 8 shows that, for ImageNet Inception v1 training, the overhead of launching tasks (as a fraction of average compute time) in BigDL, while low for 100~200 tasks, can grows to over 10% when there are close to 500 tasks [37]. To address this issue, BigDL will launch a single, multi-threaded task on each worker, so as to achieve high scalability (e.g., up to 256 servers as shown in Figure 7 above).   To scale to an even larger number (e.g., 500) of workers, one can potentially leverages the iterative nature of the model training (in which the same operations are executed repeatedly). For instance, group scheduling introduced by Drizzle [36] (a low latency execution engine for Spark) can help schedule multiple iterations (or a group) of computations at once, so as to greatly reduce scheduling overheads even if there are a large number of tasks, as benchmarked by RISELab [37] and shown in Figure 8.     Figure 8. Overheads of task scheduling and dispatch (as a fraction of average compute time) for ImageNet Inception v1 training in BigDL [37].", 
            "title": "3.3. Task scheduling"
        }, 
        {
            "location": "/whitepaper/#34-model-quantization", 
            "text": "Quantization refers to using technologies that store numbers and perform calculations on them in more compact and lower precision form (than their original format such as 32-bit floating point). BigDL takes advantage of this type of low precision computing to quantize existing models (which can be pre-trained by various frameworks such as Caffe, Keras, TensorFlow, Torch or BigDL) for optimized inference.  BigDL first loads existing models and then quantizes the parameters of some selected layers (e.g., Spatial Convolution) into 8-bit integer (using the equation shown in Figure 9) to produce a quantized model. During model inference, each quantized layer quantizes the input (float32) data into 8-bit integer on the fly, applies the 8-bit calculations (such as GEMM) using the quantized parameters and data, and dequantizes the results to 32-bit floating point. Many of these operations can be fused in the implementation, and consequently the quantization and dequantization overheads are very low at inference time.  Math.round(1.0 * value \n           / Math.max(Math.abs(max), Math.abs(min)) \n           * Byte.MaxValue).toByte  Figure 9. Equation for quantizing 32-bit floating point to 8-bit integer.  Unlike many existing quantization implementations, BigDL adopts a new local quantization scheme. That is, it performs the quantization and dequantization operations (as described above) in each small local quantization window, a small sub-block (such as a patch or kernel in convolution) of the parameters or input data. As a result, BigDL can use very low bit integers, such as 8-bit, in model quantization with extremely low model accuracy drop (less than 0.1%), 4x model size reduction, and up to 2x inference speedup, as benchmarked on AWS EC2 [38] and shown in Figure 10.   Figure 10. Model quantization results (accuracy, inference speed and model size) for SSD, VGG16 and VGG19 (using BigDL 0.3.0 and AWS EC2 C5.18xlarge instances) [38].", 
            "title": "3.4. Model quantization"
        }, 
        {
            "location": "/whitepaper/#35-local-execution", 
            "text": "In addition to being a standard Spark program, BigDL also provide support to run the model training and inference on a local JVM (without Spark). This helps improve the efficiency when running BigDL on a single node, as there are no overheads such as parameter synchronizations or task scheduling. More importantly, it makes it easy to directly integrate BigDL models (for either inference or fine-tuning) with various big data frameworks, such as Apache Storm, Apache Flink or Apache Kafka, which are usually JVM based.", 
            "title": "3.5. Local execution"
        }, 
        {
            "location": "/whitepaper/#4-applications", 
            "text": "Since its initial open source release (on Dec 30, 2016), BigDL users have built many deep learning applications on Spark and Big Data platforms. In this section, we describes two typical use cases for both model inference and training using BigDL.", 
            "title": "4. Applications"
        }, 
        {
            "location": "/whitepaper/#41-image-feature-extraction", 
            "text": "JD.com [39] is one of the largest online retailers in the world. It has built an end-to-end  object detection and image feature extraction  pipeline [40] on top of BigDL and Spark, as illustrated in Figure 11.     Figure 11. End-to-end object detection and image feature extraction pipeline (using SSD and DeepBit models) on top of Spark and BigDL [40].    The pipeline first reads hundreds of millions of pictures from a distributed database into Spark (as an RDD of pictures), and then pre-processes the RDD of pictures (including  resizing ,  normalization , and  batching ) in a distributed fashion using Spark.    After that, it uses BigDL to load a  SSD  [41] model (pre-trained in Caffe) for large scale, distributed object detection on Spark, which generates the coordinates and scores for the detected objects in each of the pictures.    It then generates the target images (by keeping the object with highest score as the target, and cropping the original picture based on the coordinates of the target), and further pre-processes the RDD of target images (including  resizing  and  batching ).    Finally it uses BigDL to load a  DeepBit  [42] model (again pre-trained in Caffe) for distributed feature extraction of the target images to generate the corresponding features, and stores the results (RDD of extracted object features) in the Hadoop Distributed File System (HDFS).    The entire data analytics and deep learning pipeline, including data loading, partitioning, preprocessing, model inference, and storing the results, can be easily implemented under a unified programming paradigm (using Spark and BigDL). In addition, the end-to-end pipeline also delivers ~3.83x speedup compared to running the same solution on a GPU cluster, as reported by JD [40] and shown in Figure 12.     Figure 12. Throughput of GPU clusters and Xeon clusters for the image feature extraction pipeline benchmarked by JD [40]; the GPU throughput is tested on 20 NVIDIA Tesla K40 cards, and the Xeon throughput is tested on 1200 logical cores (where each dual-socket Intel Xeon E5-2650 v4 server runs 50 logical cores).", 
            "title": "4.1. Image feature extraction"
        }, 
        {
            "location": "/whitepaper/#42-precipitation-nowcasting", 
            "text": "Cray has integrated BigDL to their Urika-XC analytics software suite, and built an end-to-end precipitation nowcasting ( predicting short-term precipitation ) workflow [35] on spark and BigDL, including data preparation, model training and inference, as illustrated in Figure 13.      Figure 13. End-to-end precipitation nowcasting workflow (using sequence-to-sequence model) [35] on Spark and BigDL.    The application first reads over a terabyte of raw radar scan data into Spark (as an RDD of radar images), and then converts it into an RDD of  NumPy ndarrays .    It then trains a  sequence-to-sequence  model [43][44] (as illustrated in Figure 13), using a sequence of images leading up to the current time as the input, and a sequence of predicted images arbitrarily far in the future as the output.    After the model is trained, it can be used to predict, say, precipitation patterns for the next hour, as illustrated in Figure 14.       Figure 14. Predicting precipitation patterns for the next hour [35] on Spark and BigDL (i.e., a sequence of images for the future time steps of the next hour).", 
            "title": "4.2. Precipitation Nowcasting"
        }, 
        {
            "location": "/whitepaper/#5-summary", 
            "text": "We have described BigDL, including its programming model, execution model and typical use cases. It combines the benefits of big data and HPC (high performance computing) architecture, so as to provide both an expressive, \u201cdata-analytics integrated\u201d deep learning programing model for users to build their analytics + AI pipelines, and a highly efficient \u201cparameter server\u201d style architecture directly on top of Big Data platforms for scalable data-parallel training.   BigDL is a work in progress, but our initial experience is encouraging. Since its initial open source release (on Dec 30, 2016), it has received over 2300 stars on Github; and it have enabled many users to build new analytics and deep learning applications, which can directly run on top of existing Hadoop and/or Spark clusters.", 
            "title": "5. Summary"
        }, 
        {
            "location": "/whitepaper/#6-acknowledgement", 
            "text": "We gratefully acknowledge contributions from our (current and former) colleagues at Intel (including Jun Wang, Liangying Lv, Andy Chen, Sergey Ermolin, Zewei Chen, Ning Wang, Yulia Tell, Pengfei Yue, Wesley Du, Erjin Ren, Xiao Dong Wang, Radhika Rangarajan, Jack Chen, Milind Damle and Dave Nielsen), and numerous users and collaborators from the open source community (including Shivaram Venkataraman, Zhenhua Wang, Alex Heye, Omid Khanmohamadi, Mike Ringenburg, Gopi Kumar, Xiao Xu, Suqiang Song, etc.) to the BigDL project.", 
            "title": "6. Acknowledgement"
        }, 
        {
            "location": "/whitepaper/#7-reference", 
            "text": "[1] Caffe.  http://caffe.berkeleyvision.org  [2] Torch.  http://torch.ch  [3] Mart\u00edn Abadi, et al. \u201cTensorFlow: A System for Large-Scale Machine Learning\u201d, OSDI 2016.  [4] Tianqi Chen, et al. \u201cMXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems\u201d, LearningSys 2015.  [5] Seiya Tokui, et al. \u201cChainer: a Next-Generation Open Source Framework for Deep Learning\u201d. LearningSys 2015.  [6] Apache Hadoop.  http://hadoop.apache.org  [7] Apache Spark.  https://spark.apache.org  [8] Matei Zaharia , et al. \u201cResilient Distributed Datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing\u201d, NSDI 2012.  [9] Priya Goyal, et al. \u201cAccurate, Large Minibatch SGD: Training ImageNet in 1 Hour\u201d, arXiv: 1706.02677 [cs.CV]  [10] Yang You, et al. \u201cImageNet Training in Minutes\u201d, arXiv:1709.05011 [cs.CV]  [11] BigDL.  https://github.com/intel-analytics/BigDL/  [12] Keras.  https://keras.io  [13] Michael Armbrust, et al. \u201cSpark SQL: Relational Data Processing in Spark\u201d, SIGMOD 2015.  [14] Matei Zaharia, et al. \u201cDiscretized Streams: Fault-Tolerant Streaming Computation at Scale\u201d, SOSP 2013.  [15] Xiangrui Meng, et al. \u201cMLlib: Machine Learning in Apache Spark\u201d, Journal of Machine Learning Research (JMLR) 2016.  [16] Reynold S. Xin, et al. \u201cGraphX: Unifying Data-Parallel and Graph-Parallel Analytics\u201d, OSDI 2014.  [17] Apache Storm.  http://storm.apache.org  [18] Apache Flink.  https://flink.apache.org  [19] Apache Kafka.  https://kafka.apache.org  [20] Konstantin Shvachko, et al. \u201cThe Hadoop Distributed File System\u201d, MSST 2010.  [21] Jeffrey Pennington, et al. \u201cGloVe: Global Vectors for Word Representation\u201d, EMNLP 2014.  [22] Numpy.  http://www.numpy.org  [23] Torch7.  https://github.com/torch/torch7  [24] J. Duchi, et al. \u201cAdaptive subgradient methods for online learning and stochastic optimization.\u201d Journal of Machine Learning Research (JMLR) 2011.  [25] Diederik P. Kingma, et al. \u201cAdam: A Method for Stochastic Optimization\u201d, ICLR 2015.  [26] Reynold Xin, et al. \u201cShark: SQL and Rich Analytics at Scale\u201d, SIGMOD 2013.  [27] SciKit-Learn.  http://scikit-learn.org/stable/  [28] Jeffrey Dean, et al. \u201cMapReduce: simplified data processing on large clusters\u201d, OSDI 2014.  [29] J. Chen, et al. \u201cRevisiting distributed synchronous SGD\u201d, ICLR Workshop 2016.  [30] H. Cui, et al. \u201cGeePS: Scalable deep learning on distributed GPUs with a GPU specialized parameter server\u201d, EuroSys 2016.  [31] J. Dean, et al. \u201cLarge scale distributed deep networks\u201d, NIPS 2012.  [32] T. Chilimbi, et al. \u201cProject Adam: Building an efficient and scalable deep learning training system\u201d, OSDI 2014.  [33] M. Li, et al. \u201cScaling distributed machine learning with the Parameter Server\u201d, OSDI 2014.  [34] Andrew Gibiansky.  Bringing HPC Techniques to Deep Learning  [35] Alex Heye, et al.  Scalable Deep Learning with BigDL on the Urika-XC Software Suite  [36] Shivaram Venkataraman, et al. \u201cDrizzle: Fast and Adaptable Stream Processing at Scale\u201d, SOSP 2017.  [37] Shivaram Venkataraman, et al.  Accelerating Deep Learning Training with BigDL and Drizzle on Apache Spark  [38] Jason (Jinquan) Dai, et al.  Leveraging Low Precision and Quantization for Deep Learning Using the Amazon EC2 C5 Instance and BigDL  [39] JD.  https://en.wikipedia.org/wiki/JD.com  [40] Jason (Jinquan) Dai, et al.  Building Large-Scale Image Feature Extraction with BigDL at JD.com  [41] Wei Liu, et al. \u201cSSD: Single Shot MultiBox Detector\u201d, ECCV 2016.  [42] Kevin Lin, et al. \u201cLearning Compact Binary Descriptors with Unsupervised Deep Neural Networks\u201d, CVPR 2016.  [43] I. Sutskever, et al. \u201cSequence to sequence learning with neural networks\u201d, NIPS 2014.   [44] Xingjian Shi, et al. \u201cConvolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting\u201d, NIPS 2015.", 
            "title": "7. Reference"
        }, 
        {
            "location": "/release-download/", 
            "text": "These are built BigDL packages including dependency and Python files. You can download these packages instead of building them by yourself. This is useful when you want to do something like run some examples or develop Python code.\n\n\n\n\nRemark\n\n\n\n\nOnly \nPython 2.7\n, \nPython 3.5\n and \nPython 3.6\n are supported for now.\n\n\nNote that \nPython 3.6\n is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and 2.2.0. See \nthis issue\n for more discussion.\n\n\n\n\n\n\nRelease 0.5.0\n\n\n\n\n\n\n\n\n\n\nDownload Link (for Linux x64, Mac and Win64)\n\n\n\n\n\n\n\n\n\n\nSpark 1.5.2\n\n\ndownload\n\n\n\n\n\n\nSpark 1.6.2\n\n\ndownload\n\n\n\n\n\n\nSpark 2.1.1\n\n\ndownload\n\n\n\n\n\n\nSpark 2.2.0\n\n\ndownload\n\n\n\n\n\n\n\n\n\n\nRelease 0.4.0\n\n\n\n\n\n\n\n\n\n\nDownload Link (for Linux x64, Mac and Win64)\n\n\n\n\n\n\n\n\n\n\nSpark 1.5.2\n\n\ndownload\n\n\n\n\n\n\nSpark 1.6.2\n\n\ndownload\n\n\n\n\n\n\nSpark 2.1.1\n\n\ndownload\n\n\n\n\n\n\nSpark 2.2.0\n\n\ndownload\n\n\n\n\n\n\n\n\n\n\nRelease 0.3.0\n\n\n\n\n\n\n\n\n\n\nDownload Link (for Linux x64, Mac and Win64)\n\n\n\n\n\n\n\n\n\n\nSpark 1.5.2\n\n\ndownload\n\n\n\n\n\n\nSpark 1.6.2\n\n\ndownload\n\n\n\n\n\n\nSpark 2.1.1\n\n\ndownload\n\n\n\n\n\n\nSpark 2.2.0\n\n\ndownload\n\n\n\n\n\n\n\n\n\n\nRelease 0.2.0\n\n\n\n\n\n\n\n\n\n\nLinux x64\n\n\nMac\n\n\nWin64\n\n\n\n\n\n\n\n\n\n\nSpark 1.5.2\n\n\ndownload\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 1.6.2\n\n\ndownload\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 2.0.2\n\n\ndownload\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 2.1.1\n\n\ndownload\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\n\n\n\n\nRelease 0.1.1\n\n\n\n\n\n\n\n\n\n\nLinux x64\n\n\nMac\n\n\n\n\n\n\n\n\n\n\nSpark 1.5.1\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 1.6.0\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 2.0.0\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 2.1.0\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\n\n\n\n\nRelease 0.1.0\n\n\n\n\n\n\n\n\n\n\nLinux x64\n\n\nMac\n\n\n\n\n\n\n\n\n\n\nSpark 1.5.1\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 1.6.0\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 2.0.0\n\n\ndownload\n\n\ndownload\n\n\n\n\n\n\nSpark 2.1.0\n\n\ndownload\n\n\ndownload", 
            "title": "Download"
        }, 
        {
            "location": "/release-download/#remark", 
            "text": "Only  Python 2.7 ,  Python 3.5  and  Python 3.6  are supported for now.  Note that  Python 3.6  is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and 2.2.0. See  this issue  for more discussion.", 
            "title": "Remark"
        }, 
        {
            "location": "/release-download/#release-050", 
            "text": "Download Link (for Linux x64, Mac and Win64)      Spark 1.5.2  download    Spark 1.6.2  download    Spark 2.1.1  download    Spark 2.2.0  download", 
            "title": "Release 0.5.0"
        }, 
        {
            "location": "/release-download/#release-040", 
            "text": "Download Link (for Linux x64, Mac and Win64)      Spark 1.5.2  download    Spark 1.6.2  download    Spark 2.1.1  download    Spark 2.2.0  download", 
            "title": "Release 0.4.0"
        }, 
        {
            "location": "/release-download/#release-030", 
            "text": "Download Link (for Linux x64, Mac and Win64)      Spark 1.5.2  download    Spark 1.6.2  download    Spark 2.1.1  download    Spark 2.2.0  download", 
            "title": "Release 0.3.0"
        }, 
        {
            "location": "/release-download/#release-020", 
            "text": "Linux x64  Mac  Win64      Spark 1.5.2  download  download  download    Spark 1.6.2  download  download  download    Spark 2.0.2  download  download  download    Spark 2.1.1  download  download  download", 
            "title": "Release 0.2.0"
        }, 
        {
            "location": "/release-download/#release-011", 
            "text": "Linux x64  Mac      Spark 1.5.1  download  download    Spark 1.6.0  download  download    Spark 2.0.0  download  download    Spark 2.1.0  download  download", 
            "title": "Release 0.1.1"
        }, 
        {
            "location": "/release-download/#release-010", 
            "text": "Linux x64  Mac      Spark 1.5.1  download  download    Spark 1.6.0  download  download    Spark 2.0.0  download  download    Spark 2.1.0  download  download", 
            "title": "Release 0.1.0"
        }, 
        {
            "location": "/release-docs/", 
            "text": "Release 0.5.0\n\n\nBigDL 0.5.0 Docs\n\n\n\n\nRelease 0.4.0\n\n\nBigDL 0.4.0 Docs\n\n\n\n\nRelease 0.3.0\n\n\nBigDL 0.3.0 Docs\n\n\n\n\nRelease 0.2.0\n\n\nBigDL 0.2.0 Docs\n\n\n\n\nRelease 0.1.1\n\n\nBigDL 0.1.1 Docs", 
            "title": "Documentation"
        }, 
        {
            "location": "/release-docs/#release-050", 
            "text": "BigDL 0.5.0 Docs", 
            "title": "Release 0.5.0"
        }, 
        {
            "location": "/release-docs/#release-040", 
            "text": "BigDL 0.4.0 Docs", 
            "title": "Release 0.4.0"
        }, 
        {
            "location": "/release-docs/#release-030", 
            "text": "BigDL 0.3.0 Docs", 
            "title": "Release 0.3.0"
        }, 
        {
            "location": "/release-docs/#release-020", 
            "text": "BigDL 0.2.0 Docs", 
            "title": "Release 0.2.0"
        }, 
        {
            "location": "/release-docs/#release-011", 
            "text": "BigDL 0.1.1 Docs", 
            "title": "Release 0.1.1"
        }, 
        {
            "location": "/getting-started/", 
            "text": "Before using BigDL\n\n\nBefore using BigDL, you need to install Apache Spark and obtain BigDL libraries. Then in your program, you need to ensure the SparkContext is created successfully and initialize BigDL engine before calling BigDL APIs. Navigate to \nScala User Guide/Install\n or \nPython User Guide/Install\n for details about how to install BigDL, and \nScala User Guide/Run\n or \nPython User Guide/Run\n for how to run programs. \n\n\n\n\nPrepare your Data\n\n\nYour data need to be transformed into RDD of \nSample\n in order to be fed into BigDL for training, evaluation and prediction (also refer to \nOptimization\n and \nOptimizer API guide\n). \n\n\nTensor\n, \nTable\n are essential data structures that composes the basic dataflow inside the neural network( e.g. input/output, gradients, weights, etc.). You will need to understand them to get a better idea of layer behaviors. \n\n\n\n\nUse BigDL for Prediction only\n\n\nIf you have an existing model and want to use BigDL only for prediction, you need first load the model, and then do prediction or evaluation. \n\n\nBigDL supports loading models trained and saved in BigDL, or a trained Tensorflow, Caffe or Keras model. \n\n\n\n\nTo load a BigDL model, you can use \nModule.load\n interface (Scala) or \nModel.load\n (in Python). Refer to \nModel Save\n for details.  \n\n\nTo load a Tensorflow model, refer to \nTensorflow Support\n for details.\n\n\nTo load a Caffe model, refer to \nCaffe Support\n for details.\n\n\nTo load a Keras model, refer to \nKeras Support\n for details.\n\n\n\n\nRefer to \nModel Predict\n for details about how to use a model for prediction.\n\n\nIf you are using the trained model as a component inside a Spark ML pipeline, refer to\n\nUsing BigDL in Spark ML Pipeline\n page for usage. \n\n\n\n\nTrain a Model from Scratch\n\n\nThe procedure of training a model from scratch usually involves following steps:\n\n\n\n\ndefine your model (by connecting layers/activations into a network)\n\n\ndecide your loss function (which function to optimize)\n\n\noptimization (choose a proper algorithm and hyper parameters, and train)\n\n\nevaluation (evaluate your model) \n\n\n\n\nBefore training models, please make sure BigDL is installed, BigDL engine initialized properly, and your data is in proper format. Refer to \nBefore using BigDL\n and \nPrepare Your Data\n for details.  \n\n\nThe most recommended way to create your first model is to modify from an existing one. BigDL provides plenty of models for you to refer to. See \nScala Models/Examples\n and \nPython Models/Examples and Tutorials\n. \n\n\nTo define a model, you can either use the Sequential API or Functional API. The Functional API is more flexible than Sequential API. Refer to \nSequential API\n and \nFunctional API\n for how to define models in different shapes. Navigate to \nAPI Guide/Layers\n on the side bar to find the documenations of available layers and activation.\n\n\nAfter creating the model, you will have to decide which loss function to use in training. Find the details of losses defined in BigDL in \nLosses\n.  \n\n\nNow you create an \nOptimizer\n and set the loss function, input dataset along with other hyper parameters into the Optimizer. Then call \nOptimizer.optimize\n to train. Refer to \nOptimization\n and \nOptimizer API guide\n for details. \n\n\nModel Evaluation can be performed periodically during a training. Refer to \nValidate your Model in Training\n for details.  For a list of defined metrics, refer to \nMetrics\n.\n\n\nWhen \nOptimizer.optimize\n finishes, it will return a trained model. You can then use the trained model for prediction or evaluation. Refer to \nModel Prediction\n and \nModel Evaluation\n for detailed usage.    \n\n\nIf you prefer to train a model inside a Spark ML pipeline, please refer to  \nUsing BigDL in Spark ML Pipeline\n page for usage.\n\n\n\n\nSave a Model\n\n\nWhen training is finished, you may need to save the final model for later use. \n\n\nBigDL allows you to save your BigDL model on local filesystem, HDFS, or Amazon s3 (refer to \nModel Save\n). \n\n\nYou may also save the model to Tensorflow or Caffe format (refer to \nCaffe Support\n, and \nTensorflow Support\n respectively).  \n\n\n\n\nStop and Resume a Training\n\n\nTraining a deep learning model sometimes takes a very long time. It may be stopped or interrupted and we need the training to resume from where we have left. \n\n\nTo enable this, you have to configure \nOptimizer\n to periodically take snapshots of the model (trained weights, biases, etc.) and optim-method (configurations and states of the optimization) and dump them into files. Refer to \nCheckpointing\n for details. \n\n\nTo resume a training after it stops, refer to \nResume Training\n.\n\n\n\n\nUse Pre-trained Models/Layers\n\n\nPre-train is a useful strategy when training deep learning models. You may use the pre-trained features (e.g. embeddings) in your model, or do a fine-tuning for a different dataset or target.\n\n\nTo use a learnt model as a whole, you can use \nModule.load\n to load the entire model, Then create an \nOptimizer\n with the loaded model set into it. Refer to \nOptmizer API\n and \nModule API\n for details. \n\n\nInstead of using an entire model, you can also use pre-trained weights/biases in certain layers. After a layer is created, use \nsetWeightsBias\n (in Scala) or \nset_weights\n (in Python) on the layer to initialize the weights with pre-trained weights. Then continue to train your model as usual. \n\n\n\n\nMonitor your training\n\n\nBigDL provides a convenient way to monitor/visualize your training progress. It writes the statistics collected during training/validation and they can be visualized in real-time using tensorboard. These statistics can also be retrieved into readable data structures later and visualized in other tools (e.g. Jupyter notebook). For details, refer to \nVisualization\n. \n\n\n\n\nTuning\n\n\nThere're several strategies that may be useful when tuning an optimization. \n\n\n\n\nChange the learning Rate Schedule in SGD. Refer to \nSGD docs\n for details. \n\n\nIf overfit is seen, try use Regularization. Refer to \nRegularizers\n. \n\n\nTry change the initialization methods. Refer to \nInitailizers\n.\n\n\nTry Adam or Adagrad at the first place. If they can't achieve a good score, use SGD and find a proper learning rate schedule - it usually takes time, though. RMSProp is recommended for RNN models. Refer to \nOptimization Algorithms\n for a list of supported optimization methods.", 
            "title": "Getting Started"
        }, 
        {
            "location": "/getting-started/#before-using-bigdl", 
            "text": "Before using BigDL, you need to install Apache Spark and obtain BigDL libraries. Then in your program, you need to ensure the SparkContext is created successfully and initialize BigDL engine before calling BigDL APIs. Navigate to  Scala User Guide/Install  or  Python User Guide/Install  for details about how to install BigDL, and  Scala User Guide/Run  or  Python User Guide/Run  for how to run programs.", 
            "title": "Before using BigDL"
        }, 
        {
            "location": "/getting-started/#prepare-your-data", 
            "text": "Your data need to be transformed into RDD of  Sample  in order to be fed into BigDL for training, evaluation and prediction (also refer to  Optimization  and  Optimizer API guide ).   Tensor ,  Table  are essential data structures that composes the basic dataflow inside the neural network( e.g. input/output, gradients, weights, etc.). You will need to understand them to get a better idea of layer behaviors.", 
            "title": "Prepare your Data"
        }, 
        {
            "location": "/getting-started/#use-bigdl-for-prediction-only", 
            "text": "If you have an existing model and want to use BigDL only for prediction, you need first load the model, and then do prediction or evaluation.   BigDL supports loading models trained and saved in BigDL, or a trained Tensorflow, Caffe or Keras model.    To load a BigDL model, you can use  Module.load  interface (Scala) or  Model.load  (in Python). Refer to  Model Save  for details.    To load a Tensorflow model, refer to  Tensorflow Support  for details.  To load a Caffe model, refer to  Caffe Support  for details.  To load a Keras model, refer to  Keras Support  for details.   Refer to  Model Predict  for details about how to use a model for prediction.  If you are using the trained model as a component inside a Spark ML pipeline, refer to Using BigDL in Spark ML Pipeline  page for usage.", 
            "title": "Use BigDL for Prediction only"
        }, 
        {
            "location": "/getting-started/#train-a-model-from-scratch", 
            "text": "The procedure of training a model from scratch usually involves following steps:   define your model (by connecting layers/activations into a network)  decide your loss function (which function to optimize)  optimization (choose a proper algorithm and hyper parameters, and train)  evaluation (evaluate your model)    Before training models, please make sure BigDL is installed, BigDL engine initialized properly, and your data is in proper format. Refer to  Before using BigDL  and  Prepare Your Data  for details.    The most recommended way to create your first model is to modify from an existing one. BigDL provides plenty of models for you to refer to. See  Scala Models/Examples  and  Python Models/Examples and Tutorials .   To define a model, you can either use the Sequential API or Functional API. The Functional API is more flexible than Sequential API. Refer to  Sequential API  and  Functional API  for how to define models in different shapes. Navigate to  API Guide/Layers  on the side bar to find the documenations of available layers and activation.  After creating the model, you will have to decide which loss function to use in training. Find the details of losses defined in BigDL in  Losses .    Now you create an  Optimizer  and set the loss function, input dataset along with other hyper parameters into the Optimizer. Then call  Optimizer.optimize  to train. Refer to  Optimization  and  Optimizer API guide  for details.   Model Evaluation can be performed periodically during a training. Refer to  Validate your Model in Training  for details.  For a list of defined metrics, refer to  Metrics .  When  Optimizer.optimize  finishes, it will return a trained model. You can then use the trained model for prediction or evaluation. Refer to  Model Prediction  and  Model Evaluation  for detailed usage.      If you prefer to train a model inside a Spark ML pipeline, please refer to   Using BigDL in Spark ML Pipeline  page for usage.", 
            "title": "Train a Model from Scratch"
        }, 
        {
            "location": "/getting-started/#save-a-model", 
            "text": "When training is finished, you may need to save the final model for later use.   BigDL allows you to save your BigDL model on local filesystem, HDFS, or Amazon s3 (refer to  Model Save ).   You may also save the model to Tensorflow or Caffe format (refer to  Caffe Support , and  Tensorflow Support  respectively).", 
            "title": "Save a Model"
        }, 
        {
            "location": "/getting-started/#stop-and-resume-a-training", 
            "text": "Training a deep learning model sometimes takes a very long time. It may be stopped or interrupted and we need the training to resume from where we have left.   To enable this, you have to configure  Optimizer  to periodically take snapshots of the model (trained weights, biases, etc.) and optim-method (configurations and states of the optimization) and dump them into files. Refer to  Checkpointing  for details.   To resume a training after it stops, refer to  Resume Training .", 
            "title": "Stop and Resume a Training"
        }, 
        {
            "location": "/getting-started/#use-pre-trained-modelslayers", 
            "text": "Pre-train is a useful strategy when training deep learning models. You may use the pre-trained features (e.g. embeddings) in your model, or do a fine-tuning for a different dataset or target.  To use a learnt model as a whole, you can use  Module.load  to load the entire model, Then create an  Optimizer  with the loaded model set into it. Refer to  Optmizer API  and  Module API  for details.   Instead of using an entire model, you can also use pre-trained weights/biases in certain layers. After a layer is created, use  setWeightsBias  (in Scala) or  set_weights  (in Python) on the layer to initialize the weights with pre-trained weights. Then continue to train your model as usual.", 
            "title": "Use Pre-trained Models/Layers"
        }, 
        {
            "location": "/getting-started/#monitor-your-training", 
            "text": "BigDL provides a convenient way to monitor/visualize your training progress. It writes the statistics collected during training/validation and they can be visualized in real-time using tensorboard. These statistics can also be retrieved into readable data structures later and visualized in other tools (e.g. Jupyter notebook). For details, refer to  Visualization .", 
            "title": "Monitor your training"
        }, 
        {
            "location": "/getting-started/#tuning", 
            "text": "There're several strategies that may be useful when tuning an optimization.    Change the learning Rate Schedule in SGD. Refer to  SGD docs  for details.   If overfit is seen, try use Regularization. Refer to  Regularizers .   Try change the initialization methods. Refer to  Initailizers .  Try Adam or Adagrad at the first place. If they can't achieve a good score, use SGD and find a proper learning rate schedule - it usually takes time, though. RMSProp is recommended for RNN models. Refer to  Optimization Algorithms  for a list of supported optimization methods.", 
            "title": "Tuning"
        }, 
        {
            "location": "/ScalaUserGuide/install-pre-built/", 
            "text": "Download a pre-built library\n\n\nYou can download the BigDL release and nightly build from the \nRelease Page\n\n\n\n\nLink with a release version\n\n\nCurrently, BigDL releases are hosted on maven central; here's an example to add the BigDL dependency to your own project:\n\n\ndependency\n\n    \ngroupId\ncom.intel.analytics.bigdl\n/groupId\n\n    \nartifactId\nbigdl-[SPARK_1.5|SPARK_1.6|SPARK_2.1|SPARK_2.2]\n/artifactId\n\n    \nversion\n${BIGDL_VERSION}\n/version\n\n\n/dependency\n\n\n\n\n\nPlease choose the suffix according to your Spark platform.\n\n\nSBT developers can use\n\n\nlibraryDependencies += \ncom.intel.analytics.bigdl\n % \nbigdl-[SPARK_1.5|SPARK_1.6|SPARK_2.1|SPARK_2.2]\n % \n${BIGDL_VERSION}\n\n\n\n\n\nYou can find the optional \n${BIGDL_VERSION}\n from the \nRelease Page\n.\n\n\n\n\nLink with a development version\n\n\nCurrently, BigDL development version is hosted on \nSonaType\n. \n\n\nTo link your application with the latest BigDL development version, you should add some dependencies like \nLinking with BigDL releases\n, but set \n${BIGDL_VERSION}\n to \n0.6.0-SNAPSHOT\n, and add below repository to your pom.xml.\n\n\nrepository\n\n    \nid\nsonatype\n/id\n\n    \nname\nsonatype repository\n/name\n\n    \nurl\nhttps://oss.sonatype.org/content/groups/public/\n/url\n\n    \nreleases\n\n        \nenabled\ntrue\n/enabled\n\n    \n/releases\n\n    \nsnapshots\n\n        \nenabled\ntrue\n/enabled\n\n    \n/snapshots\n\n\n/repository\n\n\n\n\n\nSBT developers can use\n\n\nresolvers += \nSonatype OSS Snapshots\n at \nhttps://oss.sonatype.org/content/repositories/snapshots\n\n\n\n\n\nNote: if you use sbt on branch 0.3 and before, you should add this configuration to \nbuild.sbt\n like below.\n\n\nval repo = \nhttp://repo1.maven.org/maven2\n\ndef mkl_native(os: String): String = {\n    s\n${repo}/com/intel/analytics/bigdl/native/mkl-java-${os}/0.3.0/mkl-java-${os}-0.3.0.jar\n\n}\n\ndef bigquant_native(os: String): String = {\n    s\n${repo}/com/intel/analytics/bigdl/bigquant/bigquant-java-${os}/0.3.0/bigquant-java-${os}-0.3.0.jar\n\n\n}\n\nlibraryDependencies += \ncom.intel.analytics.bigdl\n % \nbigdl-SPARK_2.1\n % \n0.3.0\n exclude(\ncom.intel.analytics.bigdl\n, \nbigdl-core\n)\nlibraryDependencies += \ncom.intel.analytics.bigdl.native\n % \nmkl-java-mac\n % \n0.3.0\n from mkl_native(\nmac\n)\nlibraryDependencies += \ncom.intel.analytics.bigdl.bigquant\n % \nbigquant-java-mac\n % \n0.3.0\n from bigquant_native(\nmac\n)\n\n\n\n\nIf you want to run it on other platforms too, append below,\n\n\n// Linux\nlibraryDependencies += \ncom.intel.analytics.bigdl.native\n % \nmkl-java\n % \n0.3.0\n\nlibraryDependencies += \ncom.intel.analytics.bigdl.bigquant\n % \nbigquant-java\n % \n0.3.0\n\n\n// Windows\nlibraryDependencies += \ncom.intel.analytics.bigdl.native\n % \nmkl-java-win64\n % \n0.3.0\n from mkl_native(\nwin64\n)\nlibraryDependencies += \ncom.intel.analytics.bigdl.bigquant\n % \nbigquant-java-win64\n % \n0.3.0\n from bigquant_native(\nwin64\n)\n\n\n\n\nIf you will assemble all dependencies to a jar. You need to add merge strategy like below.\n\n\nassemblyMergeStrategy in assembly := {\n    case x if x.contains(\ncom/intel/analytics/bigdl/bigquant/\n) =\n MergeStrategy.first\n    case x if x.contains(\ncom/intel/analytics/bigdl/mkl/\n) =\n MergeStrategy.first\n    case x =\n\n      val oldStrategy = (assemblyMergeStrategy in assembly).value\n      oldStrategy(x)\n}", 
            "title": "Use Pre-built Libs"
        }, 
        {
            "location": "/ScalaUserGuide/install-pre-built/#download-a-pre-built-library", 
            "text": "You can download the BigDL release and nightly build from the  Release Page", 
            "title": "Download a pre-built library"
        }, 
        {
            "location": "/ScalaUserGuide/install-pre-built/#link-with-a-release-version", 
            "text": "Currently, BigDL releases are hosted on maven central; here's an example to add the BigDL dependency to your own project:  dependency \n     groupId com.intel.analytics.bigdl /groupId \n     artifactId bigdl-[SPARK_1.5|SPARK_1.6|SPARK_2.1|SPARK_2.2] /artifactId \n     version ${BIGDL_VERSION} /version  /dependency   Please choose the suffix according to your Spark platform.  SBT developers can use  libraryDependencies +=  com.intel.analytics.bigdl  %  bigdl-[SPARK_1.5|SPARK_1.6|SPARK_2.1|SPARK_2.2]  %  ${BIGDL_VERSION}   You can find the optional  ${BIGDL_VERSION}  from the  Release Page .", 
            "title": "Link with a release version"
        }, 
        {
            "location": "/ScalaUserGuide/install-pre-built/#link-with-a-development-version", 
            "text": "Currently, BigDL development version is hosted on  SonaType .   To link your application with the latest BigDL development version, you should add some dependencies like  Linking with BigDL releases , but set  ${BIGDL_VERSION}  to  0.6.0-SNAPSHOT , and add below repository to your pom.xml.  repository \n     id sonatype /id \n     name sonatype repository /name \n     url https://oss.sonatype.org/content/groups/public/ /url \n     releases \n         enabled true /enabled \n     /releases \n     snapshots \n         enabled true /enabled \n     /snapshots  /repository   SBT developers can use  resolvers +=  Sonatype OSS Snapshots  at  https://oss.sonatype.org/content/repositories/snapshots   Note: if you use sbt on branch 0.3 and before, you should add this configuration to  build.sbt  like below.  val repo =  http://repo1.maven.org/maven2 \ndef mkl_native(os: String): String = {\n    s ${repo}/com/intel/analytics/bigdl/native/mkl-java-${os}/0.3.0/mkl-java-${os}-0.3.0.jar \n}\n\ndef bigquant_native(os: String): String = {\n    s ${repo}/com/intel/analytics/bigdl/bigquant/bigquant-java-${os}/0.3.0/bigquant-java-${os}-0.3.0.jar \n\n}\n\nlibraryDependencies +=  com.intel.analytics.bigdl  %  bigdl-SPARK_2.1  %  0.3.0  exclude( com.intel.analytics.bigdl ,  bigdl-core )\nlibraryDependencies +=  com.intel.analytics.bigdl.native  %  mkl-java-mac  %  0.3.0  from mkl_native( mac )\nlibraryDependencies +=  com.intel.analytics.bigdl.bigquant  %  bigquant-java-mac  %  0.3.0  from bigquant_native( mac )  If you want to run it on other platforms too, append below,  // Linux\nlibraryDependencies +=  com.intel.analytics.bigdl.native  %  mkl-java  %  0.3.0 \nlibraryDependencies +=  com.intel.analytics.bigdl.bigquant  %  bigquant-java  %  0.3.0 \n\n// Windows\nlibraryDependencies +=  com.intel.analytics.bigdl.native  %  mkl-java-win64  %  0.3.0  from mkl_native( win64 )\nlibraryDependencies +=  com.intel.analytics.bigdl.bigquant  %  bigquant-java-win64  %  0.3.0  from bigquant_native( win64 )  If you will assemble all dependencies to a jar. You need to add merge strategy like below.  assemblyMergeStrategy in assembly := {\n    case x if x.contains( com/intel/analytics/bigdl/bigquant/ ) =  MergeStrategy.first\n    case x if x.contains( com/intel/analytics/bigdl/mkl/ ) =  MergeStrategy.first\n    case x = \n      val oldStrategy = (assemblyMergeStrategy in assembly).value\n      oldStrategy(x)\n}", 
            "title": "Link with a development version"
        }, 
        {
            "location": "/ScalaUserGuide/install-build-src/", 
            "text": "Download BigDL Source\n\n\nBigDL source code is available at \nGitHub\n\n\n$ git clone https://github.com/intel-analytics/BigDL.git\n\n\n\n\nBy default, \ngit clone\n will download the development version of BigDL, if you want a release version, you can use command \ngit checkout\n to change the version. Available release versions is \nBigDL releases\n.\n\n\nSetup Build Environment\n\n\nThe following instructions are aligned with master code.\n\n\nMaven 3 is needed to build BigDL, you can download it from the \nmaven website\n.\n\n\nAfter installing Maven 3, please set the environment variable MAVEN_OPTS as follows:\n\n\n$ export MAVEN_OPTS=\n-Xmx2g -XX:ReservedCodeCacheSize=512m\n\n\n\n\n\nWhen compiling with Java 7, you need to add the option \u201c-XX:MaxPermSize=1G\u201d. \n\n\nBuild with script (Recommended)\n\n\nIt is highly recommended that you build BigDL using the \nmake-dist.sh script\n. And it will handle the MAVEN_OPTS variable.\n\n\nOnce downloaded, you can build BigDL with the following commands:\n\n\n$ bash make-dist.sh\n\n\n\n\nAfter that, you can find a \ndist\n folder, which contains all the needed files to run a BigDL program. The files in \ndist\n include:\n\n\n\n\ndist/bin/bigdl.sh\n: A script used to set up proper environment variables and launch the BigDL program.\n\n\ndist/lib/bigdl-VERSION-jar-with-dependencies.jar\n: This jar package contains all dependencies except Spark classes.\n\n\ndist/lib/bigdl-VERSION-python-api.zip\n: This zip package contains all Python files of BigDL.\n\n\ndist/conf/spark-bigdl.conf\n: This file contains necessary property configurations. \nEngine.createSparkConf\n will populate these properties, so try to use that method in your code. Or you need to pass the file to Spark with the \"--properties-file\" option. \n\n\n\n\nBuild for Spark 2.0 and above\n\n\nThe instructions above will build BigDL with Spark 1.5.x or 1.6.x (using Scala 2.10); to build for Spark 2.0 and above (which uses Scala 2.11 by default), pass \n-P spark_2.x\n to the \nmake-dist.sh\n script:\n\n\n$ bash make-dist.sh -P spark_2.x\n\n\n\n\nIt is highly recommended to use \nJava 8\n when running with Spark 2.x; otherwise you may observe very poor performance.\n\n\nBuild for Scala 2.10 or 2.11\n\n\nBy default, \nmake-dist.sh\n uses Scala 2.10 for Spark 1.5.x or 1.6.x, and Scala 2.11 for Spark 2.0.x or 2.1.x. To override the default behaviors, you can pass \n-P scala_2.10\n or \n-P scala_2.11\n to \nmake-dist.sh\n as appropriate.\n\n\n\n\nBuild with Maven\n\n\nTo build BigDL directly using Maven, run the command below:\n\n\n$ mvn clean package -DskipTests\n\n\n\n\nAfter that, you can find that the three jar packages in \nPATH_To_BigDL\n/target/, where \nPATH_To_BigDL\n is the path to the directory of the BigDL. \n\n\nNote that the instructions above will build BigDL with Spark 1.5.x or 1.6.x (using Scala 2.10) for Linux, and skip the build of native library code. Similarly, you may customize the default behaviors by passing the following parameters to maven:\n\n\n\n\n-P spark_2.x\n: build for Spark 2.0 and above (using Scala 2.11). (Again, it is highly recommended to use \nJava 8\n when running with Spark 2.0; otherwise you may observe very poor performance.)\n\n\n-P full-build\n: full build\n\n\n-P scala_2.10\n (or \n-P scala_2.11\n): build using Scala 2.10 (or Scala 2.11) \n\n\n\n\n\n\nSetup IDE\n\n\nWe set the scope of spark related library to \nprovided\n in pom.xml. The reason is that we don't want package spark related jars which will make bigdl a huge jar, and generally as bigdl is invoked by spark-submit, these dependencies will be provided by spark at run-time.\n\n\nThis will cause a problem in IDE. When you run applications, it will throw \nNoClassDefFoundError\n because the library scope is \nprovided\n.\n\n\nYou can easily change the scopes by the \nall-in-one\n profile.\n\n\n\n\nIn Intellij, go to View -\n Tools Windows -\n Maven Projects. Then in the Maven Projects panel, Profiles -\n click \"all-in-one\". \n\n\n\n\n\n\nBuild BigDL-core on different platforms\n\n\nEnvironments Setup\n\n\nFor building BigDL-core, there should have\n\n\n\n\nJDK 1.7+\n\n\nmaven\n\n\nmake\n\n\ng++-7\n\n\nIntel Parallel Studio\n\n\nGit.\n\n\n\n\nBigDL-core is a JNI project, \nmkl2017-xeon-blas\n needs MKL libraries with icc and \nbigquant\n needs g++-7. We use \nmaven\n + \nmake\n to control the build process where maven for java and make for c/c++ code.\n\n\nCentOS\n\n\n\n\nBuild GCC-7.2\n\n\nDownload GCC 7.2 source code\n\n\ngit clone https://github.com/gcc-mirror/gcc.git\n\n\ngit checkout gcc-7_2_0-release\n\n\n\n\n\n\ncontrib/download_prerequisites\n\n\nbase_url='http://gcc.gnu.org/pub/gcc/infrastructure/' # should change ftp to http because of proxy\n\n\n\n\n\n\n./configure --prefix=/opt/gcc-7.2.0 --enable-languages=c,c++ --disable-multilib --disable-nls\n\n\nmake -j4 \n make install\n\n\nln -s /opt/gcc-7.2.0 /opt/gcc\n\n\nbinutils 2.29\n\n\nwget https://ftp.gnu.org/gnu/binutils/binutils-2.29.tar.gz\n\n\ntar zxvf binutils-2.29.tar.gz -C /tmp/ \n cd /tmp/binutils-2.29\n\n\n./configure --prefix=/opt/binutils-2.29\n\n\nmake \n make install\n\n\nln -s /opt/binutils-2.29 /opt/binutils/\n\n\nInstall Git\n\n\n./configure --prefix=/opt/git-2.9.5\n\n\nmake -j4 \n make install\n\n\nln -s /opt/git-2.9.5 /opt/git\n\n\n\n\nset environment variables\n    ```\n    export MAVEN_HOME=/opt/maven\n    export PATH=$MAVEN_HOME/bin:$PATH\n    export MAVEN_OPTS=\"-Xmx28g -Xss10M -XX:ReservedCodeCacheSize=512m -XX:MaxPermSize=128m\"\n\n\nGCC_7_HOME=/opt/gcc\nLIBDIR=${GCC_7_HOME}/lib/../lib64\nexport LD_LIBRARY_PATH=${LIBDIR}:${LD_LIBRARY_PATH}\nexport LIBRARY_PATH=${LIBDIR}:${LIBRARY_PATH}\nexport LD_RUN_PATH=${LIBDIR}:${LD_RUN_PATH}\nexport PATH=${GCC_7_HOME}/bin/:${PATH}\nexport C_INCLUDE_PATH=/opt/gcc/include/:${C_INCLUDE_PATH}\nexport CPLUS_INCLUDE_PATH=/opt/gcc/include/:${CPLUS_INCLUDE_PATH}\n\n\nGIT_HOME=/opt/git\nexport PATH=${GIT_HOME}/bin:${PATH}\n\n\nBINUTILS_HOME=/opt/binutils\nexport LD_LIBRARY_PATH=${BINUTILS_HOME}/lib:${LD_LIBRARY_PATH}\nexport PATH=${BINUTILS_HOME}/bin:${PATH}\n```\n\n\n\n\n\n\nUbuntu/Debian\n\n\n\n\nInstall g++-7\n\n\n\n\nsudo add-apt-repository ppa:jonathonf/gcc-7.1\n   sudo apt-get update\n   sudo apt-get install gcc-7 g++-7\n   sudo apt-get install build-essential\n\n\n\n\nInstall Parallel Studio XE\n\n\n\n\nWindows\n\n\n\n\nInstall Visual Studio 2015\n\n\nInstall Intel Parallel Studio XE 2018\n\n\n\n\nInstall MinGW: https://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win64/Personal%20Builds/mingw-builds/7.2.0/threads-win32/sjlj/x86_64-7.2.0-release-win32-sjlj-rt_v5-rev0.7z\n\n\n\n\n\n\nUnzip it to C:\\MinGW.\n\n\n\n\nSet the environment\n\n\nCopy ming32-make.exe to make.exe\n\n\nCopy g++ to g++-7\n\n\nOpen a cmd terminal and input \ng++-7 -v\n , should output like below,\n      \nUsing built-in specs.\n      COLLECT_GCC=g++-7\n      COLLECT_LTO_WRAPPER=C:/MinGW/bin/../libexec/gcc/x86_64-w64-mingw32/7.1.0/lto-wrapper.exe\n      Target: x86_64-w64-mingw32\n      Configured with: ../../../src/gcc-7.1.0/configure --host=x86_64-w64-mingw32 --build=x86_64-w64-mingw32 --target=x86_64-w64-ingw32 --prefix=/mingw64 --with-sysroot=/c/mingw710/x86_64-710-win32-sjlj-rt_v5-rev2/mingw64 --enable-shared --enable-static --enable-targets=all --enable-multilib --enable-languages=c,c++,fortran,lto --enable-libstdcxx-time=yes --enable-threads=win32 --enable-libgomp --enable-libatomic --enable-lto --enable-graphite --enable-checking=release --enable-fully-dynamic-string --enable-version-specific-runtime-libs --enable-libstdcxx-filesystem-ts=yes --enable-sjlj-exceptions --disable-libstdcxx-pch --disable-libstdcxx-debug --enable-bootstrap --disable-rpath --disable-win32-registry --disable-nls --disable-werror --disable-symvers --with-gnu-as --with-gnu-ld --with-arch-32=i686 --with-arch-64=nocona --with-tune-32=generic --with-tune-64=core2 --with-libiconv --with-system-zlib --with-gmp=/c/mingw710/prerequisites/x86_64-w64-mingw32-static --with-mpfr=/c/mingw710/prerequisites/x86_64-w64-mingw32-static --with-mpc=/c/mingw710/prerequisites/x86_64-w64-mingw32-static --with-isl=/c/mingw710/prerequisites/x86_64-w64-mingw32-static --with-pkgversion='x86_64-win32-sjlj-rev2, Built by MinGW-W64 project' --with-bugurl=https://sourceforge.net/projects/mingw-w64 CFLAGS='-O2 -pipe -fno-ident -I/c/mingw710/x86_64-710-win32-sjlj-rt_v5-rev2/mingw64/opt/include -I/c/mingw710/prerequisites/x86_64-zlib-static/include -I/c/mingw710/prerequisites/x86_64-w64-mingw32-static/include' CXXFLAGS='-O2 -pipe -fno-ident -I/c/mingw710/x86_64-710-win32-sjlj-rt_v5-rev2/mingw64/opt/include -I/c/mingw710/prerequisites/x86_64-zlib-static/include -I/c/mingw710/prerequisites/x86_64-w64-mingw32-static/include' CPPFLAGS=' -I/c/mingw710/x86_64-710-win32-sjlj-rt_v5-rev2/mingw64/opt/include -I/c/mingw710/prerequisites/x86_64-zlib-static/include -I/c/mingw710/prerequisites/x86_64-w64-mingw32-static/include' LDFLAGS='-pipe -fno-ident -L/c/mingw710/x86_64-710-win32-sjlj-rt_v5-rev2/mingw64/opt/lib -L/c/mingw710/prerequisites/x86_64-zlib-static/lib -L/c/mingw710/prerequisites/x86_64-w64-mingw32-static/lib '\n      Thread model: win32\n      gcc version 7.1.0 (x86_64-win32-sjlj-rev2, Built by MinGW-W64 project)\n\n\n\n\nmacOS\n\n\n\n\nInstall Parallel Studio XE.\n\n\nInstall g++-7: \nbrew install gcc@7\n\n\n\n\nBuild \n Deploy\n\n\nWe use maven profile to control the build process. For different platforms has different profiles.\n\n\n\n\n\n\n\n\nPlatform\n\n\nProfile\n\n\nCommand\n\n\n\n\n\n\n\n\n\n\nLinux\n\n\nlinux\n\n\nmvn clean package -P linux\n\n\n\n\n\n\nRedHat5\n\n\nrh5\n\n\nmvn clean package -P rh5\n\n\n\n\n\n\nmacOS\n\n\nmac\n\n\nmvn clean package -P mac\n\n\n\n\n\n\nWindows\n\n\nwin64\n\n\nmvn clean package -P win64\n\n\n\n\n\n\n\n\nThere two ways to deploy. We should use \nmvn deploy -P deploy\n at the end.\n1. Build the jar on specific platform and deploy it. For example, we want to deploy bigquant of linux.\n    \nmvn clean deploy -P 'linux' -pl 'bigquant/bigquant-java-x86_64-linux'\n\n2. Copy the prebuilt libraries from every platform to a main machine, and deploy it.", 
            "title": "Build from Source Code"
        }, 
        {
            "location": "/ScalaUserGuide/install-build-src/#download-bigdl-source", 
            "text": "BigDL source code is available at  GitHub  $ git clone https://github.com/intel-analytics/BigDL.git  By default,  git clone  will download the development version of BigDL, if you want a release version, you can use command  git checkout  to change the version. Available release versions is  BigDL releases .", 
            "title": "Download BigDL Source"
        }, 
        {
            "location": "/ScalaUserGuide/install-build-src/#setup-build-environment", 
            "text": "The following instructions are aligned with master code.  Maven 3 is needed to build BigDL, you can download it from the  maven website .  After installing Maven 3, please set the environment variable MAVEN_OPTS as follows:  $ export MAVEN_OPTS= -Xmx2g -XX:ReservedCodeCacheSize=512m   When compiling with Java 7, you need to add the option \u201c-XX:MaxPermSize=1G\u201d.", 
            "title": "Setup Build Environment"
        }, 
        {
            "location": "/ScalaUserGuide/install-build-src/#build-with-script-recommended", 
            "text": "It is highly recommended that you build BigDL using the  make-dist.sh script . And it will handle the MAVEN_OPTS variable.  Once downloaded, you can build BigDL with the following commands:  $ bash make-dist.sh  After that, you can find a  dist  folder, which contains all the needed files to run a BigDL program. The files in  dist  include:   dist/bin/bigdl.sh : A script used to set up proper environment variables and launch the BigDL program.  dist/lib/bigdl-VERSION-jar-with-dependencies.jar : This jar package contains all dependencies except Spark classes.  dist/lib/bigdl-VERSION-python-api.zip : This zip package contains all Python files of BigDL.  dist/conf/spark-bigdl.conf : This file contains necessary property configurations.  Engine.createSparkConf  will populate these properties, so try to use that method in your code. Or you need to pass the file to Spark with the \"--properties-file\" option.", 
            "title": "Build with script (Recommended)"
        }, 
        {
            "location": "/ScalaUserGuide/install-build-src/#build-for-spark-20-and-above", 
            "text": "The instructions above will build BigDL with Spark 1.5.x or 1.6.x (using Scala 2.10); to build for Spark 2.0 and above (which uses Scala 2.11 by default), pass  -P spark_2.x  to the  make-dist.sh  script:  $ bash make-dist.sh -P spark_2.x  It is highly recommended to use  Java 8  when running with Spark 2.x; otherwise you may observe very poor performance.", 
            "title": "Build for Spark 2.0 and above"
        }, 
        {
            "location": "/ScalaUserGuide/install-build-src/#build-for-scala-210-or-211", 
            "text": "By default,  make-dist.sh  uses Scala 2.10 for Spark 1.5.x or 1.6.x, and Scala 2.11 for Spark 2.0.x or 2.1.x. To override the default behaviors, you can pass  -P scala_2.10  or  -P scala_2.11  to  make-dist.sh  as appropriate.", 
            "title": "Build for Scala 2.10 or 2.11"
        }, 
        {
            "location": "/ScalaUserGuide/install-build-src/#build-with-maven", 
            "text": "To build BigDL directly using Maven, run the command below:  $ mvn clean package -DskipTests  After that, you can find that the three jar packages in  PATH_To_BigDL /target/, where  PATH_To_BigDL  is the path to the directory of the BigDL.   Note that the instructions above will build BigDL with Spark 1.5.x or 1.6.x (using Scala 2.10) for Linux, and skip the build of native library code. Similarly, you may customize the default behaviors by passing the following parameters to maven:   -P spark_2.x : build for Spark 2.0 and above (using Scala 2.11). (Again, it is highly recommended to use  Java 8  when running with Spark 2.0; otherwise you may observe very poor performance.)  -P full-build : full build  -P scala_2.10  (or  -P scala_2.11 ): build using Scala 2.10 (or Scala 2.11)", 
            "title": "Build with Maven"
        }, 
        {
            "location": "/ScalaUserGuide/install-build-src/#setup-ide", 
            "text": "We set the scope of spark related library to  provided  in pom.xml. The reason is that we don't want package spark related jars which will make bigdl a huge jar, and generally as bigdl is invoked by spark-submit, these dependencies will be provided by spark at run-time.  This will cause a problem in IDE. When you run applications, it will throw  NoClassDefFoundError  because the library scope is  provided .  You can easily change the scopes by the  all-in-one  profile.   In Intellij, go to View -  Tools Windows -  Maven Projects. Then in the Maven Projects panel, Profiles -  click \"all-in-one\".", 
            "title": "Setup IDE"
        }, 
        {
            "location": "/ScalaUserGuide/install-build-src/#build-bigdl-core-on-different-platforms", 
            "text": "", 
            "title": "Build BigDL-core on different platforms"
        }, 
        {
            "location": "/ScalaUserGuide/install-build-src/#environments-setup", 
            "text": "For building BigDL-core, there should have   JDK 1.7+  maven  make  g++-7  Intel Parallel Studio  Git.   BigDL-core is a JNI project,  mkl2017-xeon-blas  needs MKL libraries with icc and  bigquant  needs g++-7. We use  maven  +  make  to control the build process where maven for java and make for c/c++ code.", 
            "title": "Environments Setup"
        }, 
        {
            "location": "/ScalaUserGuide/install-build-src/#centos", 
            "text": "Build GCC-7.2  Download GCC 7.2 source code  git clone https://github.com/gcc-mirror/gcc.git  git checkout gcc-7_2_0-release    contrib/download_prerequisites  base_url='http://gcc.gnu.org/pub/gcc/infrastructure/' # should change ftp to http because of proxy    ./configure --prefix=/opt/gcc-7.2.0 --enable-languages=c,c++ --disable-multilib --disable-nls  make -j4   make install  ln -s /opt/gcc-7.2.0 /opt/gcc  binutils 2.29  wget https://ftp.gnu.org/gnu/binutils/binutils-2.29.tar.gz  tar zxvf binutils-2.29.tar.gz -C /tmp/   cd /tmp/binutils-2.29  ./configure --prefix=/opt/binutils-2.29  make   make install  ln -s /opt/binutils-2.29 /opt/binutils/  Install Git  ./configure --prefix=/opt/git-2.9.5  make -j4   make install  ln -s /opt/git-2.9.5 /opt/git   set environment variables\n    ```\n    export MAVEN_HOME=/opt/maven\n    export PATH=$MAVEN_HOME/bin:$PATH\n    export MAVEN_OPTS=\"-Xmx28g -Xss10M -XX:ReservedCodeCacheSize=512m -XX:MaxPermSize=128m\"  GCC_7_HOME=/opt/gcc\nLIBDIR=${GCC_7_HOME}/lib/../lib64\nexport LD_LIBRARY_PATH=${LIBDIR}:${LD_LIBRARY_PATH}\nexport LIBRARY_PATH=${LIBDIR}:${LIBRARY_PATH}\nexport LD_RUN_PATH=${LIBDIR}:${LD_RUN_PATH}\nexport PATH=${GCC_7_HOME}/bin/:${PATH}\nexport C_INCLUDE_PATH=/opt/gcc/include/:${C_INCLUDE_PATH}\nexport CPLUS_INCLUDE_PATH=/opt/gcc/include/:${CPLUS_INCLUDE_PATH}  GIT_HOME=/opt/git\nexport PATH=${GIT_HOME}/bin:${PATH}  BINUTILS_HOME=/opt/binutils\nexport LD_LIBRARY_PATH=${BINUTILS_HOME}/lib:${LD_LIBRARY_PATH}\nexport PATH=${BINUTILS_HOME}/bin:${PATH}\n```", 
            "title": "CentOS"
        }, 
        {
            "location": "/ScalaUserGuide/install-build-src/#ubuntudebian", 
            "text": "Install g++-7   sudo add-apt-repository ppa:jonathonf/gcc-7.1\n   sudo apt-get update\n   sudo apt-get install gcc-7 g++-7\n   sudo apt-get install build-essential   Install Parallel Studio XE", 
            "title": "Ubuntu/Debian"
        }, 
        {
            "location": "/ScalaUserGuide/install-build-src/#windows", 
            "text": "Install Visual Studio 2015  Install Intel Parallel Studio XE 2018   Install MinGW: https://sourceforge.net/projects/mingw-w64/files/Toolchains%20targetting%20Win64/Personal%20Builds/mingw-builds/7.2.0/threads-win32/sjlj/x86_64-7.2.0-release-win32-sjlj-rt_v5-rev0.7z    Unzip it to C:\\MinGW.   Set the environment  Copy ming32-make.exe to make.exe  Copy g++ to g++-7  Open a cmd terminal and input  g++-7 -v  , should output like below,\n       Using built-in specs.\n      COLLECT_GCC=g++-7\n      COLLECT_LTO_WRAPPER=C:/MinGW/bin/../libexec/gcc/x86_64-w64-mingw32/7.1.0/lto-wrapper.exe\n      Target: x86_64-w64-mingw32\n      Configured with: ../../../src/gcc-7.1.0/configure --host=x86_64-w64-mingw32 --build=x86_64-w64-mingw32 --target=x86_64-w64-ingw32 --prefix=/mingw64 --with-sysroot=/c/mingw710/x86_64-710-win32-sjlj-rt_v5-rev2/mingw64 --enable-shared --enable-static --enable-targets=all --enable-multilib --enable-languages=c,c++,fortran,lto --enable-libstdcxx-time=yes --enable-threads=win32 --enable-libgomp --enable-libatomic --enable-lto --enable-graphite --enable-checking=release --enable-fully-dynamic-string --enable-version-specific-runtime-libs --enable-libstdcxx-filesystem-ts=yes --enable-sjlj-exceptions --disable-libstdcxx-pch --disable-libstdcxx-debug --enable-bootstrap --disable-rpath --disable-win32-registry --disable-nls --disable-werror --disable-symvers --with-gnu-as --with-gnu-ld --with-arch-32=i686 --with-arch-64=nocona --with-tune-32=generic --with-tune-64=core2 --with-libiconv --with-system-zlib --with-gmp=/c/mingw710/prerequisites/x86_64-w64-mingw32-static --with-mpfr=/c/mingw710/prerequisites/x86_64-w64-mingw32-static --with-mpc=/c/mingw710/prerequisites/x86_64-w64-mingw32-static --with-isl=/c/mingw710/prerequisites/x86_64-w64-mingw32-static --with-pkgversion='x86_64-win32-sjlj-rev2, Built by MinGW-W64 project' --with-bugurl=https://sourceforge.net/projects/mingw-w64 CFLAGS='-O2 -pipe -fno-ident -I/c/mingw710/x86_64-710-win32-sjlj-rt_v5-rev2/mingw64/opt/include -I/c/mingw710/prerequisites/x86_64-zlib-static/include -I/c/mingw710/prerequisites/x86_64-w64-mingw32-static/include' CXXFLAGS='-O2 -pipe -fno-ident -I/c/mingw710/x86_64-710-win32-sjlj-rt_v5-rev2/mingw64/opt/include -I/c/mingw710/prerequisites/x86_64-zlib-static/include -I/c/mingw710/prerequisites/x86_64-w64-mingw32-static/include' CPPFLAGS=' -I/c/mingw710/x86_64-710-win32-sjlj-rt_v5-rev2/mingw64/opt/include -I/c/mingw710/prerequisites/x86_64-zlib-static/include -I/c/mingw710/prerequisites/x86_64-w64-mingw32-static/include' LDFLAGS='-pipe -fno-ident -L/c/mingw710/x86_64-710-win32-sjlj-rt_v5-rev2/mingw64/opt/lib -L/c/mingw710/prerequisites/x86_64-zlib-static/lib -L/c/mingw710/prerequisites/x86_64-w64-mingw32-static/lib '\n      Thread model: win32\n      gcc version 7.1.0 (x86_64-win32-sjlj-rev2, Built by MinGW-W64 project)", 
            "title": "Windows"
        }, 
        {
            "location": "/ScalaUserGuide/install-build-src/#macos", 
            "text": "Install Parallel Studio XE.  Install g++-7:  brew install gcc@7", 
            "title": "macOS"
        }, 
        {
            "location": "/ScalaUserGuide/install-build-src/#build-deploy", 
            "text": "We use maven profile to control the build process. For different platforms has different profiles.     Platform  Profile  Command      Linux  linux  mvn clean package -P linux    RedHat5  rh5  mvn clean package -P rh5    macOS  mac  mvn clean package -P mac    Windows  win64  mvn clean package -P win64     There two ways to deploy. We should use  mvn deploy -P deploy  at the end.\n1. Build the jar on specific platform and deploy it. For example, we want to deploy bigquant of linux.\n     mvn clean deploy -P 'linux' -pl 'bigquant/bigquant-java-x86_64-linux' \n2. Copy the prebuilt libraries from every platform to a main machine, and deploy it.", 
            "title": "Build &amp; Deploy"
        }, 
        {
            "location": "/ScalaUserGuide/run/", 
            "text": "Set Environment Variables\n\n\nSet \nBIGDL_HOME\n and \nSPARK_HOME\n:\n\n\n\n\nIf you download BigDL from the \nRelease Page\n\n\n\n\nexport SPARK_HOME=folder path where you extract the spark package\nexport BIGDL_HOME=folder path where you extract the bigdl package\n\n\n\n\n\n\nIf you build BigDL by yourself\n\n\n\n\nexport SPARK_HOME=folder path where you extract the spark package\nexport BIGDL_HOME=the dist folder generated by the build process, which is under the top level of the source folder\n\n\n\n\n\n\nUse Interactive Spark Shell\n\n\nYou can try BigDL easily using the Spark interactive shell. Run below command to start spark shell with BigDL support:\n\n\n${BIGDL_HOME}/bin/spark-shell-with-bigdl.sh --master local[*]\n\n\n\n\nYou will see a welcome message looking like below:\n\n\nWelcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 1.6.0\n      /_/\n\nUsing Scala version 2.10.5 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_79)\nSpark context available as sc.\nscala\n \n\n\n\n\nTo use BigDL, you should first initialize the engine as below. \n\n\nscala\n import com.intel.analytics.bigdl.utils.Engine\nscala\n Engine.init\n\n\n\n\nOnce the engine is successfully initiated, you'll be able to play with BigDL API's. \nFor instance, to experiment with the \nTensor\n APIs in BigDL, you may try below code:\n\n\nscala\n import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nscala\n Tensor[Double](2,2).fill(1.0)\nres9: com.intel.analytics.bigdl.tensor.Tensor[Double] =\n1.0     1.0\n1.0     1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\n\n\nRun as a Spark Program\n\n\nYou can run a BigDL program, e.g., the \nVGG\n training, as a standard Spark program (running in either local mode or cluster mode) as follows:\n\n\n\n\nDownload the CIFAR-10 data from \nhere\n. Remember to choose the binary version.\n\n\nRun the following command:\n\n\n\n\n  # Spark local mode\n  spark-submit --master local[core_number] --class com.intel.analytics.bigdl.models.vgg.Train \\\n  dist/lib/bigdl-VERSION-jar-with-dependencies.jar \\\n  -f path_to_your_cifar_folder \\\n  -b batch_size\n\n  # Spark standalone mode\n  spark-submit --master spark://... --executor-cores cores_per_executor \\\n  --total-executor-cores total_cores_for_the_job \\\n  --class com.intel.analytics.bigdl.models.vgg.Train \\\n  dist/lib/bigdl-VERSION-jar-with-dependencies.jar \\\n  -f path_to_your_cifar_folder \\\n  -b batch_size\n\n  # Spark yarn client mode\n  spark-submit --master yarn --deploy-mode client \\\n  --executor-cores cores_per_executor \\\n  --num-executors executors_number \\\n  --class com.intel.analytics.bigdl.models.vgg.Train \\\n  dist/lib/bigdl-VERSION-jar-with-dependencies.jar \\\n  -f path_to_your_cifar_folder \\\n  -b batch_size\n\n  # Spark yarn cluster mode\n  spark-submit --master yarn --deploy-mode cluster \\\n  --executor-cores cores_per_executor \\\n  --num-executors executors_number \\\n  --class com.intel.analytics.bigdl.models.vgg.Train \\\n  dist/lib/bigdl-VERSION-jar-with-dependencies.jar \\\n  -f path_to_your_cifar_folder \\\n  -b batch_size\n\n\n\n\nThe parameters used in the above command are:\n\n\n\n\n\n\n-f: The folder where your put the CIFAR-10 data set. Note in this example, this is just a local file folder on the Spark driver; as the CIFAR-10 data is somewhat small (about 120MB), we will directly send it from the driver to executors in the example.\n\n\n\n\n\n\n-b: The mini-batch size. The mini-batch size is expected to be a multiple of \ntotal cores\n used in the job. In this example, the mini-batch size is suggested to be set to \ntotal cores * 4\n\n\n\n\n\n\nIf you are to run your own program, do remember to create SparkContext and initialize the engine before call other BigDL API's, as shown below. \n\n\n // Scala code example\n val conf = Engine.createSparkConf()\n val sc = new SparkContext(conf)\n Engine.init\n\n\n\n\n\n\nRun as a Local Java/Scala program\n\n\nYou can try BigDL program as a local Java/Scala program. \n\n\nTo run the BigDL model as a local Java/Scala program, you need to set Java property \nbigdl.localMode\n to \ntrue\n. If you want to specify how many cores to be used for training/testing/prediction, you need to set Java property \nbigdl.coreNumber\n to the core number. You can either call \nSystem.setProperty(\"bigdl.localMode\", \"true\")\n and \nSystem.setProperty(\"bigdl.coreNumber\", core_number)\n in the Java/Scala code, or pass -Dbigdl.localMode=true and -Dbigdl.coreNumber=core_number when running the program.\n\n\nYou need a full jar package to run local program. In our distributed jar, we exclude the spark dependency classes. To get the full jar package, you need to build from the source code.\nPlease refer the \nBuild Page\n. You can find a bigdl-VERSION-jar-with-dependencies-and-spark.jar under the spark/dl/target/ of the source folder.\n\n\nFor example, you may run the \nLenet\n model as a local Scala/Java program as follows:\n\n\n1.First, you can download the MNIST Data from \nhere\n. Unzip all the files and put them in one folder(e.g. mnist).\n\n\n2.Run below command to train lenet as local Java/Scala program:\n\n\nscala -cp spark/dl/target/bigdl-VERSION-jar-with-dependencies-and-spark.jar \\\ncom.intel.analytics.bigdl.example.lenetLocal.Train \\\n-f path_to_mnist_folder \\\n-c core_number \\\n-b batch_size \\\n--checkpoint ./model\n\n\n\n\nIn the above commands\n\n\n\n\n-f: where you put your MNIST data\n\n\n-c: The core number on local machine used for this training. The default value is physical cores number. Get it through Runtime.getRuntime().availableProcessors() / 2\n\n\n-b: The mini-batch size. It is expected that the mini-batch size is a multiple of core_number\n\n\n--checkpoint: Where you cache the model/train_state snapshot. You should input a folder and\nmake sure the folder is created when you run this example. The model snapshot will be named as\nmodel.#iteration_number, and train state will be named as state.#iteration_number. Note that if\nthere are some files already exist in the folder, the old file will not be overwrite for the\nsafety of your model files.\n\n\n\n\n3.The above commands will cache the model in specified path(--checkpoint). Run this command will\n   use the trained model to do a validation.\n\n\nscala -cp spark/dl/target/bigdl-VERSION-jar-with-dependencies-and-spark.jar \\\ncom.intel.analytics.bigdl.example.lenetLocal.Test \\\n-f path_to_mnist_folder \\\n--model ./model/model.iteration \\\n-c core_number \\\n-b batch_size\n\n\n\n\nIn the above command\n\n\n\n\n-f: where you put your MNIST data\n\n\n--model: the model snapshot file\n\n\n-c: The core number on local machine used for this testing. The default value is physical cores number. Get it through Runtime.getRuntime().availableProcessors() / 2\n\n\n-b: The mini-batch size. It is expected that the mini-batch size is a multiple of core_number   \n\n\n\n\n4.Run below command to predict with trained model:\n\n\nscala -cp spark/dl/target/bigdl-VERSION-jar-with-dependencies-and-spark.jar \\\ncom.intel.analytics.bigdl.example.lenetLocal.Predict \\\n-f path_to_mnist_folder \\\n-c core_number \\\n--model ./model/model.iteration\n\n\n\n\nIn the above command\n\n\n\n\n-f: where you put your MNIST data\n\n\n-c: The core number on local machine used for this prediction. The default value is physical cores number. Get it through Runtime.getRuntime().availableProcessors() / 2\n\n\n--model: the model snapshot file\n\n\n\n\n\n\nFor Windows User\n\n\nSome BigDL functions depends on Hadoop library, which requires winutils.exe installed on your machine. If you meet \"Could not locate executable null\\bin\\winutils.exe\", see\nthe \nknown issue page\n.", 
            "title": "Run"
        }, 
        {
            "location": "/ScalaUserGuide/run/#set-environment-variables", 
            "text": "Set  BIGDL_HOME  and  SPARK_HOME :   If you download BigDL from the  Release Page   export SPARK_HOME=folder path where you extract the spark package\nexport BIGDL_HOME=folder path where you extract the bigdl package   If you build BigDL by yourself   export SPARK_HOME=folder path where you extract the spark package\nexport BIGDL_HOME=the dist folder generated by the build process, which is under the top level of the source folder", 
            "title": "Set Environment Variables"
        }, 
        {
            "location": "/ScalaUserGuide/run/#use-interactive-spark-shell", 
            "text": "You can try BigDL easily using the Spark interactive shell. Run below command to start spark shell with BigDL support:  ${BIGDL_HOME}/bin/spark-shell-with-bigdl.sh --master local[*]  You will see a welcome message looking like below:  Welcome to\n      ____              __\n     / __/__  ___ _____/ /__\n    _\\ \\/ _ \\/ _ `/ __/  '_/\n   /___/ .__/\\_,_/_/ /_/\\_\\   version 1.6.0\n      /_/\n\nUsing Scala version 2.10.5 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_79)\nSpark context available as sc.\nscala    To use BigDL, you should first initialize the engine as below.   scala  import com.intel.analytics.bigdl.utils.Engine\nscala  Engine.init  Once the engine is successfully initiated, you'll be able to play with BigDL API's. \nFor instance, to experiment with the  Tensor  APIs in BigDL, you may try below code:  scala  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nscala  Tensor[Double](2,2).fill(1.0)\nres9: com.intel.analytics.bigdl.tensor.Tensor[Double] =\n1.0     1.0\n1.0     1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]", 
            "title": "Use Interactive Spark Shell"
        }, 
        {
            "location": "/ScalaUserGuide/run/#run-as-a-spark-program", 
            "text": "You can run a BigDL program, e.g., the  VGG  training, as a standard Spark program (running in either local mode or cluster mode) as follows:   Download the CIFAR-10 data from  here . Remember to choose the binary version.  Run the following command:     # Spark local mode\n  spark-submit --master local[core_number] --class com.intel.analytics.bigdl.models.vgg.Train \\\n  dist/lib/bigdl-VERSION-jar-with-dependencies.jar \\\n  -f path_to_your_cifar_folder \\\n  -b batch_size\n\n  # Spark standalone mode\n  spark-submit --master spark://... --executor-cores cores_per_executor \\\n  --total-executor-cores total_cores_for_the_job \\\n  --class com.intel.analytics.bigdl.models.vgg.Train \\\n  dist/lib/bigdl-VERSION-jar-with-dependencies.jar \\\n  -f path_to_your_cifar_folder \\\n  -b batch_size\n\n  # Spark yarn client mode\n  spark-submit --master yarn --deploy-mode client \\\n  --executor-cores cores_per_executor \\\n  --num-executors executors_number \\\n  --class com.intel.analytics.bigdl.models.vgg.Train \\\n  dist/lib/bigdl-VERSION-jar-with-dependencies.jar \\\n  -f path_to_your_cifar_folder \\\n  -b batch_size\n\n  # Spark yarn cluster mode\n  spark-submit --master yarn --deploy-mode cluster \\\n  --executor-cores cores_per_executor \\\n  --num-executors executors_number \\\n  --class com.intel.analytics.bigdl.models.vgg.Train \\\n  dist/lib/bigdl-VERSION-jar-with-dependencies.jar \\\n  -f path_to_your_cifar_folder \\\n  -b batch_size  The parameters used in the above command are:    -f: The folder where your put the CIFAR-10 data set. Note in this example, this is just a local file folder on the Spark driver; as the CIFAR-10 data is somewhat small (about 120MB), we will directly send it from the driver to executors in the example.    -b: The mini-batch size. The mini-batch size is expected to be a multiple of  total cores  used in the job. In this example, the mini-batch size is suggested to be set to  total cores * 4    If you are to run your own program, do remember to create SparkContext and initialize the engine before call other BigDL API's, as shown below.    // Scala code example\n val conf = Engine.createSparkConf()\n val sc = new SparkContext(conf)\n Engine.init", 
            "title": "Run as a Spark Program"
        }, 
        {
            "location": "/ScalaUserGuide/run/#run-as-a-local-javascala-program", 
            "text": "You can try BigDL program as a local Java/Scala program.   To run the BigDL model as a local Java/Scala program, you need to set Java property  bigdl.localMode  to  true . If you want to specify how many cores to be used for training/testing/prediction, you need to set Java property  bigdl.coreNumber  to the core number. You can either call  System.setProperty(\"bigdl.localMode\", \"true\")  and  System.setProperty(\"bigdl.coreNumber\", core_number)  in the Java/Scala code, or pass -Dbigdl.localMode=true and -Dbigdl.coreNumber=core_number when running the program.  You need a full jar package to run local program. In our distributed jar, we exclude the spark dependency classes. To get the full jar package, you need to build from the source code.\nPlease refer the  Build Page . You can find a bigdl-VERSION-jar-with-dependencies-and-spark.jar under the spark/dl/target/ of the source folder.  For example, you may run the  Lenet  model as a local Scala/Java program as follows:  1.First, you can download the MNIST Data from  here . Unzip all the files and put them in one folder(e.g. mnist).  2.Run below command to train lenet as local Java/Scala program:  scala -cp spark/dl/target/bigdl-VERSION-jar-with-dependencies-and-spark.jar \\\ncom.intel.analytics.bigdl.example.lenetLocal.Train \\\n-f path_to_mnist_folder \\\n-c core_number \\\n-b batch_size \\\n--checkpoint ./model  In the above commands   -f: where you put your MNIST data  -c: The core number on local machine used for this training. The default value is physical cores number. Get it through Runtime.getRuntime().availableProcessors() / 2  -b: The mini-batch size. It is expected that the mini-batch size is a multiple of core_number  --checkpoint: Where you cache the model/train_state snapshot. You should input a folder and\nmake sure the folder is created when you run this example. The model snapshot will be named as\nmodel.#iteration_number, and train state will be named as state.#iteration_number. Note that if\nthere are some files already exist in the folder, the old file will not be overwrite for the\nsafety of your model files.   3.The above commands will cache the model in specified path(--checkpoint). Run this command will\n   use the trained model to do a validation.  scala -cp spark/dl/target/bigdl-VERSION-jar-with-dependencies-and-spark.jar \\\ncom.intel.analytics.bigdl.example.lenetLocal.Test \\\n-f path_to_mnist_folder \\\n--model ./model/model.iteration \\\n-c core_number \\\n-b batch_size  In the above command   -f: where you put your MNIST data  --model: the model snapshot file  -c: The core number on local machine used for this testing. The default value is physical cores number. Get it through Runtime.getRuntime().availableProcessors() / 2  -b: The mini-batch size. It is expected that the mini-batch size is a multiple of core_number      4.Run below command to predict with trained model:  scala -cp spark/dl/target/bigdl-VERSION-jar-with-dependencies-and-spark.jar \\\ncom.intel.analytics.bigdl.example.lenetLocal.Predict \\\n-f path_to_mnist_folder \\\n-c core_number \\\n--model ./model/model.iteration  In the above command   -f: where you put your MNIST data  -c: The core number on local machine used for this prediction. The default value is physical cores number. Get it through Runtime.getRuntime().availableProcessors() / 2  --model: the model snapshot file", 
            "title": "Run as a Local Java/Scala program"
        }, 
        {
            "location": "/ScalaUserGuide/run/#for-windows-user", 
            "text": "Some BigDL functions depends on Hadoop library, which requires winutils.exe installed on your machine. If you meet \"Could not locate executable null\\bin\\winutils.exe\", see\nthe  known issue page .", 
            "title": "For Windows User"
        }, 
        {
            "location": "/ScalaUserGuide/configuration/", 
            "text": "BigDL uses Java properties to control its behavior. Here's the list of\nthese properties.\n\n\nHow to set the properties\n\n\nSpark\n\n\nIf you run BigDL on Apache Spark, you can set the properties by passing\nspark-submit options. Here's an example:\n\n\n# Say you want to set property FOO to value BAR\nspark-submit ...\n    --conf 'spark.executor.extraJavaOptions=-DFOO=BAR' # Set that property for executor process\n    --conf 'spark.driver.extraJavaOptions=-DFOO=BAR'   # Set that property for driver process\n    ...\n\n\n\n\nLocal Java/Scala program\n\n\nIf you run BigDL as a local Java/Scala program, you can set the properties\nby passing JVM parameters. Here's an example:\n\n\n# Say you want to set property FOO to value BAR\njava -cp xxx.jar -DFOO=BAR your.main.class.name\n\n\n\n\n\n\nAvailable Properties\n\n\nLogging\n\n\n\n\nbigdl.utils.LoggerFilter.disable\n: To disable redirecting logs of Spark and BigDL to a file. Default is false.\n\n\nbigdl.utils.LoggerFilter.logFile\n: To set the path to redirect log. By default, it will be directed to \nbigdl.log\n in the current working directory.\n\n\nbigdl.utils.LoggerFilter.enableSparkLog\n: To enable redirecting Spark logs to logFile. Set it to false when you don't want to see Spark logs in the redirected log file. Default is true.\n\n\n\n\nMode\n\n\n\n\nbigdl.localMode\n: Whether BigDL is running as a local Java/Scala program. Default is false.\n\n\n\n\nMulti-threading\n\n\n\n\nbigdl.coreNumber\n: To set how many cores BigDL will use on your machine. It will only be used when bigdl.localMode is set to true. If hyper thread is enabled on your machine, \nDO NOT\n set it larger than half of the virtual core number. Default is half of the virtual core number.\n\n\nbigdl.Parameter.syncPoolSize\n: To set the thread pool size for syncing parameter between executors. Default is 4.\n\n\n\n\nDistributed Training\n\n\n\n\nbigdl.network.nio\n: Whether use NIO as BlockManager backend in Spark 1.5. Default is true. If it is set to be false, user can specify spark.shuffle.blockTransferService to change the BlockManager backend. \nONLY\n use this when running on Spark 1.5.\n\n\nbigdl.failure.retryTimes\n: To set how many times to retry when there's failure in distributed training. Default is 5.\n\n\nbigdl.failure.retryTimeInterval\n: To set how long to recount the retry times. Time unit here is second. Default is 120.\n\n\nbigdl.check.singleton\n: To check whether multiple partitions run on the same executor, which is bad for performance. Default is false.\n\n\n\n\nTensor\n\n\n\n\nbigdl.tensor.fold\n: To set how many elements in a tensor to determine it is a large tensor, and thus print only part of it. Default is 1000.", 
            "title": "Configuration"
        }, 
        {
            "location": "/ScalaUserGuide/configuration/#how-to-set-the-properties", 
            "text": "", 
            "title": "How to set the properties"
        }, 
        {
            "location": "/ScalaUserGuide/configuration/#spark", 
            "text": "If you run BigDL on Apache Spark, you can set the properties by passing\nspark-submit options. Here's an example:  # Say you want to set property FOO to value BAR\nspark-submit ...\n    --conf 'spark.executor.extraJavaOptions=-DFOO=BAR' # Set that property for executor process\n    --conf 'spark.driver.extraJavaOptions=-DFOO=BAR'   # Set that property for driver process\n    ...", 
            "title": "Spark"
        }, 
        {
            "location": "/ScalaUserGuide/configuration/#local-javascala-program", 
            "text": "If you run BigDL as a local Java/Scala program, you can set the properties\nby passing JVM parameters. Here's an example:  # Say you want to set property FOO to value BAR\njava -cp xxx.jar -DFOO=BAR your.main.class.name", 
            "title": "Local Java/Scala program"
        }, 
        {
            "location": "/ScalaUserGuide/configuration/#available-properties", 
            "text": "Logging   bigdl.utils.LoggerFilter.disable : To disable redirecting logs of Spark and BigDL to a file. Default is false.  bigdl.utils.LoggerFilter.logFile : To set the path to redirect log. By default, it will be directed to  bigdl.log  in the current working directory.  bigdl.utils.LoggerFilter.enableSparkLog : To enable redirecting Spark logs to logFile. Set it to false when you don't want to see Spark logs in the redirected log file. Default is true.   Mode   bigdl.localMode : Whether BigDL is running as a local Java/Scala program. Default is false.   Multi-threading   bigdl.coreNumber : To set how many cores BigDL will use on your machine. It will only be used when bigdl.localMode is set to true. If hyper thread is enabled on your machine,  DO NOT  set it larger than half of the virtual core number. Default is half of the virtual core number.  bigdl.Parameter.syncPoolSize : To set the thread pool size for syncing parameter between executors. Default is 4.   Distributed Training   bigdl.network.nio : Whether use NIO as BlockManager backend in Spark 1.5. Default is true. If it is set to be false, user can specify spark.shuffle.blockTransferService to change the BlockManager backend.  ONLY  use this when running on Spark 1.5.  bigdl.failure.retryTimes : To set how many times to retry when there's failure in distributed training. Default is 5.  bigdl.failure.retryTimeInterval : To set how long to recount the retry times. Time unit here is second. Default is 120.  bigdl.check.singleton : To check whether multiple partitions run on the same executor, which is bad for performance. Default is false.   Tensor   bigdl.tensor.fold : To set how many elements in a tensor to determine it is a large tensor, and thus print only part of it. Default is 1000.", 
            "title": "Available Properties"
        }, 
        {
            "location": "/ScalaUserGuide/examples/", 
            "text": "This section is a short introduction of some classic examples/tutorials. They can give you a clear idea of how to build simple deep learning programs using BigDL. Besides these examples, BigDL also provides plenty of models ready for re-use and examples in both Scala and Python - refer to \nResources\n section for details. \n\n\n\n\nTraining LeNet on MNIST - The \"hello world\" for deep learning\n\n\nThis tutorial is an explanation of what is happening in the \nlenet\n example, which trains \nLeNet-5\n on the \nMNIST data\n using BigDL.\n\n\nA BigDL program starts with \nimport com.intel.analytics.bigdl._\n; it then \ncreates the \nSparkContext\n using the \nSparkConf\n returned by the \nEngine\n; after that, it \ninitializes the \nEngine\n.\n\n\n  val conf = Engine.createSparkConf()\n      .setAppName(\nTrain Lenet on MNIST\n)\n      .set(\nspark.task.maxFailures\n, \n1\n)\n  val sc = new SparkContext(conf)\n  Engine.init\n\n\n\n\nEngine.createSparkConf\n will return a \nSparkConf\n populated with some appropriate configuration. And \nEngine.init\n will verify and read some environment information(e.g. executor numbers and executor cores) from the \nSparkContext\n. \n\n\nAfter the initialization, we need to:\n\n\n1.\nCreate the LeNet model\n by calling the \nLeNet5()\n, which creates the LeNet-5 convolutional network model as follows:\n\n\n    val model = Sequential()\n    model.add(Reshape(Array(1, 28, 28)))\n      .add(SpatialConvolution(1, 6, 5, 5))\n      .add(Tanh())\n      .add(SpatialMaxPooling(2, 2, 2, 2))\n      .add(Tanh())\n      .add(SpatialConvolution(6, 12, 5, 5))\n      .add(SpatialMaxPooling(2, 2, 2, 2))\n      .add(Reshape(Array(12 * 4 * 4)))\n      .add(Linear(12 * 4 * 4, 100))\n      .add(Tanh())\n      .add(Linear(100, classNum))\n      .add(LogSoftMax())\n\n\n\n\n2.Load the data by \ncreating the \nDataSet\n (either a distributed or local one depending on whether it runs on Spark or not), and then \napplying a series of \nTransformer\n (e.g., \nSampleToGreyImg\n, \nGreyImgNormalizer\n and \nGreyImgToBatch\n):\n\n\n    val trainSet = (if (sc.isDefined) {\n        DataSet.array(load(trainData, trainLabel), sc.get, param.nodeNumber)\n      } else {\n        DataSet.array(load(trainData, trainLabel))\n      }) -\n SampleToGreyImg(28, 28) -\n GreyImgNormalizer(trainMean, trainStd) -\n GreyImgToBatch(\n        param.batchSize)\n\n\n\n\nAfter that, we \ncreate the \nOptimizer\n (either a distributed or local one depending on whether it runs on Spark or not) by specifying the \nDataSet\n, the model and the \nCriterion\n (which, given input and target, computes gradient per given loss function):\n\n\n  val optimizer = Optimizer(\n    model = model,\n    dataset = trainSet,\n    criterion = ClassNLLCriterion[Float]())\n\n\n\n\nFinally (after optionally specifying the validation data and methods for the \nOptimizer\n), we \ntrain the model by calling \nOptimizer.optimize()\n:\n\n\n  optimizer\n    .setValidation(\n      trigger = Trigger.everyEpoch,\n      dataset = validationSet,\n      vMethods = Array(new Top1Accuracy))\n    .setOptimMethod(new Adagrad(learningRate=0.01, learningRateDecay=0.0002))\n    .setEndWhen(Trigger.maxEpoch(param.maxEpoch))\n    .optimize()\n\n\n\n\n\n\nText Classification - Working with Spark RDD\n\n\nThis tutorial describes the \ntext_classification\n example, which builds a text classifier using a simple convolutional neural network (CNN) model. (It was first described by \nthis Keras tutorial\n).\n\n\nAfter importing \ncom.intel.analytics.bigdl._\n and some initialization, the \nexample\n broadcasts the pre-trained world embedding and loads the input data using RDD transformations:\n\n\n  // For large dataset, you might want to get such RDD[(String, Float)] from HDFS\n  val dataRdd = sc.parallelize(loadRawData(), param.partitionNum)\n  val (word2Meta, word2Vec) = analyzeTexts(dataRdd)\n  val word2MetaBC = sc.broadcast(word2Meta)\n  val word2VecBC = sc.broadcast(word2Vec)\n  val vectorizedRdd = dataRdd\n      .map {case (text, label) =\n (toTokens(text, word2MetaBC.value), label)}\n      .map {case (tokens, label) =\n (shaping(tokens, sequenceLen), label)}\n      .map {case (tokens, label) =\n (vectorization(\n        tokens, embeddingDim, word2VecBC.value), label)}\n\n\n\n\nThe \nexample\n then converts the processed data (\nvectorizedRdd\n) to an RDD of Sample, and randomly splits the sample RDD (\nsampleRDD\n) into training data (\ntrainingRDD\n) and validation data (\nvalRDD\n):\n\n\n  val sampleRDD = vectorizedRdd.map {case (input: Array[Array[Float]], label: Float) =\n\n        Sample(\n          featureTensor = Tensor(input.flatten, Array(sequenceLen, embeddingDim))\n            .transpose(1, 2).contiguous(),\n          labelTensor = Tensor(Array(label), Array(1)))\n      }\n\n  val Array(trainingRDD, valRDD) = sampleRDD.randomSplit(\n    Array(trainingSplit, 1 - trainingSplit))\n\n\n\n\nAfter that, the \nexample\n builds the CNN model, creates the \nOptimizer\n, pass the RDD of training data (\ntrainingRDD\n) to the \nOptimizer\n (with specific batch size), and finally trains the model (using \nAdagrad\n as the optimization method, and setting relevant hyper parameters in \nstate\n):\n\n\n  val optimizer = Optimizer(\n    model = buildModel(classNum),\n    sampleRDD = trainingRDD,\n    criterion = new ClassNLLCriterion[Float](),\n    batchSize = param.batchSize\n  )\n  optimizer\n    .setOptimMethod(new Adagrad(learningRate=0.01, learningRateDecay=0.0002))\n    .setValidation(Trigger.everyEpoch, valRDD, Array(new Top1Accuracy[Float]), param.batchSize)\n    .setEndWhen(Trigger.maxEpoch(2))\n    .optimize()\n\n\n\n\n\n\nImage Classification\n - Working with Spark DataFrame and ML pipeline\n\n\nThis tutorial describes the \nimage_classification\n example, which loads a BigDL (\nInception\n) model or Torch (\nResnet\n) model that is trained on \nImageNet\n data, and then applies the loaded model to predict the contents of a set of images using BigDL and Spark \nML pipeline\n.\n\n\nAfter importing \ncom.intel.analytics.bigdl._\n and some initialization, the \nexample\n first \nloads\n the specified model:\n\n\n  def loadModel[@specialized(Float, Double) T : ClassTag](param : PredictParams)\n    (implicit ev: TensorNumeric[T]): Module[T] = {\n    val model = param.modelType match {\n      case TorchModel =\n\n        Module.loadTorch[T](param.modelPath)\n      case BigDlModel =\n\n        Module.load[T](param.modelPath)\n      case _ =\n throw new IllegalArgumentException(s\n${param.modelType}\n)\n    }\n    model\n  }\n\n\n\n\nIt then creates \nDLClassifer\n (a Spark ML pipelines \nTransformer\n) that predicts the input value based on the specified deep learning model:\n\n\n  val model = loadModel(param)\n  val valTrans = new DLClassifierModel(model, Array(3, imageSize, imageSize))\n    .setBatchSize(param.batchSize)\n    .setFeaturesCol(\nfeatures\n)\n    .setPredictionCol(\npredict\n)\n\n\n\n\nAfter that, the \nexample\n  loads the input images into a \nDataFrame\n, and then predicts the class of each each image using the \nDLClassifer\n:\n\n\n  val valRDD = sc.parallelize(imageSet).repartition(partitionNum)\n  val transf = RowToByteRecords() -\n\n      SampleToBGRImg() -\n\n      BGRImgCropper(imageSize, imageSize) -\n\n      BGRImgNormalizer(testMean, testStd) -\n\n      BGRImgToImageVector()\n\n  val valDF = transformDF(sqlContext.createDataFrame(valRDD), transf)\n\n  valTrans.transform(valDF, paramsTrans)\n      .select(\nimageName\n, \npredict\n)\n      .show(param.showNum)", 
            "title": "Examples"
        }, 
        {
            "location": "/ScalaUserGuide/examples/#training-lenet-on-mnist-the-hello-world-for-deep-learning", 
            "text": "This tutorial is an explanation of what is happening in the  lenet  example, which trains  LeNet-5  on the  MNIST data  using BigDL.  A BigDL program starts with  import com.intel.analytics.bigdl._ ; it then  creates the  SparkContext  using the  SparkConf  returned by the  Engine ; after that, it  initializes the  Engine .    val conf = Engine.createSparkConf()\n      .setAppName( Train Lenet on MNIST )\n      .set( spark.task.maxFailures ,  1 )\n  val sc = new SparkContext(conf)\n  Engine.init  Engine.createSparkConf  will return a  SparkConf  populated with some appropriate configuration. And  Engine.init  will verify and read some environment information(e.g. executor numbers and executor cores) from the  SparkContext .   After the initialization, we need to:  1. Create the LeNet model  by calling the  LeNet5() , which creates the LeNet-5 convolutional network model as follows:      val model = Sequential()\n    model.add(Reshape(Array(1, 28, 28)))\n      .add(SpatialConvolution(1, 6, 5, 5))\n      .add(Tanh())\n      .add(SpatialMaxPooling(2, 2, 2, 2))\n      .add(Tanh())\n      .add(SpatialConvolution(6, 12, 5, 5))\n      .add(SpatialMaxPooling(2, 2, 2, 2))\n      .add(Reshape(Array(12 * 4 * 4)))\n      .add(Linear(12 * 4 * 4, 100))\n      .add(Tanh())\n      .add(Linear(100, classNum))\n      .add(LogSoftMax())  2.Load the data by  creating the  DataSet  (either a distributed or local one depending on whether it runs on Spark or not), and then  applying a series of  Transformer  (e.g.,  SampleToGreyImg ,  GreyImgNormalizer  and  GreyImgToBatch ):      val trainSet = (if (sc.isDefined) {\n        DataSet.array(load(trainData, trainLabel), sc.get, param.nodeNumber)\n      } else {\n        DataSet.array(load(trainData, trainLabel))\n      }) -  SampleToGreyImg(28, 28) -  GreyImgNormalizer(trainMean, trainStd) -  GreyImgToBatch(\n        param.batchSize)  After that, we  create the  Optimizer  (either a distributed or local one depending on whether it runs on Spark or not) by specifying the  DataSet , the model and the  Criterion  (which, given input and target, computes gradient per given loss function):    val optimizer = Optimizer(\n    model = model,\n    dataset = trainSet,\n    criterion = ClassNLLCriterion[Float]())  Finally (after optionally specifying the validation data and methods for the  Optimizer ), we  train the model by calling  Optimizer.optimize() :    optimizer\n    .setValidation(\n      trigger = Trigger.everyEpoch,\n      dataset = validationSet,\n      vMethods = Array(new Top1Accuracy))\n    .setOptimMethod(new Adagrad(learningRate=0.01, learningRateDecay=0.0002))\n    .setEndWhen(Trigger.maxEpoch(param.maxEpoch))\n    .optimize()", 
            "title": "Training LeNet on MNIST - The \"hello world\" for deep learning"
        }, 
        {
            "location": "/ScalaUserGuide/examples/#text-classification-working-with-spark-rdd", 
            "text": "This tutorial describes the  text_classification  example, which builds a text classifier using a simple convolutional neural network (CNN) model. (It was first described by  this Keras tutorial ).  After importing  com.intel.analytics.bigdl._  and some initialization, the  example  broadcasts the pre-trained world embedding and loads the input data using RDD transformations:    // For large dataset, you might want to get such RDD[(String, Float)] from HDFS\n  val dataRdd = sc.parallelize(loadRawData(), param.partitionNum)\n  val (word2Meta, word2Vec) = analyzeTexts(dataRdd)\n  val word2MetaBC = sc.broadcast(word2Meta)\n  val word2VecBC = sc.broadcast(word2Vec)\n  val vectorizedRdd = dataRdd\n      .map {case (text, label) =  (toTokens(text, word2MetaBC.value), label)}\n      .map {case (tokens, label) =  (shaping(tokens, sequenceLen), label)}\n      .map {case (tokens, label) =  (vectorization(\n        tokens, embeddingDim, word2VecBC.value), label)}  The  example  then converts the processed data ( vectorizedRdd ) to an RDD of Sample, and randomly splits the sample RDD ( sampleRDD ) into training data ( trainingRDD ) and validation data ( valRDD ):    val sampleRDD = vectorizedRdd.map {case (input: Array[Array[Float]], label: Float) = \n        Sample(\n          featureTensor = Tensor(input.flatten, Array(sequenceLen, embeddingDim))\n            .transpose(1, 2).contiguous(),\n          labelTensor = Tensor(Array(label), Array(1)))\n      }\n\n  val Array(trainingRDD, valRDD) = sampleRDD.randomSplit(\n    Array(trainingSplit, 1 - trainingSplit))  After that, the  example  builds the CNN model, creates the  Optimizer , pass the RDD of training data ( trainingRDD ) to the  Optimizer  (with specific batch size), and finally trains the model (using  Adagrad  as the optimization method, and setting relevant hyper parameters in  state ):    val optimizer = Optimizer(\n    model = buildModel(classNum),\n    sampleRDD = trainingRDD,\n    criterion = new ClassNLLCriterion[Float](),\n    batchSize = param.batchSize\n  )\n  optimizer\n    .setOptimMethod(new Adagrad(learningRate=0.01, learningRateDecay=0.0002))\n    .setValidation(Trigger.everyEpoch, valRDD, Array(new Top1Accuracy[Float]), param.batchSize)\n    .setEndWhen(Trigger.maxEpoch(2))\n    .optimize()", 
            "title": "Text Classification - Working with Spark RDD"
        }, 
        {
            "location": "/ScalaUserGuide/examples/#image-classification-working-with-spark-dataframe-and-ml-pipeline", 
            "text": "This tutorial describes the  image_classification  example, which loads a BigDL ( Inception ) model or Torch ( Resnet ) model that is trained on  ImageNet  data, and then applies the loaded model to predict the contents of a set of images using BigDL and Spark  ML pipeline .  After importing  com.intel.analytics.bigdl._  and some initialization, the  example  first  loads  the specified model:    def loadModel[@specialized(Float, Double) T : ClassTag](param : PredictParams)\n    (implicit ev: TensorNumeric[T]): Module[T] = {\n    val model = param.modelType match {\n      case TorchModel = \n        Module.loadTorch[T](param.modelPath)\n      case BigDlModel = \n        Module.load[T](param.modelPath)\n      case _ =  throw new IllegalArgumentException(s ${param.modelType} )\n    }\n    model\n  }  It then creates  DLClassifer  (a Spark ML pipelines  Transformer ) that predicts the input value based on the specified deep learning model:    val model = loadModel(param)\n  val valTrans = new DLClassifierModel(model, Array(3, imageSize, imageSize))\n    .setBatchSize(param.batchSize)\n    .setFeaturesCol( features )\n    .setPredictionCol( predict )  After that, the  example   loads the input images into a  DataFrame , and then predicts the class of each each image using the  DLClassifer :    val valRDD = sc.parallelize(imageSet).repartition(partitionNum)\n  val transf = RowToByteRecords() - \n      SampleToBGRImg() - \n      BGRImgCropper(imageSize, imageSize) - \n      BGRImgNormalizer(testMean, testStd) - \n      BGRImgToImageVector()\n\n  val valDF = transformDF(sqlContext.createDataFrame(valRDD), transf)\n\n  valTrans.transform(valDF, paramsTrans)\n      .select( imageName ,  predict )\n      .show(param.showNum)", 
            "title": "Image Classification - Working with Spark DataFrame and ML pipeline"
        }, 
        {
            "location": "/ScalaUserGuide/resources/", 
            "text": "Scala Models\n\n\nBigDL provides loads of popular models ready for use in your application. Some of them are listed blow. See all in \nscala neural network models\n. \n\n\n\n\nLeNet\n: it demonstrates how to use BigDL to train and evaluate the \nLeNet-5\n network on MNIST data.\n\n\nInception\n: it demonstrates how to use BigDL to train and evaluate \nInception v1\n and \nInception v2\n architecture on the ImageNet data.\n\n\nVGG\n: it demonstrates how to use BigDL to train and evaluate a \nVGG-like\n network on CIFAR-10 data.\n\n\nResNet\n: it demonstrates how to use BigDL to train and evaluate the \nResNet\n architecture on CIFAR-10 data.\n\n\nRNN\n: it demonstrates how to use BigDL to build and train a simple recurrent neural network \n(RNN) for language model\n.\n\n\nAuto-encoder\n: it demonstrates how to use BigDL to build and train a basic fully-connected autoencoder using MNIST data.\n\n\n\n\n\n\nScala Example\n\n\nBigDL ships plenty of Scala examples to show how to use BigDL to solve real problems. Some are listed blow. See all of them in \nscala deep learning examples\n \n\n\n\n\nText Classification\n:\n    it demonstrates how to use BigDL to build a \ntext classifier\n using a simple convolutional neural network (CNN) model.\n\n\nImage Classification\n:\n    it demonstrates how to load a BigDL or \nTorch\n model trained on ImageNet data (e.g., \nInception\n or \nResNet\n),\n    and then applies the loaded model to classify the contents of a set of images in Spark ML pipeline.\n\n\nLoad Model\n:\n    it demonstrates how to use BigDL to load a pre-trained \nTorch\n or \nCaffe\n model into Spark program for prediction.\n\n\nML Pipline\n:\n    it demonstrates how to use BigDL DLClassifier to train a Logistic Regression Model. DLClassifier extends Spark Estimator and can act as a stage in a ML Pipeline.\n\n\nTreeLSTM Sentiment\n:\n    it demonstrates how to use BigDL train a model on \nStanford Treebank dataset\n dataset using binary TreeLSTM and \nGlove\n\n    word embedding vectors.\n\n\nUDF Predictor\n:\n    it demonstrates how to load BigDL model as UDF to perform predictions in Spark SQL/Dataframes.", 
            "title": "More Resources"
        }, 
        {
            "location": "/ScalaUserGuide/resources/#scala-models", 
            "text": "BigDL provides loads of popular models ready for use in your application. Some of them are listed blow. See all in  scala neural network models .    LeNet : it demonstrates how to use BigDL to train and evaluate the  LeNet-5  network on MNIST data.  Inception : it demonstrates how to use BigDL to train and evaluate  Inception v1  and  Inception v2  architecture on the ImageNet data.  VGG : it demonstrates how to use BigDL to train and evaluate a  VGG-like  network on CIFAR-10 data.  ResNet : it demonstrates how to use BigDL to train and evaluate the  ResNet  architecture on CIFAR-10 data.  RNN : it demonstrates how to use BigDL to build and train a simple recurrent neural network  (RNN) for language model .  Auto-encoder : it demonstrates how to use BigDL to build and train a basic fully-connected autoencoder using MNIST data.", 
            "title": "Scala Models"
        }, 
        {
            "location": "/ScalaUserGuide/resources/#scala-example", 
            "text": "BigDL ships plenty of Scala examples to show how to use BigDL to solve real problems. Some are listed blow. See all of them in  scala deep learning examples     Text Classification :\n    it demonstrates how to use BigDL to build a  text classifier  using a simple convolutional neural network (CNN) model.  Image Classification :\n    it demonstrates how to load a BigDL or  Torch  model trained on ImageNet data (e.g.,  Inception  or  ResNet ),\n    and then applies the loaded model to classify the contents of a set of images in Spark ML pipeline.  Load Model :\n    it demonstrates how to use BigDL to load a pre-trained  Torch  or  Caffe  model into Spark program for prediction.  ML Pipline :\n    it demonstrates how to use BigDL DLClassifier to train a Logistic Regression Model. DLClassifier extends Spark Estimator and can act as a stage in a ML Pipeline.  TreeLSTM Sentiment :\n    it demonstrates how to use BigDL train a model on  Stanford Treebank dataset  dataset using binary TreeLSTM and  Glove \n    word embedding vectors.  UDF Predictor :\n    it demonstrates how to load BigDL model as UDF to perform predictions in Spark SQL/Dataframes.", 
            "title": "Scala Example"
        }, 
        {
            "location": "/PythonUserGuide/install-from-pip/", 
            "text": "NOTES\n\n\n\n\nPip install supports \nMac\n and \nLinux\n platforms.\n\n\nYou need to install Java \n= JDK8\n before runing BigDL, which is required by \nPySpark 2.2.0\n.\n\n\nPip install only supports \nlocal\n mode. Might support cluster mode in the future. For those who want to use BigDL in cluster mode, try to \ninstall without pip\n.\n\n\nWe've tested this package with \nPython 2.7\n, \nPython 3.5\n and \nPython 3.6\n. Only these three Python versions are supported for now.\n\n\nNote that \nPython 3.6\n is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and 2.2.0. See \nthis issue\n for more discussion.\n\n\n\n\nInstall BigDL-0.6.0.dev0\n\n\nInstall BigDL release via pip (we tested this on pip 9.0.1)\n\n\nRemark:\n\n\n\n\n\n\nYou might need to add \nsudo\n if without permission for the installation.\n\n\n\n\n\n\npyspark\n will be automatically installed first before installing BigDL if it hasn't been detected locally.\n\n\n\n\n\n\npip install --upgrade pip\npip install BigDL==0.6.0.dev0     # for Python 2.7\npip3 install BigDL==0.6.0.dev0    # for Python 3.5 and Python 3.6", 
            "title": "From pip"
        }, 
        {
            "location": "/PythonUserGuide/install-from-pip/#notes", 
            "text": "Pip install supports  Mac  and  Linux  platforms.  You need to install Java  = JDK8  before runing BigDL, which is required by  PySpark 2.2.0 .  Pip install only supports  local  mode. Might support cluster mode in the future. For those who want to use BigDL in cluster mode, try to  install without pip .  We've tested this package with  Python 2.7 ,  Python 3.5  and  Python 3.6 . Only these three Python versions are supported for now.  Note that  Python 3.6  is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and 2.2.0. See  this issue  for more discussion.", 
            "title": "NOTES"
        }, 
        {
            "location": "/PythonUserGuide/install-from-pip/#install-bigdl-060dev0", 
            "text": "Install BigDL release via pip (we tested this on pip 9.0.1)  Remark:    You might need to add  sudo  if without permission for the installation.    pyspark  will be automatically installed first before installing BigDL if it hasn't been detected locally.    pip install --upgrade pip\npip install BigDL==0.6.0.dev0     # for Python 2.7\npip3 install BigDL==0.6.0.dev0    # for Python 3.5 and Python 3.6", 
            "title": "Install BigDL-0.6.0.dev0"
        }, 
        {
            "location": "/PythonUserGuide/install-without-pip/", 
            "text": "Install without pip\n\n\nRemark:\n\n\n\n\nOnly \nPython 2.7\n, \nPython 3.5\n and \nPython 3.6\n are supported for now.\n\n\nNote that \nPython 3.6\n is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and 2.2.0. See \nthis issue\n for more discussion.\n\n\n\n\nSteps:\n\n\n\n\n\n\nDownload Spark\n\n\n\n\n\n\nYou can download the BigDL release and nightly build from the \nRelease Page\n\n  or build the BigDL package from \nsource\n.\n\n\n\n\n\n\nInstall Python dependencies:\n\n\n\n\nBigDL only depends on \nNumpy\n and \nSix\n for now.\n\n\nFor Spark standalone cluster:\n\n\nIf you're running in cluster mode, you need to install Python dependencies on both client and each worker node.\n\n\nInstall Numpy: \n   \nsudo apt-get install python-numpy\n (Ubuntu)\n\n\nInstall Six: \n   \nsudo apt-get install python-six\n (Ubuntu)\n\n\n\n\n\n\n\n\n\n* For Yarn cluster:\n    - You can run BigDL Python programs on YARN clusters without changes to the cluster (e.g., no need to pre-install the Python dependencies). You can first package all the required Python dependencies into a virtual environment on the local node (where you will run the spark-submit command), and then directly use spark-submit to run the BigDL Python program on the YARN cluster (using that virtual environment). Please follow the steps below: \n    * Make sure you already install such libraries(python-setuptools, python-dev, gcc, make, zip, pip) for creating virtual environment. If not, please install them first. For example, on Ubuntu, run these commands to install:\n      \napt-get update\n        apt-get install -y python-setuptools python-dev\n        apt-get install -y gcc make\n        apt-get install -y zip\n        easy_install pip\n \n\n     * Create dependency virtualenv package\n        * Under BigDL home directory, you can find \nbin/python_package.sh\n. Run this script to create dependency virtual environment according to dependency descriptions in requirements.txt. You can add your own dependencies in requirements.txt. The current requirements.txt only contains dependencies for BigDL python examples and models.\n        * After running this script, there will be venv.zip and venv directory generated in current directory. Use them to submit your python jobs. Please refer to \nexample\n script of submitting bigdl python job with virtual environment in Yarn cluster.\n\n\n__FAQ__\n\nIn case you encounter the following errors when you create the environment package using the above command:\n\n1. virtualenv ImportError: No module named urllib3\n    - Using python in anaconda to create virtualenv may cause this problem. Try using python default in your system instead of installing virtualenv in anaconda.\n2. AttributeError: 'module' object has no attribute 'sslwrap'\n    - Try upgrading `gevent` with `pip install --upgrade gevent`.", 
            "title": "Without pip"
        }, 
        {
            "location": "/PythonUserGuide/install-without-pip/#install-without-pip", 
            "text": "Remark:   Only  Python 2.7 ,  Python 3.5  and  Python 3.6  are supported for now.  Note that  Python 3.6  is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and 2.2.0. See  this issue  for more discussion.   Steps:    Download Spark    You can download the BigDL release and nightly build from the  Release Page \n  or build the BigDL package from  source .    Install Python dependencies:   BigDL only depends on  Numpy  and  Six  for now.  For Spark standalone cluster:  If you're running in cluster mode, you need to install Python dependencies on both client and each worker node.  Install Numpy: \n    sudo apt-get install python-numpy  (Ubuntu)  Install Six: \n    sudo apt-get install python-six  (Ubuntu)     \n* For Yarn cluster:\n    - You can run BigDL Python programs on YARN clusters without changes to the cluster (e.g., no need to pre-install the Python dependencies). You can first package all the required Python dependencies into a virtual environment on the local node (where you will run the spark-submit command), and then directly use spark-submit to run the BigDL Python program on the YARN cluster (using that virtual environment). Please follow the steps below: \n    * Make sure you already install such libraries(python-setuptools, python-dev, gcc, make, zip, pip) for creating virtual environment. If not, please install them first. For example, on Ubuntu, run these commands to install:\n       apt-get update\n        apt-get install -y python-setuptools python-dev\n        apt-get install -y gcc make\n        apt-get install -y zip\n        easy_install pip   \n     * Create dependency virtualenv package\n        * Under BigDL home directory, you can find  bin/python_package.sh . Run this script to create dependency virtual environment according to dependency descriptions in requirements.txt. You can add your own dependencies in requirements.txt. The current requirements.txt only contains dependencies for BigDL python examples and models.\n        * After running this script, there will be venv.zip and venv directory generated in current directory. Use them to submit your python jobs. Please refer to  example  script of submitting bigdl python job with virtual environment in Yarn cluster.  __FAQ__\n\nIn case you encounter the following errors when you create the environment package using the above command:\n\n1. virtualenv ImportError: No module named urllib3\n    - Using python in anaconda to create virtualenv may cause this problem. Try using python default in your system instead of installing virtualenv in anaconda.\n2. AttributeError: 'module' object has no attribute 'sslwrap'\n    - Try upgrading `gevent` with `pip install --upgrade gevent`.", 
            "title": "Install without pip"
        }, 
        {
            "location": "/PythonUserGuide/run-from-pip/", 
            "text": "Precondition\n\n\n\n\nInstall via pip\n\n\n\n\nUse an Interactive Shell\n\n\n\n\nType \npython\n in the command line to start a REPL.\n\n\nOnly \nPython 2.7\n, \nPython 3.5\n and \nPython 3.6\n are supported for now.\n\n\nNote that \nPython 3.6\n is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and 2.2.0. See \nthis issue\n for more discussion.\n\n\n\n\nRun as a local program\n\n\n\n\nIf the type of input data is ndarray instead of RDD or DataFrame, the model would be trained or validated in local mode.\n\n\nCheck \nLeNet\n for more details.\n\n\n\n\n# X_train, Y_train, X_test are all ndarray and the first dimension is the sample number.\nlocal_optimizer = Optimizer.create(\n    model=model_definition,\n    training_set=(X_train, Y_train))\nlocal_optimizer.predict(X_test)\nlocal_optimizer.predict_class(X_test)\n\n\n\n\nUse Jupyter Notebook\n\n\n\n\nJust start jupyter notebook as you normally do, e.g.\n\n\n\n\n jupyter notebook --notebook-dir=./ --ip=* --no-browser\n\n\n\n\n\n\nExample code to verify if BigDL can run successfully\n\n\nfrom bigdl.util.common import *\nfrom pyspark import SparkContext\nfrom bigdl.nn.layer import *\nimport bigdl.version\n\n# create sparkcontext with bigdl configuration\nsc = SparkContext.getOrCreate(conf=create_spark_conf().setMaster(\nlocal[*]\n))\ninit_engine() # prepare the bigdl environment \nbigdl.version.__version__ # Get the current BigDL version\nlinear = Linear(2, 3) # Try to create a Linear layer\n\n\n\n\nBigDL Configurations\n\n\n\n\nIncrease memory\n\n\n\n\nexport SPARK_DRIVER_MEMORY=20g\n\n\n\n\n\n\nAdd extra jars or python packages\n\n\n\n\n Set the environment variables \nBIGDL_JARS\n and \nBIGDL_PACKAGES\n \nBEFORE\n creating \nSparkContext\n:\n\n\nexport BIGDL_JARS=...\nexport BIGDL_PACKAGES=...\n\n\n\n\n\n\nRedirect logs\n\n\n\n\n If you want to redirect spark logs to file and keep BigDL logs in console only, call the following API before you train your model:\n\n\nfrom bigdl.util.common import *\n\n# by default redirected to `bigdl.log` under the current workspace\nredire_spark_logs(log_path=\nbigdl.log\n)\nshow_bigdl_info_logs()", 
            "title": "After pip install"
        }, 
        {
            "location": "/PythonUserGuide/run-from-pip/#precondition", 
            "text": "Install via pip", 
            "title": "Precondition"
        }, 
        {
            "location": "/PythonUserGuide/run-from-pip/#use-an-interactive-shell", 
            "text": "Type  python  in the command line to start a REPL.  Only  Python 2.7 ,  Python 3.5  and  Python 3.6  are supported for now.  Note that  Python 3.6  is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and 2.2.0. See  this issue  for more discussion.", 
            "title": "Use an Interactive Shell"
        }, 
        {
            "location": "/PythonUserGuide/run-from-pip/#run-as-a-local-program", 
            "text": "If the type of input data is ndarray instead of RDD or DataFrame, the model would be trained or validated in local mode.  Check  LeNet  for more details.   # X_train, Y_train, X_test are all ndarray and the first dimension is the sample number.\nlocal_optimizer = Optimizer.create(\n    model=model_definition,\n    training_set=(X_train, Y_train))\nlocal_optimizer.predict(X_test)\nlocal_optimizer.predict_class(X_test)", 
            "title": "Run as a local program"
        }, 
        {
            "location": "/PythonUserGuide/run-from-pip/#use-jupyter-notebook", 
            "text": "Just start jupyter notebook as you normally do, e.g.    jupyter notebook --notebook-dir=./ --ip=* --no-browser", 
            "title": "Use Jupyter Notebook"
        }, 
        {
            "location": "/PythonUserGuide/run-from-pip/#example-code-to-verify-if-bigdl-can-run-successfully", 
            "text": "from bigdl.util.common import *\nfrom pyspark import SparkContext\nfrom bigdl.nn.layer import *\nimport bigdl.version\n\n# create sparkcontext with bigdl configuration\nsc = SparkContext.getOrCreate(conf=create_spark_conf().setMaster( local[*] ))\ninit_engine() # prepare the bigdl environment \nbigdl.version.__version__ # Get the current BigDL version\nlinear = Linear(2, 3) # Try to create a Linear layer", 
            "title": "Example code to verify if BigDL can run successfully"
        }, 
        {
            "location": "/PythonUserGuide/run-from-pip/#bigdl-configurations", 
            "text": "Increase memory   export SPARK_DRIVER_MEMORY=20g   Add extra jars or python packages    Set the environment variables  BIGDL_JARS  and  BIGDL_PACKAGES   BEFORE  creating  SparkContext :  export BIGDL_JARS=...\nexport BIGDL_PACKAGES=...   Redirect logs    If you want to redirect spark logs to file and keep BigDL logs in console only, call the following API before you train your model:  from bigdl.util.common import *\n\n# by default redirected to `bigdl.log` under the current workspace\nredire_spark_logs(log_path= bigdl.log )\nshow_bigdl_info_logs()", 
            "title": "BigDL Configurations"
        }, 
        {
            "location": "/PythonUserGuide/run-without-pip/", 
            "text": "Precondition\n\n\nFirst of all, you need to obtain the BigDL libs. Refer to \nInstall from pre built\n\nor \nInstall from source code\n for more details\n\n\nRemark\n\n\n\n\nOnly \nPython 2.7\n, \nPython 3.5\n and \nPython 3.6\n are supported for now.\n\n\nNote that \nPython 3.6\n is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and 2.2.0. See \nthis issue\n for more discussion.\n\n\n\n\nSet Environment Variables\n\n\nSet \nBIGDL_HOME\n and \nSPARK_HOME\n:\n\n\n\n\nIf you download BigDL from the \nRelease Page\n\n\n\n\nexport SPARK_HOME=folder path where you extract the spark package\nexport BIGDL_HOME=folder path where you extract the bigdl package\n\n\n\n\n\n\nIf you build BigDL by yourself\n\n\n\n\nexport SPARK_HOME=folder path where you extract the spark package\nexport BIGDL_HOME=the dist folder generated by the build process, which is under the top level of the source folder\n\n\n\n\nUpdate spark-bigdl.conf (Optional)\n\n\nIf you have some customized properties in some files, which is used with the \n--properties-file\n option\nin spark-submit/pyspark, add these customized properties into ${BIGDL_HOME}/conf/spark-bigdl.conf.\n\n\nRun with pyspark\n\n\n${BIGDL_HOME}/bin/pyspark-with-bigdl.sh --master local[*]\n\n\n\n\n\n\n--master\n set the master URL to connect to\n\n\n--jars\n if there are extra jars needed.\n\n\n--py-files\n if there are extra python packages needed.\n\n\n\n\nYou can also specify other options available for pyspark in the above command if needed.\n\n\nExample code to verify if BigDL can run successfully\n\n\nRun with spark-submit\n\n\nA BigDL Python program runs as a standard pyspark program, which requires all Python dependencies\n(e.g., NumPy) used by the program to be installed on each node in the Spark cluster. You can try\nrunning the BigDL \nlenet Python example\n\nas follows:\n\n\n${BIGDL_HOME}/bin/spark-submit-with-bigdl.sh --master local[4] lenet5.py\n\n\n\n\nRun with Jupyter\n\n\nWith the full Python API support in BigDL, users can use BigDL together with powerful notebooks\n(such as Jupyter notebook) in a distributed fashion across the cluster, combining Python libraries,\nSpark SQL / dataframes and MLlib, deep learning models in BigDL, as well as interactive\nvisualization tools.\n\n\nPrerequisites\n: Install all the necessary libraries on the local node where you will run Jupyter, e.g., \n\n\nsudo apt install python\nsudo apt install python-pip\nsudo pip install numpy scipy pandas scikit-learn matplotlib seaborn wordcloud\n\n\n\n\nLaunch the Jupyter notebook as follows:\n\n\n${BIGDL_HOME}/bin/jupyter-with-bigdl.sh --master local[*]\n\n\n\n\n\n\n--master\n set the master URL to connect to\n\n\n--jars\n if there are extra jars needed.\n\n\n--py-files\n if there are extra python packages needed.\n\n\n\n\nYou can also specify other options available for pyspark in the above command if needed.\n\n\nAfter successfully launching Jupyter, you will be able to navigate to the notebook dashboard using\nyour browser. You can find the exact URL in the console output when you started Jupyter; by default,\nthe dashboard URL is http://your_node:8888/\n\n\nExample code to verify if BigDL can run successfully\n\n\n\n\nRun with virtual environment in Yarn\n\n\nIf you already created BigDL dependency virtual environment according to \nYarn cluster guide in install without pip \n, you can run python program using BigDL as following examples.\n\n\n\n\nNote: please set BigDL_HOME, SPARK_HOME environment. Set VENV_HOME to the parent directory of venv.zip and venv directory. Replace VERSION with your BigDL version, like 0.5.0. If you don't install BigDL from source, replace ${BigDL_HOME}/pyspark/bigdl/examples/lenet/lenet.py with your python program which is using BigDL.\n\n\nYarn cluster mode\n\n\n\n\n    BigDL_HOME=\n    SPARK_HOME=\n    PYTHON_API_PATH=${BigDL_HOME}/dist/lib/bigdl-VERSION-python-api.zip\n    BigDL_JAR_PATH=${BigDL_HOME}/dist/lib/bigdl-VERSION-jar-with-dependencies.jar\n    PYTHONPATH=${PYTHON_API_PATH}:$PYTHONPATH\n    VENV_HOME=\n\n    PYSPARK_PYTHON=./venv.zip/venv/bin/python ${SPARK_HOME}/bin/spark-submit \\\n    --conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=./venv.zip/venv/bin/python \\\n    --master yarn-cluster \\\n    --executor-memory 10g \\\n    --driver-memory 10g \\\n    --executor-cores 8 \\\n    --num-executors 2 \\\n    --properties-file ${BigDL_HOME}/dist/conf/spark-bigdl.conf \\\n    --jars ${BigDL_JAR_PATH} \\\n    --py-files ${PYTHON_API_PATH} \\\n    --archives ${VENV_HOME}/venv.zip \\\n    --conf spark.driver.extraClassPath=bigdl-VERSION-jar-with-dependencies.jar \\\n    --conf spark.executor.extraClassPath=bigdl-VERSION-jar-with-dependencies.jar \\\n    ${BigDL_HOME}/pyspark/bigdl/examples/lenet/lenet.py\n\n\n\n\n\n\n\n\nYarn client mode\n```\n    BigDL_HOME=\n    SPARK_HOME=\n    PYTHON_API_PATH=${BigDL_HOME}/dist/lib/bigdl-VERSION-python-api.zip\n    BigDL_JAR_PATH=${BigDL_HOME}/dist/lib/bigdl-VERSION-jar-with-dependencies.jar\n    PYTHONPATH=${PYTHON_API_PATH}:$PYTHONPATH\n    VENV_HOME=\n\n\nPYSPARK_DRIVER_PYTHON=${VENV_HOME}/venv/bin/python PYSPARK_PYTHON=./venv.zip/venv/bin/python ${SPARK_HOME}/bin/spark-submit \\\n--master yarn \\\n--deploy-mode client \\\n--executor-memory 10g \\\n--driver-memory 10g \\\n--executor-cores 16 \\\n--num-executors 2 \\\n--properties-file ${BigDL_HOME}/dist/conf/spark-bigdl.conf \\\n--jars ${BigDL_JAR_PATH} \\\n--py-files ${PYTHON_API_PATH} \\\n--archives ${VENV_HOME}/venv.zip \\\n--conf spark.driver.extraClassPath=${BigDL_JAR_PATH} \\\n--conf spark.executor.extraClassPath=bigdl-VERSION-jar-with-dependencies.jar \\\n${BigDL_HOME}/pyspark/bigdl/examples/lenet/lenet.py\n ```\n\n\n\n\n\n\nBigDL Configuration\n\n\nPlease check \nthis page", 
            "title": "Without pip install"
        }, 
        {
            "location": "/PythonUserGuide/run-without-pip/#precondition", 
            "text": "First of all, you need to obtain the BigDL libs. Refer to  Install from pre built \nor  Install from source code  for more details", 
            "title": "Precondition"
        }, 
        {
            "location": "/PythonUserGuide/run-without-pip/#remark", 
            "text": "Only  Python 2.7 ,  Python 3.5  and  Python 3.6  are supported for now.  Note that  Python 3.6  is only compatible with Spark 1.6.4, 2.0.3, 2.1.1 and 2.2.0. See  this issue  for more discussion.", 
            "title": "Remark"
        }, 
        {
            "location": "/PythonUserGuide/run-without-pip/#set-environment-variables", 
            "text": "Set  BIGDL_HOME  and  SPARK_HOME :   If you download BigDL from the  Release Page   export SPARK_HOME=folder path where you extract the spark package\nexport BIGDL_HOME=folder path where you extract the bigdl package   If you build BigDL by yourself   export SPARK_HOME=folder path where you extract the spark package\nexport BIGDL_HOME=the dist folder generated by the build process, which is under the top level of the source folder", 
            "title": "Set Environment Variables"
        }, 
        {
            "location": "/PythonUserGuide/run-without-pip/#update-spark-bigdlconf-optional", 
            "text": "If you have some customized properties in some files, which is used with the  --properties-file  option\nin spark-submit/pyspark, add these customized properties into ${BIGDL_HOME}/conf/spark-bigdl.conf.", 
            "title": "Update spark-bigdl.conf (Optional)"
        }, 
        {
            "location": "/PythonUserGuide/run-without-pip/#run-with-pyspark", 
            "text": "${BIGDL_HOME}/bin/pyspark-with-bigdl.sh --master local[*]   --master  set the master URL to connect to  --jars  if there are extra jars needed.  --py-files  if there are extra python packages needed.   You can also specify other options available for pyspark in the above command if needed.  Example code to verify if BigDL can run successfully", 
            "title": "Run with pyspark"
        }, 
        {
            "location": "/PythonUserGuide/run-without-pip/#run-with-spark-submit", 
            "text": "A BigDL Python program runs as a standard pyspark program, which requires all Python dependencies\n(e.g., NumPy) used by the program to be installed on each node in the Spark cluster. You can try\nrunning the BigDL  lenet Python example \nas follows:  ${BIGDL_HOME}/bin/spark-submit-with-bigdl.sh --master local[4] lenet5.py", 
            "title": "Run with spark-submit"
        }, 
        {
            "location": "/PythonUserGuide/run-without-pip/#run-with-jupyter", 
            "text": "With the full Python API support in BigDL, users can use BigDL together with powerful notebooks\n(such as Jupyter notebook) in a distributed fashion across the cluster, combining Python libraries,\nSpark SQL / dataframes and MLlib, deep learning models in BigDL, as well as interactive\nvisualization tools.  Prerequisites : Install all the necessary libraries on the local node where you will run Jupyter, e.g.,   sudo apt install python\nsudo apt install python-pip\nsudo pip install numpy scipy pandas scikit-learn matplotlib seaborn wordcloud  Launch the Jupyter notebook as follows:  ${BIGDL_HOME}/bin/jupyter-with-bigdl.sh --master local[*]   --master  set the master URL to connect to  --jars  if there are extra jars needed.  --py-files  if there are extra python packages needed.   You can also specify other options available for pyspark in the above command if needed.  After successfully launching Jupyter, you will be able to navigate to the notebook dashboard using\nyour browser. You can find the exact URL in the console output when you started Jupyter; by default,\nthe dashboard URL is http://your_node:8888/  Example code to verify if BigDL can run successfully", 
            "title": "Run with Jupyter"
        }, 
        {
            "location": "/PythonUserGuide/run-without-pip/#run-with-virtual-environment-in-yarn", 
            "text": "If you already created BigDL dependency virtual environment according to  Yarn cluster guide in install without pip  , you can run python program using BigDL as following examples.   Note: please set BigDL_HOME, SPARK_HOME environment. Set VENV_HOME to the parent directory of venv.zip and venv directory. Replace VERSION with your BigDL version, like 0.5.0. If you don't install BigDL from source, replace ${BigDL_HOME}/pyspark/bigdl/examples/lenet/lenet.py with your python program which is using BigDL.  Yarn cluster mode       BigDL_HOME=\n    SPARK_HOME=\n    PYTHON_API_PATH=${BigDL_HOME}/dist/lib/bigdl-VERSION-python-api.zip\n    BigDL_JAR_PATH=${BigDL_HOME}/dist/lib/bigdl-VERSION-jar-with-dependencies.jar\n    PYTHONPATH=${PYTHON_API_PATH}:$PYTHONPATH\n    VENV_HOME=\n\n    PYSPARK_PYTHON=./venv.zip/venv/bin/python ${SPARK_HOME}/bin/spark-submit \\\n    --conf spark.yarn.appMasterEnv.PYSPARK_PYTHON=./venv.zip/venv/bin/python \\\n    --master yarn-cluster \\\n    --executor-memory 10g \\\n    --driver-memory 10g \\\n    --executor-cores 8 \\\n    --num-executors 2 \\\n    --properties-file ${BigDL_HOME}/dist/conf/spark-bigdl.conf \\\n    --jars ${BigDL_JAR_PATH} \\\n    --py-files ${PYTHON_API_PATH} \\\n    --archives ${VENV_HOME}/venv.zip \\\n    --conf spark.driver.extraClassPath=bigdl-VERSION-jar-with-dependencies.jar \\\n    --conf spark.executor.extraClassPath=bigdl-VERSION-jar-with-dependencies.jar \\\n    ${BigDL_HOME}/pyspark/bigdl/examples/lenet/lenet.py    Yarn client mode\n```\n    BigDL_HOME=\n    SPARK_HOME=\n    PYTHON_API_PATH=${BigDL_HOME}/dist/lib/bigdl-VERSION-python-api.zip\n    BigDL_JAR_PATH=${BigDL_HOME}/dist/lib/bigdl-VERSION-jar-with-dependencies.jar\n    PYTHONPATH=${PYTHON_API_PATH}:$PYTHONPATH\n    VENV_HOME=  PYSPARK_DRIVER_PYTHON=${VENV_HOME}/venv/bin/python PYSPARK_PYTHON=./venv.zip/venv/bin/python ${SPARK_HOME}/bin/spark-submit \\\n--master yarn \\\n--deploy-mode client \\\n--executor-memory 10g \\\n--driver-memory 10g \\\n--executor-cores 16 \\\n--num-executors 2 \\\n--properties-file ${BigDL_HOME}/dist/conf/spark-bigdl.conf \\\n--jars ${BigDL_JAR_PATH} \\\n--py-files ${PYTHON_API_PATH} \\\n--archives ${VENV_HOME}/venv.zip \\\n--conf spark.driver.extraClassPath=${BigDL_JAR_PATH} \\\n--conf spark.executor.extraClassPath=bigdl-VERSION-jar-with-dependencies.jar \\\n${BigDL_HOME}/pyspark/bigdl/examples/lenet/lenet.py\n ```", 
            "title": "Run with virtual environment in Yarn"
        }, 
        {
            "location": "/PythonUserGuide/run-without-pip/#bigdl-configuration", 
            "text": "Please check  this page", 
            "title": "BigDL Configuration"
        }, 
        {
            "location": "/PythonUserGuide/python-faq/", 
            "text": "This page lists solutions to some common questions.\n\n\n\n\n\n\nImportError\n: from\u00a0bigdl.nn.layer\u00a0import\u00a0*\n\n\n\n\nCheck if the path is pointing to python-api.zip: \n--py-files ${PYTHON_API_ZIP_PATH}\n\n\nCheck if the path is pointing to python-api.zip: \nexport PYTHONPATH=${PYTHON_API_ZIP_PATH}:$PYTHONPATH\n\n\n\n\n\n\n\n\nPython in worker has a different version 2.7 than that in driver 3.5\n\n\n\n\nexport PYSPARK_PYTHON=/usr/local/bin/python3.5\n  This path should be valid on every worker node.\n\n\nexport PYSPARK_DRIVER_PYTHON=/usr/local/bin/python3.5\n  This path should be valid on every driver node.\n\n\n\n\n\n\n\n\nTypeError\n: 'JavaPackage' object is not callable\n\n\n\n\nCheck if every path within the launch script is valid especially the path that ends with jar.\n\n\nIf there are extra jars involved, check if the Spark version BigDL is built and the Spark version the extra jar is built are compatible.\n\n\n\n\n\n\n\n\njava.lang.\nNoSuchMethodError\n:XXX or \nPy4JError\n: ofFloat does not exist in the JVM\n\n\n\n\nCheck if the Spark version matches, i.e check if you are using Spark2.x but the underneath BigDL is compiled with Spark1.6.\n\n\nIf there are extra jars involved, also check if the Spark version matches.\n\n\n\n\n\n\n\n\nLogs are not displayed properly during the training process.\n\n\n\n\nCall the following API before you train your model to redirect spark logs to file and keep BigDL logs in console only.\n\n\n\n\n\n\n\n\nfrom bigdl.util.common import *\n\n# by default redirected to `bigdl.log` under the current workspace\nredire_spark_logs(log_path=\nbigdl.log\n)\nshow_bigdl_info_logs()", 
            "title": "FAQ"
        }, 
        {
            "location": "/PythonUserGuide/python-examples/", 
            "text": "Text Classification using BigDL Python API\n\n\nThis tutorial describes the \ntextclassifier\n example written using BigDL Python API, which builds a text classifier using a CNN (convolutional neural network) or LSTM or GRU model (as specified by the user). (It was first described by \nthis Keras tutorial\n)\n\n\nThe example first creates the \nSparkContext\n using the SparkConf\nreturn by the\ncreate_spark_conf()` method, and then initialize the engine:\n\n\n  sc = SparkContext(appName=\ntext_classifier\n,\n                    conf=create_spark_conf())\n  init_engine()\n\n\n\n\nIt then loads the \n20 Newsgroup dataset\n into RDD, and transforms the input data into an RDD of \nSample\n. (Each \nSample\n in essence contains a tuple of two NumPy ndarray representing the feature and label).\n\n\n  texts = news20.get_news20()\n  data_rdd = sc.parallelize(texts, 2)\n  ...\n  sample_rdd = vector_rdd.map(\n      lambda (vectors, label): to_sample(vectors, label, embedding_dim))\n  train_rdd, val_rdd = sample_rdd.randomSplit(\n      [training_split, 1-training_split])   \n\n\n\n\nAfter that, the example creates the neural network model as follows:\n\n\ndef build_model(class_num):\n    model = Sequential()\n\n    if model_type.lower() == \ncnn\n:\n        model.add(Reshape([embedding_dim, 1, sequence_len]))\n        model.add(SpatialConvolution(embedding_dim, 128, 5, 1))\n        model.add(ReLU())\n        model.add(SpatialMaxPooling(5, 1, 5, 1))\n        model.add(SpatialConvolution(128, 128, 5, 1))\n        model.add(ReLU())\n        model.add(SpatialMaxPooling(5, 1, 5, 1))\n        model.add(Reshape([128]))\n    elif model_type.lower() == \nlstm\n:\n        model.add(Recurrent()\n                  .add(LSTM(embedding_dim, 128)))\n        model.add(Select(2, -1))\n    elif model_type.lower() == \ngru\n:\n        model.add(Recurrent()\n                  .add(GRU(embedding_dim, 128)))\n        model.add(Select(2, -1))\n    else:\n        raise ValueError('model can only be cnn, lstm, or gru')\n\n    model.add(Linear(128, 100))\n    model.add(Linear(100, class_num))\n    model.add(LogSoftMax())\n    return model\n\n\n\n\nFinally the example creates the \nOptimizer\n (which accepts both the model and the training Sample RDD) and trains the model by calling \nOptimizer.optimize()\n:\n\n\noptimizer = Optimizer(\n    model=build_model(news20.CLASS_NUM),\n    training_rdd=train_rdd,\n    criterion=ClassNLLCriterion(),\n    end_trigger=MaxEpoch(max_epoch),\n    batch_size=batch_size,\n    optim_method=Adagrad())\n...\ntrain_model = optimizer.optimize()", 
            "title": "Examples"
        }, 
        {
            "location": "/PythonUserGuide/python-examples/#text-classification-using-bigdl-python-api", 
            "text": "This tutorial describes the  textclassifier  example written using BigDL Python API, which builds a text classifier using a CNN (convolutional neural network) or LSTM or GRU model (as specified by the user). (It was first described by  this Keras tutorial )  The example first creates the  SparkContext  using the SparkConf return by the create_spark_conf()` method, and then initialize the engine:    sc = SparkContext(appName= text_classifier ,\n                    conf=create_spark_conf())\n  init_engine()  It then loads the  20 Newsgroup dataset  into RDD, and transforms the input data into an RDD of  Sample . (Each  Sample  in essence contains a tuple of two NumPy ndarray representing the feature and label).    texts = news20.get_news20()\n  data_rdd = sc.parallelize(texts, 2)\n  ...\n  sample_rdd = vector_rdd.map(\n      lambda (vectors, label): to_sample(vectors, label, embedding_dim))\n  train_rdd, val_rdd = sample_rdd.randomSplit(\n      [training_split, 1-training_split])     After that, the example creates the neural network model as follows:  def build_model(class_num):\n    model = Sequential()\n\n    if model_type.lower() ==  cnn :\n        model.add(Reshape([embedding_dim, 1, sequence_len]))\n        model.add(SpatialConvolution(embedding_dim, 128, 5, 1))\n        model.add(ReLU())\n        model.add(SpatialMaxPooling(5, 1, 5, 1))\n        model.add(SpatialConvolution(128, 128, 5, 1))\n        model.add(ReLU())\n        model.add(SpatialMaxPooling(5, 1, 5, 1))\n        model.add(Reshape([128]))\n    elif model_type.lower() ==  lstm :\n        model.add(Recurrent()\n                  .add(LSTM(embedding_dim, 128)))\n        model.add(Select(2, -1))\n    elif model_type.lower() ==  gru :\n        model.add(Recurrent()\n                  .add(GRU(embedding_dim, 128)))\n        model.add(Select(2, -1))\n    else:\n        raise ValueError('model can only be cnn, lstm, or gru')\n\n    model.add(Linear(128, 100))\n    model.add(Linear(100, class_num))\n    model.add(LogSoftMax())\n    return model  Finally the example creates the  Optimizer  (which accepts both the model and the training Sample RDD) and trains the model by calling  Optimizer.optimize() :  optimizer = Optimizer(\n    model=build_model(news20.CLASS_NUM),\n    training_rdd=train_rdd,\n    criterion=ClassNLLCriterion(),\n    end_trigger=MaxEpoch(max_epoch),\n    batch_size=batch_size,\n    optim_method=Adagrad())\n...\ntrain_model = optimizer.optimize()", 
            "title": "Text Classification using BigDL Python API"
        }, 
        {
            "location": "/PythonUserGuide/python-resources/", 
            "text": "Models/Examples\n\n\nBigDL provides plenty of Python models and examples ready for re-use. Some are listed blow. See all in \npython models\n.\n\n\n\n\nLeNet\n: it demonstrates how to use BigDL Python APIs to train and evaluate the \nLeNet-5\n network on MNIST data.\n\n\nText Classifier\n:  it demonstrates how to use BigDL Python APIs to build a text classifier using a simple [convolutional neural network (CNN) model(https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html)] or a simple LSTM/GRU model.\n\n\nJupyter Notebook Tutorial\n: it contains a tutorial for using BigDL Python APIs in Jupyter notebooks (together with TensorBoard support) for interactive data explorations and visualizations.\n\n\n\n\n\n\nTutorial Notebooks\n\n\nBigDL Tutorials Notebooks\n - A series of notebooks that step-by- step introduce you how to do data science on Apache Spark and BigDL framework", 
            "title": "More Examples and Tutorials"
        }, 
        {
            "location": "/PythonUserGuide/python-resources/#modelsexamples", 
            "text": "BigDL provides plenty of Python models and examples ready for re-use. Some are listed blow. See all in  python models .   LeNet : it demonstrates how to use BigDL Python APIs to train and evaluate the  LeNet-5  network on MNIST data.  Text Classifier :  it demonstrates how to use BigDL Python APIs to build a text classifier using a simple [convolutional neural network (CNN) model(https://blog.keras.io/using-pre-trained-word-embeddings-in-a-keras-model.html)] or a simple LSTM/GRU model.  Jupyter Notebook Tutorial : it contains a tutorial for using BigDL Python APIs in Jupyter notebooks (together with TensorBoard support) for interactive data explorations and visualizations.", 
            "title": "Models/Examples"
        }, 
        {
            "location": "/PythonUserGuide/python-resources/#tutorial-notebooks", 
            "text": "BigDL Tutorials Notebooks  - A series of notebooks that step-by- step introduce you how to do data science on Apache Spark and BigDL framework", 
            "title": "Tutorial Notebooks"
        }, 
        {
            "location": "/ProgrammingGuide/Model/Sequential/", 
            "text": "BigDL supports two different model definition styles: Sequential API and Functional API.\n\n\nHere we introduce how to define a model in Sequential API.\n\n\n\n\nDefine a simple model\n\n\nSuppose we want to define a model with three layers\n\n\nLinear -\n Sigmoid -\n Softmax\n\n\n\n\nYou can write code like this\n\n\nScala:\n\n\nval model = Sequential()\nmodel.add(Linear(...))\nmodel.add(Sigmoid())\nmodel.add(Softmax())\n\n\n\n\nPython:\n\n\nmodel = Sequential()\nmodel.add(Linear(...))\nmodel.add(Sigmoid())\nmodel.add(Softmax())\n\n\n\n\nIn the above code, we first create a container Sequential. Then add the layers\ninto the container one by one. The order of the layers in the model is same with the insertion\norder. This model definition\nlooks very straightforward.\n\n\nBigDL provides multiple types of contianers allow user to define complex model in sequential\nstyle. We will take a look at it.\n\n\n\n\nDefine a model with branches\n\n\nSuppose we want to define a model like this\n\n\nLinear -\n ReLU --\n Linear -\n ReLU\n               |-\n Linear -\n ReLU\n\n\n\n\nThe model has two outputs from two branches. The inputs of the branches are both the\noutput from the first ReLU.\n\n\nYou can define the model like this\n\n\nScala\n\n\nval branch1 = Sequential().add(Linear(...)).add(ReLU())\nval branch2 = Sequential().add(Linear(...)).add(ReLU())\nval branches = ConcatTable().add(branch1).add(branch2)\n\nval model = Sequential()\nmodel.add(Linear(...))\nmodel.add(ReLU())\nmodel.add(branches)\n\n\n\n\nPython\n\n\nbranch1 = Sequential().add(Linear(...)).add(ReLU())\nbranch2 = Sequential().add(Linear(...)).add(ReLU())\nbranches = ConcatTable().add(branch1).add(branch2)\n\nval model = Sequential()\nmodel.add(Linear(...))\nmodel.add(ReLU())\nmodel.add(branches)\n\n\n\n\nIn the above code, to handle the branch structure, we use another container ConcatTable.\nWhen you add layers into ConcatTable, the new layer won't be placed after the previous one\nbut will become a new branch.\n\n\nThe input of the model is a tensor and the output of the model is two tensors.\n\n\n\n\nDefine a model with merged branch\n\n\nSuppose we want to define a model like this\n\n\nLinear -\n ReLU --\n Linear -\n ReLU ----\n Add\n               |-\n Linear -\n ReLU --|\n\n\n\n\nIn the model, the outputs of the two branches are merged by an add operation.\n\n\nYou can define the model like this\n\n\nScala\n\n\nval branch1 = Sequential().add(Linear(...)).add(ReLU())\nval branch2 = Sequential().add(Linear(...)).add(ReLU())\nval branches = ConcatTable().add(branch1).add(branch2)\n\nval model = Sequential()\nmodel.add(Linear(...))\nmodel.add(ReLU())\nmodel.add(branches)\nmodel.add(CAddTable())\n\n\n\n\nPython\n\n\nbranch1 = Sequential().add(Linear(...)).add(ReLU())\nbranch2 = Sequential().add(Linear(...)).add(ReLU())\nbranches = ConcatTable().add(branch1).add(branch2)\n\nval model = Sequential()\nmodel.add(Linear(...))\nmodel.add(ReLU())\nmodel.add(branches)\nmodel.add(CAddTable())\n\n\n\n\nTo merge the outputs of the branches by an add operation, we use CAddTable. It\ntakes a list of tensors from the previous layer, and merge the tensors by adding them together.\n\n\nBigDL provides many merge layers. Please check Merge layers document page. They all\ntake a list of tensors as input and merge the tensors by some operation.\n\n\n\n\nDefine a model with multiple inputs\n\n\nWe have already seen how to define branches in model and how to merge branches.\nWhat if we have multiple input? Suppose we want to define a model like this\n\n\nLinear -\n ReLU ----\n Add\nLinear -\n ReLU --|\n\n\n\n\nThe above model takes two tensors as input, and merge them together by add operation.\n\n\nYou can define the model like this\n\n\nScala\n\n\nval model = Sequential()\nval branches = ParallelTable()\nval branch1 = Sequential().add(Linear(...)).add(ReLU())\nval branch2 = Sequential().add(Linear(...)).add(ReLU())\nbranches.add(branch1).add(branch2)\nmodel.add(branches).add(CAddTable())\n\n\n\n\nPython\n\n\nmodel = Sequential()\nbranches = ParallelTable()\nbranch1 = Sequential().add(Linear(...)).add(ReLU())\nbranch2 = Sequential().add(Linear(...)).add(ReLU())\nbranches.add(branch1).add(branch2)\nmodel.add(branches).add(CAddTable())\n\n\n\n\nIn the above code, we use ParallelTable to handle the multiple inputs. ParallelTable also\ndefine a multiple branches structure like ConcatTable. The difference is it takes a list\nof tensors as inputs and assign each tensor to the corresponding branch.", 
            "title": "Using Sequential API"
        }, 
        {
            "location": "/ProgrammingGuide/Model/Sequential/#define-a-simple-model", 
            "text": "Suppose we want to define a model with three layers  Linear -  Sigmoid -  Softmax  You can write code like this  Scala:  val model = Sequential()\nmodel.add(Linear(...))\nmodel.add(Sigmoid())\nmodel.add(Softmax())  Python:  model = Sequential()\nmodel.add(Linear(...))\nmodel.add(Sigmoid())\nmodel.add(Softmax())  In the above code, we first create a container Sequential. Then add the layers\ninto the container one by one. The order of the layers in the model is same with the insertion\norder. This model definition\nlooks very straightforward.  BigDL provides multiple types of contianers allow user to define complex model in sequential\nstyle. We will take a look at it.", 
            "title": "Define a simple model"
        }, 
        {
            "location": "/ProgrammingGuide/Model/Sequential/#define-a-model-with-branches", 
            "text": "Suppose we want to define a model like this  Linear -  ReLU --  Linear -  ReLU\n               |-  Linear -  ReLU  The model has two outputs from two branches. The inputs of the branches are both the\noutput from the first ReLU.  You can define the model like this  Scala  val branch1 = Sequential().add(Linear(...)).add(ReLU())\nval branch2 = Sequential().add(Linear(...)).add(ReLU())\nval branches = ConcatTable().add(branch1).add(branch2)\n\nval model = Sequential()\nmodel.add(Linear(...))\nmodel.add(ReLU())\nmodel.add(branches)  Python  branch1 = Sequential().add(Linear(...)).add(ReLU())\nbranch2 = Sequential().add(Linear(...)).add(ReLU())\nbranches = ConcatTable().add(branch1).add(branch2)\n\nval model = Sequential()\nmodel.add(Linear(...))\nmodel.add(ReLU())\nmodel.add(branches)  In the above code, to handle the branch structure, we use another container ConcatTable.\nWhen you add layers into ConcatTable, the new layer won't be placed after the previous one\nbut will become a new branch.  The input of the model is a tensor and the output of the model is two tensors.", 
            "title": "Define a model with branches"
        }, 
        {
            "location": "/ProgrammingGuide/Model/Sequential/#define-a-model-with-merged-branch", 
            "text": "Suppose we want to define a model like this  Linear -  ReLU --  Linear -  ReLU ----  Add\n               |-  Linear -  ReLU --|  In the model, the outputs of the two branches are merged by an add operation.  You can define the model like this  Scala  val branch1 = Sequential().add(Linear(...)).add(ReLU())\nval branch2 = Sequential().add(Linear(...)).add(ReLU())\nval branches = ConcatTable().add(branch1).add(branch2)\n\nval model = Sequential()\nmodel.add(Linear(...))\nmodel.add(ReLU())\nmodel.add(branches)\nmodel.add(CAddTable())  Python  branch1 = Sequential().add(Linear(...)).add(ReLU())\nbranch2 = Sequential().add(Linear(...)).add(ReLU())\nbranches = ConcatTable().add(branch1).add(branch2)\n\nval model = Sequential()\nmodel.add(Linear(...))\nmodel.add(ReLU())\nmodel.add(branches)\nmodel.add(CAddTable())  To merge the outputs of the branches by an add operation, we use CAddTable. It\ntakes a list of tensors from the previous layer, and merge the tensors by adding them together.  BigDL provides many merge layers. Please check Merge layers document page. They all\ntake a list of tensors as input and merge the tensors by some operation.", 
            "title": "Define a model with merged branch"
        }, 
        {
            "location": "/ProgrammingGuide/Model/Sequential/#define-a-model-with-multiple-inputs", 
            "text": "We have already seen how to define branches in model and how to merge branches.\nWhat if we have multiple input? Suppose we want to define a model like this  Linear -  ReLU ----  Add\nLinear -  ReLU --|  The above model takes two tensors as input, and merge them together by add operation.  You can define the model like this  Scala  val model = Sequential()\nval branches = ParallelTable()\nval branch1 = Sequential().add(Linear(...)).add(ReLU())\nval branch2 = Sequential().add(Linear(...)).add(ReLU())\nbranches.add(branch1).add(branch2)\nmodel.add(branches).add(CAddTable())  Python  model = Sequential()\nbranches = ParallelTable()\nbranch1 = Sequential().add(Linear(...)).add(ReLU())\nbranch2 = Sequential().add(Linear(...)).add(ReLU())\nbranches.add(branch1).add(branch2)\nmodel.add(branches).add(CAddTable())  In the above code, we use ParallelTable to handle the multiple inputs. ParallelTable also\ndefine a multiple branches structure like ConcatTable. The difference is it takes a list\nof tensors as inputs and assign each tensor to the corresponding branch.", 
            "title": "Define a model with multiple inputs"
        }, 
        {
            "location": "/ProgrammingGuide/Model/Functional/", 
            "text": "BigDL supports two different model definition styles: Sequential API and Functional API.\n\n\nIn Functional API, the model is described as a graph. It is more convenient than Sequential API\nwhen define some complex model.\n\n\n\n\nDefine a simple model\n\n\nSuppose we want to define a model with three layers\n\n\nLinear -\n Sigmoid -\n Softmax\n\n\n\n\nYou can write code like this\n\n\nScala:\n\n\nval linear = Linear(...).inputs()\nval sigmoid = Sigmoid().inputs(linear)\nval softmax = Softmax().inputs(sigmoid)\nval model = Graph(Seq[linear], Seq[softmax])\n\n\n\n\nPython:\n\n\nlinear = Linear(...)()\nsigmoid = Sigmoid()(linear)\nsoftmax = Softmax()(sigmoid)\nmodel = Model([linear], [softmax])\n\n\n\n\nAn easy way to understand the Functional API is to think of each layer in the model as a directed\nedge connecting its input and output\n\n\nIn the above code, first we create an input node named as linear by using\nthe Linear layer, then connect it to the sigmoid node with a Sigmoid\nlayer, then connect the sigmoid node to the softmax node with a Softmax layer.\n\n\nAfter defined the graph, we create the model by passing in the input nodes\nand output nodes.\n\n\n\n\nDefine a model with branches\n\n\nSuppose we want to define a model like this\n\n\nLinear -\n ReLU --\n Linear -\n ReLU\n               |-\n Linear -\n ReLU\n\n\n\n\nThe model has two outputs from two branches. The inputs of the branches are both the\noutput from the first ReLU.\n\n\nYou can define the model like this\n\n\nScala:\n\n\nval linear1 = Linear(...).inputs()\nval relu1 = ReLU().inputs(linear1)\nval linear2 = Linear(...).inputs(relu1)\nval relu2 = ReLU().inputs(linear2)\nval linear3 = Linear(...).inputs(relu1)\nval relu3 = ReLU().inputs(linear3)\nval model = Graph(Seq[linear1], Seq[relu2, relu3])\n\n\n\n\nPython:\n\n\nlinear1 = Linear(...)()\nrelu1 = ReLU()(linear1)\nlinear2 = Linear(...)(relu1)\nrelu2 = ReLU()(linear2)\nlinear3 = Linear(...)(relu1)\nrelu3 = ReLU()(linear3)\nmodel = Model([linear1], [relu2, relu3])\n\n\n\n\nIn the above node, linear2 and linear3 are both from relu1 with separated\nLinear layers, which construct the branch structure. When we create the model,\nthe outputs parameter contains relu2 and relu3 as the model has two outputs.\n\n\n\n\nDefine a model with merged branch\n\n\nSuppose we want to define a model like this\n\n\nLinear -\n ReLU --\n Linear -\n ReLU ----\n Add\n               |-\n Linear -\n ReLU --|\n\n\n\n\nIn the model, the outputs of the two branches are merged by an add operation.\n\n\nYou can define the model like this\n\n\nScala:\n\n\nval linear1 = Linear(...).inputs()\nval relu1 = ReLU().inputs(linear1)\nval linear2 = Linear(...).inputs(relu1)\nval relu2 = ReLU().inputs(linear2)\nval linear3 = Linear(...).inputs(relu1)\nval relu3 = ReLU().inputs(linear3)\nval add = CAddTable().inputs(relu2, relu3)\nval model = Graph(Seq[linear1], Seq[add])\n\n\n\n\nPython:\n\n\nlinear1 = Linear(...)()\nrelu1 = ReLU()(linear1)\nlinear2 = Linear(...)(relu1)\nrelu2 = ReLU()(linear2)\nlinear3 = Linear(...)(relu1)\nrelu3 = ReLU()(linear3)\nadd = CAddTable()(relu2, relu3)\nmodel = Model([linear1], [add])\n\n\n\n\nIn the above code, to merge the branch, we use the CAddTable, which takes two\ninput nodes, to generate one output node.\n\n\nBigDL provides many merge layers. Please check Merge layers document page. They all\ntake a list of tensors as input and merge the tensors by some operation.\n\n\n\n\nDefine a model with multiple inputs\n\n\nWe have already seen how to define branches in model and how to merge branches.\nWhat if we have multiple input? Suppose we want to define a model like this\n\n\nLinear -\n ReLU ----\n Add\nLinear -\n ReLU --|\n\n\n\n\nYou can define the model like this\n\n\nScala:\n\n\nval linear1 = Linear(...).inputs()\nval relu1 = ReLU().inputs(linear1)\nval linear2 = Linear(...).inputs()\nval relu2 = ReLU().inputs(linear2)\nval add = CAddTable().inputs(relu1, relu2)\nval model = Graph(Seq[linear1, linear2], Seq[add])\n\n\n\n\nPython:\n\n\nlinear1 = Linear(...)()\nrelu1 = ReLU()(linear1)\nlinear2 = Linear(...)()\nrelu2 = ReLU()(linear2)\nadd = CAddTable()(relu1, relu2)\nmodel = Model([linear1, linear2], [add])\n\n\n\n\nIn the above code, we define two input nodes linear1 and linear2 and put them\ninto the first parameter when create the graph model.", 
            "title": "Using Functional API"
        }, 
        {
            "location": "/ProgrammingGuide/Model/Functional/#define-a-simple-model", 
            "text": "Suppose we want to define a model with three layers  Linear -  Sigmoid -  Softmax  You can write code like this  Scala:  val linear = Linear(...).inputs()\nval sigmoid = Sigmoid().inputs(linear)\nval softmax = Softmax().inputs(sigmoid)\nval model = Graph(Seq[linear], Seq[softmax])  Python:  linear = Linear(...)()\nsigmoid = Sigmoid()(linear)\nsoftmax = Softmax()(sigmoid)\nmodel = Model([linear], [softmax])  An easy way to understand the Functional API is to think of each layer in the model as a directed\nedge connecting its input and output  In the above code, first we create an input node named as linear by using\nthe Linear layer, then connect it to the sigmoid node with a Sigmoid\nlayer, then connect the sigmoid node to the softmax node with a Softmax layer.  After defined the graph, we create the model by passing in the input nodes\nand output nodes.", 
            "title": "Define a simple model"
        }, 
        {
            "location": "/ProgrammingGuide/Model/Functional/#define-a-model-with-branches", 
            "text": "Suppose we want to define a model like this  Linear -  ReLU --  Linear -  ReLU\n               |-  Linear -  ReLU  The model has two outputs from two branches. The inputs of the branches are both the\noutput from the first ReLU.  You can define the model like this  Scala:  val linear1 = Linear(...).inputs()\nval relu1 = ReLU().inputs(linear1)\nval linear2 = Linear(...).inputs(relu1)\nval relu2 = ReLU().inputs(linear2)\nval linear3 = Linear(...).inputs(relu1)\nval relu3 = ReLU().inputs(linear3)\nval model = Graph(Seq[linear1], Seq[relu2, relu3])  Python:  linear1 = Linear(...)()\nrelu1 = ReLU()(linear1)\nlinear2 = Linear(...)(relu1)\nrelu2 = ReLU()(linear2)\nlinear3 = Linear(...)(relu1)\nrelu3 = ReLU()(linear3)\nmodel = Model([linear1], [relu2, relu3])  In the above node, linear2 and linear3 are both from relu1 with separated\nLinear layers, which construct the branch structure. When we create the model,\nthe outputs parameter contains relu2 and relu3 as the model has two outputs.", 
            "title": "Define a model with branches"
        }, 
        {
            "location": "/ProgrammingGuide/Model/Functional/#define-a-model-with-merged-branch", 
            "text": "Suppose we want to define a model like this  Linear -  ReLU --  Linear -  ReLU ----  Add\n               |-  Linear -  ReLU --|  In the model, the outputs of the two branches are merged by an add operation.  You can define the model like this  Scala:  val linear1 = Linear(...).inputs()\nval relu1 = ReLU().inputs(linear1)\nval linear2 = Linear(...).inputs(relu1)\nval relu2 = ReLU().inputs(linear2)\nval linear3 = Linear(...).inputs(relu1)\nval relu3 = ReLU().inputs(linear3)\nval add = CAddTable().inputs(relu2, relu3)\nval model = Graph(Seq[linear1], Seq[add])  Python:  linear1 = Linear(...)()\nrelu1 = ReLU()(linear1)\nlinear2 = Linear(...)(relu1)\nrelu2 = ReLU()(linear2)\nlinear3 = Linear(...)(relu1)\nrelu3 = ReLU()(linear3)\nadd = CAddTable()(relu2, relu3)\nmodel = Model([linear1], [add])  In the above code, to merge the branch, we use the CAddTable, which takes two\ninput nodes, to generate one output node.  BigDL provides many merge layers. Please check Merge layers document page. They all\ntake a list of tensors as input and merge the tensors by some operation.", 
            "title": "Define a model with merged branch"
        }, 
        {
            "location": "/ProgrammingGuide/Model/Functional/#define-a-model-with-multiple-inputs", 
            "text": "We have already seen how to define branches in model and how to merge branches.\nWhat if we have multiple input? Suppose we want to define a model like this  Linear -  ReLU ----  Add\nLinear -  ReLU --|  You can define the model like this  Scala:  val linear1 = Linear(...).inputs()\nval relu1 = ReLU().inputs(linear1)\nval linear2 = Linear(...).inputs()\nval relu2 = ReLU().inputs(linear2)\nval add = CAddTable().inputs(relu1, relu2)\nval model = Graph(Seq[linear1, linear2], Seq[add])  Python:  linear1 = Linear(...)()\nrelu1 = ReLU()(linear1)\nlinear2 = Linear(...)()\nrelu2 = ReLU()(linear2)\nadd = CAddTable()(relu1, relu2)\nmodel = Model([linear1, linear2], [add])  In the above code, we define two input nodes linear1 and linear2 and put them\ninto the first parameter when create the graph model.", 
            "title": "Define a model with multiple inputs"
        }, 
        {
            "location": "/ProgrammingGuide/optimization/", 
            "text": "Use Optimizer for Training\n\n\nYou can use \nOptimizer\n in BigDL to train a model. \n\n\nYou need to first create an \nOptimizer\n, and then call \nOptimizer.optimize\n to start the training. \n\n\nTo create an optimizer, you need at least provide model, data, loss function and batch size.\n\n\n\n\nmodel\n\n\n\n\nA neural network model. May be a layer, a sequence of layers or a\ngraph of layers.\n\n\n\n\ndata\n\n\n\n\nYour training data. As we train models on Spark, one of\nthe most common distributed data structures is RDD. Of course\nyou can use DataFrame. Please check the BigDL pipeline example.\n\n\nThe element in the RDD is \nSample\n, which is actually a sequence of\nTensors. You need to convert your data record(image, audio, text)\nto Tensors before you feed them into Optimizer. We also provide\nmany utilities to do it.\n\n\n\n\nloss function\n\n\n\n\nIn supervised machine learning, loss function compares the output of\nthe model with the ground truth(the labels of the training data). It\noutputs a loss value to measure how good the model is(the lower the\nbetter). It also provides a gradient to indicate how to tune the model.\n\n\nIn BigDL, all loss functions are subclass of Criterion. Refer to \nLosses\n for a list of defined losses.\n\n\n\n\nbatch size\n\n\n\n\nTraining is an iterative process. In each iteration, only a batch of data\nis used for training the model. You need to specify the batch size. Please note, \nthe batch size should be divisible by the total cores number.\n\n\nHere's an example of how to train a Linear classification model\n\n\nscala\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.dataset._\nimport com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\n\n// Define the model\nval model = Linear[Float](2, 1)\nmodel.bias.zero()\n\n// Generate 2D dummy data, y = 0.1 * x[1] + 0.3 * x[2]\nval samples = Seq(\n  Sample[Float](Tensor[Float](T(5f, 5f)), Tensor[Float](T(2.0f))),\n  Sample[Float](Tensor[Float](T(-5f, -5f)), Tensor[Float](T(-2.0f))),\n  Sample[Float](Tensor[Float](T(-2f, 5f)), Tensor[Float](T(1.3f))),\n  Sample[Float](Tensor[Float](T(-5f, 2f)), Tensor[Float](T(0.1f))),\n  Sample[Float](Tensor[Float](T(5f, -2f)), Tensor[Float](T(-0.1f))),\n  Sample[Float](Tensor[Float](T(2f, -5f)), Tensor[Float](T(-1.3f)))\n)\nval trainData = sc.parallelize(samples, 1)\n\n// Define the model\nval optimizer = Optimizer[Float](model, trainData, MSECriterion[Float](), 4)\nEngine.init\noptimizer.optimize()\nprintln(model.weight)\n\n\n\n\nThe weight of linear is init randomly. But the output should be like\n\n\nscala\n println(model.weight)\n0.09316949      0.2887804\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2]\n\n\n\n\npython\n\n\nfrom bigdl.nn.layer import Linear\nfrom bigdl.util.common import *\nfrom bigdl.nn.criterion import MSECriterion\nfrom bigdl.optim.optimizer import Optimizer, MaxIteration\nimport numpy as np\n\nmodel = Linear(2, 1)\nsamples = [\n  Sample.from_ndarray(np.array([5, 5]), np.array([2.0])),\n  Sample.from_ndarray(np.array([-5, -5]), np.array([-2.0])),\n  Sample.from_ndarray(np.array([-2, 5]), np.array([1.3])),\n  Sample.from_ndarray(np.array([-5, 2]), np.array([0.1])),\n  Sample.from_ndarray(np.array([5, -2]), np.array([-0.1])),\n  Sample.from_ndarray(np.array([2, -5]), np.array([-1.3]))\n]\ntrain_data = sc.parallelize(samples, 1)\ninit_engine()\noptimizer = Optimizer(model, train_data, MSECriterion(), MaxIteration(100), 4)\noptimizer.optimize()\nmodel.get_weights()[0]\n\n\n\n\nThe output should be like\n\n\narray([[ 0.11578175,  0.28315681]], dtype=float32)\n\n\n\n\nYou can see the model is trained.\n\n\nDefine when to end the training\n\n\nYou need define when to end the training. It can be several iterations, or how many round\ndata you want to process, a.k.a epoch.\n\n\nscala\n\n\n// The default endWhen in scala is 100 iterations\noptimizer.setEndWhen(Trigger.maxEpoch(10))  // Change to 10 epoch\n\n\n\n\npython\n\n\n# Python need to define in the constructor\noptimizer = Optimizer(model, train_data, MSECriterion(), MaxIteration(100), 4)\n\n\n\n\nChange the optimization algorithm\n\n\nGradient based optimization algorithms are the most popular algorithms to train the neural\nnetwork model. The most famous one is SGD. SGD has many variants, adagrad, adam, etc.\n\n\nscala\n\n\n// The default is SGD\noptimizer.setOptimMethod(new Adam())  // Change to adam\n\n\n\n\npython\n\n\n# Python need to define the optimization algorithm in the constructor\noptimizer = Optimizer(model, train_data, MSECriterion(), MaxIteration(100), 4, optim_method = Adam())\n\n\n\n\nValidate your model in training\n\n\nSometimes, people want to evaluate the model with a separated dataset. When model\nperforms well on train dataset, but bad on validation dataset, we call the model is overfit or\nweak generalization. People may want to evaluate the model every several iterations or \nepochs. BigDL can easily do this by\n\n\nscala\n\n\noptimizer.setValidation(trigger, testData, validationMethod, batchSize)\n\n\n\n\npython\n\n\noptimizer.set_validation(batch_size, val_rdd, trigger, validationMethod)\n\n\n\n\nFor validation, you need to provide\n\n\n\n\ntrigger: how often to do validation, maybe each several iterations or epochs\n\n\ntest data: the separate dataset for test\n\n\nvalidation method: how to evaluate the model, maybe top1 accuracy, etc.\n\n\nbatch size: how many data evaluate in one time\n\n\n\n\nCheckpointing\n\n\nYou can configure the optimizer to periodically take snapshots of the model (trained weights, biases, etc.) and optim-method (configurations and states of the optimization) and dump them into files. \n\n\nThe model snapshot will be named as \nmodel.#iteration_number\n, and optim method snapshot will be named as \nstate.#iteration_number\n.\n\n\nUsage as below.\n\n\nscala\n\n\noptimizer.setCheckpoint(path, trigger)\n\n\n\n\npython\n\n\noptimizer.set_checkpoint(path, trigger,isOverWrite=True)\n\n\n\n\nParameters you need to specify are:\n\n\n\n\npath - the directory to save the snapshots\n\n\ntrigger - how often to save the check point \n\n\n\n\nIn scala, you can also use \noverWriteCheckpoint()\n to enable overwriting any existing snapshot files with the same name (default is disabled). In Python, you can just set parameter isOverWrite (default is True).\n\n\nscala\n\n\noptimizer.overWriteCheckpoint()`\n\n\n\n\npython\n\n\noptimizer.set_checkpoint(path, trigger,isOverWrite=True)\n\n\n\n\nResume Training\n\n\nAfter training stops, you can resume from any saved point. Choose one of   the model snapshots and the corresponding optim-method snapshot to resume (saved in checkpoint path, details see \nCheckpointing\n).     Use \nModule.load\n (Scala) or \nModel.load\n(Python) to load the model         snapshot into an model object, and \nOptimMethod.load\n (Scala and Python) to load optimization method into an OptimMethod  object. Then create a new \nOptimizer\n with the loaded model and optim       method. Call \nOptimizer.optimize\n, and you will resume from the point       where the snapshot is taken. Refer to \nOptimMethod Load\n and \nModel Load\n for details.\n\n\nYou can also resume training without loading the optim method, if you       intend to change the learning rate schedule or even the optimization        algorithm. Just create an \nOptimizer\n with loaded model and a new instance  of OptimMethod (both Scala and Python).\n\n\nMonitor your training\n\n\nscala\n\n\noptimizer.setTrainSummary(trainSummary)\noptimizer.setValidationSummary(validationSummary)\n\n\n\n\npython\n\n\nset_train_summary(train_summary)\noptimizer.set_val_summary(val_summary)\n\n\n\n\nSee details in \nVisualization\n\n\nPerformance tuning\n\n\nFor performance investigation, BigDL records the time-consuming distribution on each node for each step(e.g. sync weight, computing).The information can be displayed in the driver log. By default, it is suspended.To turn it on, please follow these steps:\n\n\n1.Prepare a log4j property file\n\n\n# Root logger option\nlog4j.rootLogger=INFO, stdout\n# Direct log messages to stdout\nlog4j.appender.stdout=org.apache.log4j.ConsoleAppender\nlog4j.appender.stdout.Target=System.out\nlog4j.appender.stdout.layout=org.apache.log4j.PatternLayout\nlog4j.appender.stdout.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n\nlog4j.logger.com.intel.analytics.bigdl.optim=DEBUG\n\n\n\n\n\n2.Add an option to your spark-submit command\n\n\n--conf \"spark.driver.extraJavaOptions=-Dlog4j.configuration=file:where_is_your_log4j_file\"", 
            "title": "Optimization"
        }, 
        {
            "location": "/ProgrammingGuide/optimization/#use-optimizer-for-training", 
            "text": "You can use  Optimizer  in BigDL to train a model.   You need to first create an  Optimizer , and then call  Optimizer.optimize  to start the training.   To create an optimizer, you need at least provide model, data, loss function and batch size.   model   A neural network model. May be a layer, a sequence of layers or a\ngraph of layers.   data   Your training data. As we train models on Spark, one of\nthe most common distributed data structures is RDD. Of course\nyou can use DataFrame. Please check the BigDL pipeline example.  The element in the RDD is  Sample , which is actually a sequence of\nTensors. You need to convert your data record(image, audio, text)\nto Tensors before you feed them into Optimizer. We also provide\nmany utilities to do it.   loss function   In supervised machine learning, loss function compares the output of\nthe model with the ground truth(the labels of the training data). It\noutputs a loss value to measure how good the model is(the lower the\nbetter). It also provides a gradient to indicate how to tune the model.  In BigDL, all loss functions are subclass of Criterion. Refer to  Losses  for a list of defined losses.   batch size   Training is an iterative process. In each iteration, only a batch of data\nis used for training the model. You need to specify the batch size. Please note, \nthe batch size should be divisible by the total cores number.  Here's an example of how to train a Linear classification model  scala  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.dataset._\nimport com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\n\n// Define the model\nval model = Linear[Float](2, 1)\nmodel.bias.zero()\n\n// Generate 2D dummy data, y = 0.1 * x[1] + 0.3 * x[2]\nval samples = Seq(\n  Sample[Float](Tensor[Float](T(5f, 5f)), Tensor[Float](T(2.0f))),\n  Sample[Float](Tensor[Float](T(-5f, -5f)), Tensor[Float](T(-2.0f))),\n  Sample[Float](Tensor[Float](T(-2f, 5f)), Tensor[Float](T(1.3f))),\n  Sample[Float](Tensor[Float](T(-5f, 2f)), Tensor[Float](T(0.1f))),\n  Sample[Float](Tensor[Float](T(5f, -2f)), Tensor[Float](T(-0.1f))),\n  Sample[Float](Tensor[Float](T(2f, -5f)), Tensor[Float](T(-1.3f)))\n)\nval trainData = sc.parallelize(samples, 1)\n\n// Define the model\nval optimizer = Optimizer[Float](model, trainData, MSECriterion[Float](), 4)\nEngine.init\noptimizer.optimize()\nprintln(model.weight)  The weight of linear is init randomly. But the output should be like  scala  println(model.weight)\n0.09316949      0.2887804\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2]  python  from bigdl.nn.layer import Linear\nfrom bigdl.util.common import *\nfrom bigdl.nn.criterion import MSECriterion\nfrom bigdl.optim.optimizer import Optimizer, MaxIteration\nimport numpy as np\n\nmodel = Linear(2, 1)\nsamples = [\n  Sample.from_ndarray(np.array([5, 5]), np.array([2.0])),\n  Sample.from_ndarray(np.array([-5, -5]), np.array([-2.0])),\n  Sample.from_ndarray(np.array([-2, 5]), np.array([1.3])),\n  Sample.from_ndarray(np.array([-5, 2]), np.array([0.1])),\n  Sample.from_ndarray(np.array([5, -2]), np.array([-0.1])),\n  Sample.from_ndarray(np.array([2, -5]), np.array([-1.3]))\n]\ntrain_data = sc.parallelize(samples, 1)\ninit_engine()\noptimizer = Optimizer(model, train_data, MSECriterion(), MaxIteration(100), 4)\noptimizer.optimize()\nmodel.get_weights()[0]  The output should be like  array([[ 0.11578175,  0.28315681]], dtype=float32)  You can see the model is trained.", 
            "title": "Use Optimizer for Training"
        }, 
        {
            "location": "/ProgrammingGuide/optimization/#define-when-to-end-the-training", 
            "text": "You need define when to end the training. It can be several iterations, or how many round\ndata you want to process, a.k.a epoch.  scala  // The default endWhen in scala is 100 iterations\noptimizer.setEndWhen(Trigger.maxEpoch(10))  // Change to 10 epoch  python  # Python need to define in the constructor\noptimizer = Optimizer(model, train_data, MSECriterion(), MaxIteration(100), 4)", 
            "title": "Define when to end the training"
        }, 
        {
            "location": "/ProgrammingGuide/optimization/#change-the-optimization-algorithm", 
            "text": "Gradient based optimization algorithms are the most popular algorithms to train the neural\nnetwork model. The most famous one is SGD. SGD has many variants, adagrad, adam, etc.  scala  // The default is SGD\noptimizer.setOptimMethod(new Adam())  // Change to adam  python  # Python need to define the optimization algorithm in the constructor\noptimizer = Optimizer(model, train_data, MSECriterion(), MaxIteration(100), 4, optim_method = Adam())", 
            "title": "Change the optimization algorithm"
        }, 
        {
            "location": "/ProgrammingGuide/optimization/#validate-your-model-in-training", 
            "text": "Sometimes, people want to evaluate the model with a separated dataset. When model\nperforms well on train dataset, but bad on validation dataset, we call the model is overfit or\nweak generalization. People may want to evaluate the model every several iterations or \nepochs. BigDL can easily do this by  scala  optimizer.setValidation(trigger, testData, validationMethod, batchSize)  python  optimizer.set_validation(batch_size, val_rdd, trigger, validationMethod)  For validation, you need to provide   trigger: how often to do validation, maybe each several iterations or epochs  test data: the separate dataset for test  validation method: how to evaluate the model, maybe top1 accuracy, etc.  batch size: how many data evaluate in one time", 
            "title": "Validate your model in training"
        }, 
        {
            "location": "/ProgrammingGuide/optimization/#checkpointing", 
            "text": "You can configure the optimizer to periodically take snapshots of the model (trained weights, biases, etc.) and optim-method (configurations and states of the optimization) and dump them into files.   The model snapshot will be named as  model.#iteration_number , and optim method snapshot will be named as  state.#iteration_number .  Usage as below.  scala  optimizer.setCheckpoint(path, trigger)  python  optimizer.set_checkpoint(path, trigger,isOverWrite=True)  Parameters you need to specify are:   path - the directory to save the snapshots  trigger - how often to save the check point    In scala, you can also use  overWriteCheckpoint()  to enable overwriting any existing snapshot files with the same name (default is disabled). In Python, you can just set parameter isOverWrite (default is True).  scala  optimizer.overWriteCheckpoint()`  python  optimizer.set_checkpoint(path, trigger,isOverWrite=True)", 
            "title": "Checkpointing"
        }, 
        {
            "location": "/ProgrammingGuide/optimization/#resume-training", 
            "text": "After training stops, you can resume from any saved point. Choose one of   the model snapshots and the corresponding optim-method snapshot to resume (saved in checkpoint path, details see  Checkpointing ).     Use  Module.load  (Scala) or  Model.load (Python) to load the model         snapshot into an model object, and  OptimMethod.load  (Scala and Python) to load optimization method into an OptimMethod  object. Then create a new  Optimizer  with the loaded model and optim       method. Call  Optimizer.optimize , and you will resume from the point       where the snapshot is taken. Refer to  OptimMethod Load  and  Model Load  for details.  You can also resume training without loading the optim method, if you       intend to change the learning rate schedule or even the optimization        algorithm. Just create an  Optimizer  with loaded model and a new instance  of OptimMethod (both Scala and Python).", 
            "title": "Resume Training"
        }, 
        {
            "location": "/ProgrammingGuide/optimization/#monitor-your-training", 
            "text": "scala  optimizer.setTrainSummary(trainSummary)\noptimizer.setValidationSummary(validationSummary)  python  set_train_summary(train_summary)\noptimizer.set_val_summary(val_summary)  See details in  Visualization", 
            "title": "Monitor your training"
        }, 
        {
            "location": "/ProgrammingGuide/optimization/#performance-tuning", 
            "text": "For performance investigation, BigDL records the time-consuming distribution on each node for each step(e.g. sync weight, computing).The information can be displayed in the driver log. By default, it is suspended.To turn it on, please follow these steps:  1.Prepare a log4j property file  # Root logger option\nlog4j.rootLogger=INFO, stdout\n# Direct log messages to stdout\nlog4j.appender.stdout=org.apache.log4j.ConsoleAppender\nlog4j.appender.stdout.Target=System.out\nlog4j.appender.stdout.layout=org.apache.log4j.PatternLayout\nlog4j.appender.stdout.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n\nlog4j.logger.com.intel.analytics.bigdl.optim=DEBUG  2.Add an option to your spark-submit command  --conf \"spark.driver.extraJavaOptions=-Dlog4j.configuration=file:where_is_your_log4j_file\"", 
            "title": "Performance tuning"
        }, 
        {
            "location": "/ProgrammingGuide/MLPipeline/", 
            "text": "Overview\n\n\nBigDL provides \nDLEstimator\n and \nDLClassifier\n for users with Apache Spark MLlib experience, which\nprovides high level API for training a BigDL Model with the Apache Spark\n\nEstimator\n/\n\nTransfomer\n\npattern, thus users can conveniently fit BigDL into a ML pipeline. The fitted model \nDLModel\n and\n\nDLClassiferModel\n contains the trained BigDL model and extends the Spark ML \nModel\n class.\nAlternatively users may also construct a \nDLModel\n with a pre-trained BigDL model to use it in\nSpark ML Pipeline for prediction. We are going to show you how to define a DLEstimator and\nDLClassifier and how to use it. For advanced users, please check our\n\nML Pipeline API\n for detailed usage.\n\n\n\n\nDefine a DLEstimator\n\n\nBefore we are trying to use DLEstimator to automate the training process, we need to make clear\nwhich model used to be updated parameters and gradients, which criterion used to measure the loss,\nthe dimension of the features and the label. These are the key elements the DLEstimator required to\nprepare for the training. If you are unfamiliar with creating a model and criterion, check out\n\nModel\n and \nLosses\n sections with provided links.\n\n\nSo, suppose we create a model with single linear layer and use  MSECriterion as loss function here.\nYou can choose any other model or criterion for your own good when you start your own training.\n\n\nThen basically one can write code like this:\n\n\nScala:\n\n\nval model = Sequential().add(Linear(2, 2))\nval estimator = new DLEstimator(model, criterion, Array(2), Array(2))\n\n\n\n\nPython:\n\n\nlinear_model = Sequential().add(Linear(2, 2))\nmse_criterion = MSECriterion()\nestimator = DLEstimator(model=linear_model, criterion=mse_criterion,\nfeature_size=[2], label_size=[2])\n\n\n\n\nNow, you have a DLEstimator based on your own choice of model, criterion. Also, make sure your specified\nfeature size and label size consistent with the actual ones otherwise exception will be encountered.\n\n\nDefine a DLClassifier\n\n\nSince DLlassifier is the subclass of DLEstimator, the way of defining a DLClassifier is almost the same\nlike creating a DLEstimator except that you don't need to specify the label size because it's set to\ndefault binary value and pay attention to choosing the criterion suitable for classification problem wisely.\n\n\nSuppose we still create a model with single linear layer and use  ClassNLL criterion as loss\nfunction here.\n\n\nScala:\n\n\nval model = Sequential().add(Linear(2, 2)).add(LogSoftMax())\nval criterion = ClassNLLCriterion()\nval estimator = new DLClassifier(model, criterion, Array(2))\n\n\n\n\nPython:\n\n\nlinear_model = Sequential().add(Linear(2, 2))\nclassNLL_criterion = ClassNLLCriterion()\nclassifier = DLClassifier(model=linear_model, criterion=classNLL_criterion,\nfeature_size=[2])\n\n\n\n\nHyperparameter setting\n\n\nPrior to the commencement of the training process, you can modify the batch size, the epoch number of your\ntraining, and learning rate to meet your goal or DLEstimator/DLClassifier will use the default value.\n\n\nContinue the codes above, DLEstimator and DLClassifier can be setted in the same way.\n\n\nScala:\n\n\n//for esitmator\nestimator.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01)\n//for classifier\nclassifier.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01)\n\n\n\n\nPython:\n\n\n# for esitmator\nestimator.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01)\n# for classifier\nclassifier.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01)\n\n\n\n\n\nPrepare the data and start the training process\n\n\nUsers need to convert the data into Spark's\n\nDataFrame/DataSet\n\nto feed to the DLEstimator/DLCLassifer.\nThen after these steps, we can start training now.\n\n\nSuppose \ndf\n is the training data, simple call \nfit\n method and let BigDL train the model for you. You will\nget a DLModel or DLClassifierModel based on which one you choose from DLEstimator and DLClassifier.\n\n\nScala:\n\n\n//get a DLModel\nval dlModel = estimator.fit(df)\n//get a DLClassifierModel\nval dlClassifierModel = classifier.fit(df)\n\n\n\n\nPython:\n\n\n# get a DLModel\ndlModel = estimator.fit(df)\n# get a DLClassifierModel\ndlClassifierModel = classifier.fit(df)\n\n\n\n\nMake prediction on chosen data by using DLModel/DLClassifierModel\n\n\nSince DLModel/DLClassifierModel inherits from Spark's Transformer abstract class, simply call \ntransform\n\n method on DLModel/DLClassifierModel to make prediction.\n\n\nScala:\n\n\ndlModel.transform(df).show(false)\n\n\n\n\nPython:\n\n\ndlModel.transform(df).show(false)", 
            "title": "Use Spark ML"
        }, 
        {
            "location": "/ProgrammingGuide/MLPipeline/#overview", 
            "text": "BigDL provides  DLEstimator  and  DLClassifier  for users with Apache Spark MLlib experience, which\nprovides high level API for training a BigDL Model with the Apache Spark Estimator / Transfomer \npattern, thus users can conveniently fit BigDL into a ML pipeline. The fitted model  DLModel  and DLClassiferModel  contains the trained BigDL model and extends the Spark ML  Model  class.\nAlternatively users may also construct a  DLModel  with a pre-trained BigDL model to use it in\nSpark ML Pipeline for prediction. We are going to show you how to define a DLEstimator and\nDLClassifier and how to use it. For advanced users, please check our ML Pipeline API  for detailed usage.", 
            "title": "Overview"
        }, 
        {
            "location": "/ProgrammingGuide/MLPipeline/#define-a-dlestimator", 
            "text": "Before we are trying to use DLEstimator to automate the training process, we need to make clear\nwhich model used to be updated parameters and gradients, which criterion used to measure the loss,\nthe dimension of the features and the label. These are the key elements the DLEstimator required to\nprepare for the training. If you are unfamiliar with creating a model and criterion, check out Model  and  Losses  sections with provided links.  So, suppose we create a model with single linear layer and use  MSECriterion as loss function here.\nYou can choose any other model or criterion for your own good when you start your own training.  Then basically one can write code like this:  Scala:  val model = Sequential().add(Linear(2, 2))\nval estimator = new DLEstimator(model, criterion, Array(2), Array(2))  Python:  linear_model = Sequential().add(Linear(2, 2))\nmse_criterion = MSECriterion()\nestimator = DLEstimator(model=linear_model, criterion=mse_criterion,\nfeature_size=[2], label_size=[2])  Now, you have a DLEstimator based on your own choice of model, criterion. Also, make sure your specified\nfeature size and label size consistent with the actual ones otherwise exception will be encountered.", 
            "title": "Define a DLEstimator"
        }, 
        {
            "location": "/ProgrammingGuide/MLPipeline/#define-a-dlclassifier", 
            "text": "Since DLlassifier is the subclass of DLEstimator, the way of defining a DLClassifier is almost the same\nlike creating a DLEstimator except that you don't need to specify the label size because it's set to\ndefault binary value and pay attention to choosing the criterion suitable for classification problem wisely.  Suppose we still create a model with single linear layer and use  ClassNLL criterion as loss\nfunction here.  Scala:  val model = Sequential().add(Linear(2, 2)).add(LogSoftMax())\nval criterion = ClassNLLCriterion()\nval estimator = new DLClassifier(model, criterion, Array(2))  Python:  linear_model = Sequential().add(Linear(2, 2))\nclassNLL_criterion = ClassNLLCriterion()\nclassifier = DLClassifier(model=linear_model, criterion=classNLL_criterion,\nfeature_size=[2])", 
            "title": "Define a DLClassifier"
        }, 
        {
            "location": "/ProgrammingGuide/MLPipeline/#hyperparameter-setting", 
            "text": "Prior to the commencement of the training process, you can modify the batch size, the epoch number of your\ntraining, and learning rate to meet your goal or DLEstimator/DLClassifier will use the default value.  Continue the codes above, DLEstimator and DLClassifier can be setted in the same way.  Scala:  //for esitmator\nestimator.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01)\n//for classifier\nclassifier.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01)  Python:  # for esitmator\nestimator.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01)\n# for classifier\nclassifier.setBatchSize(4).setMaxEpoch(10).setLearningRate(0.01)", 
            "title": "Hyperparameter setting"
        }, 
        {
            "location": "/ProgrammingGuide/MLPipeline/#prepare-the-data-and-start-the-training-process", 
            "text": "Users need to convert the data into Spark's DataFrame/DataSet \nto feed to the DLEstimator/DLCLassifer.\nThen after these steps, we can start training now.  Suppose  df  is the training data, simple call  fit  method and let BigDL train the model for you. You will\nget a DLModel or DLClassifierModel based on which one you choose from DLEstimator and DLClassifier.  Scala:  //get a DLModel\nval dlModel = estimator.fit(df)\n//get a DLClassifierModel\nval dlClassifierModel = classifier.fit(df)  Python:  # get a DLModel\ndlModel = estimator.fit(df)\n# get a DLClassifierModel\ndlClassifierModel = classifier.fit(df)", 
            "title": "Prepare the data and start the training process"
        }, 
        {
            "location": "/ProgrammingGuide/MLPipeline/#make-prediction-on-chosen-data-by-using-dlmodeldlclassifiermodel", 
            "text": "Since DLModel/DLClassifierModel inherits from Spark's Transformer abstract class, simply call  transform \n method on DLModel/DLClassifierModel to make prediction.  Scala:  dlModel.transform(df).show(false)  Python:  dlModel.transform(df).show(false)", 
            "title": "Make prediction on chosen data by using DLModel/DLClassifierModel"
        }, 
        {
            "location": "/ProgrammingGuide/visualization/", 
            "text": "Generating summary info in BigDL\n\n\nTo enable visualization support, you need first properly configure the \nOptimizer\n to collect statistics summary in different stages of training (i.e. training (\nTrainSummary\n) and validation (\nValidationSummary\n),respectively). It should be done before the training starts (calling \nOptimizer.optimize()\n). See examples below: \n\n\nExample: Generating summary info in Scala\n\n\nval optimizer = Optimizer(...)\n...\nval logdir = \nmylogdir\n\nval appName = \nmyapp\n\nval trainSummary = TrainSummary(logdir, appName)\nval validationSummary = ValidationSummary(logdir, appName)\noptimizer.setTrainSummary(trainSummary)\noptimizer.setValidationSummary(validationSummary)\n...\nval trained_model = optimizer.optimize()\n\n\n\n\nExample: Configure summary generation in Python\n\n\noptimizer = Optimizer(...)\n...\nlog_dir = 'mylogdir'\napp_name = 'myapp'\ntrain_summary = TrainSummary(log_dir=log_dir, app_name=app_name)\nval_summary = ValidationSummary(log_dir=log_dir, app_name=app_name)\noptimizer.set_train_summary(train_summary)\noptimizer.set_val_summary(val_summary)\n...\ntrainedModel = optimizer.optimize()\n\n\n\n\nAfter you start to run your spark job, the train and validation summary will be saved to \nmylogdir/myapp/train\n and \nmylogdir/myapp/validation\n respectively (Note: you may want to use different \nappName\n for different job runs to avoid possible conflicts.)\n\n\nSave graph model to summary so visualize model in tensorboard\n\n\nModel structure is very important for people to create/understand model. For sequential models, you can\njust print them out by using the \ntoString\n method. For complex graph model, you can use tensorboard\nto visualize it.\n\n\nHere's how to save your graph model to summary log path to display it in the tensorboard.\n\n\nExample: Save graph model to summary in Scala\n\n\nval model = Graph(...)\nmodel.saveGraphTopology(\nlogpath\n)\n\n\n\n\nExample: Save graph model to summary in Python\n\n\nmodel=Model(...)\nmodel.save_graph_topology(\nlogpath\n)\n\n\n\n\n\n\n\nRetrieving summary info as readable format\n\n\nYou can use provided API \nreadScalar\n(Scala) and \nread_scalar\n(Python) to retrieve the summaries into readable format, and export them to other tools for further analysis or visualization.\n\n\nExample: Reading summary info in Scala\n\n\nval trainLoss = trainSummary.readScalar(\nLoss\n)\nval validationLoss = validationSummary.readScalar(\nLoss\n)\n...\n\n\n\n\nExample: Reading summary info in Python\n\n\nloss = np.array(train_summary.read_scalar('Loss'))\nvalloss = np.array(val_summary.read_scalar('Loss'))\n...\n\n\n\n\n\n\nVisualizing training with TensorBoard\n\n\nWith the summary info generated, we can then use \nTensorBoard\n to visualize the behaviors of the BigDL program.  \n\n\n\n\nInstalling TensorBoard\n\n\n\n\nPrerequisites:\n\n\n\n\nPython verison: 2.7, 3.4, 3.5, or 3.6\n\n\nPip version \n= 9.0.1\n\n\n\n\nTo install TensorBoard using Python 2, you may run the command:\n\n\npip install tensorboard==1.0.0a4\n\n\n\n\nTo install TensorBoard using Python 3, you may run the command:\n\n\npip3 install tensorboard==1.0.0a4\n\n\n\n\nPlease refer to \nthis page\n for possible issues when installing TensorBoard.\n\n\n\n\nLaunching TensorBoard\n\n\n\n\nYou can launch TensorBoard using the command below:\n\n\ntensorboard --logdir=/tmp/bigdl_summaries\n\n\n\n\nAfter that, navigate to the TensorBoard dashboard using a browser. You can find the URL in the console output after TensorBoard is successfully launched; by default the URL is http://your_node:6006\n\n\n\n\nVisualizations in TensorBoard\n\n\n\n\nWithin the TensorBoard dashboard, you will be able to read the visualizations of each run, including the \u201cLoss\u201d and \u201cThroughput\u201d curves under the SCALARS tab (as illustrated below):\n\n\n\nAnd \u201cweights\u201d, \u201cbias\u201d, \u201cgradientWeights\u201d and \u201cgradientBias\u201d under the DISTRIBUTIONS and HISTOGRAMS tabs (as illustrated below):\n\n\n\n\n\n\n\nVisualizing training with Jupyter notebook\n\n\nIf you're using Jupyter notebook, you can also draw the training curves using popular plotting tools (e.g. matplotlib) and show the plots inline. \n\n\nFirst, retrieve the summaries as instructed in \nRetrieve Summary\n. The retrieved summary is a list of tuples. Each tuple is a recorded event in format (iteration count, recorded value, timestamp). You can convert it to numpy array or dataframe to plot it. See example below:  \n\n\nExample: Plot the train/validation loss in Jupyter\n\n\n#retrieve train and validation summary object and read the loss data into ndarray's. \nloss = np.array(train_summary.read_scalar(\nLoss\n))\nval_loss  = np.array(val_summary.read_scalar(\nLoss\n))\n\n#plot the train and validation curves\n# each event data is a tuple in form of (iteration_count, value, timestamp)\nplt.plot(loss[:,0],loss[:,1],label='train loss')\nplt.plot(val_loss[:,0],val_loss[:,1],label='val loss',color='green')\nplt.scatter(val_loss[:,0],val_loss[:,1],color='green')\nplt.legend();\n\n\n\n\n\n\nLogging\n\n\nBigDL also has a straight-forward logging output on the console along the    training, as shown below. You can see real-time epoch/iteration/loss/       throughput in the log.\n\n\n  2017-01-10 10:03:55 INFO  DistriOptimizer$:241 - [Epoch 1 0/               5000][Iteration 1][Wall Clock XXX] Train 512 in   XXXseconds. Throughput    is XXX records/second. Loss is XXX.\n  2017-01-10 10:03:58 INFO  DistriOptimizer$:241 - [Epoch 1 512/             5000][Iteration 2][Wall Clock XXX] Train 512    in XXXseconds. Throughput   is XXX records/second. Loss is XXX.\n  2017-01-10 10:04:00 INFO  DistriOptimizer$:241 - [Epoch 1 1024/            5000][Iteration 3][Wall Clock XXX] Train 512   in XXXseconds. Throughput    is XXX records/second. Loss is XXX.\n\n\n\n\nThe DistriOptimizer log level is INFO by default. We implement a method     named with \nredirectSparkInfoLogs\n  in \nspark/utils/LoggerFilter.scala\n.    You can import and redirect at first.\n\n\n  import com.intel.analytics.bigdl.utils.LoggerFilter\n  LoggerFilter.redirectSparkInfoLogs()\n\n\n\n\nThis method will redirect all logs of \norg\n, \nakka\n, \nbreeze\n to \nbigdl.    log\n with \nINFO\n level, except \norg.  apache.spark.SparkContext\n. And it    will output all \nERROR\n message in console too.\n\n\nYou can disable the redirection with java property \n-Dbigdl.utils.          LoggerFilter.disable=true\n. By default,   it will do redirect of all        examples and models in our code.\n\n\nYou can set where the \nbigdl.log\n will be generated with \n-Dbigdl.utils.    LoggerFilter.logFile=\npath\n. By    default, it will be generated under     current workspace.", 
            "title": "Visualization"
        }, 
        {
            "location": "/ProgrammingGuide/visualization/#generating-summary-info-in-bigdl", 
            "text": "To enable visualization support, you need first properly configure the  Optimizer  to collect statistics summary in different stages of training (i.e. training ( TrainSummary ) and validation ( ValidationSummary ),respectively). It should be done before the training starts (calling  Optimizer.optimize() ). See examples below:   Example: Generating summary info in Scala  val optimizer = Optimizer(...)\n...\nval logdir =  mylogdir \nval appName =  myapp \nval trainSummary = TrainSummary(logdir, appName)\nval validationSummary = ValidationSummary(logdir, appName)\noptimizer.setTrainSummary(trainSummary)\noptimizer.setValidationSummary(validationSummary)\n...\nval trained_model = optimizer.optimize()  Example: Configure summary generation in Python  optimizer = Optimizer(...)\n...\nlog_dir = 'mylogdir'\napp_name = 'myapp'\ntrain_summary = TrainSummary(log_dir=log_dir, app_name=app_name)\nval_summary = ValidationSummary(log_dir=log_dir, app_name=app_name)\noptimizer.set_train_summary(train_summary)\noptimizer.set_val_summary(val_summary)\n...\ntrainedModel = optimizer.optimize()  After you start to run your spark job, the train and validation summary will be saved to  mylogdir/myapp/train  and  mylogdir/myapp/validation  respectively (Note: you may want to use different  appName  for different job runs to avoid possible conflicts.)", 
            "title": "Generating summary info in BigDL"
        }, 
        {
            "location": "/ProgrammingGuide/visualization/#save-graph-model-to-summary-so-visualize-model-in-tensorboard", 
            "text": "Model structure is very important for people to create/understand model. For sequential models, you can\njust print them out by using the  toString  method. For complex graph model, you can use tensorboard\nto visualize it.  Here's how to save your graph model to summary log path to display it in the tensorboard.  Example: Save graph model to summary in Scala  val model = Graph(...)\nmodel.saveGraphTopology( logpath )  Example: Save graph model to summary in Python  model=Model(...)\nmodel.save_graph_topology( logpath )", 
            "title": "Save graph model to summary so visualize model in tensorboard"
        }, 
        {
            "location": "/ProgrammingGuide/visualization/#retrieving-summary-info-as-readable-format", 
            "text": "You can use provided API  readScalar (Scala) and  read_scalar (Python) to retrieve the summaries into readable format, and export them to other tools for further analysis or visualization.  Example: Reading summary info in Scala  val trainLoss = trainSummary.readScalar( Loss )\nval validationLoss = validationSummary.readScalar( Loss )\n...  Example: Reading summary info in Python  loss = np.array(train_summary.read_scalar('Loss'))\nvalloss = np.array(val_summary.read_scalar('Loss'))\n...", 
            "title": "Retrieving summary info as readable format"
        }, 
        {
            "location": "/ProgrammingGuide/visualization/#visualizing-training-with-tensorboard", 
            "text": "With the summary info generated, we can then use  TensorBoard  to visualize the behaviors of the BigDL program.     Installing TensorBoard   Prerequisites:   Python verison: 2.7, 3.4, 3.5, or 3.6  Pip version  = 9.0.1   To install TensorBoard using Python 2, you may run the command:  pip install tensorboard==1.0.0a4  To install TensorBoard using Python 3, you may run the command:  pip3 install tensorboard==1.0.0a4  Please refer to  this page  for possible issues when installing TensorBoard.   Launching TensorBoard   You can launch TensorBoard using the command below:  tensorboard --logdir=/tmp/bigdl_summaries  After that, navigate to the TensorBoard dashboard using a browser. You can find the URL in the console output after TensorBoard is successfully launched; by default the URL is http://your_node:6006   Visualizations in TensorBoard   Within the TensorBoard dashboard, you will be able to read the visualizations of each run, including the \u201cLoss\u201d and \u201cThroughput\u201d curves under the SCALARS tab (as illustrated below):  And \u201cweights\u201d, \u201cbias\u201d, \u201cgradientWeights\u201d and \u201cgradientBias\u201d under the DISTRIBUTIONS and HISTOGRAMS tabs (as illustrated below):", 
            "title": "Visualizing training with TensorBoard"
        }, 
        {
            "location": "/ProgrammingGuide/visualization/#visualizing-training-with-jupyter-notebook", 
            "text": "If you're using Jupyter notebook, you can also draw the training curves using popular plotting tools (e.g. matplotlib) and show the plots inline.   First, retrieve the summaries as instructed in  Retrieve Summary . The retrieved summary is a list of tuples. Each tuple is a recorded event in format (iteration count, recorded value, timestamp). You can convert it to numpy array or dataframe to plot it. See example below:    Example: Plot the train/validation loss in Jupyter  #retrieve train and validation summary object and read the loss data into ndarray's. \nloss = np.array(train_summary.read_scalar( Loss ))\nval_loss  = np.array(val_summary.read_scalar( Loss ))\n\n#plot the train and validation curves\n# each event data is a tuple in form of (iteration_count, value, timestamp)\nplt.plot(loss[:,0],loss[:,1],label='train loss')\nplt.plot(val_loss[:,0],val_loss[:,1],label='val loss',color='green')\nplt.scatter(val_loss[:,0],val_loss[:,1],color='green')\nplt.legend();", 
            "title": "Visualizing training with Jupyter notebook"
        }, 
        {
            "location": "/ProgrammingGuide/visualization/#logging", 
            "text": "BigDL also has a straight-forward logging output on the console along the    training, as shown below. You can see real-time epoch/iteration/loss/       throughput in the log.    2017-01-10 10:03:55 INFO  DistriOptimizer$:241 - [Epoch 1 0/               5000][Iteration 1][Wall Clock XXX] Train 512 in   XXXseconds. Throughput    is XXX records/second. Loss is XXX.\n  2017-01-10 10:03:58 INFO  DistriOptimizer$:241 - [Epoch 1 512/             5000][Iteration 2][Wall Clock XXX] Train 512    in XXXseconds. Throughput   is XXX records/second. Loss is XXX.\n  2017-01-10 10:04:00 INFO  DistriOptimizer$:241 - [Epoch 1 1024/            5000][Iteration 3][Wall Clock XXX] Train 512   in XXXseconds. Throughput    is XXX records/second. Loss is XXX.  The DistriOptimizer log level is INFO by default. We implement a method     named with  redirectSparkInfoLogs   in  spark/utils/LoggerFilter.scala .    You can import and redirect at first.    import com.intel.analytics.bigdl.utils.LoggerFilter\n  LoggerFilter.redirectSparkInfoLogs()  This method will redirect all logs of  org ,  akka ,  breeze  to  bigdl.    log  with  INFO  level, except  org.  apache.spark.SparkContext . And it    will output all  ERROR  message in console too.  You can disable the redirection with java property  -Dbigdl.utils.          LoggerFilter.disable=true . By default,   it will do redirect of all        examples and models in our code.  You can set where the  bigdl.log  will be generated with  -Dbigdl.utils.    LoggerFilter.logFile= path . By    default, it will be generated under     current workspace.", 
            "title": "Logging"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-ec2/", 
            "text": "You can start BigDL with BigDL Amazon Machine Images (AMI).\n\n\n\n\nAWS Marketplace AMI\n\n\nThe easiest way to get started with BigDL is to launch the pre-configured BigDL Amazon Machine Image (AMI) from the AWS Marketplace. The AMI includes Apache Spark, BigDL, Python and Anaconda with ready-to-run Jupyter Notebooks. Within a few minutes you can run python code and investigate the architecture it uses to create an image recognition model. Upload your own data into one of the sample notebooks and you can try BigDL with your own data. \n\n\nTo use the BigDL AMI in the AWS Marketplace, visit [https://aws.amazon.com/marketplace/] and search for 'BigDL'. Launch the AMI by clicking the \"Continue to Subscribe\" button from the BigDL Product Page. The software stack is free and open source. You only pay standard AWS charges. Because it includes Apache Spark, a t2.large instance is the minimum size recommended to run this BigDL AMI. Once you launch the AMI, type the domain name (URL) and port 8888 (ex: ec2-xxx-xxx-xxx-xxx.compute-1.amazonaws.com:8888) into your favorite web browser. The password for the Jupyter Notebook, which runs automatically, is the Instance ID (ex: i-08ba9c6fcdea6388f) of your EC2 Instance which you can find in your EC2 Dashboard [https://console.aws.amazon.com/ec2/v2/home]. \n\n\nIf you ssh into your EC2 instance, you can use \"docker ps\" (ex: docker ps -a) to find the container id, and \"docker exec -it \n bash\" to see what is installed. Use git to download additional notebooks to the /work directory (ex: \"$ git clone github.com/intel-analytics/BigDL-Tutorial\". Additional Jupyter Notebooks can be found at [https://github.com/intel-analytics/BigDL-Tutorials]\n\n\nDetailed Instructions\n\n\nLogin to the AWS Console \n go to ec2 dashboard\n\n\n \n\n \n\n\nFind BIGDL AMI in the Marketplace\n\n\nTo choose AMI, select AWS Marketplace, search \u201cBigDL\u201d\n\n \n\n\nSelect BigDL with Apache Spark\n\n\n \n\n \n\n\nChoosing and configuring instance\n\n\n \n\n \n\n\nAdd storage and tags\n\n\n \n\n \n\n\nConfigure Security Group\n\n\n \n\n\nReview and Launch\n\n\n \n\n\nClick the instance\n\n\n \n\n\nWhen the status is running, copy the ip\n\n\n \n\n\nOpen it via a web browser with http://[ip]:12345\n\n\n \n\n\nLogin the notebook with the instance ID\n\n\nCopy the instance ID from dashboard and paste it as a password/token\n\n\n\nHave fun and build with BigDL!\n\n\n \n\n\n\n\nThe Public AMI\n\n\nTo make it easier to try out BigDL examples on Spark using EC2, a public AMI is provided. It will automatically retrieve the latest BigDL package, download the necessary input data, and then run the specified BigDL example (using Java 8 on a Spark cluster). The details of the public AMI are shown in the table below.\n\n\n\n\n\n\n\n\nBigDL version\n\n\nAMI version\n\n\nDate\n\n\nAMI ID\n\n\nAMI Name\n\n\nRegion\n\n\nStatus\n\n\n\n\n\n\n\n\n\n\nmaster\n\n\n0.2S\n\n\nMar 13, 2017\n\n\nami-37b73957\n\n\nBigDL Client 0.2S\n\n\nUS West (Oregon)\n\n\nActive\n\n\n\n\n\n\nmaster\n\n\n0.2S\n\n\nApr 10, 2017\n\n\nami-8c87099a\n\n\nBigDL Client 0.2S\n\n\nUS East (N. Virginia)\n\n\nActive\n\n\n\n\n\n\n0.1.0\n\n\n0.1.0\n\n\nApr 10, 2017\n\n\nami-9a8818fa\n\n\nBigDL Client 0.1.0\n\n\nUS West (Oregon)\n\n\nActive\n\n\n\n\n\n\n0.1.0\n\n\n0.1.0\n\n\nApr 10, 2017\n\n\nami-6476f872\n\n\nBigDL Client 0.1.0\n\n\nUS East (N. Virginia)\n\n\nActive\n\n\n\n\n\n\n\n\nPlease note that it is highly recommended to run BigDL using EC2 instances with Xeon E5 v3 or v4 processors.\n\n\nAfter launching the AMI on EC2, please log on to the instance and run a \"bootstrap.sh\" script to download example scripts.\n\n\n./bootstrap.sh\n\n\n\n\n\n\nBefore you start\n\n\nBefore running the BigDL examples, you need to launch a Spark cluster on EC2 (you may refer to \nhttps://github.com/amplab/spark-ec2\n for more instructions). In addition, to run the Inception-v1 example, you also need to start a HDFS cluster on EC2 to store the input image data.\n\n\n\n\nRun BigDL Examples\n\n\nYou can run BigDL examples using the \nrun.example.sh\n script in home directory of your BigDL Client instance (e.g. \n/home/ubuntu/\n) with the following parameters:\n\n\n\n\n\n\nMandatory parameters:\n\n\n\n\n\n\n-m|--model\n which model to train, including\n\n\n\n\n\n\nlenet: train the \nLeNet\n example\n\n\n\n\n\n\nvgg: train the \nVGG\n example\n\n\n\n\n\n\ninception-v1: train the \nInception v1\n example\n\n\n\n\n\n\nperf: test the training speed using the \nInception v1\n model with dummy data\n\n\n\n\n\n\n\n\n\n\n-s|--spark-url\n the master URL for the Spark cluster\n\n\n\n\n\n\n-n|--nodes\n number of Spark slave nodes\n\n\n\n\n\n\n-o|--cores\n number of cores used on each node\n\n\n\n\n\n\n-r|--memory\n memory used on each node, e.g. 200g\n\n\n\n\n\n\n-b|--batch-size\n batch size when training the model; it is expected to be a multiple of \"nodes * cores\"\n\n\n\n\n\n\n-f|--hdfs-data-dir\n HDFS directory for the input images (for the \"inception-v1\" model training only)\n\n\n\n\n\n\n\n\n\n\nOptional parameters:\n\n\n\n\n\n\n-e|--max-epoch\n the maximum number of epochs (i.e., going through all the input data once) used in the training; default to 90 if not specified\n\n\n\n\n\n\n-p|--spark\n by default the example will run with Spark 1.5 or 1.6; to use Spark 2.0, please specify \"spark_2.0\" here (it is highly recommended to use \nJava 8\n when running BigDL for Spark 2.0, otherwise you may observe very poor performance)\n\n\n\n\n\n\n-l|--learning-rate\n by default the the example will use an initial learning rate of \"0.01\"; you can specify a different value here\n\n\n\n\n\n\n\n\n\n\nAfter the training, you can check the log files and generated models in the home directory (e.g., \n/home/ubuntu/\n).  \n\n\n\n\nRun the \"inception-v1\" example\n\n\nYou can refer to the \nInception v1\n example to prepare the input \nImageNet\n data here. Alternatively, you may also download just a small set of images (with dummy labels) to run the example as follows, which can be useful if you only want to try it out to see the training speed on a Spark cluster.\n\n\n\n\nDownload and prepare the input image data (a subset of the \nFlickr Style\n data)\n\n\n\n\n  ./download.sh $HDFS-NAMENODE\n\n\n\n\nAfter the download completes, the downloaded images are stored in \nhdfs://HDFS-NAMENODE:9000/seq\n. (If the download fails with error \"Unable to establish SSL connection.\" please check your network connection and retry this later.)\n\n\n\n\nTo run the \"inception-v1\" example on a 4-worker Spark cluster (using, say, the \"m4.10xlarge\" instance), run the example command below: \n\n\n\n\n  nohup bash ./run.example.sh --model inception-v1  \\\n         --spark-url spark://SPARK-MASTER:7077    \\\n         --nodes 4 --cores 20 --memory 150g       \\\n         --batch-size 400 --learning-rate 0.0898  \\\n         --hdfs-data-dir hdfs://HDFS-NAMENODE:9000/seq \\\n         --spark spark_2.0 --max-epoch 4 \\\n         \n incep.log 2\n1 \n     \n\n\n\n\n\n\nView output of the training in the log file generated by the previous step:\n\n\n\n\n  $ tail -f incep.log\n  2017-01-10 10:03:55 INFO  DistriOptimizer$:241 - [Epoch 1 0/5000][Iteration 1][Wall Clock XXX] Train 512 in XXXseconds. Throughput is XXX records/second. Loss is XXX.\n  2017-01-10 10:03:58 INFO  DistriOptimizer$:241 - [Epoch 1 512/5000][Iteration 2][Wall Clock XXX] Train 512 in XXXseconds. Throughput is XXX records/second. Loss is XXX.\n  2017-01-10 10:04:00 INFO  DistriOptimizer$:241 - [Epoch 1 1024/5000][Iteration 3][Wall Clock XXX] Train 512 in XXXseconds. Throughput is XXX records/second. Loss is XXX.\n  2017-01-10 10:04:03 INFO  DistriOptimizer$:241 - [Epoch 1 1536/5000][Iteration 4][Wall Clock XXX] Train 512 in XXXseconds. Throughput is XXX records/second. Loss is XXX.\n  2017-01-10 10:04:05 INFO  DistriOptimizer$:241 - [Epoch 1 2048/5000][Iteration 5][Wall Clock XXX] Train 512 in XXXseconds. Throughput is XXX records/second. Loss is XXX.\n\n\n\n\n\n\nRun the \"perf\" example\n\n\nTo run the \"perf\" example on a 4-worker Spark cluster (using, say, the \"m4.10xlarge\" instance), you may try the example command below: \n\n\n  nohup bash ./run.example.sh --model perf  \\\n       --spark-url spark://SPARK-MASTER:7077    \\\n       --nodes 4 --cores 20 --memory 150g       \\\n       --spark spark_2.0 --max-epoch 4 \\\n       \n perf.log 2\n1", 
            "title": "Run on Amazon EC2"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-ec2/#aws-marketplace-ami", 
            "text": "The easiest way to get started with BigDL is to launch the pre-configured BigDL Amazon Machine Image (AMI) from the AWS Marketplace. The AMI includes Apache Spark, BigDL, Python and Anaconda with ready-to-run Jupyter Notebooks. Within a few minutes you can run python code and investigate the architecture it uses to create an image recognition model. Upload your own data into one of the sample notebooks and you can try BigDL with your own data.   To use the BigDL AMI in the AWS Marketplace, visit [https://aws.amazon.com/marketplace/] and search for 'BigDL'. Launch the AMI by clicking the \"Continue to Subscribe\" button from the BigDL Product Page. The software stack is free and open source. You only pay standard AWS charges. Because it includes Apache Spark, a t2.large instance is the minimum size recommended to run this BigDL AMI. Once you launch the AMI, type the domain name (URL) and port 8888 (ex: ec2-xxx-xxx-xxx-xxx.compute-1.amazonaws.com:8888) into your favorite web browser. The password for the Jupyter Notebook, which runs automatically, is the Instance ID (ex: i-08ba9c6fcdea6388f) of your EC2 Instance which you can find in your EC2 Dashboard [https://console.aws.amazon.com/ec2/v2/home].   If you ssh into your EC2 instance, you can use \"docker ps\" (ex: docker ps -a) to find the container id, and \"docker exec -it   bash\" to see what is installed. Use git to download additional notebooks to the /work directory (ex: \"$ git clone github.com/intel-analytics/BigDL-Tutorial\". Additional Jupyter Notebooks can be found at [https://github.com/intel-analytics/BigDL-Tutorials]", 
            "title": "AWS Marketplace AMI"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-ec2/#detailed-instructions", 
            "text": "", 
            "title": "Detailed Instructions"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-ec2/#login-to-the-aws-console-go-to-ec2-dashboard", 
            "text": "", 
            "title": "Login to the AWS Console &amp; go to ec2 dashboard"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-ec2/#find-bigdl-ami-in-the-marketplace", 
            "text": "To choose AMI, select AWS Marketplace, search \u201cBigDL\u201d", 
            "title": "Find BIGDL AMI in the Marketplace"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-ec2/#select-bigdl-with-apache-spark", 
            "text": "", 
            "title": "Select BigDL with Apache Spark"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-ec2/#choosing-and-configuring-instance", 
            "text": "", 
            "title": "Choosing and configuring instance"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-ec2/#add-storage-and-tags", 
            "text": "", 
            "title": "Add storage and tags"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-ec2/#configure-security-group", 
            "text": "", 
            "title": "Configure Security Group"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-ec2/#review-and-launch", 
            "text": "", 
            "title": "Review and Launch"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-ec2/#click-the-instance", 
            "text": "", 
            "title": "Click the instance"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-ec2/#when-the-status-is-running-copy-the-ip", 
            "text": "", 
            "title": "When the status is running, copy the ip"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-ec2/#open-it-via-a-web-browser-with-httpip12345", 
            "text": "", 
            "title": "Open it via a web browser with http://[ip]:12345"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-ec2/#login-the-notebook-with-the-instance-id", 
            "text": "Copy the instance ID from dashboard and paste it as a password/token", 
            "title": "Login the notebook with the instance ID"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-ec2/#have-fun-and-build-with-bigdl", 
            "text": "", 
            "title": "Have fun and build with BigDL!"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-ec2/#the-public-ami", 
            "text": "To make it easier to try out BigDL examples on Spark using EC2, a public AMI is provided. It will automatically retrieve the latest BigDL package, download the necessary input data, and then run the specified BigDL example (using Java 8 on a Spark cluster). The details of the public AMI are shown in the table below.     BigDL version  AMI version  Date  AMI ID  AMI Name  Region  Status      master  0.2S  Mar 13, 2017  ami-37b73957  BigDL Client 0.2S  US West (Oregon)  Active    master  0.2S  Apr 10, 2017  ami-8c87099a  BigDL Client 0.2S  US East (N. Virginia)  Active    0.1.0  0.1.0  Apr 10, 2017  ami-9a8818fa  BigDL Client 0.1.0  US West (Oregon)  Active    0.1.0  0.1.0  Apr 10, 2017  ami-6476f872  BigDL Client 0.1.0  US East (N. Virginia)  Active     Please note that it is highly recommended to run BigDL using EC2 instances with Xeon E5 v3 or v4 processors.  After launching the AMI on EC2, please log on to the instance and run a \"bootstrap.sh\" script to download example scripts.  ./bootstrap.sh", 
            "title": "The Public AMI"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-ec2/#before-you-start", 
            "text": "Before running the BigDL examples, you need to launch a Spark cluster on EC2 (you may refer to  https://github.com/amplab/spark-ec2  for more instructions). In addition, to run the Inception-v1 example, you also need to start a HDFS cluster on EC2 to store the input image data.", 
            "title": "Before you start"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-ec2/#run-bigdl-examples", 
            "text": "You can run BigDL examples using the  run.example.sh  script in home directory of your BigDL Client instance (e.g.  /home/ubuntu/ ) with the following parameters:    Mandatory parameters:    -m|--model  which model to train, including    lenet: train the  LeNet  example    vgg: train the  VGG  example    inception-v1: train the  Inception v1  example    perf: test the training speed using the  Inception v1  model with dummy data      -s|--spark-url  the master URL for the Spark cluster    -n|--nodes  number of Spark slave nodes    -o|--cores  number of cores used on each node    -r|--memory  memory used on each node, e.g. 200g    -b|--batch-size  batch size when training the model; it is expected to be a multiple of \"nodes * cores\"    -f|--hdfs-data-dir  HDFS directory for the input images (for the \"inception-v1\" model training only)      Optional parameters:    -e|--max-epoch  the maximum number of epochs (i.e., going through all the input data once) used in the training; default to 90 if not specified    -p|--spark  by default the example will run with Spark 1.5 or 1.6; to use Spark 2.0, please specify \"spark_2.0\" here (it is highly recommended to use  Java 8  when running BigDL for Spark 2.0, otherwise you may observe very poor performance)    -l|--learning-rate  by default the the example will use an initial learning rate of \"0.01\"; you can specify a different value here      After the training, you can check the log files and generated models in the home directory (e.g.,  /home/ubuntu/ ).", 
            "title": "Run BigDL Examples"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-ec2/#run-the-inception-v1-example", 
            "text": "You can refer to the  Inception v1  example to prepare the input  ImageNet  data here. Alternatively, you may also download just a small set of images (with dummy labels) to run the example as follows, which can be useful if you only want to try it out to see the training speed on a Spark cluster.   Download and prepare the input image data (a subset of the  Flickr Style  data)     ./download.sh $HDFS-NAMENODE  After the download completes, the downloaded images are stored in  hdfs://HDFS-NAMENODE:9000/seq . (If the download fails with error \"Unable to establish SSL connection.\" please check your network connection and retry this later.)   To run the \"inception-v1\" example on a 4-worker Spark cluster (using, say, the \"m4.10xlarge\" instance), run the example command below:      nohup bash ./run.example.sh --model inception-v1  \\\n         --spark-url spark://SPARK-MASTER:7077    \\\n         --nodes 4 --cores 20 --memory 150g       \\\n         --batch-size 400 --learning-rate 0.0898  \\\n         --hdfs-data-dir hdfs://HDFS-NAMENODE:9000/seq \\\n         --spark spark_2.0 --max-epoch 4 \\\n           incep.log 2 1          View output of the training in the log file generated by the previous step:     $ tail -f incep.log\n  2017-01-10 10:03:55 INFO  DistriOptimizer$:241 - [Epoch 1 0/5000][Iteration 1][Wall Clock XXX] Train 512 in XXXseconds. Throughput is XXX records/second. Loss is XXX.\n  2017-01-10 10:03:58 INFO  DistriOptimizer$:241 - [Epoch 1 512/5000][Iteration 2][Wall Clock XXX] Train 512 in XXXseconds. Throughput is XXX records/second. Loss is XXX.\n  2017-01-10 10:04:00 INFO  DistriOptimizer$:241 - [Epoch 1 1024/5000][Iteration 3][Wall Clock XXX] Train 512 in XXXseconds. Throughput is XXX records/second. Loss is XXX.\n  2017-01-10 10:04:03 INFO  DistriOptimizer$:241 - [Epoch 1 1536/5000][Iteration 4][Wall Clock XXX] Train 512 in XXXseconds. Throughput is XXX records/second. Loss is XXX.\n  2017-01-10 10:04:05 INFO  DistriOptimizer$:241 - [Epoch 1 2048/5000][Iteration 5][Wall Clock XXX] Train 512 in XXXseconds. Throughput is XXX records/second. Loss is XXX.", 
            "title": "Run the \"inception-v1\" example"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-ec2/#run-the-perf-example", 
            "text": "To run the \"perf\" example on a 4-worker Spark cluster (using, say, the \"m4.10xlarge\" instance), you may try the example command below:     nohup bash ./run.example.sh --model perf  \\\n       --spark-url spark://SPARK-MASTER:7077    \\\n       --nodes 4 --cores 20 --memory 150g       \\\n       --spark spark_2.0 --max-epoch 4 \\\n         perf.log 2 1", 
            "title": "Run the \"perf\" example"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-dataproc/", 
            "text": "Deploy BigDL on Dataproc\n\n\nBefore using BigDL on Google Dataproc, you need setup a project and create a cluster on Dataproc(you may refer to \nhttps://cloud.google.com/sdk/docs/how-to\n for more instructions). Now you can create a Cloud Dataproc cluster using the Google Cloud SDK's(https://cloud.google.com/sdk/docs/) gcloud command-line tool.\n\n\nTo make it easy to try out BigDL on Spark on Dataproc, an initial action script is provided. You can use use this initialization action to create a new Dataproc cluster with BigDL pre-installed by https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/blob/master/bigdl/bigdl.sh\nYou can use below command to create a new cluster with BigDL preinstall\n\n\ngcloud dataproc clusters create \nCLUSTER_NAME\n --initialization-actions=gs://dataproc-initialization-actions/bigdl/bigdl.sh\n\n\n\n\nNote:\n\n\nBy default, it will automatically download BigDL 0.4.0 for Dataproc 1.2 (Spark 2.2.0 and Scala 2.11.8). To download a different version of BigDL or one targeted to a different version of Spark/Scala, find the download URL from the BigDL releases page, and set the metadata key \"bigdl-download-url\".\neg.\n\n\ngcloud dataproc clusters create \nCLUSTER_NAME\n \\\n    --image-version 1.0 \\\n    --initialization-actions gs://dataproc-initialization-actions/bigdl/bigdl.sh \\\n    --initialization-action-timeout 10m \\\n    --metadata 'bigdl-download-url=https://s3-ap-southeast-1.amazonaws.com/bigdl-download/dist-spark-1.6.2-scala-2.10.5-all-0.4.0-dist.zip'\n\n\n\n\nMore information please refer https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/tree/master/bigdl\n\n\nOnce the cluster is provisioned, you will be able to see the cluster running in the Google Cloud Platform Console. Now you can SSH to the master node.\n\n\nCloud Dataproc support various way to SSH to the master, here we use SSH from Google Cloud SDK.\nE.g.,\n\n\ngcloud compute --project \nPROJECT_ID\n ssh --zone \nZONE\n \nCLUSTER_NAME\n\n\n\n\n\nGoogle cloud SDK will perform the authentication for you and open an SSH client (Eg Putty).\n\n\nYou should be able to find BigDL is located under /opt/intel-bigdl. And your VM is ready for running deep learning examples at scale!\n\n\n\n\nRun BigDL Scala Examples\n\n\nNow you can run BigDL examples on Google Dataproc. For instance, you may use the \nrun.example.sh\n script which is located under ./bin directory with following parameters:\n\n\n\n\n\n\nMandatory parameters:\n\n\n\n\n\n\n-m|--model\n which model to train, including\n\n\n\n\n\n\nlenet: train the \nLeNet\n example\n\n\n\n\n\n\nvgg: train the \nVGG\n example\n\n\n\n\n\n\ninception-v1: train the \nInception v1\n example\n\n\n\n\n\n\nperf: test the training speed using the \nInception v1\n model with dummy data\n\n\n\n\n\n\n\n\n\n\n-s|--spark-url\n the master URL for the Spark cluster\n\n\n\n\n\n\n-n|--nodes\n number of Spark slave nodes\n\n\n\n\n\n\n-o|--cores\n number of cores used on each node\n\n\n\n\n\n\n-r|--memory\n memory used on each node, e.g. 200g\n\n\n\n\n\n\n-b|--batch-size\n batch size when training the model; it is expected to be a multiple of \"nodes * cores\"\n\n\n\n\n\n\n-f|--hdfs-data-dir\n HDFS directory for the input images (for the \"inception-v1\" model training only)\n\n\n\n\n\n\n\n\n\n\nOptional parameters:\n\n\n\n\n\n\n-e|--max-epoch\n the maximum number of epochs (i.e., going through all the input data once) used in the training; default to 90 if not specified\n\n\n\n\n\n\n-p|--spark\n by default the example will run with Spark 1.5 or 1.6; to use Spark 2.0, please specify \"spark_2.0\" here (it is highly recommended to use \nJava 8\n when running BigDL for Spark 2.0, otherwise you may observe very poor performance)\n\n\n\n\n\n\n-l|--learning-rate\n by default the the example will use an initial learning rate of \"0.01\"; you can specify a different value here\n\n\n\n\n\n\n\n\n\n\nAfter the training, you can check the log files and generated models  \n\n\nReplace $BIGDLJAR with bigdl binary name in ./lib in below command, eg: bigdl-SPARK_2.2-0.3.0-jar-with-dependencies.jar  \n\n\n./bin/run.example.sh --model lenet --nodes 2 --cores 2 --memory 1g --batch-size 16 -j lib/$BIGDLJAR -p spark_buildIn\n\n\n\n\nYou can also run lenet examples in below command. Before submit below command, please make sure you have already downloaded mnist and put it under mnist directory, more detail see https://github.com/intel-analytics/BigDL/tree/master/spark/dl/src/main/scala/com/intel/analytics/bigdl/models/lenet:   \n\n\nspark-submit \\\n --executor-cores 2 \\\n --num-executors 2 \\\n --driver-class-path ./lib/$BIGDLJAR \\\n --class com.intel.analytics.bigdl.models.lenet.Train \\\n ./lib/$BIGDLJAR \\\n -f ./mnist \\\n -b 16\n\n\n\n\n\n\nRun BigDL Python example\n\n\nDownload lenet5.py from https://github.com/intel-analytics/BigDL/blob/master/pyspark/bigdl/models/lenet/lenet5.py\n\n\nwget https://raw.githubusercontent.com/intel-analytics/BigDL/master/pyspark/bigdl/models/lenet/lenet5.py\n\n\n\n\nReplace $BIGDLJAR with bigdl binary name in ./lib, eg: bigdl-SPARK_2.2-0.3.0-jar-with-dependencies.jar\n\nReplace $BIGDL_PYTHON_ZIP with bigdl python binary name in ./lib, eg: bigdl-0.3.0-python-api.zip\n\n\nPYTHON_API_ZIP_PATH=./lib/$BIGDL_PYTHON_ZIP\nBigDL_JAR_PATH=./lib/$BIGDLJAR\nPYTHONPATH=${PYTHON_API_ZIP_PATH}:$PYTHONPATH\nspark-submit \\\n        --driver-cores 2  \\\n        --driver-memory 2g  \\\n        --num-executors 2  \\\n        --executor-cores 2  \\\n        --executor-memory 4g \\\n        --py-files ${PYTHON_API_ZIP_PATH},./lenet5.py  \\\n        --properties-file ./conf/spark-bigdl.conf \\\n        --jars ${BigDL_JAR_PATH} \\\n        --conf spark.driver.extraClassPath=${BigDL_JAR_PATH} \\\n        --conf spark.executor.extraClassPath=${BigDL_JAR_PATH} \\\n        ./lenet5.py \\\n        --action train", 
            "title": "Run on Google Cloud Dataproc"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-dataproc/#deploy-bigdl-on-dataproc", 
            "text": "Before using BigDL on Google Dataproc, you need setup a project and create a cluster on Dataproc(you may refer to  https://cloud.google.com/sdk/docs/how-to  for more instructions). Now you can create a Cloud Dataproc cluster using the Google Cloud SDK's(https://cloud.google.com/sdk/docs/) gcloud command-line tool.  To make it easy to try out BigDL on Spark on Dataproc, an initial action script is provided. You can use use this initialization action to create a new Dataproc cluster with BigDL pre-installed by https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/blob/master/bigdl/bigdl.sh\nYou can use below command to create a new cluster with BigDL preinstall  gcloud dataproc clusters create  CLUSTER_NAME  --initialization-actions=gs://dataproc-initialization-actions/bigdl/bigdl.sh  Note:  By default, it will automatically download BigDL 0.4.0 for Dataproc 1.2 (Spark 2.2.0 and Scala 2.11.8). To download a different version of BigDL or one targeted to a different version of Spark/Scala, find the download URL from the BigDL releases page, and set the metadata key \"bigdl-download-url\".\neg.  gcloud dataproc clusters create  CLUSTER_NAME  \\\n    --image-version 1.0 \\\n    --initialization-actions gs://dataproc-initialization-actions/bigdl/bigdl.sh \\\n    --initialization-action-timeout 10m \\\n    --metadata 'bigdl-download-url=https://s3-ap-southeast-1.amazonaws.com/bigdl-download/dist-spark-1.6.2-scala-2.10.5-all-0.4.0-dist.zip'  More information please refer https://github.com/GoogleCloudPlatform/dataproc-initialization-actions/tree/master/bigdl  Once the cluster is provisioned, you will be able to see the cluster running in the Google Cloud Platform Console. Now you can SSH to the master node.  Cloud Dataproc support various way to SSH to the master, here we use SSH from Google Cloud SDK.\nE.g.,  gcloud compute --project  PROJECT_ID  ssh --zone  ZONE   CLUSTER_NAME   Google cloud SDK will perform the authentication for you and open an SSH client (Eg Putty).  You should be able to find BigDL is located under /opt/intel-bigdl. And your VM is ready for running deep learning examples at scale!", 
            "title": "Deploy BigDL on Dataproc"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-dataproc/#run-bigdl-scala-examples", 
            "text": "Now you can run BigDL examples on Google Dataproc. For instance, you may use the  run.example.sh  script which is located under ./bin directory with following parameters:    Mandatory parameters:    -m|--model  which model to train, including    lenet: train the  LeNet  example    vgg: train the  VGG  example    inception-v1: train the  Inception v1  example    perf: test the training speed using the  Inception v1  model with dummy data      -s|--spark-url  the master URL for the Spark cluster    -n|--nodes  number of Spark slave nodes    -o|--cores  number of cores used on each node    -r|--memory  memory used on each node, e.g. 200g    -b|--batch-size  batch size when training the model; it is expected to be a multiple of \"nodes * cores\"    -f|--hdfs-data-dir  HDFS directory for the input images (for the \"inception-v1\" model training only)      Optional parameters:    -e|--max-epoch  the maximum number of epochs (i.e., going through all the input data once) used in the training; default to 90 if not specified    -p|--spark  by default the example will run with Spark 1.5 or 1.6; to use Spark 2.0, please specify \"spark_2.0\" here (it is highly recommended to use  Java 8  when running BigDL for Spark 2.0, otherwise you may observe very poor performance)    -l|--learning-rate  by default the the example will use an initial learning rate of \"0.01\"; you can specify a different value here      After the training, you can check the log files and generated models    Replace $BIGDLJAR with bigdl binary name in ./lib in below command, eg: bigdl-SPARK_2.2-0.3.0-jar-with-dependencies.jar    ./bin/run.example.sh --model lenet --nodes 2 --cores 2 --memory 1g --batch-size 16 -j lib/$BIGDLJAR -p spark_buildIn  You can also run lenet examples in below command. Before submit below command, please make sure you have already downloaded mnist and put it under mnist directory, more detail see https://github.com/intel-analytics/BigDL/tree/master/spark/dl/src/main/scala/com/intel/analytics/bigdl/models/lenet:     spark-submit \\\n --executor-cores 2 \\\n --num-executors 2 \\\n --driver-class-path ./lib/$BIGDLJAR \\\n --class com.intel.analytics.bigdl.models.lenet.Train \\\n ./lib/$BIGDLJAR \\\n -f ./mnist \\\n -b 16", 
            "title": "Run BigDL Scala Examples"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-dataproc/#run-bigdl-python-example", 
            "text": "Download lenet5.py from https://github.com/intel-analytics/BigDL/blob/master/pyspark/bigdl/models/lenet/lenet5.py  wget https://raw.githubusercontent.com/intel-analytics/BigDL/master/pyspark/bigdl/models/lenet/lenet5.py  Replace $BIGDLJAR with bigdl binary name in ./lib, eg: bigdl-SPARK_2.2-0.3.0-jar-with-dependencies.jar \nReplace $BIGDL_PYTHON_ZIP with bigdl python binary name in ./lib, eg: bigdl-0.3.0-python-api.zip  PYTHON_API_ZIP_PATH=./lib/$BIGDL_PYTHON_ZIP\nBigDL_JAR_PATH=./lib/$BIGDLJAR\nPYTHONPATH=${PYTHON_API_ZIP_PATH}:$PYTHONPATH\nspark-submit \\\n        --driver-cores 2  \\\n        --driver-memory 2g  \\\n        --num-executors 2  \\\n        --executor-cores 2  \\\n        --executor-memory 4g \\\n        --py-files ${PYTHON_API_ZIP_PATH},./lenet5.py  \\\n        --properties-file ./conf/spark-bigdl.conf \\\n        --jars ${BigDL_JAR_PATH} \\\n        --conf spark.driver.extraClassPath=${BigDL_JAR_PATH} \\\n        --conf spark.executor.extraClassPath=${BigDL_JAR_PATH} \\\n        ./lenet5.py \\\n        --action train", 
            "title": "Run BigDL Python example"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-k8s/", 
            "text": "The \nApache Spark on Kubernetes\n project enables\nnative support for submitting Spark application to a kubernetes cluster. As a deep learning library for Apache\nSpark, BigDL can also run on Kubernetes by leveraging Spark on Kubernetes.\n\n\n\n\nPrerequisites\n\n\n\n\n\n\nYou need to have a running Kubernetes cluster that support Spark on Kubernetes. See \nhere\n\n\n\n\n\n\nYou need to spin up the \nresource staging server\n for dependency management. See \nDependency Management\n (This is optional if all your application dependencies are\npackaged into your own custom docker image or resides in remote locations like HDFS. See \nDependency Management Without The Resource Staging Server\n)\n\n\n\n\n\n\n\n\nDocker images\n\n\nBigDL already published pre-built docker images that can be deployed into containers with pods.\n\n\nThe images are as follows:\n\n\n\n\n\n\n\n\nComponent\n\n\nImage\n\n\n\n\n\n\n\n\n\n\nSpark Driver Image\n\n\nintelanalytics/spark-driver:v2.2.0-kubernetes-0.5.0\n\n\n\n\n\n\nSpark Executor Image\n\n\nintelanalytics/spark-executor:v2.2.0-kubernetes-0.5.0\n\n\n\n\n\n\nSpark Initialization Image\n\n\nintelanalytics/spark-init:v2.2.0-kubernetes-0.5.0\n\n\n\n\n\n\nPySpark Driver Image\n\n\nintelanalytics/spark-driver-py:v2.2.0-kubernetes-0.5.0\n\n\n\n\n\n\nPySpark Executor Image\n\n\nintelanalytics/spark-executor-py:v2.2.0-kubernetes-0.5.0\n\n\n\n\n\n\n\n\nYou may also build your own customized images. see instructions \nhere\n.\n\n\n\n\nRun BigDL examples\n\n\nRun BigDL on Kubernetes is quite easy once you meet the prerequisites above. For example,\nto run the BigDL scala Lenet example:\n\n\nSPARK_HOME=...\nBIGDL_HOME=...\n$SPARK_HOME/bin/spark-submit \\\n  --deploy-mode cluster \\\n  --class com.intel.analytics.bigdl.models.lenet.Train \\\n  --master k8s://https://\nk8s-apiserver-host\n:\nk8s-apiserver-port\n \\\n  --kubernetes-namespace default \\\n  --conf spark.executor.instances=4 \\\n  --conf spark.app.name=bigdl-lenet \\\n  --conf spark.executor.cores=1 \\\n  --conf spark.cores.max=4 \\\n  --conf spark.kubernetes.driver.docker.image=intelanalytics/spark-driver:v2.2.0-kubernetes-0.5.0-ubuntu-14.04 \\\n  --conf spark.kubernetes.executor.docker.image=intelanalytics/spark-executor:v2.2.0-kubernetes-0.5.0-ubuntu-14.04 \\\n  --conf spark.kubernetes.initcontainer.docker.image=intelanalytics/spark-init:v2.2.0-kubernetes-0.5.0-ubuntu-14.04 \\\n  --conf spark.kubernetes.resourceStagingServer.uri=http://\naddress-of-any-cluster-node\n:31000 \\\n  $BIGDL_HOME/lib/bigdl-0.4.0-SNAPSHOT-jar-with-dependencies.jar \\\n-f hdfs://master:9000/mnist \\\n-b 128 \\\n-e 2 \\\n--checkpoint /tmp\n\n\n\n\nTo run python lenet example:\n\n\nSPARK_HOME=...\nBIGDL_HOME=...\n$SPARK_HOME/bin/spark-submit \\\n  --deploy-mode cluster \\\n  --master k8s://https://\nk8s-apiserver-host\n:\nk8s-apiserver-port\n \\\n  --kubernetes-namespace default \\\n  --jars $BIGDL_HOME/lib/bigdl-0.4.0-SNAPSHOT-jar-with-dependencies.jar \\\n  --py-files $BIGDL_HOME/lib/bigdl-0.4.0-SNAPSHOT-python-api.zip \\\n  --conf spark.executor.instances=4 \\\n  --conf spark.app.name=bigdl-1 \\\n  --conf spark.executor.cores=1 \\\n  --conf spark.cores.max=4 \\\n  --conf spark.kubernetes.driver.docker.image=intelanalytics/spark-driver-py:v2.2.0-kubernetes-0.5.0-ubuntu-14.04 \\\n  --conf spark.kubernetes.executor.docker.image=intelanalytics/spark-executor-py:v2.2.0-kubernetes-0.5.0-ubuntu-14.04 \\\n  --conf spark.kubernetes.initcontainer.docker.image=intelanalytics/spark-init:v2.2.0-kubernetes-0.5.0-ubuntu-14.04 \\\n  --conf spark.kubernetes.resourceStagingServer.uri=http://\naddress-of-any-cluster-node\n:31000 \\\n  bigdl/models/lenet/lenet5.py \\\n  --action train \\\n  --dataPath /tmp/mnist \\\n  -n 2", 
            "title": "Run on Kubernetes"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-k8s/#prerequisites", 
            "text": "You need to have a running Kubernetes cluster that support Spark on Kubernetes. See  here    You need to spin up the  resource staging server  for dependency management. See  Dependency Management  (This is optional if all your application dependencies are\npackaged into your own custom docker image or resides in remote locations like HDFS. See  Dependency Management Without The Resource Staging Server )", 
            "title": "Prerequisites"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-k8s/#docker-images", 
            "text": "BigDL already published pre-built docker images that can be deployed into containers with pods.  The images are as follows:     Component  Image      Spark Driver Image  intelanalytics/spark-driver:v2.2.0-kubernetes-0.5.0    Spark Executor Image  intelanalytics/spark-executor:v2.2.0-kubernetes-0.5.0    Spark Initialization Image  intelanalytics/spark-init:v2.2.0-kubernetes-0.5.0    PySpark Driver Image  intelanalytics/spark-driver-py:v2.2.0-kubernetes-0.5.0    PySpark Executor Image  intelanalytics/spark-executor-py:v2.2.0-kubernetes-0.5.0     You may also build your own customized images. see instructions  here .", 
            "title": "Docker images"
        }, 
        {
            "location": "/ProgrammingGuide/run-on-k8s/#run-bigdl-examples", 
            "text": "Run BigDL on Kubernetes is quite easy once you meet the prerequisites above. For example,\nto run the BigDL scala Lenet example:  SPARK_HOME=...\nBIGDL_HOME=...\n$SPARK_HOME/bin/spark-submit \\\n  --deploy-mode cluster \\\n  --class com.intel.analytics.bigdl.models.lenet.Train \\\n  --master k8s://https:// k8s-apiserver-host : k8s-apiserver-port  \\\n  --kubernetes-namespace default \\\n  --conf spark.executor.instances=4 \\\n  --conf spark.app.name=bigdl-lenet \\\n  --conf spark.executor.cores=1 \\\n  --conf spark.cores.max=4 \\\n  --conf spark.kubernetes.driver.docker.image=intelanalytics/spark-driver:v2.2.0-kubernetes-0.5.0-ubuntu-14.04 \\\n  --conf spark.kubernetes.executor.docker.image=intelanalytics/spark-executor:v2.2.0-kubernetes-0.5.0-ubuntu-14.04 \\\n  --conf spark.kubernetes.initcontainer.docker.image=intelanalytics/spark-init:v2.2.0-kubernetes-0.5.0-ubuntu-14.04 \\\n  --conf spark.kubernetes.resourceStagingServer.uri=http:// address-of-any-cluster-node :31000 \\\n  $BIGDL_HOME/lib/bigdl-0.4.0-SNAPSHOT-jar-with-dependencies.jar \\\n-f hdfs://master:9000/mnist \\\n-b 128 \\\n-e 2 \\\n--checkpoint /tmp  To run python lenet example:  SPARK_HOME=...\nBIGDL_HOME=...\n$SPARK_HOME/bin/spark-submit \\\n  --deploy-mode cluster \\\n  --master k8s://https:// k8s-apiserver-host : k8s-apiserver-port  \\\n  --kubernetes-namespace default \\\n  --jars $BIGDL_HOME/lib/bigdl-0.4.0-SNAPSHOT-jar-with-dependencies.jar \\\n  --py-files $BIGDL_HOME/lib/bigdl-0.4.0-SNAPSHOT-python-api.zip \\\n  --conf spark.executor.instances=4 \\\n  --conf spark.app.name=bigdl-1 \\\n  --conf spark.executor.cores=1 \\\n  --conf spark.cores.max=4 \\\n  --conf spark.kubernetes.driver.docker.image=intelanalytics/spark-driver-py:v2.2.0-kubernetes-0.5.0-ubuntu-14.04 \\\n  --conf spark.kubernetes.executor.docker.image=intelanalytics/spark-executor-py:v2.2.0-kubernetes-0.5.0-ubuntu-14.04 \\\n  --conf spark.kubernetes.initcontainer.docker.image=intelanalytics/spark-init:v2.2.0-kubernetes-0.5.0-ubuntu-14.04 \\\n  --conf spark.kubernetes.resourceStagingServer.uri=http:// address-of-any-cluster-node :31000 \\\n  bigdl/models/lenet/lenet5.py \\\n  --action train \\\n  --dataPath /tmp/mnist \\\n  -n 2", 
            "title": "Run BigDL examples"
        }, 
        {
            "location": "/ProgrammingGuide/tensorflow-support/", 
            "text": "BigDL supports loading and saving tensorflow models.\nThis page will give you a basic introduction of this feature. For more\ninteresting and sophisticated examples, please checkout \nhere\n.\n\n\nLoading a Tensorflow model into BigDL\n\n\nBigDL supports loading tensorflow model with only a few lines of code.\n\n\nIf we already have a freezed graph protobuf file, we can use the \nloadTF\n api directly to\nload the tensorflow model. \n\n\nOtherwise, we should first use the \nexport_tf_checkpoint.py\n script provided by BigDL's distribution\npackage, or the \ndump_model\n function defined in \nhere\n to\ngenerate the model definition file (\nmodel.pb\n) and variable binary file (\nmodel.bin\n). \n\n\nGenerate model definition file and variable binary file\n\n\nUse Script\n\n\nCKPT_FILE_PREFIX=/tmp/tensorflow/model.ckpt\nSAVE_PATH=/tmp/model/\npython export_tf_checkpoint.py $CKPT_FILE_PREFIX $SAVE_PATH\n\n\n\n\nUse python function\n\n\nimport tensorflow as tf\n\n# This is your model definition.\nxs = tf.placeholder(tf.float32, [None, 1])\n\nW1 = tf.Variable(tf.zeros([1,10])+0.2)\nb1 = tf.Variable(tf.zeros([10])+0.1)\nWx_plus_b1 = tf.nn.bias_add(tf.matmul(xs,W1), b1)\noutput = tf.nn.tanh(Wx_plus_b1, name=\noutput\n)\n\n# Adding the following lines right after your model definition \nfrom bigdl.util.tf_utils import dump_model\ndump_model_path = \n/tmp/model\n\n# This line of code will create a Session and initialized all the Variable and\n# save the model definition and variable to dump_model_path as BigDL readable format.\ndump_model(path=dump_model_path)\n\n\n\n\nOptionally, you can also pass in a initialized (either from scratch or from a checkpoint) Session object containing\nall the variables of your model or pass in a pre-trained checkpoint path directly. See the \ndump_model\n doc in this\n\nfile\n.\n\n\nLoad Tensorflow model in BigDL\n\n\nScala\n\n\nimport com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.nn.Module\nimport java.nio.ByteOrder\n\nval modelPath = \n/tmp/model/model.pb\n\nval binPath = \n/tmp/model/model.bin\n\nval inputs = Seq(\nPlaceholder\n)\nval outputs = Seq(\noutput\n)\nval model = Module.loadTF(modelPath, Seq(\nPlaceholder\n),\n    Seq(\noutput\n), ByteOrder.LITTLE_ENDIAN, Some(binPath))\n\n\n\n\nPython\n\n\nfrom bigdl.nn.layer import *\nmodel_def = \n/tmp/model/model.pb\n\nmodel_variable = \n/tmp/model/model.bin\n\ninputs = [\nPlaceholder\n]\noutputs = [\noutput\n]\nmodel = Model.load_tensorflow(model_def, inputs, outputs, byte_order = \nlittle_endian\n, bigdl_type=\nfloat\n, bin_file=model_variable)\n\n\n\n\n\n\nSaving a BigDL functional model to Tensorflow model file\n\n\nYou can also save a \nfunctional model\n to protobuf files so that it can be used in Tensorflow inference.\n\n\nWhen saving the model, placeholders will be added to the tf model as input nodes. So\nyou need to pass in the names and shapes of the placeholders. BigDL model does not have\nsuch information. The order of the placeholder information should be same as the inputs\nof the graph model.\n\n\nScala\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.tf.TensorflowSaver\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n// create a graph model\nval linear = Linear(10, 2).inputs()\nval sigmoid = Sigmoid().inputs(linear)\nval softmax = SoftMax().inputs(sigmoid)\nval model = Graph(Array(linear), Array(softmax))\n\n// save it to Tensorflow model file\nmodel.saveTF(Seq((\ninput\n, Seq(4, 10))), \n/tmp/model.pb\n)\n\n\n\n\nPython\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\n# create a graph model\nlinear = Linear(10, 2)()\nsigmoid = Sigmoid()(linear)\nsoftmax = SoftMax()(sigmoid)\nmodel = Model([linear], [softmax])\n\n# save it to Tensorflow model file\nmodel.save_tensorflow([(\ninput\n, [4, 10])], \n/tmp/model.pb\n)\n\n\n\n\n\n\nBuild Tensorflow model and run on BigDL\n\n\nYou can construct your BigDL model directly from the input and output nodes of\nTensorflow model. That is to say, you can use Tensorflow to define\na model and use BigDL to run it.\n\n\nPython:\n\n\nimport tensorflow as tf\nimport numpy as np\nfrom bigdl.nn.layer import *\n\ntf.set_random_seed(1234)\ninput = tf.placeholder(tf.float32, [None, 5])\nweight = tf.Variable(tf.random_uniform([5, 10]))\nbias = tf.Variable(tf.random_uniform([10]))\nmiddle = tf.nn.bias_add(tf.matmul(input, weight), bias)\noutput = tf.nn.tanh(middle)\n\n# construct BigDL model and get the result form \nbigdl_model = Model(input, output, model_type=\ntensorflow\n)\n\n\n\n\nSupported Operations\n\n\nPlease check this \npage", 
            "title": "Tensorflow Support"
        }, 
        {
            "location": "/ProgrammingGuide/tensorflow-support/#loading-a-tensorflow-model-into-bigdl", 
            "text": "BigDL supports loading tensorflow model with only a few lines of code.  If we already have a freezed graph protobuf file, we can use the  loadTF  api directly to\nload the tensorflow model.   Otherwise, we should first use the  export_tf_checkpoint.py  script provided by BigDL's distribution\npackage, or the  dump_model  function defined in  here  to\ngenerate the model definition file ( model.pb ) and variable binary file ( model.bin ).", 
            "title": "Loading a Tensorflow model into BigDL"
        }, 
        {
            "location": "/ProgrammingGuide/tensorflow-support/#generate-model-definition-file-and-variable-binary-file", 
            "text": "Use Script  CKPT_FILE_PREFIX=/tmp/tensorflow/model.ckpt\nSAVE_PATH=/tmp/model/\npython export_tf_checkpoint.py $CKPT_FILE_PREFIX $SAVE_PATH  Use python function  import tensorflow as tf\n\n# This is your model definition.\nxs = tf.placeholder(tf.float32, [None, 1])\n\nW1 = tf.Variable(tf.zeros([1,10])+0.2)\nb1 = tf.Variable(tf.zeros([10])+0.1)\nWx_plus_b1 = tf.nn.bias_add(tf.matmul(xs,W1), b1)\noutput = tf.nn.tanh(Wx_plus_b1, name= output )\n\n# Adding the following lines right after your model definition \nfrom bigdl.util.tf_utils import dump_model\ndump_model_path =  /tmp/model \n# This line of code will create a Session and initialized all the Variable and\n# save the model definition and variable to dump_model_path as BigDL readable format.\ndump_model(path=dump_model_path)  Optionally, you can also pass in a initialized (either from scratch or from a checkpoint) Session object containing\nall the variables of your model or pass in a pre-trained checkpoint path directly. See the  dump_model  doc in this file .", 
            "title": "Generate model definition file and variable binary file"
        }, 
        {
            "location": "/ProgrammingGuide/tensorflow-support/#load-tensorflow-model-in-bigdl", 
            "text": "Scala  import com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.nn.Module\nimport java.nio.ByteOrder\n\nval modelPath =  /tmp/model/model.pb \nval binPath =  /tmp/model/model.bin \nval inputs = Seq( Placeholder )\nval outputs = Seq( output )\nval model = Module.loadTF(modelPath, Seq( Placeholder ),\n    Seq( output ), ByteOrder.LITTLE_ENDIAN, Some(binPath))  Python  from bigdl.nn.layer import *\nmodel_def =  /tmp/model/model.pb \nmodel_variable =  /tmp/model/model.bin \ninputs = [ Placeholder ]\noutputs = [ output ]\nmodel = Model.load_tensorflow(model_def, inputs, outputs, byte_order =  little_endian , bigdl_type= float , bin_file=model_variable)", 
            "title": "Load Tensorflow model in BigDL"
        }, 
        {
            "location": "/ProgrammingGuide/tensorflow-support/#saving-a-bigdl-functional-model-to-tensorflow-model-file", 
            "text": "You can also save a  functional model  to protobuf files so that it can be used in Tensorflow inference.  When saving the model, placeholders will be added to the tf model as input nodes. So\nyou need to pass in the names and shapes of the placeholders. BigDL model does not have\nsuch information. The order of the placeholder information should be same as the inputs\nof the graph model.  Scala  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.tf.TensorflowSaver\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n// create a graph model\nval linear = Linear(10, 2).inputs()\nval sigmoid = Sigmoid().inputs(linear)\nval softmax = SoftMax().inputs(sigmoid)\nval model = Graph(Array(linear), Array(softmax))\n\n// save it to Tensorflow model file\nmodel.saveTF(Seq(( input , Seq(4, 10))),  /tmp/model.pb )  Python  from bigdl.nn.layer import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\n# create a graph model\nlinear = Linear(10, 2)()\nsigmoid = Sigmoid()(linear)\nsoftmax = SoftMax()(sigmoid)\nmodel = Model([linear], [softmax])\n\n# save it to Tensorflow model file\nmodel.save_tensorflow([( input , [4, 10])],  /tmp/model.pb )", 
            "title": "Saving a BigDL functional model to Tensorflow model file"
        }, 
        {
            "location": "/ProgrammingGuide/tensorflow-support/#build-tensorflow-model-and-run-on-bigdl", 
            "text": "You can construct your BigDL model directly from the input and output nodes of\nTensorflow model. That is to say, you can use Tensorflow to define\na model and use BigDL to run it.  Python:  import tensorflow as tf\nimport numpy as np\nfrom bigdl.nn.layer import *\n\ntf.set_random_seed(1234)\ninput = tf.placeholder(tf.float32, [None, 5])\nweight = tf.Variable(tf.random_uniform([5, 10]))\nbias = tf.Variable(tf.random_uniform([10]))\nmiddle = tf.nn.bias_add(tf.matmul(input, weight), bias)\noutput = tf.nn.tanh(middle)\n\n# construct BigDL model and get the result form \nbigdl_model = Model(input, output, model_type= tensorflow )", 
            "title": "Build Tensorflow model and run on BigDL"
        }, 
        {
            "location": "/ProgrammingGuide/tensorflow-support/#supported-operations", 
            "text": "Please check this  page", 
            "title": "Supported Operations"
        }, 
        {
            "location": "/ProgrammingGuide/caffe-support/", 
            "text": "If you have a pretrained caffe model(model definition prototxt and model binary file), you can load it as BigDL model.\nYou can also convert a BigDL model to caffe model.\n\n\nLoad Caffe Model\n\n\nAssume you have a \ncaffe.prototxt\n and \ncaffe.model\n,\nyou can load it into BigDL by calling \nModule.loadCaffeModel\n (scala) or \nModel.load_caffe_model\n (python).\n\n\n\n\nScala Example\n\n\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nval model = Module.loadCaffeModel(caffe.prototxt, caffe.model)\n\n\n\n\n\n\nPython Example\n\n\n\n\nmodel = Model.load_caffe_model(caffe.prototxt, caffe.model)\n\n\n\n\nLoad Caffe Model Weights to Predefined BigDL Model\n\n\nIf you have a predefined BigDL model, and want to load caffe model weights into BigDl model\n\n\n\n\nScala Example\n\n\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nval model = Module.loadCaffe(bigdlModel, caffe.prototxt, caffe.model, matchAll = true)\n\n\n\n\n\n\nPython Example\n\n\n\n\nmodel = Model.load_caffe(bigdlModel, caffe.prototxt, caffe.model, match_all=True)\n\n\n\n\nNote that if \nmatchAll/match_all = false\n, then only layers with same name will be loaded, the rest will use initialized parameters.\n\n\nSave BigDL Model to Caffe Model\n\n\n\n\nScala Example\n\n\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nbigdlModel.saveCaffe(prototxtPath, modelPath, useV2 = true, overwrite = false)\n\n\n\n\n\n\nPython Example\n\n\n\n\nbigdl_model.save_caffe(prototxt_path, model_path, use_v2 = True, overwrite = False)\n\n\n\n\nIn the above examples, if \nuseV2/use_v2 = true\n, it will convert to caffe V2 layer,\n otherwise, it will convert to caffe V1 layer.\nIf \noverwrite = true\n, it will overwrite the existing files.\n\n\nNote: only graph model can be saved to caffe model.\n\n\nLimitation\n\n\nThis functionality has been tested with some common models like AlexNet, Inception, Resnet which were created with standard Caffe layers, for those models with customized layers such as SSD, it is going to be supported in future work, but you can define your customized conversion method for your own layers.\n\n\nSupported Layers\n\n\nPlease check this \npage", 
            "title": "Caffe Support"
        }, 
        {
            "location": "/ProgrammingGuide/caffe-support/#load-caffe-model", 
            "text": "Assume you have a  caffe.prototxt  and  caffe.model ,\nyou can load it into BigDL by calling  Module.loadCaffeModel  (scala) or  Model.load_caffe_model  (python).   Scala Example   import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nval model = Module.loadCaffeModel(caffe.prototxt, caffe.model)   Python Example   model = Model.load_caffe_model(caffe.prototxt, caffe.model)", 
            "title": "Load Caffe Model"
        }, 
        {
            "location": "/ProgrammingGuide/caffe-support/#load-caffe-model-weights-to-predefined-bigdl-model", 
            "text": "If you have a predefined BigDL model, and want to load caffe model weights into BigDl model   Scala Example   import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nval model = Module.loadCaffe(bigdlModel, caffe.prototxt, caffe.model, matchAll = true)   Python Example   model = Model.load_caffe(bigdlModel, caffe.prototxt, caffe.model, match_all=True)  Note that if  matchAll/match_all = false , then only layers with same name will be loaded, the rest will use initialized parameters.", 
            "title": "Load Caffe Model Weights to Predefined BigDL Model"
        }, 
        {
            "location": "/ProgrammingGuide/caffe-support/#save-bigdl-model-to-caffe-model", 
            "text": "Scala Example   import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nbigdlModel.saveCaffe(prototxtPath, modelPath, useV2 = true, overwrite = false)   Python Example   bigdl_model.save_caffe(prototxt_path, model_path, use_v2 = True, overwrite = False)  In the above examples, if  useV2/use_v2 = true , it will convert to caffe V2 layer,\n otherwise, it will convert to caffe V1 layer.\nIf  overwrite = true , it will overwrite the existing files.  Note: only graph model can be saved to caffe model.", 
            "title": "Save BigDL Model to Caffe Model"
        }, 
        {
            "location": "/ProgrammingGuide/caffe-support/#limitation", 
            "text": "This functionality has been tested with some common models like AlexNet, Inception, Resnet which were created with standard Caffe layers, for those models with customized layers such as SSD, it is going to be supported in future work, but you can define your customized conversion method for your own layers.", 
            "title": "Limitation"
        }, 
        {
            "location": "/ProgrammingGuide/caffe-support/#supported-layers", 
            "text": "Please check this  page", 
            "title": "Supported Layers"
        }, 
        {
            "location": "/ProgrammingGuide/keras-support/", 
            "text": "For \nPython\n users, BigDL supports loading pre-defined Keras models.\n\n\nThe Keras version we support and test is \nKeras 1.2.2\n with TensorFlow backend. Up to now, we have generally supported \nALL\n its layers.\n\n\nAfter loading a model into BigDL, you can train, evaluate or tune this model in a distributed manner. We have generally supported \nALL\n the \nlosses\n in Keras 1.2.2. See \nhere\n to find the corresponding criterions in BigDL.\n\n\nIf you haven't been familiar with BigDL yet, you may refer to Python User Guide on how to \ninstall\n and \nrun\n BigDL for Python users before you start this page.\n\n\nLoad a Keras model into BigDL\n\n\nA Keras model definition in \nJSON\n file can be loaded as a BigDL model.\nSaved weights in \nHDF5\n file can also be loaded together with the architecture of a Keras model.\nSee \nhere\n on how to save a model in Keras.\n\n\nYou can directly call the API \nModel.load_keras\n to load a Keras model into BigDL.\n\n\nRemark\n: \nkeras==1.2.2\n is required beforehand. If you are to load a HDF5 file, you also need to install \nh5py\n. These packages can be installed via \npip\n easily.\n\n\nfrom bigdl.nn.layer import *\n\nbigdl_model = Model.load_keras(json_path=None, hdf5_path=None, by_name=False)\n\n\n\n\nParameters\n:\n\n\n\n\njson_path\n The JSON file path containing the Keras model definition to be loaded. Default to be \nNone\n if you choose to load a Keras model from a HDF5 file.\n\n\nhdf5_path\n The HDF5 file path containing the pre-trained weights with or without the model architecture. Please use weights from Keras 1.2.2 with \ntensorflow backend\n. Default to be \nNone\n if you choose to only load the model definition from JSON but not to load weights. In this case, BigDL will use initialized weights for the model.\n\n\nby_name\n  Whether to load the weights of layers by name. Use this option only when you provide a HDF5 file. Default to be \nFalse\n, meaning that  weights are loaded based on the network's execution order topology. Otherwise, if it is set to be \nTrue\n, only those layers with the same name will be loaded with weights.\n\n\n\n\nNOTES\n:\n\n\n\n\n\n\nPlease provide either \njson_path\n or \nhdf5_path\n when you call \nModel.load_keras\n. You can provide \njson_path\n only to just load the model definition. You can provide \njson_path\n and \nhdf5_path\n together if you have separate files for the model architecture and its pre-trained weights. Also, if you save the model architecture and its weights in a single HDF5 file, you can provide \nhdf5_path\n only.\n\n\n\n\n\n\nJSON and HDF5 files can be loaded from any Hadoop-supported file system URI. For example,\n\n\n\n\n\n\n# load from local file system\nbigdl_model = Model.load_keras(json_path=\n/tmp/model.json\n, hdf5_path=\n/tmp/weights.h5\n)\n# load from HDFS\nbigdl_model = Model.load_keras(hdf5_path=\nhdfs://model.h5\n)\n# load from S3\nbigdl_model = Model.load_keras(hdf5_path=\ns3://model.h5\n)\n\n\n\n\nLeNet Example\n\n\nHere we show a simple example on how to load a Keras model into BigDL. The model used in this example is a \nCNN\n from Keras 1.2.2.\n\n\n# Define a CNN model in Keras 1.2.2\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Convolution2D, MaxPooling2D\n\nkeras_model = Sequential()\nkeras_model.add(Convolution2D(32, 3, 3, border_mode='valid',\n                              input_shape=(1, 28, 28)))\nkeras_model.add(Activation('relu'))\nkeras_model.add(Convolution2D(32, 3, 3))\nkeras_model.add(Activation('relu'))\nkeras_model.add(MaxPooling2D(pool_size=(2, 2)))\nkeras_model.add(Dropout(0.25))\nkeras_model.add(Flatten())\nkeras_model.add(Dense(128))\nkeras_model.add(Activation('relu'))\nkeras_model.add(Dropout(0.5))\nkeras_model.add(Dense(10))\nkeras_model.add(Activation('softmax'))\n\n# Save the Keras model definition to JSON\nmodel_json = keras_model.to_json()\npath = \n/tmp/lenet.json\n\nwith open(def_path, \nw\n) as json_file:\n    json_file.write(model_json)\n\n# Load the JSON file to a BigDL model\nfrom bigdl.nn.layer import *\nbigdl_model = Model.load_keras(json_path=path)\n\n\n\n\nAfter loading the model into BigDL, you can train it with the MNIST dataset. See \nhere\n for the full example code which includes the training and validation after model loading. After 12 epochs, accuracy \n97% can be achieved.\n\n\nYou can find several more examples \nhere\n to get familiar with loading a Keras model into BigDL. We will add more examples to this directory in the future.\n\n\nLimitations\n\n\nWe have tested the model loading functionality with several standard Keras \napplications\n and \nexamples\n.\n\n\nHowever, there exist some arguments for Keras layers that are not supported in BigDL for now. Also, we haven't supported self-defined Keras layers, but one can still define your customized layer converter and weight converter methods for new layers if you wish. See \nhere\n for the full list of unsupported layer arguments and some known issues we have found so far.\n\n\nIn our future work, we will continue to add functionality and better support running Keras on BigDL.", 
            "title": "Keras Support"
        }, 
        {
            "location": "/ProgrammingGuide/keras-support/#load-a-keras-model-into-bigdl", 
            "text": "A Keras model definition in  JSON  file can be loaded as a BigDL model.\nSaved weights in  HDF5  file can also be loaded together with the architecture of a Keras model.\nSee  here  on how to save a model in Keras.  You can directly call the API  Model.load_keras  to load a Keras model into BigDL.  Remark :  keras==1.2.2  is required beforehand. If you are to load a HDF5 file, you also need to install  h5py . These packages can be installed via  pip  easily.  from bigdl.nn.layer import *\n\nbigdl_model = Model.load_keras(json_path=None, hdf5_path=None, by_name=False)  Parameters :   json_path  The JSON file path containing the Keras model definition to be loaded. Default to be  None  if you choose to load a Keras model from a HDF5 file.  hdf5_path  The HDF5 file path containing the pre-trained weights with or without the model architecture. Please use weights from Keras 1.2.2 with  tensorflow backend . Default to be  None  if you choose to only load the model definition from JSON but not to load weights. In this case, BigDL will use initialized weights for the model.  by_name   Whether to load the weights of layers by name. Use this option only when you provide a HDF5 file. Default to be  False , meaning that  weights are loaded based on the network's execution order topology. Otherwise, if it is set to be  True , only those layers with the same name will be loaded with weights.   NOTES :    Please provide either  json_path  or  hdf5_path  when you call  Model.load_keras . You can provide  json_path  only to just load the model definition. You can provide  json_path  and  hdf5_path  together if you have separate files for the model architecture and its pre-trained weights. Also, if you save the model architecture and its weights in a single HDF5 file, you can provide  hdf5_path  only.    JSON and HDF5 files can be loaded from any Hadoop-supported file system URI. For example,    # load from local file system\nbigdl_model = Model.load_keras(json_path= /tmp/model.json , hdf5_path= /tmp/weights.h5 )\n# load from HDFS\nbigdl_model = Model.load_keras(hdf5_path= hdfs://model.h5 )\n# load from S3\nbigdl_model = Model.load_keras(hdf5_path= s3://model.h5 )", 
            "title": "Load a Keras model into BigDL"
        }, 
        {
            "location": "/ProgrammingGuide/keras-support/#lenet-example", 
            "text": "Here we show a simple example on how to load a Keras model into BigDL. The model used in this example is a  CNN  from Keras 1.2.2.  # Define a CNN model in Keras 1.2.2\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Convolution2D, MaxPooling2D\n\nkeras_model = Sequential()\nkeras_model.add(Convolution2D(32, 3, 3, border_mode='valid',\n                              input_shape=(1, 28, 28)))\nkeras_model.add(Activation('relu'))\nkeras_model.add(Convolution2D(32, 3, 3))\nkeras_model.add(Activation('relu'))\nkeras_model.add(MaxPooling2D(pool_size=(2, 2)))\nkeras_model.add(Dropout(0.25))\nkeras_model.add(Flatten())\nkeras_model.add(Dense(128))\nkeras_model.add(Activation('relu'))\nkeras_model.add(Dropout(0.5))\nkeras_model.add(Dense(10))\nkeras_model.add(Activation('softmax'))\n\n# Save the Keras model definition to JSON\nmodel_json = keras_model.to_json()\npath =  /tmp/lenet.json \nwith open(def_path,  w ) as json_file:\n    json_file.write(model_json)\n\n# Load the JSON file to a BigDL model\nfrom bigdl.nn.layer import *\nbigdl_model = Model.load_keras(json_path=path)  After loading the model into BigDL, you can train it with the MNIST dataset. See  here  for the full example code which includes the training and validation after model loading. After 12 epochs, accuracy  97% can be achieved.  You can find several more examples  here  to get familiar with loading a Keras model into BigDL. We will add more examples to this directory in the future.", 
            "title": "LeNet Example"
        }, 
        {
            "location": "/ProgrammingGuide/keras-support/#limitations", 
            "text": "We have tested the model loading functionality with several standard Keras  applications  and  examples .  However, there exist some arguments for Keras layers that are not supported in BigDL for now. Also, we haven't supported self-defined Keras layers, but one can still define your customized layer converter and weight converter methods for new layers if you wish. See  here  for the full list of unsupported layer arguments and some known issues we have found so far.  In our future work, we will continue to add functionality and better support running Keras on BigDL.", 
            "title": "Limitations"
        }, 
        {
            "location": "/ProgrammingGuide/quantization-support/", 
            "text": "Introduction\n\n\nQuantization is a method that will use low-precision caculations to substitute float caculations. It will improve the inference performance and reduce the size of model by up to 4x.\n\n\nQuantize the pretrained model\n\n\nBigDL provide command line tools for converting the pretrained (BigDL, Caffe, Torch and Tensorflow) model to quantized model with parameter \n--quantize true\n.\n\n\n#!/bin/bash\n\nset -x\n\nBIGDL_HOME=${WORKSPACE}/dist\nJAR_HOME=${BIGDL_HOME}/spark/dl/target\nSPARK_JAR=/opt/spark/jars/*\nJAR=${JAR_HOME}/bigdl-0.6.0-SNAPSHOT-jar-with-dependencies.jar:${SPARK_JAR}\nCLASS=com.intel.analytics.bigdl.utils.ConvertModel\n\nFROM=caffe\nTO=bigdl\nMODEL=bvlc_alexnet.caffemodel\n\njava -cp ${JAR} ${CLASS} --from ${FROM} --to ${TO} \\\n    --input ${MODEL} --output ${MODEL%%.caffemodel}.bigdlmodel \\\n    --prototxt ${PWD}/deploy.prototxt --quantize true\n\n\n\n\nConvertModel supports converting different types of pretrained models to bigdlmodel.\nIt also supports converting bigdlmodel to other types. The help is\n\n\nUsage: Convert models between different dl frameworks [options]\n\n  --from \nvalue\n\n        What's the type origin model bigdl,caffe,torch,tensorflow?\n  --to \nvalue\n\n        What's the type of model you want bigdl,caffe,torch?\n  --input \nvalue\n\n        Where's the origin model file?\n  --output \nvalue\n\n        Where's the bigdl model file to save?\n  --prototxt \nvalue\n\n        Where's the caffe deploy prototxt?\n  --quantize \nvalue\n\n        Do you want to quantize the model? Only works when \n--to\n is bigdl;you can only perform inference using the new quantized model.\n  --tf_inputs \nvalue\n\n        Inputs for Tensorflow\n  --tf_outputs \nvalue\n\n        Outputs for Tensorflow\n\n\n\n\n\nQuantize model in code\n\n\nYou can call \nquantize()\n method to quantize the model. It will deep copy original model and generate new one. You can only perform inference using the new quantized model.\n\n\nval model = xxx\nval quantizedModel = model.quantize()\nquantizeModel.forward(inputTensor)\n\n\n\n\nThere's also a Python API which is same as scala version.\n\n\nmodel = xxx\nquantizedModel = model.quantize()", 
            "title": "Quantization Support"
        }, 
        {
            "location": "/ProgrammingGuide/quantization-support/#introduction", 
            "text": "Quantization is a method that will use low-precision caculations to substitute float caculations. It will improve the inference performance and reduce the size of model by up to 4x.", 
            "title": "Introduction"
        }, 
        {
            "location": "/ProgrammingGuide/quantization-support/#quantize-the-pretrained-model", 
            "text": "BigDL provide command line tools for converting the pretrained (BigDL, Caffe, Torch and Tensorflow) model to quantized model with parameter  --quantize true .  #!/bin/bash\n\nset -x\n\nBIGDL_HOME=${WORKSPACE}/dist\nJAR_HOME=${BIGDL_HOME}/spark/dl/target\nSPARK_JAR=/opt/spark/jars/*\nJAR=${JAR_HOME}/bigdl-0.6.0-SNAPSHOT-jar-with-dependencies.jar:${SPARK_JAR}\nCLASS=com.intel.analytics.bigdl.utils.ConvertModel\n\nFROM=caffe\nTO=bigdl\nMODEL=bvlc_alexnet.caffemodel\n\njava -cp ${JAR} ${CLASS} --from ${FROM} --to ${TO} \\\n    --input ${MODEL} --output ${MODEL%%.caffemodel}.bigdlmodel \\\n    --prototxt ${PWD}/deploy.prototxt --quantize true  ConvertModel supports converting different types of pretrained models to bigdlmodel.\nIt also supports converting bigdlmodel to other types. The help is  Usage: Convert models between different dl frameworks [options]\n\n  --from  value \n        What's the type origin model bigdl,caffe,torch,tensorflow?\n  --to  value \n        What's the type of model you want bigdl,caffe,torch?\n  --input  value \n        Where's the origin model file?\n  --output  value \n        Where's the bigdl model file to save?\n  --prototxt  value \n        Where's the caffe deploy prototxt?\n  --quantize  value \n        Do you want to quantize the model? Only works when  --to  is bigdl;you can only perform inference using the new quantized model.\n  --tf_inputs  value \n        Inputs for Tensorflow\n  --tf_outputs  value \n        Outputs for Tensorflow", 
            "title": "Quantize the pretrained model"
        }, 
        {
            "location": "/ProgrammingGuide/quantization-support/#quantize-model-in-code", 
            "text": "You can call  quantize()  method to quantize the model. It will deep copy original model and generate new one. You can only perform inference using the new quantized model.  val model = xxx\nval quantizedModel = model.quantize()\nquantizeModel.forward(inputTensor)  There's also a Python API which is same as scala version.  model = xxx\nquantizedModel = model.quantize()", 
            "title": "Quantize model in code"
        }, 
        {
            "location": "/ProgrammingGuide/add-layer-criterion/", 
            "text": "How to add your own layer or criterion into BigDL\n\n\nIf you'd like to create a layer or criterion which has not been covered by BigDL library, you just\nneed to extend the AbstractModule or AbstractCriterion class in scala.\n\n\nHere we show how to do it with some examples.\n\n\nCreate a layer in scala\n\n\nSay we want to create a layer which adds one to each element of the input tensor. We can write code\nlike this:\n\n\nimport com.intel.analytics.bigdl.nn.abstractnn.AbstractModule\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\n\nclass AddOneLayer extends AbstractModule[Tensor[Float], Tensor[Float], Float]{\n\n  override def updateOutput(input: Tensor[Float]): Tensor[Float] = {\n    output.resizeAs(input).copy(input).add(1.0f)\n    output\n  }\n\n  override def updateGradInput(input: Tensor[Float], gradOutput: Tensor[Float]): Tensor[Float] = {\n    gradInput.resizeAs(gradOutput).copy(gradOutput)\n    gradInput\n  }\n}\n\n\n\n\nIn the above code piece, we create a new Layer class by extending the AbstractModule. AbstractModule\nhas three generic type: \ninput data type\n, \noutput data type\n and \nparameter type\n. In this\nexample, the new layer takes a float tensor as input, and outputs a float tensor.\n\n\nWe override two methods, \nupdateOutput\n and \nupdateGradInput\n\n\n\n\nupdateOutput\n\n\n\n\nIn the forward process, each layer invokes the updateOutput method to process the input data. The\n\nAddOneLayer\n copy the input data to the output tensor, and then add one to each element.\n\n\nYou may notice that we don't change the input tensor. The input tensor may be used in serval layers,\nso change it may cause incorrect result.\n\n\nEach layer has an buffer named as \noutput\n. The output is cached in that buffer to be used by the\nsucceed layers. The output buffer is inited as an empty tensor, so we need to resize it when we use.\n\n\n\n\nupdateGradInput\n\n\n\n\nIn the backward process, each layer invokes the updateGradInput method to back propagate the\ngradients. Note the direction is backward, so the layer takes a gradOutput and produce a gradInput.\n\n\nFor how the backward works, please check the \nChain Rule\n.\nThe \nAddOneLayer\n just back propagate the gradients identity to its prior layers. We don't modify\nthe gradOutput for the same reason in the updateOutput method.\n\n\nCreate a layer with multiple inputs\n\n\nWhen a layer has multiple input data(e.g. multiple tensors), we can use \nTable\n as input type of\nthe layer. \nTable\n is a nested type.\n\n\nSay we want to create a layer, which takes two float tensors as input, and add them together as\noutput.\n\n\nHere's the code example:\n\n\nimport com.intel.analytics.bigdl.nn.abstractnn.AbstractModule\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.{T, Table}\n\nclass AddTwoTensorLayer extends AbstractModule[Table, Tensor[Float], Float]{\n\n  override def updateOutput(input: Table): Tensor[Float] = {\n    val firstTensor = input[Tensor[Float]](1)\n    val secondTensor = input[Tensor[Float]](2)\n    output.resizeAs(firstTensor).copy(firstTensor).add(secondTensor)\n    output\n  }\n\n  override def updateGradInput(input: Table, gradOutput: Tensor[Float]): Table = {\n    val firstGrad = gradInput.getOrElse[Tensor[Float]](1, Tensor[Float]())\n    val secondGrad = gradInput.getOrElse[Tensor[Float]](2, Tensor[Float]())\n    firstGrad.resizeAs(gradOutput).copy(gradOutput)\n    secondGrad.resizeAs(gradOutput).copy(gradOutput)\n    gradInput(1) = firstGrad\n    gradInput(2) = secondGrad\n    gradInput\n  }\n}\n\n\n\n\nWhen use table, we provide the index key(start from 1) and the type. Please note that as the input\ntype is Table, the gradInput buffer is also inited as an empty Table.\n\n\nCreate a layer with multiple outputs\n\n\nWhen a layer has multiple outputs, we just need to specify the output type as \nTable\n.\n\n\nSay we want a layer to split a N-d tensor into many (N - 1)-d tensors in the first dimension. Here\nis the code example:\n\n\nimport com.intel.analytics.bigdl.nn.abstractnn.AbstractModule\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.{T, Table}\n\nclass UnpackLayer extends AbstractModule[Tensor[Float], Table, Float]{\n\n  override def updateOutput(input: Tensor[Float]): Table = {\n    require(input.nDimension() \n 1)\n    output = T()\n    (1 to input.size(1)).foreach(i =\n {\n      output(i) = Tensor[Float]().resizeAs(input.select(1, i)).copy(input.select(1, i))\n    })\n    output\n  }\n\n  override def updateGradInput(input: Tensor[Float], gradOutput: Table): Tensor[Float] = {\n    gradInput.resizeAs(input)\n    (1 to input.size(1)).foreach(i =\n {\n      gradInput.select(1, i).copy(gradOutput[Tensor[Float]](i))\n    })\n    gradInput\n  }\n}\n\n\n\n\nCreate a layer with parameters\n\n\nSome layers are trainable, which means they have some parameters and the parameters are changed in\nthe training process. Trainable layer need to override extra methods.\n\n\nParameters are all tensors and their numeric type is determined by the third generic type of the\nAbstractModule.\n\n\nSay we want to create a tensor which multiply a N x 3 matrix with a 3 x 2 parameter, and get a N x 2\noutput. It looks like our first example. Here is the initial code:\n\n\nimport com.intel.analytics.bigdl.nn.abstractnn.AbstractModule\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.{T, Table}\n\nclass MatrixLayer extends AbstractModule[Tensor[Float], Tensor[Float], Float]{\n\n  private val w = Tensor[Float](3, 2)\n\n  override def updateOutput(input: Tensor[Float]): Tensor[Float] = {\n    require(input.size(2) == 3)\n    output.resize(input.size(1), 2).zero().addmm(input, w)\n  }\n\n  override def updateGradInput(input: Tensor[Float], gradOutput: Tensor[Float]): Tensor[Float] = {\n    gradInput.resizeAs(input)\n    gradInput.zero().addmm(gradOutput, w.t())\n  }\n}\n\n\n\n\nHowever, the parameter w here is not trainable. We need override several methods. Here's the code\nexample\n\n\n  private val g = Tensor[Float](3, 2)\n\n  override def accGradParameters(input: Tensor[Float], gradOutput: Tensor[Float]): Unit = {\n    g.addmm(gradOutput, input.t())\n  }\n\n  override def parameters(): (Array[Tensor[Float]], Array[Tensor[Float]]) = {\n    (Array(w), Array(g))\n  }\n\n  override def zeroGradParameters(): Unit = {\n    g.zero()\n  }\n\n  override def reset(): Unit = {\n      w.rand()\n      g.zero()\n  }\n\n\n\n\nFirst we introduce a new tensor g, which has same size with parameter w. We call g gradParameter, as\nit stores the gradients which will be used to update w.\n\n\n\n\naccGradParameters\n\n\n\n\nIn this method, we cacluate the gradient of w and accumulate it to gradParameter g\n\n\n\n\nparameters\n\n\n\n\nReturn parameters and gradient parameters of this layer. Default it return nothing. In this example,\nwe return w and g. Please note that some layer can have multiple parameters.\n\n\n\n\nzeroGradParameters\n\n\n\n\nReset gradParameters to zero.\n\n\n\n\nreset\n\n\n\n\nReInitialize the parameter and reset gradParameter to zero\n\n\nHow to use gradient to update parameter\n\n\nYou may notice that in the layer we don't define how to use g to update w. Layers just provide\ngradient and parameters. How to use gradient to update parameter is handled by\n\noptimize methods\n and\n\noptimizer\n.\n\n\nCreate a criterion in scala\n\n\nTo create your own criterion, you need to extend the \nAbstractCriterion\n class. The criterion\ntake two inputs, and calculate some scalar 'distance' between them, and the gradient indicting how\nto reduce the 'distance'.\n\n\nLet's create a simple criterion to demostrate how it works. This criterion will calculate the sum of\nabstract value of elementwise difference between the two input tensors. Here is the code:\n\n\nimport com.intel.analytics.bigdl.nn.abstractnn.{AbstractCriterion, AbstractModule}\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.{T, Table}\n\nclass AbsCriterion extends AbstractCriterion[Tensor[Float], Tensor[Float], Float]{\n\n  override def updateOutput(input: Tensor[Float], target: Tensor[Float]): Float = {\n    (input - target).abs().sum\n  }\n\n  override def updateGradInput(input: Tensor[Float], target: Tensor[Float]): Tensor[Float] = {\n    gradInput.resizeAs(input).copy(input)\n    gradInput.map(target, (a, b) =\n if (a \n b) 1 else if (a == b) 0 else -1)\n  }\n}\n\n\n\n\nAbstractCeiterion has three generic types: \nfirst input type\n, \nsecond input type\n and\n\nloss type\n. In this example, the first input and the second input are both tensors. The loss\nis float.\n\n\nWe need to override two method: \nupdateOutput\n and \nupdateGradInput\n. It's similiar to layer.\n\n\n\n\nupdateOutput\n\n\n\n\nCalculate the loss from the given two inputs. In this example, we first element-wise sub the two\ntensor, then calculate the abstract value and then sum the result together.\n\n\n\n\nupdateGradInput\n\n\n\n\nComput the gradient against the input tensor. In this example, we element-wise compare the two\ntensors. If input \n target, the gradient is 1, if input == target, the gradient is 0, else the\ngradient is -1.", 
            "title": "Define New Layer/Criterion"
        }, 
        {
            "location": "/ProgrammingGuide/add-layer-criterion/#how-to-add-your-own-layer-or-criterion-into-bigdl", 
            "text": "If you'd like to create a layer or criterion which has not been covered by BigDL library, you just\nneed to extend the AbstractModule or AbstractCriterion class in scala.  Here we show how to do it with some examples.", 
            "title": "How to add your own layer or criterion into BigDL"
        }, 
        {
            "location": "/ProgrammingGuide/add-layer-criterion/#create-a-layer-in-scala", 
            "text": "Say we want to create a layer which adds one to each element of the input tensor. We can write code\nlike this:  import com.intel.analytics.bigdl.nn.abstractnn.AbstractModule\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\n\nclass AddOneLayer extends AbstractModule[Tensor[Float], Tensor[Float], Float]{\n\n  override def updateOutput(input: Tensor[Float]): Tensor[Float] = {\n    output.resizeAs(input).copy(input).add(1.0f)\n    output\n  }\n\n  override def updateGradInput(input: Tensor[Float], gradOutput: Tensor[Float]): Tensor[Float] = {\n    gradInput.resizeAs(gradOutput).copy(gradOutput)\n    gradInput\n  }\n}  In the above code piece, we create a new Layer class by extending the AbstractModule. AbstractModule\nhas three generic type:  input data type ,  output data type  and  parameter type . In this\nexample, the new layer takes a float tensor as input, and outputs a float tensor.  We override two methods,  updateOutput  and  updateGradInput   updateOutput   In the forward process, each layer invokes the updateOutput method to process the input data. The AddOneLayer  copy the input data to the output tensor, and then add one to each element.  You may notice that we don't change the input tensor. The input tensor may be used in serval layers,\nso change it may cause incorrect result.  Each layer has an buffer named as  output . The output is cached in that buffer to be used by the\nsucceed layers. The output buffer is inited as an empty tensor, so we need to resize it when we use.   updateGradInput   In the backward process, each layer invokes the updateGradInput method to back propagate the\ngradients. Note the direction is backward, so the layer takes a gradOutput and produce a gradInput.  For how the backward works, please check the  Chain Rule .\nThe  AddOneLayer  just back propagate the gradients identity to its prior layers. We don't modify\nthe gradOutput for the same reason in the updateOutput method.", 
            "title": "Create a layer in scala"
        }, 
        {
            "location": "/ProgrammingGuide/add-layer-criterion/#create-a-layer-with-multiple-inputs", 
            "text": "When a layer has multiple input data(e.g. multiple tensors), we can use  Table  as input type of\nthe layer.  Table  is a nested type.  Say we want to create a layer, which takes two float tensors as input, and add them together as\noutput.  Here's the code example:  import com.intel.analytics.bigdl.nn.abstractnn.AbstractModule\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.{T, Table}\n\nclass AddTwoTensorLayer extends AbstractModule[Table, Tensor[Float], Float]{\n\n  override def updateOutput(input: Table): Tensor[Float] = {\n    val firstTensor = input[Tensor[Float]](1)\n    val secondTensor = input[Tensor[Float]](2)\n    output.resizeAs(firstTensor).copy(firstTensor).add(secondTensor)\n    output\n  }\n\n  override def updateGradInput(input: Table, gradOutput: Tensor[Float]): Table = {\n    val firstGrad = gradInput.getOrElse[Tensor[Float]](1, Tensor[Float]())\n    val secondGrad = gradInput.getOrElse[Tensor[Float]](2, Tensor[Float]())\n    firstGrad.resizeAs(gradOutput).copy(gradOutput)\n    secondGrad.resizeAs(gradOutput).copy(gradOutput)\n    gradInput(1) = firstGrad\n    gradInput(2) = secondGrad\n    gradInput\n  }\n}  When use table, we provide the index key(start from 1) and the type. Please note that as the input\ntype is Table, the gradInput buffer is also inited as an empty Table.", 
            "title": "Create a layer with multiple inputs"
        }, 
        {
            "location": "/ProgrammingGuide/add-layer-criterion/#create-a-layer-with-multiple-outputs", 
            "text": "When a layer has multiple outputs, we just need to specify the output type as  Table .  Say we want a layer to split a N-d tensor into many (N - 1)-d tensors in the first dimension. Here\nis the code example:  import com.intel.analytics.bigdl.nn.abstractnn.AbstractModule\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.{T, Table}\n\nclass UnpackLayer extends AbstractModule[Tensor[Float], Table, Float]{\n\n  override def updateOutput(input: Tensor[Float]): Table = {\n    require(input.nDimension()   1)\n    output = T()\n    (1 to input.size(1)).foreach(i =  {\n      output(i) = Tensor[Float]().resizeAs(input.select(1, i)).copy(input.select(1, i))\n    })\n    output\n  }\n\n  override def updateGradInput(input: Tensor[Float], gradOutput: Table): Tensor[Float] = {\n    gradInput.resizeAs(input)\n    (1 to input.size(1)).foreach(i =  {\n      gradInput.select(1, i).copy(gradOutput[Tensor[Float]](i))\n    })\n    gradInput\n  }\n}", 
            "title": "Create a layer with multiple outputs"
        }, 
        {
            "location": "/ProgrammingGuide/add-layer-criterion/#create-a-layer-with-parameters", 
            "text": "Some layers are trainable, which means they have some parameters and the parameters are changed in\nthe training process. Trainable layer need to override extra methods.  Parameters are all tensors and their numeric type is determined by the third generic type of the\nAbstractModule.  Say we want to create a tensor which multiply a N x 3 matrix with a 3 x 2 parameter, and get a N x 2\noutput. It looks like our first example. Here is the initial code:  import com.intel.analytics.bigdl.nn.abstractnn.AbstractModule\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.{T, Table}\n\nclass MatrixLayer extends AbstractModule[Tensor[Float], Tensor[Float], Float]{\n\n  private val w = Tensor[Float](3, 2)\n\n  override def updateOutput(input: Tensor[Float]): Tensor[Float] = {\n    require(input.size(2) == 3)\n    output.resize(input.size(1), 2).zero().addmm(input, w)\n  }\n\n  override def updateGradInput(input: Tensor[Float], gradOutput: Tensor[Float]): Tensor[Float] = {\n    gradInput.resizeAs(input)\n    gradInput.zero().addmm(gradOutput, w.t())\n  }\n}  However, the parameter w here is not trainable. We need override several methods. Here's the code\nexample    private val g = Tensor[Float](3, 2)\n\n  override def accGradParameters(input: Tensor[Float], gradOutput: Tensor[Float]): Unit = {\n    g.addmm(gradOutput, input.t())\n  }\n\n  override def parameters(): (Array[Tensor[Float]], Array[Tensor[Float]]) = {\n    (Array(w), Array(g))\n  }\n\n  override def zeroGradParameters(): Unit = {\n    g.zero()\n  }\n\n  override def reset(): Unit = {\n      w.rand()\n      g.zero()\n  }  First we introduce a new tensor g, which has same size with parameter w. We call g gradParameter, as\nit stores the gradients which will be used to update w.   accGradParameters   In this method, we cacluate the gradient of w and accumulate it to gradParameter g   parameters   Return parameters and gradient parameters of this layer. Default it return nothing. In this example,\nwe return w and g. Please note that some layer can have multiple parameters.   zeroGradParameters   Reset gradParameters to zero.   reset   ReInitialize the parameter and reset gradParameter to zero  How to use gradient to update parameter  You may notice that in the layer we don't define how to use g to update w. Layers just provide\ngradient and parameters. How to use gradient to update parameter is handled by optimize methods  and optimizer .", 
            "title": "Create a layer with parameters"
        }, 
        {
            "location": "/ProgrammingGuide/add-layer-criterion/#create-a-criterion-in-scala", 
            "text": "To create your own criterion, you need to extend the  AbstractCriterion  class. The criterion\ntake two inputs, and calculate some scalar 'distance' between them, and the gradient indicting how\nto reduce the 'distance'.  Let's create a simple criterion to demostrate how it works. This criterion will calculate the sum of\nabstract value of elementwise difference between the two input tensors. Here is the code:  import com.intel.analytics.bigdl.nn.abstractnn.{AbstractCriterion, AbstractModule}\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.{T, Table}\n\nclass AbsCriterion extends AbstractCriterion[Tensor[Float], Tensor[Float], Float]{\n\n  override def updateOutput(input: Tensor[Float], target: Tensor[Float]): Float = {\n    (input - target).abs().sum\n  }\n\n  override def updateGradInput(input: Tensor[Float], target: Tensor[Float]): Tensor[Float] = {\n    gradInput.resizeAs(input).copy(input)\n    gradInput.map(target, (a, b) =  if (a   b) 1 else if (a == b) 0 else -1)\n  }\n}  AbstractCeiterion has three generic types:  first input type ,  second input type  and loss type . In this example, the first input and the second input are both tensors. The loss\nis float.  We need to override two method:  updateOutput  and  updateGradInput . It's similiar to layer.   updateOutput   Calculate the loss from the given two inputs. In this example, we first element-wise sub the two\ntensor, then calculate the abstract value and then sum the result together.   updateGradInput   Comput the gradient against the input tensor. In this example, we element-wise compare the two\ntensors. If input   target, the gradient is 1, if input == target, the gradient is 0, else the\ngradient is -1.", 
            "title": "Create a criterion in scala"
        }, 
        {
            "location": "/ProgrammingGuide/Model/Serialization/", 
            "text": "It's recommended to use protobuffer based serialization method \nsaveModule\n when you want to persist your trained\nmodels or models loaded from third party frameworks, details could be found from \nModule API\n.\nThis article illustrates the implementations and how to implement customized serializer for your layers\n\n\nBigDL serialziation hierarchy\n\n\nBelow is the class hierarchy for the serialization framework\n\n\n                     Loadable       Savable\n                         .              .\n                         .              .\n                         ................\n                                 .\n                                 .\n                        ModuleSerializable\n                                 .\n                                 .\n        ........................................................................\n        .               .              .                       .               . \n        .               .              .                       .               .\n ModuleSerializer CellSerializer  ContainerSerializable   KerasSerializer  [UserDefinedSerializer]\n                                       .\n                                       .\n                           ..........................\n                           .                        .\n                           .                        .\n                     ContainerSerializer  [UserDefinedContainerSerializer]\n\n\n\n\n\nModuleSerializable: abstract class to define serialization methods and provide a default implementation\n\n\nModuleSerializer: entry for all layers' serializers\n\n\nCellSerializer: Default implementation for RNN cell modules\n\n\nContainerSerializable: Abstract class for container serializers like Sequential and provide a default implementation\n\n\nContainerSerializer: Default serializer for containers\n\n\nKerasSerializer: Keras adapter serializer implementation for keras compatible layers\n\n\n\n\nUsers can extend ModuleSerializable or ContainerSerializable to implement optional serializers for your own layer or containers\n\n\nSupported data types\n\n\nBelow are the data types supported in serialization\n\n\n\n\nInt\n\n\nLong\n\n\nShort\n\n\nFloat\n\n\nDouble\n\n\nBoolean\n\n\nString\n\n\nRegularizer\n\n\nDataFormat\n\n\nVariableFormat\n\n\nShape\n\n\nInitializationMethod\n\n\nTensor\n\n\nModule\n\n\nArray\n\n\nMap\n\n\nCustomized Data\n\n\n\n\nImplement customized data converter\n\n\nif you have your own defined data types that are not supported in serialization\nor cannot be indirectly supported by above types, you can also define your own data\nconverter by extending trait \nDataConverter\n, which has two abstract methods to implement\n\n\nThe \nsetAttributeValue\n is to define how to set your own object value to attributeBuilder\n\n\n def setAttributeValue[T : ClassTag](context: SerializeContext[T],\n                                      attributeBuilder : AttrValue.Builder, value: Any,\n                                      valueType: universe.Type = null)\n    (implicit ev: TensorNumeric[T]) : Unit\n\n\n\n\n\nIn opposite you should implement \ngetAttributeValue\n to get value from attibute\n\n\n def getAttributeValue[T : ClassTag](context: DeserializeContext,\n                                      attribute: AttrValue)(\n    implicit ev: TensorNumeric[T]) : AnyRef\n\n\n\n\nCheck \nBigDL\ncom.intel.analytics.bigdl.utils.serializer.converters.DataConverter\n\nto see more details\n\n\nThen register your data converter in \nDataConverter\n\n\ndef registerConverter(tpe : String, converter : DataConverter) : Unit \n\n\n\n\ntpe\n is the \nscala.reflect.Type\n string representation\n\n\nImplement customized serializer\n\n\nAs described above, BigDL provides a default serializer which works for most layers, thus we don't need to write serializer\nfor these layers. But there are some layers which are not stateless (Note : \nstateless\n here means except for parameters like weight and bias, and fields from layer constructor, there are no other fields that their values could change and the layer will behavior differently with these values)\n\n\nTo implement a customized serializer is straightforward, you just need to define a new serializer by extending trait \nModuleSerializable\n For most cases, you just need to override two methods\n\n\ndoSerializeModule\n defines how you serialize the stateful variables (besides weights and bias), if you layer has construct fields types of which are supported \n by BigDL, you don't even need to explicitly manage then, you could just call \nsuper.doSerializeModule(context, bigDLModelBuilder)\n instead for these values.\n\n\n```scala\n protected def doSerializeModule\nT: ClassTag\n\n                                              (implicit ev: TensorNumeric[T]) : Unit\n\n\n\n`doLoadModule` defines how you deserialize the statefule variables, same as serialization, if you layer has construct fields types of which are supported \nby BigDL, you don't even need to explicitly manage then, you could just call `super.doSerializeModule(context)` instead \n\n```scala\nprotected def doLoadModule[T: ClassTag](context: DeserializeContext)\n    (implicit ev: TensorNumeric[T]) : AbstractModule[Activity, Activity, T]\n\n\n\n\nThe only thing you want to enable your serializer is to register it in \nModuleSerializer\n\n\ndef registerModule(moduleType : String, serializer : ModuleSerializable) : Unit \n\n\n\n\nModuleType\n is the full classpath of your layer and the serializer is the serializer object you just defined\n\n\nSimilarly,  if you want to define a new serializer for your containers, you just need to define your own serializer by \nextending \nContainerSerializable\n and override the same two methods above", 
            "title": "Implement Customized Serializer"
        }, 
        {
            "location": "/ProgrammingGuide/Model/Serialization/#bigdl-serialziation-hierarchy", 
            "text": "Below is the class hierarchy for the serialization framework                       Loadable       Savable\n                         .              .\n                         .              .\n                         ................\n                                 .\n                                 .\n                        ModuleSerializable\n                                 .\n                                 .\n        ........................................................................\n        .               .              .                       .               . \n        .               .              .                       .               .\n ModuleSerializer CellSerializer  ContainerSerializable   KerasSerializer  [UserDefinedSerializer]\n                                       .\n                                       .\n                           ..........................\n                           .                        .\n                           .                        .\n                     ContainerSerializer  [UserDefinedContainerSerializer]   ModuleSerializable: abstract class to define serialization methods and provide a default implementation  ModuleSerializer: entry for all layers' serializers  CellSerializer: Default implementation for RNN cell modules  ContainerSerializable: Abstract class for container serializers like Sequential and provide a default implementation  ContainerSerializer: Default serializer for containers  KerasSerializer: Keras adapter serializer implementation for keras compatible layers   Users can extend ModuleSerializable or ContainerSerializable to implement optional serializers for your own layer or containers", 
            "title": "BigDL serialziation hierarchy"
        }, 
        {
            "location": "/ProgrammingGuide/Model/Serialization/#supported-data-types", 
            "text": "Below are the data types supported in serialization   Int  Long  Short  Float  Double  Boolean  String  Regularizer  DataFormat  VariableFormat  Shape  InitializationMethod  Tensor  Module  Array  Map  Customized Data", 
            "title": "Supported data types"
        }, 
        {
            "location": "/ProgrammingGuide/Model/Serialization/#implement-customized-data-converter", 
            "text": "if you have your own defined data types that are not supported in serialization\nor cannot be indirectly supported by above types, you can also define your own data\nconverter by extending trait  DataConverter , which has two abstract methods to implement  The  setAttributeValue  is to define how to set your own object value to attributeBuilder   def setAttributeValue[T : ClassTag](context: SerializeContext[T],\n                                      attributeBuilder : AttrValue.Builder, value: Any,\n                                      valueType: universe.Type = null)\n    (implicit ev: TensorNumeric[T]) : Unit  In opposite you should implement  getAttributeValue  to get value from attibute   def getAttributeValue[T : ClassTag](context: DeserializeContext,\n                                      attribute: AttrValue)(\n    implicit ev: TensorNumeric[T]) : AnyRef  Check  BigDL com.intel.analytics.bigdl.utils.serializer.converters.DataConverter \nto see more details  Then register your data converter in  DataConverter  def registerConverter(tpe : String, converter : DataConverter) : Unit   tpe  is the  scala.reflect.Type  string representation", 
            "title": "Implement customized data converter"
        }, 
        {
            "location": "/ProgrammingGuide/Model/Serialization/#implement-customized-serializer", 
            "text": "As described above, BigDL provides a default serializer which works for most layers, thus we don't need to write serializer\nfor these layers. But there are some layers which are not stateless (Note :  stateless  here means except for parameters like weight and bias, and fields from layer constructor, there are no other fields that their values could change and the layer will behavior differently with these values)  To implement a customized serializer is straightforward, you just need to define a new serializer by extending trait  ModuleSerializable  For most cases, you just need to override two methods  doSerializeModule  defines how you serialize the stateful variables (besides weights and bias), if you layer has construct fields types of which are supported \n by BigDL, you don't even need to explicitly manage then, you could just call  super.doSerializeModule(context, bigDLModelBuilder)  instead for these values.  ```scala\n protected def doSerializeModule T: ClassTag \n                                              (implicit ev: TensorNumeric[T]) : Unit  \n`doLoadModule` defines how you deserialize the statefule variables, same as serialization, if you layer has construct fields types of which are supported \nby BigDL, you don't even need to explicitly manage then, you could just call `super.doSerializeModule(context)` instead \n\n```scala\nprotected def doLoadModule[T: ClassTag](context: DeserializeContext)\n    (implicit ev: TensorNumeric[T]) : AbstractModule[Activity, Activity, T]  The only thing you want to enable your serializer is to register it in  ModuleSerializer  def registerModule(moduleType : String, serializer : ModuleSerializable) : Unit   ModuleType  is the full classpath of your layer and the serializer is the serializer object you just defined  Similarly,  if you want to define a new serializer for your containers, you just need to define your own serializer by \nextending  ContainerSerializable  and override the same two methods above", 
            "title": "Implement customized serializer"
        }, 
        {
            "location": "/ProgrammingGuide/image-support/", 
            "text": "Overview\n\n\nBigDL provides supports for end-to-end image processing pipeline,\nincluding image loading, pre-processing, inference/training and some utilities.\n\n\nThe basic unit of an image is \nImageFeature\n, which describes various status of the image\nby using key-value store.\nFor example, \nImageFeature\n can include original image file in bytes, image in OpenCVMat format,\nimage uri, image meta data and so on.\n\n\nImageFrame\n is a collection of \nImageFeature\n.\nIt can be a \nDistributedImageFrame\n for distributed image RDD or\n \nLocalImageFrame\n for local image array.\n\n\nImage Loading\n\n\nYou can read an \nImageFrame\n from local/distributed folder/parquet file,\nor you can directly construct a ImageFrame from RDD[ImageFeature] or Array[ImageFeature].\n\n\nScala example:\n\n\n// create LocalImageFrame from an image folder\nval localImageFrame = ImageFrame.read(\n/tmp/image/\n)\n\n// create DistributedImageFrame from an image folder\nval distributedImageFrame2 = ImageFrame.read(\n/tmp/image/\n, sc, 2)\n\n\n\n\nPython example:\n\n\n# create LocalImageFrame from an image folder\nlocal_image_frame2 = ImageFrame.read(\n/tmp/image/\n)\n\n# create DistributedImageFrame from an image folder\ndistributed_image_frame = ImageFrame.read(\n/tmp/image/\n, sc, 2)\n\n\n\n\nMore examples can be found \nhere\n\n\nImage Transformer\n\n\nBigDL has many pre-defined image transformers built on top of OpenCV:\n\n\n\n\nBrightness\n: Adjust the image brightness.\n\n\nHue\n: Adjust the image hue.\n\n\nSaturation\n: Adjust the image Saturation.\n\n\nContrast\n: Adjust the image Contrast.\n\n\nChannelOrder\n: Random change the channel order of an image\n\n\nColorJitter\n: Random adjust brightness, contrast, hue, saturation\n\n\nResize\n: Resize image\n\n\nAspectScale\n: Resize the image, keep the aspect ratio. scale according to the short edge\n\n\nRandomAspectScale\n: Resize the image by randomly choosing a scale\n\n\nChannelNormalize\n: Image channel normalize\n\n\nPixelNormalizer\n: Pixel level normalizer\n\n\nCenterCrop\n: Crop a \ncropWidth\n x \ncropHeight\n patch from center of image.\n\n\nRandomCrop\n: Random crop a \ncropWidth\n x \ncropHeight\n patch from an image.\n\n\nFixedCrop\n: Crop a fixed area of image\n\n\nDetectionCrop\n: Crop from object detections, each image should has a tensor detection,\n\n\nExpand\n: Expand image, fill the blank part with the meanR, meanG, meanB\n\n\nFiller\n: Fill part of image with certain pixel value\n\n\nHFlip\n: Flip the image horizontally\n\n\nRandomTransformer\n: It is a wrapper for transformers to control the transform probability\n\n\nBytesToMat\n: Transform byte array(original image file in byte) to OpenCVMat\n\n\nMatToFloats\n: Transform OpenCVMat to float array, note that in this transformer, the mat is released.\n\n\nMatToTensor\n: Transform opencv mat to tensor, note that in this transformer, the mat is released.\n\n\nImageFrameToSample\n: Transforms tensors that map inputKeys and targetKeys to sample, note that in this transformer, the mat has been released.\n\n\n\n\nMore examples can be found \nhere\n\n\nYou can also define your own Transformer by extending \nFeatureTransformer\n,\nand override the function \ntransformMat\n to do the actual transformation to \nImageFeature\n.\n\n\nBuild Image Transformation Pipeline\n\n\nYou can easily build the image transformation pipeline by chaining transformers.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.transform.vision.image._\nimport com.intel.analytics.bigdl.transform.vision.image.augmentation._\n\nval imgAug = BytesToMat() -\n ColorJitter() -\n\n      Expand() -\n\n      Resize(300, 300, -1) -\n\n      HFlip() -\n\n      ChannelNormalize(123, 117, 104) -\n\n      MatToTensor() -\n ImageFrameToSample()\n\n\n\n\nIn the above example, the transformations will perform sequentially.\n\n\nAssume you have an ImageFrame containing original bytes array,\n\nBytesToMat\n will transform the bytes array to \nOpenCVMat\n.\n\n\nColorJitter\n, \nExpand\n, \nResize\n, \nHFlip\n and \nChannelNormalize\n will transform over \nOpenCVMat\n,\nnote that \nOpenCVMat\n is overwrite by default.\n\n\nMatToTensor\n transform \nOpenCVMat\n to \nTensor\n, and \nOpenCVMat\n is released in this step.\n\n\nImageFrameToSample\n transform the tensors that map inputKeys and targetKeys to sample,\nwhich can be used by the following prediction or training tasks.\n\n\nPython example:\n\n\nfrom bigdl.util.common import *\nfrom bigdl.transform.vision.image import *\n\nimg_aug = Pipeline([BytesToMat(),\n      ColorJitter(),\n      Expand(),\n      Resize(300, 300, -1),\n      HFlip(),\n      ChannelNormalize(123.0, 117.0, 104.0),\n      MatToTensor(),\n      ImageFrameToSample()])\n\n\n\n\nImage Prediction\n\n\nBigDL provides easy-to-use prediction API \npredictImage\n for \nImageFrame\n.\n\n\nScala:\n\n\nmodel.predictImage(imageFrame: ImageFrame,\n                   outputLayer: String = null,\n                   shareBuffer: Boolean = false,\n                   batchPerPartition: Int = 4,\n                   predictKey: String = ImageFeature.predict)\n\n\n\n\nPython:\n\n\nmodel.predict_image(image_frame, output_layer=None, share_buffer=False,\n                    batch_per_partition=4, predict_key=\npredict\n)\n\n\n\n\nModel predict images, return imageFrame with predicted tensor\n\n\n\n\nimageFrame\n imageFrame that contains images\n\n\noutputLayer\n if outputLayer is not null, the output of layer that matches outputLayer will be used as predicted output\n\n\nshareBuffer\n whether to share same memory for each batch predict results\n\n\nbatchPerPartition\n batch size per partition, default is 4\n\n\npredictKey\n key to store predicted result\n\n\n\n\nConstruct Image Prediction Pipeline\n\n\nWith the above image-related supports, we can easily build a image prediction pipeline.\n\n\nScala example:\n\n\nval imageFrame = ImageFrame.read(imagePath, sc, nPartition)\nval transformer = Resize(256, 256) -\n CenterCrop(224, 224) -\n\n                 ChannelNormalize(0.485f, 0.456f, 0.406f, 0.229f, 0.224f, 0.225f) -\n\n                 MatToTensor() -\n ImageFrameToSample()\nval transformed = transformer(imageFrame)\nval model = Module.loadModule(modelPath)\nval output = model.predictImage(transformed)\n\n\n\n\nThe above example read a distributed ImageFrame, and performs data pre-processing.\nThen it loads a pre-trained BigDL model, and predicts over imageFrame.\nIt returns imageFrame with prediction result, which can be accessed by the key \nImageFeature.predict\n.\n\n\nIf you want to run the local example, just replace \nImageFrame.read(imagePath, sc, nPartition)\n\nwith \nImageFrame.read(imagePath)\n.\n\n\nPython example:\n\n\nimage_frame = ImageFrame.read(image_path, self.sc)\ntransformer = Pipeline([Resize(256, 256), CenterCrop(224, 224),\n                        ChannelNormalize(0.485, 0.456, 0.406, 0.229, 0.224, 0.225),\n                        MatToTensor(), ImageFrameToSample()])\ntransformed = transformer(image_frame)\nmodel = Model.loadModel(model_path)\noutput = model.predict_image(image_frame)\n\n\n\n\nYou can call \noutput.get_predict()\n to get the prediction results.", 
            "title": "Build Image Application"
        }, 
        {
            "location": "/ProgrammingGuide/image-support/#overview", 
            "text": "BigDL provides supports for end-to-end image processing pipeline,\nincluding image loading, pre-processing, inference/training and some utilities.  The basic unit of an image is  ImageFeature , which describes various status of the image\nby using key-value store.\nFor example,  ImageFeature  can include original image file in bytes, image in OpenCVMat format,\nimage uri, image meta data and so on.  ImageFrame  is a collection of  ImageFeature .\nIt can be a  DistributedImageFrame  for distributed image RDD or\n  LocalImageFrame  for local image array.", 
            "title": "Overview"
        }, 
        {
            "location": "/ProgrammingGuide/image-support/#image-loading", 
            "text": "You can read an  ImageFrame  from local/distributed folder/parquet file,\nor you can directly construct a ImageFrame from RDD[ImageFeature] or Array[ImageFeature].  Scala example:  // create LocalImageFrame from an image folder\nval localImageFrame = ImageFrame.read( /tmp/image/ )\n\n// create DistributedImageFrame from an image folder\nval distributedImageFrame2 = ImageFrame.read( /tmp/image/ , sc, 2)  Python example:  # create LocalImageFrame from an image folder\nlocal_image_frame2 = ImageFrame.read( /tmp/image/ )\n\n# create DistributedImageFrame from an image folder\ndistributed_image_frame = ImageFrame.read( /tmp/image/ , sc, 2)  More examples can be found  here", 
            "title": "Image Loading"
        }, 
        {
            "location": "/ProgrammingGuide/image-support/#image-transformer", 
            "text": "BigDL has many pre-defined image transformers built on top of OpenCV:   Brightness : Adjust the image brightness.  Hue : Adjust the image hue.  Saturation : Adjust the image Saturation.  Contrast : Adjust the image Contrast.  ChannelOrder : Random change the channel order of an image  ColorJitter : Random adjust brightness, contrast, hue, saturation  Resize : Resize image  AspectScale : Resize the image, keep the aspect ratio. scale according to the short edge  RandomAspectScale : Resize the image by randomly choosing a scale  ChannelNormalize : Image channel normalize  PixelNormalizer : Pixel level normalizer  CenterCrop : Crop a  cropWidth  x  cropHeight  patch from center of image.  RandomCrop : Random crop a  cropWidth  x  cropHeight  patch from an image.  FixedCrop : Crop a fixed area of image  DetectionCrop : Crop from object detections, each image should has a tensor detection,  Expand : Expand image, fill the blank part with the meanR, meanG, meanB  Filler : Fill part of image with certain pixel value  HFlip : Flip the image horizontally  RandomTransformer : It is a wrapper for transformers to control the transform probability  BytesToMat : Transform byte array(original image file in byte) to OpenCVMat  MatToFloats : Transform OpenCVMat to float array, note that in this transformer, the mat is released.  MatToTensor : Transform opencv mat to tensor, note that in this transformer, the mat is released.  ImageFrameToSample : Transforms tensors that map inputKeys and targetKeys to sample, note that in this transformer, the mat has been released.   More examples can be found  here  You can also define your own Transformer by extending  FeatureTransformer ,\nand override the function  transformMat  to do the actual transformation to  ImageFeature .", 
            "title": "Image Transformer"
        }, 
        {
            "location": "/ProgrammingGuide/image-support/#build-image-transformation-pipeline", 
            "text": "You can easily build the image transformation pipeline by chaining transformers.  Scala example:  import com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.transform.vision.image._\nimport com.intel.analytics.bigdl.transform.vision.image.augmentation._\n\nval imgAug = BytesToMat() -  ColorJitter() - \n      Expand() - \n      Resize(300, 300, -1) - \n      HFlip() - \n      ChannelNormalize(123, 117, 104) - \n      MatToTensor() -  ImageFrameToSample()  In the above example, the transformations will perform sequentially.  Assume you have an ImageFrame containing original bytes array, BytesToMat  will transform the bytes array to  OpenCVMat .  ColorJitter ,  Expand ,  Resize ,  HFlip  and  ChannelNormalize  will transform over  OpenCVMat ,\nnote that  OpenCVMat  is overwrite by default.  MatToTensor  transform  OpenCVMat  to  Tensor , and  OpenCVMat  is released in this step.  ImageFrameToSample  transform the tensors that map inputKeys and targetKeys to sample,\nwhich can be used by the following prediction or training tasks.  Python example:  from bigdl.util.common import *\nfrom bigdl.transform.vision.image import *\n\nimg_aug = Pipeline([BytesToMat(),\n      ColorJitter(),\n      Expand(),\n      Resize(300, 300, -1),\n      HFlip(),\n      ChannelNormalize(123.0, 117.0, 104.0),\n      MatToTensor(),\n      ImageFrameToSample()])", 
            "title": "Build Image Transformation Pipeline"
        }, 
        {
            "location": "/ProgrammingGuide/image-support/#image-prediction", 
            "text": "BigDL provides easy-to-use prediction API  predictImage  for  ImageFrame .  Scala:  model.predictImage(imageFrame: ImageFrame,\n                   outputLayer: String = null,\n                   shareBuffer: Boolean = false,\n                   batchPerPartition: Int = 4,\n                   predictKey: String = ImageFeature.predict)  Python:  model.predict_image(image_frame, output_layer=None, share_buffer=False,\n                    batch_per_partition=4, predict_key= predict )  Model predict images, return imageFrame with predicted tensor   imageFrame  imageFrame that contains images  outputLayer  if outputLayer is not null, the output of layer that matches outputLayer will be used as predicted output  shareBuffer  whether to share same memory for each batch predict results  batchPerPartition  batch size per partition, default is 4  predictKey  key to store predicted result", 
            "title": "Image Prediction"
        }, 
        {
            "location": "/ProgrammingGuide/image-support/#construct-image-prediction-pipeline", 
            "text": "With the above image-related supports, we can easily build a image prediction pipeline.  Scala example:  val imageFrame = ImageFrame.read(imagePath, sc, nPartition)\nval transformer = Resize(256, 256) -  CenterCrop(224, 224) - \n                 ChannelNormalize(0.485f, 0.456f, 0.406f, 0.229f, 0.224f, 0.225f) - \n                 MatToTensor() -  ImageFrameToSample()\nval transformed = transformer(imageFrame)\nval model = Module.loadModule(modelPath)\nval output = model.predictImage(transformed)  The above example read a distributed ImageFrame, and performs data pre-processing.\nThen it loads a pre-trained BigDL model, and predicts over imageFrame.\nIt returns imageFrame with prediction result, which can be accessed by the key  ImageFeature.predict .  If you want to run the local example, just replace  ImageFrame.read(imagePath, sc, nPartition) \nwith  ImageFrame.read(imagePath) .  Python example:  image_frame = ImageFrame.read(image_path, self.sc)\ntransformer = Pipeline([Resize(256, 256), CenterCrop(224, 224),\n                        ChannelNormalize(0.485, 0.456, 0.406, 0.229, 0.224, 0.225),\n                        MatToTensor(), ImageFrameToSample()])\ntransformed = transformer(image_frame)\nmodel = Model.loadModel(model_path)\noutput = model.predict_image(image_frame)  You can call  output.get_predict()  to get the prediction results.", 
            "title": "Construct Image Prediction Pipeline"
        }, 
        {
            "location": "/APIGuide/Engine/", 
            "text": "BigDL need some environment variables be set correctly to get a good performance. Engine.init method\ncan help you set and verify them.\n\n\nHow to do it in the code?\n\n\nBefore any BigDL related code piece, please invoke \nEngine.init\n like this\n\n\nval conf = Engine.createSparkConf()\nval sc = new SparkContext(conf)\nEngine.init\n\n\n\n\nconf=create_spark_conf()\nsc = SparkContext(conf)\ninit_engine()\n\n\n\n\nPlease note that there's an old Engine.init(executorNum, coreNumber) API, which need you pass in the\nexecutor number and core number. As user may input an incorrect value, we have changed to auto\ndetect these two values. So the old API is deprecated.\n\n\nWhat if the spark context has been created before my code get executed?\n\n\nIn some platform or application(e.g. spark-shell, pyspark or jupyter notebook), the spark context\nis created before your code execution. In such case, you cannot use the 'createSparkConf' API to\ninitialize your own spark context. Such platform or application should always allow you to modify\nthe spark configuration in some way, so you can pass in the required spark configurations by youself.\n\n\nWhat's the required configurations?\n\n\nYou can find them in the \nconf/spark-bigdl.conf\n file.\n\n\nHow to do it?\n\n\nIf you use spark shell or pyspark notebook\n\n\n# Spark shell\nspark-shell --properties-file dist/conf/spark-bigdl.conf ...\n\n# Pyspark\npyspark --properties-file dist/conf/spark-bigdl.conf ... \n\n\n\n\nIn your code\n\n\nEngine.init \n\n\n\n\ninit_engine()\n\n\n\n\nRun BigDL without Spark\n\n\nIf you run BigDL models without Spark, you should set the JVM property \nbigdl.localMode\n to true.\nSo the Engine.init won't check spark related environments.", 
            "title": "Engine"
        }, 
        {
            "location": "/APIGuide/Engine/#how-to-do-it-in-the-code", 
            "text": "Before any BigDL related code piece, please invoke  Engine.init  like this  val conf = Engine.createSparkConf()\nval sc = new SparkContext(conf)\nEngine.init  conf=create_spark_conf()\nsc = SparkContext(conf)\ninit_engine()  Please note that there's an old Engine.init(executorNum, coreNumber) API, which need you pass in the\nexecutor number and core number. As user may input an incorrect value, we have changed to auto\ndetect these two values. So the old API is deprecated.", 
            "title": "How to do it in the code?"
        }, 
        {
            "location": "/APIGuide/Engine/#what-if-the-spark-context-has-been-created-before-my-code-get-executed", 
            "text": "In some platform or application(e.g. spark-shell, pyspark or jupyter notebook), the spark context\nis created before your code execution. In such case, you cannot use the 'createSparkConf' API to\ninitialize your own spark context. Such platform or application should always allow you to modify\nthe spark configuration in some way, so you can pass in the required spark configurations by youself.", 
            "title": "What if the spark context has been created before my code get executed?"
        }, 
        {
            "location": "/APIGuide/Engine/#whats-the-required-configurations", 
            "text": "You can find them in the  conf/spark-bigdl.conf  file.", 
            "title": "What's the required configurations?"
        }, 
        {
            "location": "/APIGuide/Engine/#how-to-do-it", 
            "text": "If you use spark shell or pyspark notebook  # Spark shell\nspark-shell --properties-file dist/conf/spark-bigdl.conf ...\n\n# Pyspark\npyspark --properties-file dist/conf/spark-bigdl.conf ...   In your code  Engine.init   init_engine()", 
            "title": "How to do it?"
        }, 
        {
            "location": "/APIGuide/Engine/#run-bigdl-without-spark", 
            "text": "If you run BigDL models without Spark, you should set the JVM property  bigdl.localMode  to true.\nSo the Engine.init won't check spark related environments.", 
            "title": "Run BigDL without Spark"
        }, 
        {
            "location": "/APIGuide/Data/", 
            "text": "Tensor\n\n\nModeled after the \nTensor\n class in \nTorch\n, the \nTensor\n \npackage\n (written in Scala and leveraging \nIntel MKL\n) in BigDL provides numeric computing support for the deep learning applications (e.g., the input, output, weight, bias and   gradient of the neural networks).\n\n\nA \nTensor\n is essentially a multi-dimensional array of numeric types (\nFloat\n or \nDouble\n), you can import the numeric implicit objects(\ncom.intel.analytics.bigdl.numeric.NumericFloat\n or \ncom.intel.analytics.bigdl.numeric.NumericDouble\n), to specify the numeric type you want.\n\n\nScala example:\n\n\nYou may check it out in the interactive Scala shell (by typing \nscala -cp bigdl_SPARKVERSION-BIGDLVERSION-SNAPSHOT-jar-with-dependencies.jar\n), for instance:\n\n\n scala\n import com.intel.analytics.bigdl.tensor.Tensor\n import com.intel.analytics.bigdl.tensor.Tensor\n\n scala\n import com.intel.analytics.bigdl.numeric.NumericFloat\n import com.intel.analytics.bigdl.numeric.NumericFloat\n\n scala\n import com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.utils.T\n\n scala\n val tensor = Tensor(2, 3)\n tensor: com.intel.analytics.bigdl.tensor.Tensor =\n 0.0     0.0     0.0\n 0.0     0.0     0.0\n [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nTensor can be created with existing data.\n\n\nscala\n val a = Tensor(T(\n     | T(1f, 2f, 3f),\n     | T(4f, 5f, 6f)))\na: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0 2.0 3.0\n4.0 5.0 6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nscala\n val b = Tensor(T(\n     | T(6f, 5f, 4f),\n     | T(3f, 2f, 1f)))\nb: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n6.0 5.0 4.0\n3.0 2.0 1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\n\n\n\n+\n \n-\n \n*\n \n/\n can be applied to tensor. When the second parameter is a constant value, \n+\n \n-\n \n*\n \n*\n is element-wise operation. But when the second parameter is a tensor, \n+\n \n-\n \n/\n is element-wise operation to the tensor too, but \n*\n is a matrix multiply on two 2D tensors. \n\n\nscala\n a + 1\nres: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n2.0 3.0 4.0\n5.0 6.0 7.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nscala\n a + b\nres: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n7.0 7.0 7.0\n7.0 7.0 7.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\nscala\n a - b\nres: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-5.0    -3.0    -1.0\n1.0 3.0 5.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\nscala\n a * b.t\nres: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n28.0    10.0\n73.0    28.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\nscala\n a / b\nres: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.16666667  0.4 0.75\n1.3333334   2.5 6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nFor more API, navigate to \nAPI Guide/Full API docs\n on side bar.\n\n\n\n\nSparseTensor\n\n\nTo describe an SparseTensor, we need indices, values, and shape:\n\nindices means the indices of non-zero elements; values means the values of the non-zero elements;\nshape means the dense shape of this SparseTensor.\n\n\nFor example, an 2D 3x4 DenseTensor:\n\n\n1, 0, 0, 4\n0, 2, 0, 0\n0, 0, 3, 0\n\n\n\n\nIt's sparse representation should be \n\n\nindices(0) = Array(0, 0, 1, 2)\nindices(1) = Array(0, 3, 1, 2)\nvalues     = Array(1, 4, 2, 3)\nshape      = Array(3, 4)\n\n\n\n\nThis 2D SparseTensor representation is similar to \nzero-based coordinate matrix storage format\n.\n\n\nScala example:\n\n\nscala\n import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nscala\n import com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nscala\n val indices = Array(Array(0, 0, 1, 2), Array(0, 3, 1, 2))\nindices: Array[Array[Int]] = Array(Array(0, 0, 1, 2), Array(0, 3, 1, 2))\n\nscala\n val values = Array(1, 4, 2, 3)\nvalues: Array[Int] = Array(1, 4, 2, 3)\n\nscala\n val shape = Array(3, 4)\nshape: Array[Int] = Array(3, 4)\n\nscala\n val sparseTensor = Tensor.sparse(indices, values, shape)\nsparseTensor: com.intel.analytics.bigdl.tensor.Tensor[Int] =\n(0, 0) : 1\n(0, 3) : 4\n(1, 1) : 2\n(2, 2) : 3\n[com.intel.analytics.bigdl.tensor.SparseTensor of size 3x4]\n\nscala\n val denseTensor = Tensor.dense(sparseTensor)\ndenseTensor: com.intel.analytics.bigdl.tensor.Tensor[Int] =\n1   0   0   4\n0   2   0   0\n0   0   3   0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4]\n\n\n\n\n\n\nTable\n\n\nModeled after the \nTable\n class in \nTorch\n, the \nTable\n class (defined in package \ncom.intel.analytics.bigdl.utils\n) is widely used in BigDL (e.g., a \nTable\n of \nTensor\n can be used as the input or output of neural networks). In essence, a \nTable\n can be considered as a key-value map, and there is also a syntax sugar to create a \nTable\n using \nT()\n in BigDL.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nprintln(T(Tensor(2,2).fill(1), Tensor(2,2).fill(2)))\n\n\n\n\nOutput is\n\n\n {\n    2: 2.0  2.0 \n       2.0  2.0 \n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n    1: 1.0  1.0 \n       1.0  1.0 \n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n }\n\n\n\n\n\n\nSample\n\n\nA \nSample\n represents one record of your data set, which is comprised of \nfeature\n and \nlabel\n.\n\n\n\n\nfeature\n is one tensor or a few tensors\n\n\nlabel\n is also one tensor or a few tensors, and it may be empty in testing or unsupervised learning.\n\n\n\n\nFor example, one image and its category in image classification, one word in word2vec and one sentence and its label in RNN language model are all \nSample\n.\n\n\nEvery \nSample\n is actually a set of tensors, and them will be transformed to the input/output of the model. For example, in the case of image classification, a \nSample\n has two tensors. One is a 3D tensor representing an image; another is a 1-element tensor representing its category. For the 1-element label, you also can use a \nT\n instead of tensor.\n\n\nScala example:\n\n\n\n\nThe case where feature is one tensor with a 1-element label.\n\n\n\n\nimport com.intel.analytics.bigdl.dataset.Sample\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nval image = Tensor(3, 32, 32).rand\nval label = 1f\nval sample = Sample(image, label)\n\n\n\n\n\n\nThe case where feature is a few tensors and label is also a few tensors.\n\n\n\n\nimport com.intel.analytics.bigdl.dataset.Sample\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nval features = Array(Tensor(2, 2).rand, Tensor(2, 2).rand)\nval labels = Array(Tensor(1).fill(1), Tensor(1).fill(-1))\nval sample = Sample(features, labels)\n\n\n\n\nPython example:\n\n\nNote\n: Please always use \nSample.from_ndarray\n to construct a \nSample\n in Python.\n\n\n\n\nThe case where feature is one tensor with a 1-element label.\n\n\n\n\nAfter constructing a \nSample\n in this case, you can use \nSample.feature\n and \nSample.label\n to retrieve its feature and label, each as a tensor, respectively.\n\n\nfrom bigdl.util.common import Sample\nimport numpy as np\n\nimage = np.random.rand(3, 32, 32)\nlabel = np.array(1)\nsample = Sample.from_ndarray(image, label)\n\n# Retrieve feature and label from a Sample\nsample.feature\nsample.label\n\n\n\n\n\n\nThe case where feature is a few tensors and label is also a few tensors.\n\n\n\n\nAfter constructing a \nSample\n in this case, you can use \nSample.features\n and \nSample.labels\n to retrieve its features and labels, each as a list of tensors, respectively.\n\n\nfrom bigdl.util.common import Sample\nimport numpy as np\n\nfeatures = [np.random.rand(3, 8, 16), np.random.rand(3, 8, 16)]\nlabels = [np.array(1), np.array(-1)]\nsample = Sample.from_ndarray(features, labels)\n\n# Retrieve features and labels from a Sample\nsample.features\nsample.labels\n\n\n\n\nNote that essentially \nSample.label\n is equivalent to \nSample.labels[0]\n. You can choose to use the former if label is only one tensor and use the latter if label is a list of tensors. Similarly, \nSample.feature\n is equivalent to \nSample.features[0]\n.\n\n\n\n\nMiniBatch\n\n\nMiniBatch\n is a data structure to feed input/target to model in \nOptimizer\n. It provide \ngetInput()\n and \ngetTarget()\n function to get the input and target in this \nMiniBatch\n.\n\n\nIn almost all the cases, BigDL's default \nMiniBatch\n class can fit user's requirement. Just create your \nRDD[Sample]\n and pass it to \nOptimizer\n. If \nMiniBatch\n can't meet your requirement, you can implement your own \nMiniBatch\n class by extends \nMiniBatch\n.\n\n\nMiniBatch\n can be created by \nMiniBatch(nInputs: Int, nOutputs: Int)\n, \nnInputs\n means number of inputs, \nnOutputs\n means number of outputs. And you can use \nset(samples: Seq[Sample[T])\n to fill the content in this MiniBatch. If you \nSample\ns are not the same size, you can use \nPaddingParam\n to pad the \nSample\ns to the same size.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.dataset.Sample\nimport com.intel.analytics.bigdl.dataset.MiniBatch\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nval samples  = Array.tabulate(5)(i =\n Sample(Tensor(1, 3, 3).fill(i), i + 1f))\nval miniBatch = MiniBatch(1, 1).set(samples)\nprintln(miniBatch.getInput())\nprintln(miniBatch.getTarget())\n\n\n\n\nOutput is\n\n\n(1,1,.,.) =\n0.0 0.0 0.0 \n0.0 0.0 0.0 \n0.0 0.0 0.0 \n\n(2,1,.,.) =\n1.0 1.0 1.0 \n1.0 1.0 1.0 \n1.0 1.0 1.0 \n\n(3,1,.,.) =\n2.0 2.0 2.0 \n2.0 2.0 2.0 \n2.0 2.0 2.0 \n\n(4,1,.,.) =\n3.0 3.0 3.0 \n3.0 3.0 3.0 \n3.0 3.0 3.0 \n\n(5,1,.,.) =\n4.0 4.0 4.0 \n4.0 4.0 4.0 \n4.0 4.0 4.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5x1x3x3]\n1.0 \n2.0 \n3.0 \n4.0 \n5.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5x1]\n\n\n\n\nIf you \nSample\ns are not the same size, you can use \nPaddingParam\n to pad the \nSample\ns to the same size.\n\n\nimport com.intel.analytics.bigdl.dataset._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nval sample1 = Sample(Tensor.range(1, 6, 1).resize(2, 3), 1f)\nval sample2 = Sample(Tensor.range(7, 9, 1).resize(1, 3), 2f)\nval sample3 = Sample(Tensor.range(10, 18, 1).resize(3, 3), 3f)\nval samples = Array(sample1, sample2, sample3)\nval featurePadding = PaddingParam(Some(Array(Tensor(T(-1f, -2f, -3f)))), FixedLength(Array(4)))\nval labelPadding = PaddingParam[Float](None, FixedLength(Array(4)))\n\nval miniBatch = MiniBatch(1, 1, Some(featurePadding), Some(labelPadding)).set(samples)\nprintln(miniBatch.getInput())\nprintln(miniBatch.getTarget())\n\n\n\n\nOutput is \n\n\n(1,.,.) =\n1.0 2.0 3.0 \n4.0 5.0 6.0 \n-1.0    -2.0    -3.0    \n-1.0    -2.0    -3.0    \n\n(2,.,.) =\n7.0 8.0 9.0 \n-1.0    -2.0    -3.0    \n-1.0    -2.0    -3.0    \n-1.0    -2.0    -3.0    \n\n(3,.,.) =\n10.0    11.0    12.0    \n13.0    14.0    15.0    \n16.0    17.0    18.0    \n-1.0    -2.0    -3.0    \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x3]\n\n\n1.0 0.0 0.0 0.0 \n2.0 0.0 0.0 0.0 \n3.0 0.0 0.0 0.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4]\n\n\n\n\nDataSet\n\n\nDataSet\n is a set of data which is used in the model optimization process. You can use \nDataSet.array()\n and \nDataSet.rdd()\n function to create a \nDataset\n. The \nDataSet\n can be accessed in a random data sample sequence. In the training process, the data sequence is a looped endless sequence. While in the validation process, the data sequence is a limited length sequence. User can use the \ndata()\n method to get the data sequence. \n\n\nNotice: In most case, we recommend using a RDD[Sample] for \nOptimizer\n. Only when you want to write an application with some advanced optimization, using \nDataSet\n directly is recommended.  \n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.dataset.DataSet\n\nval tensors  = Array.tabulate(5)(i =\n Tensor(1, 3, 3).fill(i))\nval dataset = DataSet.array(tensors) // Local model, just for testing and example.\ndataset.shuffle()\nval iter = dataset.data(false)\nwhile (iter.hasNext) {\n  val d = iter.next()\n  println(d)\n}\n\n\n\n\nOutput may be\n\n\n(1,.,.) =\n4.0 4.0 4.0 \n4.0 4.0 4.0 \n4.0 4.0 4.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]\n(1,.,.) =\n0.0 0.0 0.0 \n0.0 0.0 0.0 \n0.0 0.0 0.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]\n(1,.,.) =\n2.0 2.0 2.0 \n2.0 2.0 2.0 \n2.0 2.0 2.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]\n(1,.,.) =\n1.0 1.0 1.0 \n1.0 1.0 1.0 \n1.0 1.0 1.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]\n(1,.,.) =\n3.0 3.0 3.0 \n3.0 3.0 3.0 \n3.0 3.0 3.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]\n\n\n\n\n\n\nOpenCVMat\n\n\nOpenCVMat is a Serializable wrapper of org.opencv.core.Mat.\n\n\nIt can be created by\n\n \nread\n: read local image path as opencv mat\n\n \nfromImageBytes\n: convert image file in bytes to opencv mat\n\n \nfromFloats\n: convert float array(pixels) to OpenCV mat\n\n \nfromTensor\n: convert float tensor to OpenCV mat\n\n\nScala example:\n\n\n// read local image path as OpenCVMat\nval mat = OpenCVMat.read(\n/tmp/test.jpg\n)\n\n// convert image file in bytes to OpenCVMat\nval bytes = FileUtils.readFileToByteArray(new File(path))\nval mat2 = OpenCVMat.fromImageBytes(bytes)\n\n// Convert float array(pixels) to OpenCVMat\nval mat3 = OpenCVMat.fromFloats(floatPixels, height=300, width=300)\n\n// Convert tensor to OpenCVMat\nval mat4 = OpenCVMat.fromTensor(tensor, format = \nHWC\n)\n\n\n\n\n\n\nImageFeature\n\n\nImageFeature\n is a representation of one image.\nIt can include various status of an image, by using key-value store.\nThe key is string that identifies the corresponding value.\nSome predefined keys are listed as follows:\n\n uri: uri that identifies image\n\n mat: image in OpenCVMat\n\n bytes: image file in bytes\n\n floats: image pixels in float array\n\n size: current image size (height, width, channel)\n\n originalSize: original image size (height, width, channel)\n\n label: image label\n\n predict: image prediction result\n\n boundingBox: store boundingBox of current image,\nit may be used in crop/expand that may change the size of image\n\n sample: image (and label if available) stored as Sample\n* imageTensor: image pixels in Tensor\n\n\nBesides the above keys, you can also define your key and store information needed\nin the prediction pipeline.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.transform.vision.image.ImageFeature\nimport org.apache.commons.io.FileUtils\nimport java.io.File\n\nval file = new File(\n/tmp/test.jpg\n)\nval imageFeature = ImageFeature(FileUtils.readFileToByteArray(file), uri = file.getAbsolutePath)\nprintln(imageFeature.keys())\n\n\n\n\noutput is\n\n\nSet(uri, bytes)\n\n\n\n\nPython example:\n\n\nfrom bigdl.transform.vision.image import *\nimage = cv2.imread(\n/tmp/test.jpg\n)\nimage_feature = ImageFeature(image)\nprint image_feature.keys()\n\n\n\n\noutput is\n\n\ncreating: createImageFeature\n[u'originalSize', u'mat', u'bytes']\n\n\n\n\n\n\nImageFrame\n\n\nImageFrame\n is a collection of \nImageFeature\n.\nIt can be a \nDistributedImageFrame\n for distributed image RDD or\n \nLocalImageFrame\n for local image array.\nYou can read an \nImageFrame\n from local/distributed folder/parquet file,\nor you can directly construct a ImageFrame from RDD[ImageFeature] or Array[ImageFeature].\n\n\nScala example:\n\n\nCreate LocalImageFrame, assume there is an image file \"/tmp/test.jpg\"\nand an image folder \"/tmp/image/\"\n\n\nimport com.intel.analytics.bigdl.transform.vision.image.ImageFrame\nimport com.intel.analytics.bigdl.transform.vision.image.ImageFeature\n\n// create LocalImageFrame from an image\nval localImageFrame = ImageFrame.read(\n/tmp/test.jpg\n)\n\n// create LocalImageFrame from an image folder\nval localImageFrame2 = ImageFrame.read(\n/tmp/image/\n)\n\n// create LocalImageFrame from array of ImageFeature\nval array = Array[ImageFeature]()\nval localImageFrame3 = ImageFrame.array(array)\n\n\n\n\nCreate DistributedImageFrame, assume there is an image file \"/tmp/test.jpg\"\nand an image folder\n\n\nimport com.intel.analytics.bigdl.transform.vision.image.ImageFrame\nimport com.intel.analytics.bigdl.transform.vision.image.ImageFeature\nimport com.intel.analytics.bigdl.utils.Engine\nimport org.apache.spark.SparkContext\nimport org.apache.spark.sql.SQLContext\n\nval conf = Engine.createSparkConf().setAppName(\nImageSpec\n).setMaster(\nlocal[2]\n)\nval sc = new SparkContext(conf)\nval sqlContext = new SQLContext(sc)\n\n// create DistributedImageFrame from an image\nval distributedImageFrame = ImageFrame.read(\n/tmp/test.jpg\n, sc, 2)\n\n// create DistributedImageFrame from an image folder\nval distributedImageFrame2 = ImageFrame.read(\n/tmp/image/\n, sc, 2)\n\n// create DistributedImageFrame from rdd of ImageFeature\nval array = Array[ImageFeature]()\nval rdd = sc.parallelize(array)\nval distributedImageFrame3 = ImageFrame.rdd(rdd)\n\n// create DistributedImageFrame from Parquet\nval distributedImageFrame4 = ImageFrame.readParquet(dir, sqlContext)\n\n\n\n\nPython example:\n\n\nCreate LocalImageFrame\n\n\nfrom bigdl.util.common import *\nfrom bigdl.transform.vision.image import *\n\n# create LocalImageFrame from an image\nlocal_image_frame = ImageFrame.read(\n/tmp/test.jpg\n)\n\n# create LocalImageFrame from an image folder\nlocal_image_frame2 = ImageFrame.read(\n/tmp/image/\n)\n\n# create LocalImageFrame from list of images\nimage = cv2.imread(\n/tmp/test.jpg\n)\nlocal_image_frame3 = LocalImageFrame([image])\n\n\n\n\nCreate DistributedImageFrame\n\n\nfrom bigdl.util.common import *\nfrom bigdl.transform.vision.image import *\n\nsparkConf = create_spark_conf().setMaster(\nlocal[2]\n).setAppName(\ntest image\n)\nsc = get_spark_context(sparkConf)\ninit_engine()\n\n# create DistributedImageFrame from an image\ndistributed_image_frame = ImageFrame.read(\n/tmp/test.jpg\n, sc, 2)\n\n# create DistributedImageFrame from an image folder\ndistributed_image_frame = ImageFrame.read(\n/tmp/image/\n, sc, 2)\n\n# create DistributedImageFrame from image rdd\nimage = cv2.imread(\n/tmp/test.jpg\n)\nimage_rdd = sc.parallelize([image], 2)\ndistributed_image_frame = DistributedImageFrame(image_rdd)", 
            "title": "Data"
        }, 
        {
            "location": "/APIGuide/Data/#tensor", 
            "text": "Modeled after the  Tensor  class in  Torch , the  Tensor   package  (written in Scala and leveraging  Intel MKL ) in BigDL provides numeric computing support for the deep learning applications (e.g., the input, output, weight, bias and   gradient of the neural networks).  A  Tensor  is essentially a multi-dimensional array of numeric types ( Float  or  Double ), you can import the numeric implicit objects( com.intel.analytics.bigdl.numeric.NumericFloat  or  com.intel.analytics.bigdl.numeric.NumericDouble ), to specify the numeric type you want.  Scala example:  You may check it out in the interactive Scala shell (by typing  scala -cp bigdl_SPARKVERSION-BIGDLVERSION-SNAPSHOT-jar-with-dependencies.jar ), for instance:   scala  import com.intel.analytics.bigdl.tensor.Tensor\n import com.intel.analytics.bigdl.tensor.Tensor\n\n scala  import com.intel.analytics.bigdl.numeric.NumericFloat\n import com.intel.analytics.bigdl.numeric.NumericFloat\n\n scala  import com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.utils.T\n\n scala  val tensor = Tensor(2, 3)\n tensor: com.intel.analytics.bigdl.tensor.Tensor =\n 0.0     0.0     0.0\n 0.0     0.0     0.0\n [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Tensor can be created with existing data.  scala  val a = Tensor(T(\n     | T(1f, 2f, 3f),\n     | T(4f, 5f, 6f)))\na: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0 2.0 3.0\n4.0 5.0 6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nscala  val b = Tensor(T(\n     | T(6f, 5f, 4f),\n     | T(3f, 2f, 1f)))\nb: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n6.0 5.0 4.0\n3.0 2.0 1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]  +   -   *   /  can be applied to tensor. When the second parameter is a constant value,  +   -   *   *  is element-wise operation. But when the second parameter is a tensor,  +   -   /  is element-wise operation to the tensor too, but  *  is a matrix multiply on two 2D tensors.   scala  a + 1\nres: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n2.0 3.0 4.0\n5.0 6.0 7.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nscala  a + b\nres: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n7.0 7.0 7.0\n7.0 7.0 7.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\nscala  a - b\nres: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-5.0    -3.0    -1.0\n1.0 3.0 5.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\nscala  a * b.t\nres: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n28.0    10.0\n73.0    28.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\nscala  a / b\nres: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.16666667  0.4 0.75\n1.3333334   2.5 6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  For more API, navigate to  API Guide/Full API docs  on side bar.", 
            "title": "Tensor"
        }, 
        {
            "location": "/APIGuide/Data/#sparsetensor", 
            "text": "To describe an SparseTensor, we need indices, values, and shape: \nindices means the indices of non-zero elements; values means the values of the non-zero elements;\nshape means the dense shape of this SparseTensor.  For example, an 2D 3x4 DenseTensor:  1, 0, 0, 4\n0, 2, 0, 0\n0, 0, 3, 0  It's sparse representation should be   indices(0) = Array(0, 0, 1, 2)\nindices(1) = Array(0, 3, 1, 2)\nvalues     = Array(1, 4, 2, 3)\nshape      = Array(3, 4)  This 2D SparseTensor representation is similar to  zero-based coordinate matrix storage format .  Scala example:  scala  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nscala  import com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nscala  val indices = Array(Array(0, 0, 1, 2), Array(0, 3, 1, 2))\nindices: Array[Array[Int]] = Array(Array(0, 0, 1, 2), Array(0, 3, 1, 2))\n\nscala  val values = Array(1, 4, 2, 3)\nvalues: Array[Int] = Array(1, 4, 2, 3)\n\nscala  val shape = Array(3, 4)\nshape: Array[Int] = Array(3, 4)\n\nscala  val sparseTensor = Tensor.sparse(indices, values, shape)\nsparseTensor: com.intel.analytics.bigdl.tensor.Tensor[Int] =\n(0, 0) : 1\n(0, 3) : 4\n(1, 1) : 2\n(2, 2) : 3\n[com.intel.analytics.bigdl.tensor.SparseTensor of size 3x4]\n\nscala  val denseTensor = Tensor.dense(sparseTensor)\ndenseTensor: com.intel.analytics.bigdl.tensor.Tensor[Int] =\n1   0   0   4\n0   2   0   0\n0   0   3   0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4]", 
            "title": "SparseTensor"
        }, 
        {
            "location": "/APIGuide/Data/#table", 
            "text": "Modeled after the  Table  class in  Torch , the  Table  class (defined in package  com.intel.analytics.bigdl.utils ) is widely used in BigDL (e.g., a  Table  of  Tensor  can be used as the input or output of neural networks). In essence, a  Table  can be considered as a key-value map, and there is also a syntax sugar to create a  Table  using  T()  in BigDL.  Scala example:  import com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nprintln(T(Tensor(2,2).fill(1), Tensor(2,2).fill(2)))  Output is   {\n    2: 2.0  2.0 \n       2.0  2.0 \n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n    1: 1.0  1.0 \n       1.0  1.0 \n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n }", 
            "title": "Table"
        }, 
        {
            "location": "/APIGuide/Data/#sample", 
            "text": "A  Sample  represents one record of your data set, which is comprised of  feature  and  label .   feature  is one tensor or a few tensors  label  is also one tensor or a few tensors, and it may be empty in testing or unsupervised learning.   For example, one image and its category in image classification, one word in word2vec and one sentence and its label in RNN language model are all  Sample .  Every  Sample  is actually a set of tensors, and them will be transformed to the input/output of the model. For example, in the case of image classification, a  Sample  has two tensors. One is a 3D tensor representing an image; another is a 1-element tensor representing its category. For the 1-element label, you also can use a  T  instead of tensor.  Scala example:   The case where feature is one tensor with a 1-element label.   import com.intel.analytics.bigdl.dataset.Sample\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nval image = Tensor(3, 32, 32).rand\nval label = 1f\nval sample = Sample(image, label)   The case where feature is a few tensors and label is also a few tensors.   import com.intel.analytics.bigdl.dataset.Sample\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nval features = Array(Tensor(2, 2).rand, Tensor(2, 2).rand)\nval labels = Array(Tensor(1).fill(1), Tensor(1).fill(-1))\nval sample = Sample(features, labels)  Python example:  Note : Please always use  Sample.from_ndarray  to construct a  Sample  in Python.   The case where feature is one tensor with a 1-element label.   After constructing a  Sample  in this case, you can use  Sample.feature  and  Sample.label  to retrieve its feature and label, each as a tensor, respectively.  from bigdl.util.common import Sample\nimport numpy as np\n\nimage = np.random.rand(3, 32, 32)\nlabel = np.array(1)\nsample = Sample.from_ndarray(image, label)\n\n# Retrieve feature and label from a Sample\nsample.feature\nsample.label   The case where feature is a few tensors and label is also a few tensors.   After constructing a  Sample  in this case, you can use  Sample.features  and  Sample.labels  to retrieve its features and labels, each as a list of tensors, respectively.  from bigdl.util.common import Sample\nimport numpy as np\n\nfeatures = [np.random.rand(3, 8, 16), np.random.rand(3, 8, 16)]\nlabels = [np.array(1), np.array(-1)]\nsample = Sample.from_ndarray(features, labels)\n\n# Retrieve features and labels from a Sample\nsample.features\nsample.labels  Note that essentially  Sample.label  is equivalent to  Sample.labels[0] . You can choose to use the former if label is only one tensor and use the latter if label is a list of tensors. Similarly,  Sample.feature  is equivalent to  Sample.features[0] .", 
            "title": "Sample"
        }, 
        {
            "location": "/APIGuide/Data/#minibatch", 
            "text": "MiniBatch  is a data structure to feed input/target to model in  Optimizer . It provide  getInput()  and  getTarget()  function to get the input and target in this  MiniBatch .  In almost all the cases, BigDL's default  MiniBatch  class can fit user's requirement. Just create your  RDD[Sample]  and pass it to  Optimizer . If  MiniBatch  can't meet your requirement, you can implement your own  MiniBatch  class by extends  MiniBatch .  MiniBatch  can be created by  MiniBatch(nInputs: Int, nOutputs: Int) ,  nInputs  means number of inputs,  nOutputs  means number of outputs. And you can use  set(samples: Seq[Sample[T])  to fill the content in this MiniBatch. If you  Sample s are not the same size, you can use  PaddingParam  to pad the  Sample s to the same size.  Scala example:  import com.intel.analytics.bigdl.dataset.Sample\nimport com.intel.analytics.bigdl.dataset.MiniBatch\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nval samples  = Array.tabulate(5)(i =  Sample(Tensor(1, 3, 3).fill(i), i + 1f))\nval miniBatch = MiniBatch(1, 1).set(samples)\nprintln(miniBatch.getInput())\nprintln(miniBatch.getTarget())  Output is  (1,1,.,.) =\n0.0 0.0 0.0 \n0.0 0.0 0.0 \n0.0 0.0 0.0 \n\n(2,1,.,.) =\n1.0 1.0 1.0 \n1.0 1.0 1.0 \n1.0 1.0 1.0 \n\n(3,1,.,.) =\n2.0 2.0 2.0 \n2.0 2.0 2.0 \n2.0 2.0 2.0 \n\n(4,1,.,.) =\n3.0 3.0 3.0 \n3.0 3.0 3.0 \n3.0 3.0 3.0 \n\n(5,1,.,.) =\n4.0 4.0 4.0 \n4.0 4.0 4.0 \n4.0 4.0 4.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5x1x3x3]\n1.0 \n2.0 \n3.0 \n4.0 \n5.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5x1]  If you  Sample s are not the same size, you can use  PaddingParam  to pad the  Sample s to the same size.  import com.intel.analytics.bigdl.dataset._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nval sample1 = Sample(Tensor.range(1, 6, 1).resize(2, 3), 1f)\nval sample2 = Sample(Tensor.range(7, 9, 1).resize(1, 3), 2f)\nval sample3 = Sample(Tensor.range(10, 18, 1).resize(3, 3), 3f)\nval samples = Array(sample1, sample2, sample3)\nval featurePadding = PaddingParam(Some(Array(Tensor(T(-1f, -2f, -3f)))), FixedLength(Array(4)))\nval labelPadding = PaddingParam[Float](None, FixedLength(Array(4)))\n\nval miniBatch = MiniBatch(1, 1, Some(featurePadding), Some(labelPadding)).set(samples)\nprintln(miniBatch.getInput())\nprintln(miniBatch.getTarget())  Output is   (1,.,.) =\n1.0 2.0 3.0 \n4.0 5.0 6.0 \n-1.0    -2.0    -3.0    \n-1.0    -2.0    -3.0    \n\n(2,.,.) =\n7.0 8.0 9.0 \n-1.0    -2.0    -3.0    \n-1.0    -2.0    -3.0    \n-1.0    -2.0    -3.0    \n\n(3,.,.) =\n10.0    11.0    12.0    \n13.0    14.0    15.0    \n16.0    17.0    18.0    \n-1.0    -2.0    -3.0    \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x3]\n\n\n1.0 0.0 0.0 0.0 \n2.0 0.0 0.0 0.0 \n3.0 0.0 0.0 0.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4]", 
            "title": "MiniBatch"
        }, 
        {
            "location": "/APIGuide/Data/#dataset", 
            "text": "DataSet  is a set of data which is used in the model optimization process. You can use  DataSet.array()  and  DataSet.rdd()  function to create a  Dataset . The  DataSet  can be accessed in a random data sample sequence. In the training process, the data sequence is a looped endless sequence. While in the validation process, the data sequence is a limited length sequence. User can use the  data()  method to get the data sequence.   Notice: In most case, we recommend using a RDD[Sample] for  Optimizer . Only when you want to write an application with some advanced optimization, using  DataSet  directly is recommended.    Scala example:  import com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.dataset.DataSet\n\nval tensors  = Array.tabulate(5)(i =  Tensor(1, 3, 3).fill(i))\nval dataset = DataSet.array(tensors) // Local model, just for testing and example.\ndataset.shuffle()\nval iter = dataset.data(false)\nwhile (iter.hasNext) {\n  val d = iter.next()\n  println(d)\n}  Output may be  (1,.,.) =\n4.0 4.0 4.0 \n4.0 4.0 4.0 \n4.0 4.0 4.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]\n(1,.,.) =\n0.0 0.0 0.0 \n0.0 0.0 0.0 \n0.0 0.0 0.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]\n(1,.,.) =\n2.0 2.0 2.0 \n2.0 2.0 2.0 \n2.0 2.0 2.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]\n(1,.,.) =\n1.0 1.0 1.0 \n1.0 1.0 1.0 \n1.0 1.0 1.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]\n(1,.,.) =\n3.0 3.0 3.0 \n3.0 3.0 3.0 \n3.0 3.0 3.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]", 
            "title": "DataSet"
        }, 
        {
            "location": "/APIGuide/Data/#opencvmat", 
            "text": "OpenCVMat is a Serializable wrapper of org.opencv.core.Mat.  It can be created by   read : read local image path as opencv mat   fromImageBytes : convert image file in bytes to opencv mat   fromFloats : convert float array(pixels) to OpenCV mat   fromTensor : convert float tensor to OpenCV mat  Scala example:  // read local image path as OpenCVMat\nval mat = OpenCVMat.read( /tmp/test.jpg )\n\n// convert image file in bytes to OpenCVMat\nval bytes = FileUtils.readFileToByteArray(new File(path))\nval mat2 = OpenCVMat.fromImageBytes(bytes)\n\n// Convert float array(pixels) to OpenCVMat\nval mat3 = OpenCVMat.fromFloats(floatPixels, height=300, width=300)\n\n// Convert tensor to OpenCVMat\nval mat4 = OpenCVMat.fromTensor(tensor, format =  HWC )", 
            "title": "OpenCVMat"
        }, 
        {
            "location": "/APIGuide/Data/#imagefeature", 
            "text": "ImageFeature  is a representation of one image.\nIt can include various status of an image, by using key-value store.\nThe key is string that identifies the corresponding value.\nSome predefined keys are listed as follows:  uri: uri that identifies image  mat: image in OpenCVMat  bytes: image file in bytes  floats: image pixels in float array  size: current image size (height, width, channel)  originalSize: original image size (height, width, channel)  label: image label  predict: image prediction result  boundingBox: store boundingBox of current image,\nit may be used in crop/expand that may change the size of image  sample: image (and label if available) stored as Sample\n* imageTensor: image pixels in Tensor  Besides the above keys, you can also define your key and store information needed\nin the prediction pipeline.  Scala example:  import com.intel.analytics.bigdl.transform.vision.image.ImageFeature\nimport org.apache.commons.io.FileUtils\nimport java.io.File\n\nval file = new File( /tmp/test.jpg )\nval imageFeature = ImageFeature(FileUtils.readFileToByteArray(file), uri = file.getAbsolutePath)\nprintln(imageFeature.keys())  output is  Set(uri, bytes)  Python example:  from bigdl.transform.vision.image import *\nimage = cv2.imread( /tmp/test.jpg )\nimage_feature = ImageFeature(image)\nprint image_feature.keys()  output is  creating: createImageFeature\n[u'originalSize', u'mat', u'bytes']", 
            "title": "ImageFeature"
        }, 
        {
            "location": "/APIGuide/Data/#imageframe", 
            "text": "ImageFrame  is a collection of  ImageFeature .\nIt can be a  DistributedImageFrame  for distributed image RDD or\n  LocalImageFrame  for local image array.\nYou can read an  ImageFrame  from local/distributed folder/parquet file,\nor you can directly construct a ImageFrame from RDD[ImageFeature] or Array[ImageFeature].  Scala example:  Create LocalImageFrame, assume there is an image file \"/tmp/test.jpg\"\nand an image folder \"/tmp/image/\"  import com.intel.analytics.bigdl.transform.vision.image.ImageFrame\nimport com.intel.analytics.bigdl.transform.vision.image.ImageFeature\n\n// create LocalImageFrame from an image\nval localImageFrame = ImageFrame.read( /tmp/test.jpg )\n\n// create LocalImageFrame from an image folder\nval localImageFrame2 = ImageFrame.read( /tmp/image/ )\n\n// create LocalImageFrame from array of ImageFeature\nval array = Array[ImageFeature]()\nval localImageFrame3 = ImageFrame.array(array)  Create DistributedImageFrame, assume there is an image file \"/tmp/test.jpg\"\nand an image folder  import com.intel.analytics.bigdl.transform.vision.image.ImageFrame\nimport com.intel.analytics.bigdl.transform.vision.image.ImageFeature\nimport com.intel.analytics.bigdl.utils.Engine\nimport org.apache.spark.SparkContext\nimport org.apache.spark.sql.SQLContext\n\nval conf = Engine.createSparkConf().setAppName( ImageSpec ).setMaster( local[2] )\nval sc = new SparkContext(conf)\nval sqlContext = new SQLContext(sc)\n\n// create DistributedImageFrame from an image\nval distributedImageFrame = ImageFrame.read( /tmp/test.jpg , sc, 2)\n\n// create DistributedImageFrame from an image folder\nval distributedImageFrame2 = ImageFrame.read( /tmp/image/ , sc, 2)\n\n// create DistributedImageFrame from rdd of ImageFeature\nval array = Array[ImageFeature]()\nval rdd = sc.parallelize(array)\nval distributedImageFrame3 = ImageFrame.rdd(rdd)\n\n// create DistributedImageFrame from Parquet\nval distributedImageFrame4 = ImageFrame.readParquet(dir, sqlContext)  Python example:  Create LocalImageFrame  from bigdl.util.common import *\nfrom bigdl.transform.vision.image import *\n\n# create LocalImageFrame from an image\nlocal_image_frame = ImageFrame.read( /tmp/test.jpg )\n\n# create LocalImageFrame from an image folder\nlocal_image_frame2 = ImageFrame.read( /tmp/image/ )\n\n# create LocalImageFrame from list of images\nimage = cv2.imread( /tmp/test.jpg )\nlocal_image_frame3 = LocalImageFrame([image])  Create DistributedImageFrame  from bigdl.util.common import *\nfrom bigdl.transform.vision.image import *\n\nsparkConf = create_spark_conf().setMaster( local[2] ).setAppName( test image )\nsc = get_spark_context(sparkConf)\ninit_engine()\n\n# create DistributedImageFrame from an image\ndistributed_image_frame = ImageFrame.read( /tmp/test.jpg , sc, 2)\n\n# create DistributedImageFrame from an image folder\ndistributed_image_frame = ImageFrame.read( /tmp/image/ , sc, 2)\n\n# create DistributedImageFrame from image rdd\nimage = cv2.imread( /tmp/test.jpg )\nimage_rdd = sc.parallelize([image], 2)\ndistributed_image_frame = DistributedImageFrame(image_rdd)", 
            "title": "ImageFrame"
        }, 
        {
            "location": "/APIGuide/Transformer/", 
            "text": "Transformer is for pre-processing. In many deep learning workload, input data need to be pre-processed before fed into   model. For example, in CNN, the image file need to be decoded from some compressed format(e.g. jpeg) to float arrays,    normalized and cropped to some fixed shape. You can also find pre-processing in other types of deep learning work        load(e.g. NLP, speech recognition). In BigDL, we provide many pre-process procedures for user. They're implemented as    Transformer.\n\n\nThe transformer interface is\n\n\n\ntrait Transformer[A, B] extends Serializable {\n   def apply(prev: Iterator[A]): Iterator[B]\n }\n\n\n\n\nIt's simple, right? What a transformer do is convert a sequence of objects of Class A to a sequence of objects of Class  B.\n\n\nTransformer is flexible. You can chain them together to do pre-processing. Let's still use the CNN example, say first    we need read image files from given paths, then extract the image binaries to array of float, then normalized the image  content and crop a fixed size from the image at a random position. Here we need 4 transformers, \nPathToImage\n,           \nImageToArray\n, \nNormalizor\n and \nCropper\n. And then chain them together.\n\n\nFeatureTransformer\n\n\nFeatureTransformer\n is the transformer that transforms from \nImageFeature\n to \nImageFeature\n.\n\nFeatureTransformer\n extends 'Transformer[ImageFeature, ImageFeature]'.\n\n\nFeatureTransformer can be chained with FeatureTransformer with the\n\n\nThe key function in \nFeatureTransformer\n is \ntransform\n, which does the ImageFeature transformation\nand exception control.\nWhile \ntransformMat\n is called by \ntransform\n,\nand it is expected to contain the actual transformation of an ImageFeature.\nIt is advised to override \ntransformMat\n when you implement your own FeatureTransformer.\n\n\n\n\nBrightness\n\n\nScala:\n\n\nval brightness = Brightness(deltaLow: Double, deltaHigh: Double)\n\n\n\n\nPython:\n\n\nbrightness = Brightness(delta_low, delta_high)\n\n\n\n\nAdjust the image brightness.\n\n \ndeltaLow\n brightness parameter: low bound\n\n \ndeltaHigh\n brightness parameter: high bound\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read(\n/tmp/test.jpg\n)\nval transformer = Brightness(0, 32)\nval transformed = transformer(data)\n\n\n\n\nPython example:\n\n\nfrom bigdl.transform.vision.image import *\nbrightness = Brightness(0.0, 32.0)\nlocal_image_frame = ImageFrame.read(\n/tmp/test.jpg\n)\ntransformed = brightness(local_image_frame)\n\n\n\n\n\n\nHue\n\n\nScala:\n\n\nval transformer = Hue(deltaLow: Double, deltaHigh: Double)\n\n\n\n\nPython:\n\n\ntransformer = Hue(delta_low, delta_high)\n\n\n\n\nAdjust the image hue.\n\n \ndeltaLow\n Hue parameter: low bound\n\n \ndeltaHigh\n Hue parameter: high bound\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read(\n/tmp/test.jpg\n)\nval transformer = Hue(-18, 18)\nval transformed = transformer(data)\n\n\n\n\nPython example:\n\n\nfrom bigdl.transform.vision.image import *\ntransformer = Hue(-18.0, 18.0)\nlocal_image_frame = ImageFrame.read(\n/tmp/test.jpg\n)\ntransformed = transformer(local_image_frame)\n\n\n\n\n\n\nSaturation\n\n\nScala:\n\n\nval transformer = Saturation(deltaLow: Double, deltaHigh: Double)\n\n\n\n\nPython:\n\n\ntransformer = Saturation(delta_low, delta_high)\n\n\n\n\nAdjust the image Saturation.\n\n \ndeltaLow\n Saturation parameter: low bound\n\n \ndeltaHigh\n Saturation parameter: high bound\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read(\n/tmp/test.jpg\n)\nval transformer = Saturation(10, 20)\nval transformed = transformer(data)\n\n\n\n\nPython example:\n\n\nfrom bigdl.transform.vision.image import *\ntransformer = Saturation(10.0, 20.0)\nlocal_image_frame = ImageFrame.read(\n/tmp/test.jpg\n)\ntransformed = transformer(local_image_frame)\n\n\n\n\n\n\nContrast\n\n\nScala:\n\n\nval transformer = Contrast(deltaLow: Double, deltaHigh: Double)\n\n\n\n\nPython:\n\n\ntransformer = Contrast(delta_low, delta_high)\n\n\n\n\nAdjust the image Contrast.\n\n \ndeltaLow\n Contrast parameter: low bound\n\n \ndeltaHigh\n Contrast parameter: high bound\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read(\n/tmp/test.jpg\n)\nval transformer = Contrast(0.5, 1.5)\nval transformed = transformer(data)\n\n\n\n\nPython example:\n\n\nfrom bigdl.transform.vision.image import *\ntransformer = Hue(0.5, 1.5)\nlocal_image_frame = ImageFrame.read(\n/tmp/test.jpg\n)\ntransformed = transformer(local_image_frame)\n\n\n\n\n\n\nChannelOrder\n\n\nScala:\n\n\nval transformer = ChannelOrder()\n\n\n\n\nPython:\n\n\ntransformer = ChannelOrder()\n\n\n\n\nRandom change the channel order of an image\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read(\n/tmp/test.jpg\n)\nval transformer = ChannelOrder()\nval transformed = transformer(data)\n\n\n\n\nPython example:\n\n\nfrom bigdl.transform.vision.image import *\ntransformer = ChannelOrder()\nlocal_image_frame = ImageFrame.read(\n/tmp/test.jpg\n)\ntransformed = transformer(local_image_frame)\n\n\n\n\n\n\nColorJitter\n\n\nScala:\n\n\nval transformer = ColorJitter(brightnessProb: Double = 0.5,\n                              brightnessDelta: Double = 32,\n                              contrastProb: Double = 0.5,\n                              contrastLower: Double = 0.5,\n                              contrastUpper: Double = 1.5,\n                              hueProb: Double = 0.5,\n                              hueDelta: Double = 18,\n                              saturationProb: Double = 0.5,\n                              saturationLower: Double = 0.5,\n                              saturationUpper: Double = 1.5,\n                              randomOrderProb: Double = 0,\n                              shuffle: Boolean = false)\n\n\n\n\nPython:\n\n\ntransformer = ColorJitter(brightness_prob = 0.5,\n                           brightness_delta = 32.0,\n                           contrast_prob = 0.5,\n                           contrast_lower = 0.5,\n                           contrast_upper = 1.5,\n                           hue_prob = 0.5,\n                           hue_delta = 18.0,\n                           saturation_prob = 0.5,\n                           saturation_lower = 0.5,\n                           saturation_upper = 1.5,\n                           random_order_prob = 0.0,\n                           shuffle = False)\n\n\n\n\nRandom adjust brightness, contrast, hue, saturation\n\n\n\n\nbrightnessProb\n: probability to adjust brightness\n\n\nbrightnessDelta\n: brightness parameter\n\n\ncontrastProb\n: probability to adjust contrast\n\n\ncontrastLower\n: contrast lower parameter\n\n\ncontrastUpper\n: contrast upper parameter\n\n\nhueProb\n: probability to adjust hue\n\n\nhueDelta\n: hue parameter\n\n\nsaturationProb\n: probability to adjust saturation\n\n\nsaturationLower\n: saturation lower parameter\n\n\nsaturationUpper\n: saturation upper parameter\n\n\nrandomChannelOrderProb\n: random order for different operation\n\n\nshuffle\n: shuffle the transformers\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read(\n/tmp/test.jpg\n)\nval transformer = ColorJitter()\nval transformed = transformer(data)\n\n\n\n\nPython example:\n\n\nfrom bigdl.transform.vision.image import *\ntransformer = ColorJitter()\nlocal_image_frame = ImageFrame.read(\n/tmp/test.jpg\n)\ntransformed = transformer(local_image_frame)\n\n\n\n\n\n\nResize\n\n\nScala:\n\n\nval transformer = Resize(resizeH: Int, resizeW: Int,\n                    resizeMode: Int = Imgproc.INTER_LINEAR,\n                    useScaleFactor: Boolean = true)\n\n\n\n\nPython:\n\n\ntransformer = Resize(resize_h, resize_w, resize_mode = 1, use_scale_factor=True)\n\n\n\n\nResize image\n * \nresizeH\n height after resize\n * \nresizeW\n width after resize\n * \nresizeMode\n if resizeMode = -1, random select a mode from\n(Imgproc.INTER_LINEAR, Imgproc.INTER_CUBIC, Imgproc.INTER_AREA,\n                   Imgproc.INTER_NEAREST, Imgproc.INTER_LANCZOS4)\n * \nuseScaleFactor\n if true, scale factor fx and fy is used, fx = fy = 0\n note that the result of the following are different:\n\n\nImgproc.resize(mat, mat, new Size(resizeWH, resizeWH), 0, 0, Imgproc.INTER_LINEAR)\nImgproc.resize(mat, mat, new Size(resizeWH, resizeWH))\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read(\n/tmp/test.jpg\n)\nval transformer = Resize(300, 300)\nval transformed = transformer(data)\n\n\n\n\nPython example:\n\n\nfrom bigdl.transform.vision.image import *\ntransformer = Resize(300, 300)\nlocal_image_frame = ImageFrame.read(\n/tmp/test.jpg\n)\ntransformed = transformer(local_image_frame)\n\n\n\n\n\n\nAspectScale\n\n\nScala:\n\n\nval transformer = AspectScale(scale: Int, scaleMultipleOf: Int = 1,\n                    maxSize: Int = 1000)\n\n\n\n\nPython:\n\n\ntransformer = AspectScale(scale, scale_multiple_of = 1, max_size = 1000)\n\n\n\n\nResize the image, keep the aspect ratio. scale according to the short edge\n * \nscale\n scale size, apply to short edge\n * \nscaleMultipleOf\n make the scaled size multiple of some value\n * \nmaxSize\n max size after scale\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read(\n/tmp/test.jpg\n)\nval transformer = AspectScale(750, maxSize = 3000)\nval transformed = transformer(data)\n\n\n\n\nPython example:\n\n\nfrom bigdl.transform.vision.image import *\ntransformer = AspectScale(750, max_size = 3000)\nlocal_image_frame = ImageFrame.read(\n/tmp/test.jpg\n)\ntransformed = transformer(local_image_frame)\n\n\n\n\n\n\nRandomAspectScale\n\n\nScala:\n\n\nval transformer = AspectScale(scale: Int, scaleMultipleOf: Int = 1,\n                    maxSize: Int = 1000)\n\n\n\n\nPython:\n\n\ntransformer = AspectScale(scale, scale_multiple_of = 1, max_size = 1000)\n\n\n\n\nresize the image by randomly choosing a scale\n * \nscales\n array of scale options that for random choice\n * \nscaleMultipleOf\n Resize test images so that its width and height are multiples of\n * \nmaxSize\n Max pixel size of the longest side of a scaled input image\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read(\n/tmp/test.jpg\n)\nval transformer = RandomAspectScale(Array(750, 600), maxSize = 3000)\nval transformed = transformer(data)\n\n\n\n\nPython example:\n\n\nfrom bigdl.transform.vision.image import *\ntransformer = RandomAspectScale([750, 600], max_size = 3000)\nlocal_image_frame = ImageFrame.read(\n/tmp/test.jpg\n)\ntransformed = transformer(local_image_frame)\n\n\n\n\n\n\nChannelNormalize\n\n\nScala:\n\n\nval transformer = ChannelNormalize(meanR: Float, meanG: Float, meanB: Float,\n                                         stdR: Float = 1, stdG: Float = 1, stdB: Float = 1)\n\n\n\n\nPython:\n\n\ntransformer = ChannelNormalize(mean_r, mean_b, mean_g, std_r=1.0, std_g=1.0, std_b=1.0)\n\n\n\n\nimage channel normalize\n * \nmeanR\n mean value in R channel\n * \nmeanG\n mean value in G channel\n * \nmeanB\n mean value in B channel\n * \nstdR\n std value in R channel\n * \nstdG\n std value in G channel\n * \nstdB\n std value in B channel\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read(\n/tmp/test.jpg\n)\nval transformer = ChannelNormalize(100f, 200f, 300f, 2f, 3f, 4f)\nval transformed = transformer(data)\n\n\n\n\nPython example:\n\n\nfrom bigdl.transform.vision.image import *\ntransformer = ChannelNormalize(100.0, 200.0, 300.0, 2.0, 3.0, 4.0)\nlocal_image_frame = ImageFrame.read(\n/tmp/test.jpg\n)\ntransformed = transformer(local_image_frame)\n\n\n\n\n\n\nPixelNormalizer\n\n\nScala:\n\n\nval transformer = PixelNormalizer(means: Array[Float])\n\n\n\n\nPython:\n\n\ntransformer = PixelNormalizer(means)\n\n\n\n\nPixel level normalizer, data(i) = data(i) - mean(i)\n\n\n\n\nmeans\n pixel level mean, following H * W * C order\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read(\n/tmp/test.jpg\n)\n// Assume the image pixels length is 375 * 500 * 3\nval means = new Array[Float](375 * 500 * 3)\nval transformer = PixelNormalizer(means)\nval transformed = transformer(data)\n\n\n\n\nPython example:\n\n\nfrom bigdl.transform.vision.image import *\nmeans = [2.0] * 3 * 500 * 375\ntransformer = PixelNormalize(means)\nlocal_image_frame = ImageFrame.read(\n/tmp/test.jpg\n)\ntransformed = transformer(local_image_frame)\n\n\n\n\n\n\nCenterCrop\n\n\nScala:\n\n\nval transformer = CenterCrop(cropWidth: Int, cropHeight: Int, isClip: Boolean = true)\n\n\n\n\nPython:\n\n\ntransformer = CenterCrop(crop_width, crop_height, is_clip=True)\n\n\n\n\nCrop a \ncropWidth\n x \ncropHeight\n patch from center of image.\nThe patch size should be less than the image size.\n\n\n\n\ncropWidth\n width after crop\n\n\ncropHeight\n height after crop\n\n\nisClip\n whether to clip the roi to image boundaries\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read(\n/tmp/test.jpg\n)\nval transformer = CenterCrop(200, 200)\nval transformed = transformer(data)\n\n\n\n\nPython example:\n\n\nfrom bigdl.transform.vision.image import *\ntransformer = CenterCrop(200, 200)\nlocal_image_frame = ImageFrame.read(\n/tmp/test.jpg\n)\ntransformed = transformer(local_image_frame)\n\n\n\n\n\n\nRandomCrop\n\n\nScala:\n\n\nval transformer = RandomCrop(cropWidth: Int, cropHeight: Int, isClip: Boolean = true)\n\n\n\n\nPython:\n\n\ntransformer = RandomCrop(crop_width, crop_height, is_clip=True)\n\n\n\n\nRandom crop a \ncropWidth\n x \ncropHeight\n patch from an image.\nThe patch size should be less than the image size.\n\n\n\n\ncropWidth\n width after crop\n\n\ncropHeight\n height after crop\n\n\nisClip\n whether to clip the roi to image boundaries\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read(\n/tmp/test.jpg\n)\nval transformer = RandomCrop(200, 200)\nval transformed = transformer(data)\n\n\n\n\nPython example:\n\n\nfrom bigdl.transform.vision.image import *\ntransformer = RandomCrop(200, 200)\nlocal_image_frame = ImageFrame.read(\n/tmp/test.jpg\n)\ntransformed = transformer(local_image_frame)\n\n\n\n\n\n\nFixedCrop\n\n\nScala:\n\n\nval transformer = FixedCrop(x1: Float, y1: Float, x2: Float, y2: Float, normalized: Boolean,\n                      isClip: Boolean = true)\n\n\n\n\nPython:\n\n\ntransformer = FixedCrop(x1, y1, x2, y2, normalized=True, is_clip=True)\n\n\n\n\nCrop a fixed area of image\n\n\n\n\nx1\n start in width\n\n\ny1\n start in height\n\n\nx2\n end in width\n\n\ny2\n end in height\n\n\nnormalized\n whether args are normalized, i.e. in range [0, 1]\n\n\nisClip\n whether to clip the roi to image boundaries\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read(\n/tmp/test.jpg\n)\nval transformer = FixedCrop(0, 0, 50, 50, false)\nval transformed = transformer(data)\n\nval transformer2 = FixedCrop(0, 0, 0.1f, 0.1333f, true)\nval transformed2 = transformer(data)\n\n\n\n\nPython example:\n\n\nfrom bigdl.transform.vision.image import *\nlocal_image_frame = ImageFrame.read(\n/tmp/test.jpg\n)\n\ntransformer = FixedCrop(0.0, 0.0, 50.0, 50.0, False)\ntransformed = transformer(local_image_frame)\n\ntransformer2 = FixedCrop(0.0, 0.0, 0.1, 0.1333, True)\ntransformed2 = transformer(local_image_frame)\n\n\n\n\n\n\nDetectionCrop\n\n\nScala:\n\n\nval transformer = DetectionCrop(roiKey: String, normalized: Boolean = true)\n\n\n\n\nPython:\n\n\ntransformer = DetectionCrop(roi_key, normalized=True)\n\n\n\n\nCrop from object detections, each image should has a tensor detection,\nwhich is stored in ImageFeature\n\n\n\n\nroiKey\n roiKey that map a tensor detection\n\n\nnormalized\n whether is detection is normalized, i.e. in range [0, 1]\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.transform.vision.image.augmentation._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval data = ImageFrame.read(\n/tmp/test.jpg\n).toLocal()\nval imf = data.array(0)\nimf(\nroi\n) = Tensor[Float](T(1, 1, 0.2, 0, 0, 0.5, 0.5))\nval transformer = DetectionCrop(\nroi\n)\nval transformed = transformer(data)\n\n\n\n\n\n\nExpand\n\n\nScala:\n\n\nval transformer = Expand(meansR: Int = 123, meansG: Int = 117, meansB: Int = 104,\n                    minExpandRatio: Double = 1, maxExpandRatio: Double = 4.0)\n\n\n\n\nPython:\n\n\ntransformer = Expand(means_r=123, means_g=117, means_b=104,\n                                      min_expand_ratio=1.0,\n                                      max_expand_ratio=4.0)\n\n\n\n\nexpand image, fill the blank part with the meanR, meanG, meanB\n\n\n\n\nmeansR\n means in R channel\n\n\nmeansG\n means in G channel\n\n\nmeansB\n means in B channel\n\n\nminExpandRatio\n min expand ratio\n\n\nmaxExpandRatio\n max expand ratio\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.transform.vision.image.augmentation._\n\nval data = ImageFrame.read(\n/tmp/test.jpg\n)\nval transformer = Expand(minExpandRatio = 2, maxExpandRatio = 2)\nval transformed = transformer(data)\n\n\n\n\nPython example:\n\n\nfrom bigdl.transform.vision.image import *\ndata = ImageFrame.read(\n/tmp/test.jpg\n)\ntransformer = Expand(min_expand_ratio = 2.0, max_expand_ratio = 2.0)\ntransformed = transformer(data)\n\n\n\n\n\n\nFiller\n\n\nScala:\n\n\nval transformer = Filler(startX: Float, startY: Float, endX: Float, endY: Float, value: Int = 255)\n\n\n\n\nPython:\n\n\ntransformer = Filler(start_x, start_y, end_x, end_y, value = 255)\n\n\n\n\nFill part of image with certain pixel value\n\n\n\n\nstartX\n start x ratio\n\n\nstartY\n start y ratio\n\n\nendX\n end x ratio\n\n\nendY\n end y ratio\n\n\nvalue\n filling value\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.transform.vision.image.augmentation._\n\nval data = ImageFrame.read(\n/tmp/test.jpg\n)\nval transformer = Filler(0, 0, 1, 0.5f, 255)\nval transformed = transformer(data)\n\n\n\n\nPython example:\n\n\nfrom bigdl.transform.vision.image import *\ndata = ImageFrame.read(\n/tmp/test.jpg\n)\ntransformer = Filler(0.0, 0.0, 1.0, 0.5, 255)\ntransformed = transformer(data)\n\n\n\n\n\n\nHFlip\n\n\nScala:\n\n\nval transformer = HFlip()\n\n\n\n\nPython:\n\n\ntransformer = HFlip()\n\n\n\n\nFlip the image horizontally\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.transform.vision.image.augmentation._\n\nval data = ImageFrame.read(\n/tmp/test.jpg\n)\nval transformer = HFlip()\nval transformed = transformer(data)\n\n\n\n\nPython example:\n\n\nfrom bigdl.transform.vision.image import *\ndata = ImageFrame.read(\n/tmp/test.jpg\n)\ntransformer = HFlip()\ntransformed = transformer(data)\n\n\n\n\n\n\nRandomTransformer\n\n\nScala:\n\n\nval transformer = RandomTransformer(transformer: FeatureTransformer, maxProb: Double)\n\n\n\n\nPython:\n\n\ntransformer = RandomTransformer(transformer, maxProb)\n\n\n\n\nIt is a wrapper for transformers to control the transform probability\n * \ntransformer\n transformer to apply randomness\n * \nmaxProb\n max prob\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.transform.vision.image.augmentation._\n\nval data = ImageFrame.read(\n/tmp/test.jpg\n)\nval transformer = RandomTransformer(HFlip(), 0.5)\nval transformed = transformer(data)\n\n\n\n\nPython example:\n\n\nfrom bigdl.transform.vision.image import *\ndata = ImageFrame.read(\n/tmp/test.jpg\n)\ntransformer = RandomTransformer(HFlip(), 0.5)\ntransformed = transformer(data)\n\n\n\n\n\n\nBytesToMat\n\n\nScala:\n\n\nval transformer = BytesToMat(byteKey: String = ImageFeature.bytes)\n\n\n\n\nPython:\n\n\ntransformer = BytesToMat(byte_key=\nbytes\n)\n\n\n\n\nTransform byte array(original image file in byte) to OpenCVMat\n* \nbyteKey\n: key that maps byte array\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.transform.vision.image.BytesToMat\n\nval data = ImageFrame.read(\n/tmp/test.jpg\n)\nval transformer = BytesToMat()\nval transformed = transformer(data)\n\n\n\n\nPython example:\n\n\nfrom bigdl.transform.vision.image import *\ndata = ImageFrame.read(\n/tmp/test.jpg\n)\ntransformer = BytesToMat()\ntransformed = transformer(data)\n\n\n\n\n\n\nMatToFloats\n\n\nScala:\n\n\nval transformer = MatToFloats(validHeight: Int, validWidth: Int, validChannels: Int,\n                    outKey: String = ImageFeature.floats, shareBuffer: Boolean = true)\n\n\n\n\nPython:\n\n\ntransformer = MatToFloats(valid_height=300, valid_width=300, valid_channel=300,\n                                          out_key = \nfloats\n, share_buffer=True)\n\n\n\n\nTransform OpenCVMat to float array, note that in this transformer, the mat is released.\n * \nvalidHeight\n valid height in case the mat is invalid\n * \nvalidWidth\n valid width in case the mat is invalid\n * \nvalidChannels\n valid channel in case the mat is invalid\n * \noutKey\n key to store float array\n * \nshareBuffer\n share buffer of output\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.transform.vision.image.MatToFloats\n\nval data = ImageFrame.read(\n/tmp/test.jpg\n)\nval transformer = MatToFloats()\nval transformed = transformer(data)\n\n\n\n\nPython example:\n\n\nfrom bigdl.transform.vision.image import *\ndata = ImageFrame.read(\n/tmp/test.jpg\n)\ntransformer = MatToFloats()\ntransformed = transformer(data)\n\n\n\n\n\n\nMatToTensor\n\n\nScala:\n\n\nval transformer = MatToFloats(toRGB: Boolean = false,\n                               tensorKey: String = ImageFeature.imageTensor)\n\n\n\n\nPython:\n\n\ntransformer = MatToFloats(to_rgb=False, tensor_key=\nimageTensor\n)\n\n\n\n\nTransform opencv mat to tensor, note that in this transformer, the mat is released.\n * \ntoRGB\n BGR to RGB (default is BGR)\n * \ntensorKey\n key to store transformed tensor\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.transform.vision.image.MatToTensor\n\nval data = ImageFrame.read(\n/tmp/test.jpg\n)\nval transformer = MatToTensor[Float]()\nval transformed = transformer(data)\n\n\n\n\nPython example:\n\n\nfrom bigdl.transform.vision.image import *\ndata = ImageFrame.read(\n/tmp/test.jpg\n)\ntransformer = MatToTensor()\ntransformed = transformer(data)\n\n\n\n\n\n\nImageFrameToSample\n\n\nScala:\n\n\nval transformer = ImageFrameToSample(inputKeys: Array[String] = Array(ImageFeature.imageTensor),\n                               targetKeys: Array[String] = null,\n                               sampleKey: String = ImageFeature.sample)\n\n\n\n\nPython:\n\n\ntransformer = ImageFrameToSample(input_keys=[\nimageTensor\n], target_keys=None,\n                                           sample_key=\nsample\n)\n\n\n\n\nTransforms tensors that map inputKeys and targetKeys to sample,\nnote that in this transformer, the mat has been released.\n  * \ninputKeys\n keys that maps inputs (each input should be a tensor)\n  * \ntargetKeys\n keys that maps targets (each target should be a tensor)\n  * \nsampleKey\n key to store sample\n\n\nNote that you may need to chain \nMatToTensor\n before \nImageFrameToSample\n,\nsince \nImageFrameToSample\n requires all inputkeys map Tensor type\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.transform.vision.image._\n\nval data = ImageFrame.read(\n/tmp/test.jpg\n)\nval transformer = MatToTensor[Float]()\nval toSample = ImageFrameToSample[Float]()\nval transformed = transformer(data)\ntoSample(transformed)\n\n\n\n\nPython example:\n\n\nfrom bigdl.transform.vision.image import *\ndata = ImageFrame.read(\n/tmp/test.jpg\n)\ntransformer = MatToTensor()\nto_sample = ImageFrameToSample()\ntransformed = transformer(data)\nto_sample(transformed)", 
            "title": "Transformer"
        }, 
        {
            "location": "/APIGuide/Transformer/#featuretransformer", 
            "text": "FeatureTransformer  is the transformer that transforms from  ImageFeature  to  ImageFeature . FeatureTransformer  extends 'Transformer[ImageFeature, ImageFeature]'.  FeatureTransformer can be chained with FeatureTransformer with the  The key function in  FeatureTransformer  is  transform , which does the ImageFeature transformation\nand exception control.\nWhile  transformMat  is called by  transform ,\nand it is expected to contain the actual transformation of an ImageFeature.\nIt is advised to override  transformMat  when you implement your own FeatureTransformer.", 
            "title": "FeatureTransformer"
        }, 
        {
            "location": "/APIGuide/Transformer/#brightness", 
            "text": "Scala:  val brightness = Brightness(deltaLow: Double, deltaHigh: Double)  Python:  brightness = Brightness(delta_low, delta_high)  Adjust the image brightness.   deltaLow  brightness parameter: low bound   deltaHigh  brightness parameter: high bound  Scala example:  import com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read( /tmp/test.jpg )\nval transformer = Brightness(0, 32)\nval transformed = transformer(data)  Python example:  from bigdl.transform.vision.image import *\nbrightness = Brightness(0.0, 32.0)\nlocal_image_frame = ImageFrame.read( /tmp/test.jpg )\ntransformed = brightness(local_image_frame)", 
            "title": "Brightness"
        }, 
        {
            "location": "/APIGuide/Transformer/#hue", 
            "text": "Scala:  val transformer = Hue(deltaLow: Double, deltaHigh: Double)  Python:  transformer = Hue(delta_low, delta_high)  Adjust the image hue.   deltaLow  Hue parameter: low bound   deltaHigh  Hue parameter: high bound  Scala example:  import com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read( /tmp/test.jpg )\nval transformer = Hue(-18, 18)\nval transformed = transformer(data)  Python example:  from bigdl.transform.vision.image import *\ntransformer = Hue(-18.0, 18.0)\nlocal_image_frame = ImageFrame.read( /tmp/test.jpg )\ntransformed = transformer(local_image_frame)", 
            "title": "Hue"
        }, 
        {
            "location": "/APIGuide/Transformer/#saturation", 
            "text": "Scala:  val transformer = Saturation(deltaLow: Double, deltaHigh: Double)  Python:  transformer = Saturation(delta_low, delta_high)  Adjust the image Saturation.   deltaLow  Saturation parameter: low bound   deltaHigh  Saturation parameter: high bound  Scala example:  import com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read( /tmp/test.jpg )\nval transformer = Saturation(10, 20)\nval transformed = transformer(data)  Python example:  from bigdl.transform.vision.image import *\ntransformer = Saturation(10.0, 20.0)\nlocal_image_frame = ImageFrame.read( /tmp/test.jpg )\ntransformed = transformer(local_image_frame)", 
            "title": "Saturation"
        }, 
        {
            "location": "/APIGuide/Transformer/#contrast", 
            "text": "Scala:  val transformer = Contrast(deltaLow: Double, deltaHigh: Double)  Python:  transformer = Contrast(delta_low, delta_high)  Adjust the image Contrast.   deltaLow  Contrast parameter: low bound   deltaHigh  Contrast parameter: high bound  Scala example:  import com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read( /tmp/test.jpg )\nval transformer = Contrast(0.5, 1.5)\nval transformed = transformer(data)  Python example:  from bigdl.transform.vision.image import *\ntransformer = Hue(0.5, 1.5)\nlocal_image_frame = ImageFrame.read( /tmp/test.jpg )\ntransformed = transformer(local_image_frame)", 
            "title": "Contrast"
        }, 
        {
            "location": "/APIGuide/Transformer/#channelorder", 
            "text": "Scala:  val transformer = ChannelOrder()  Python:  transformer = ChannelOrder()  Random change the channel order of an image  Scala example:  import com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read( /tmp/test.jpg )\nval transformer = ChannelOrder()\nval transformed = transformer(data)  Python example:  from bigdl.transform.vision.image import *\ntransformer = ChannelOrder()\nlocal_image_frame = ImageFrame.read( /tmp/test.jpg )\ntransformed = transformer(local_image_frame)", 
            "title": "ChannelOrder"
        }, 
        {
            "location": "/APIGuide/Transformer/#colorjitter", 
            "text": "Scala:  val transformer = ColorJitter(brightnessProb: Double = 0.5,\n                              brightnessDelta: Double = 32,\n                              contrastProb: Double = 0.5,\n                              contrastLower: Double = 0.5,\n                              contrastUpper: Double = 1.5,\n                              hueProb: Double = 0.5,\n                              hueDelta: Double = 18,\n                              saturationProb: Double = 0.5,\n                              saturationLower: Double = 0.5,\n                              saturationUpper: Double = 1.5,\n                              randomOrderProb: Double = 0,\n                              shuffle: Boolean = false)  Python:  transformer = ColorJitter(brightness_prob = 0.5,\n                           brightness_delta = 32.0,\n                           contrast_prob = 0.5,\n                           contrast_lower = 0.5,\n                           contrast_upper = 1.5,\n                           hue_prob = 0.5,\n                           hue_delta = 18.0,\n                           saturation_prob = 0.5,\n                           saturation_lower = 0.5,\n                           saturation_upper = 1.5,\n                           random_order_prob = 0.0,\n                           shuffle = False)  Random adjust brightness, contrast, hue, saturation   brightnessProb : probability to adjust brightness  brightnessDelta : brightness parameter  contrastProb : probability to adjust contrast  contrastLower : contrast lower parameter  contrastUpper : contrast upper parameter  hueProb : probability to adjust hue  hueDelta : hue parameter  saturationProb : probability to adjust saturation  saturationLower : saturation lower parameter  saturationUpper : saturation upper parameter  randomChannelOrderProb : random order for different operation  shuffle : shuffle the transformers   Scala example:  import com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read( /tmp/test.jpg )\nval transformer = ColorJitter()\nval transformed = transformer(data)  Python example:  from bigdl.transform.vision.image import *\ntransformer = ColorJitter()\nlocal_image_frame = ImageFrame.read( /tmp/test.jpg )\ntransformed = transformer(local_image_frame)", 
            "title": "ColorJitter"
        }, 
        {
            "location": "/APIGuide/Transformer/#resize", 
            "text": "Scala:  val transformer = Resize(resizeH: Int, resizeW: Int,\n                    resizeMode: Int = Imgproc.INTER_LINEAR,\n                    useScaleFactor: Boolean = true)  Python:  transformer = Resize(resize_h, resize_w, resize_mode = 1, use_scale_factor=True)  Resize image\n *  resizeH  height after resize\n *  resizeW  width after resize\n *  resizeMode  if resizeMode = -1, random select a mode from\n(Imgproc.INTER_LINEAR, Imgproc.INTER_CUBIC, Imgproc.INTER_AREA,\n                   Imgproc.INTER_NEAREST, Imgproc.INTER_LANCZOS4)\n *  useScaleFactor  if true, scale factor fx and fy is used, fx = fy = 0\n note that the result of the following are different:  Imgproc.resize(mat, mat, new Size(resizeWH, resizeWH), 0, 0, Imgproc.INTER_LINEAR)\nImgproc.resize(mat, mat, new Size(resizeWH, resizeWH))  Scala example:  import com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read( /tmp/test.jpg )\nval transformer = Resize(300, 300)\nval transformed = transformer(data)  Python example:  from bigdl.transform.vision.image import *\ntransformer = Resize(300, 300)\nlocal_image_frame = ImageFrame.read( /tmp/test.jpg )\ntransformed = transformer(local_image_frame)", 
            "title": "Resize"
        }, 
        {
            "location": "/APIGuide/Transformer/#aspectscale", 
            "text": "Scala:  val transformer = AspectScale(scale: Int, scaleMultipleOf: Int = 1,\n                    maxSize: Int = 1000)  Python:  transformer = AspectScale(scale, scale_multiple_of = 1, max_size = 1000)  Resize the image, keep the aspect ratio. scale according to the short edge\n *  scale  scale size, apply to short edge\n *  scaleMultipleOf  make the scaled size multiple of some value\n *  maxSize  max size after scale  Scala example:  import com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read( /tmp/test.jpg )\nval transformer = AspectScale(750, maxSize = 3000)\nval transformed = transformer(data)  Python example:  from bigdl.transform.vision.image import *\ntransformer = AspectScale(750, max_size = 3000)\nlocal_image_frame = ImageFrame.read( /tmp/test.jpg )\ntransformed = transformer(local_image_frame)", 
            "title": "AspectScale"
        }, 
        {
            "location": "/APIGuide/Transformer/#randomaspectscale", 
            "text": "Scala:  val transformer = AspectScale(scale: Int, scaleMultipleOf: Int = 1,\n                    maxSize: Int = 1000)  Python:  transformer = AspectScale(scale, scale_multiple_of = 1, max_size = 1000)  resize the image by randomly choosing a scale\n *  scales  array of scale options that for random choice\n *  scaleMultipleOf  Resize test images so that its width and height are multiples of\n *  maxSize  Max pixel size of the longest side of a scaled input image  Scala example:  import com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read( /tmp/test.jpg )\nval transformer = RandomAspectScale(Array(750, 600), maxSize = 3000)\nval transformed = transformer(data)  Python example:  from bigdl.transform.vision.image import *\ntransformer = RandomAspectScale([750, 600], max_size = 3000)\nlocal_image_frame = ImageFrame.read( /tmp/test.jpg )\ntransformed = transformer(local_image_frame)", 
            "title": "RandomAspectScale"
        }, 
        {
            "location": "/APIGuide/Transformer/#channelnormalize", 
            "text": "Scala:  val transformer = ChannelNormalize(meanR: Float, meanG: Float, meanB: Float,\n                                         stdR: Float = 1, stdG: Float = 1, stdB: Float = 1)  Python:  transformer = ChannelNormalize(mean_r, mean_b, mean_g, std_r=1.0, std_g=1.0, std_b=1.0)  image channel normalize\n *  meanR  mean value in R channel\n *  meanG  mean value in G channel\n *  meanB  mean value in B channel\n *  stdR  std value in R channel\n *  stdG  std value in G channel\n *  stdB  std value in B channel  Scala example:  import com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read( /tmp/test.jpg )\nval transformer = ChannelNormalize(100f, 200f, 300f, 2f, 3f, 4f)\nval transformed = transformer(data)  Python example:  from bigdl.transform.vision.image import *\ntransformer = ChannelNormalize(100.0, 200.0, 300.0, 2.0, 3.0, 4.0)\nlocal_image_frame = ImageFrame.read( /tmp/test.jpg )\ntransformed = transformer(local_image_frame)", 
            "title": "ChannelNormalize"
        }, 
        {
            "location": "/APIGuide/Transformer/#pixelnormalizer", 
            "text": "Scala:  val transformer = PixelNormalizer(means: Array[Float])  Python:  transformer = PixelNormalizer(means)  Pixel level normalizer, data(i) = data(i) - mean(i)   means  pixel level mean, following H * W * C order   Scala example:  import com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read( /tmp/test.jpg )\n// Assume the image pixels length is 375 * 500 * 3\nval means = new Array[Float](375 * 500 * 3)\nval transformer = PixelNormalizer(means)\nval transformed = transformer(data)  Python example:  from bigdl.transform.vision.image import *\nmeans = [2.0] * 3 * 500 * 375\ntransformer = PixelNormalize(means)\nlocal_image_frame = ImageFrame.read( /tmp/test.jpg )\ntransformed = transformer(local_image_frame)", 
            "title": "PixelNormalizer"
        }, 
        {
            "location": "/APIGuide/Transformer/#centercrop", 
            "text": "Scala:  val transformer = CenterCrop(cropWidth: Int, cropHeight: Int, isClip: Boolean = true)  Python:  transformer = CenterCrop(crop_width, crop_height, is_clip=True)  Crop a  cropWidth  x  cropHeight  patch from center of image.\nThe patch size should be less than the image size.   cropWidth  width after crop  cropHeight  height after crop  isClip  whether to clip the roi to image boundaries   Scala example:  import com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read( /tmp/test.jpg )\nval transformer = CenterCrop(200, 200)\nval transformed = transformer(data)  Python example:  from bigdl.transform.vision.image import *\ntransformer = CenterCrop(200, 200)\nlocal_image_frame = ImageFrame.read( /tmp/test.jpg )\ntransformed = transformer(local_image_frame)", 
            "title": "CenterCrop"
        }, 
        {
            "location": "/APIGuide/Transformer/#randomcrop", 
            "text": "Scala:  val transformer = RandomCrop(cropWidth: Int, cropHeight: Int, isClip: Boolean = true)  Python:  transformer = RandomCrop(crop_width, crop_height, is_clip=True)  Random crop a  cropWidth  x  cropHeight  patch from an image.\nThe patch size should be less than the image size.   cropWidth  width after crop  cropHeight  height after crop  isClip  whether to clip the roi to image boundaries   Scala example:  import com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read( /tmp/test.jpg )\nval transformer = RandomCrop(200, 200)\nval transformed = transformer(data)  Python example:  from bigdl.transform.vision.image import *\ntransformer = RandomCrop(200, 200)\nlocal_image_frame = ImageFrame.read( /tmp/test.jpg )\ntransformed = transformer(local_image_frame)", 
            "title": "RandomCrop"
        }, 
        {
            "location": "/APIGuide/Transformer/#fixedcrop", 
            "text": "Scala:  val transformer = FixedCrop(x1: Float, y1: Float, x2: Float, y2: Float, normalized: Boolean,\n                      isClip: Boolean = true)  Python:  transformer = FixedCrop(x1, y1, x2, y2, normalized=True, is_clip=True)  Crop a fixed area of image   x1  start in width  y1  start in height  x2  end in width  y2  end in height  normalized  whether args are normalized, i.e. in range [0, 1]  isClip  whether to clip the roi to image boundaries   Scala example:  import com.intel.analytics.bigdl.transform.vision.image.augmentation._\nval data = ImageFrame.read( /tmp/test.jpg )\nval transformer = FixedCrop(0, 0, 50, 50, false)\nval transformed = transformer(data)\n\nval transformer2 = FixedCrop(0, 0, 0.1f, 0.1333f, true)\nval transformed2 = transformer(data)  Python example:  from bigdl.transform.vision.image import *\nlocal_image_frame = ImageFrame.read( /tmp/test.jpg )\n\ntransformer = FixedCrop(0.0, 0.0, 50.0, 50.0, False)\ntransformed = transformer(local_image_frame)\n\ntransformer2 = FixedCrop(0.0, 0.0, 0.1, 0.1333, True)\ntransformed2 = transformer(local_image_frame)", 
            "title": "FixedCrop"
        }, 
        {
            "location": "/APIGuide/Transformer/#detectioncrop", 
            "text": "Scala:  val transformer = DetectionCrop(roiKey: String, normalized: Boolean = true)  Python:  transformer = DetectionCrop(roi_key, normalized=True)  Crop from object detections, each image should has a tensor detection,\nwhich is stored in ImageFeature   roiKey  roiKey that map a tensor detection  normalized  whether is detection is normalized, i.e. in range [0, 1]   Scala example:  import com.intel.analytics.bigdl.transform.vision.image.augmentation._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval data = ImageFrame.read( /tmp/test.jpg ).toLocal()\nval imf = data.array(0)\nimf( roi ) = Tensor[Float](T(1, 1, 0.2, 0, 0, 0.5, 0.5))\nval transformer = DetectionCrop( roi )\nval transformed = transformer(data)", 
            "title": "DetectionCrop"
        }, 
        {
            "location": "/APIGuide/Transformer/#expand", 
            "text": "Scala:  val transformer = Expand(meansR: Int = 123, meansG: Int = 117, meansB: Int = 104,\n                    minExpandRatio: Double = 1, maxExpandRatio: Double = 4.0)  Python:  transformer = Expand(means_r=123, means_g=117, means_b=104,\n                                      min_expand_ratio=1.0,\n                                      max_expand_ratio=4.0)  expand image, fill the blank part with the meanR, meanG, meanB   meansR  means in R channel  meansG  means in G channel  meansB  means in B channel  minExpandRatio  min expand ratio  maxExpandRatio  max expand ratio   Scala example:  import com.intel.analytics.bigdl.transform.vision.image.augmentation._\n\nval data = ImageFrame.read( /tmp/test.jpg )\nval transformer = Expand(minExpandRatio = 2, maxExpandRatio = 2)\nval transformed = transformer(data)  Python example:  from bigdl.transform.vision.image import *\ndata = ImageFrame.read( /tmp/test.jpg )\ntransformer = Expand(min_expand_ratio = 2.0, max_expand_ratio = 2.0)\ntransformed = transformer(data)", 
            "title": "Expand"
        }, 
        {
            "location": "/APIGuide/Transformer/#filler", 
            "text": "Scala:  val transformer = Filler(startX: Float, startY: Float, endX: Float, endY: Float, value: Int = 255)  Python:  transformer = Filler(start_x, start_y, end_x, end_y, value = 255)  Fill part of image with certain pixel value   startX  start x ratio  startY  start y ratio  endX  end x ratio  endY  end y ratio  value  filling value   Scala example:  import com.intel.analytics.bigdl.transform.vision.image.augmentation._\n\nval data = ImageFrame.read( /tmp/test.jpg )\nval transformer = Filler(0, 0, 1, 0.5f, 255)\nval transformed = transformer(data)  Python example:  from bigdl.transform.vision.image import *\ndata = ImageFrame.read( /tmp/test.jpg )\ntransformer = Filler(0.0, 0.0, 1.0, 0.5, 255)\ntransformed = transformer(data)", 
            "title": "Filler"
        }, 
        {
            "location": "/APIGuide/Transformer/#hflip", 
            "text": "Scala:  val transformer = HFlip()  Python:  transformer = HFlip()  Flip the image horizontally  Scala example:  import com.intel.analytics.bigdl.transform.vision.image.augmentation._\n\nval data = ImageFrame.read( /tmp/test.jpg )\nval transformer = HFlip()\nval transformed = transformer(data)  Python example:  from bigdl.transform.vision.image import *\ndata = ImageFrame.read( /tmp/test.jpg )\ntransformer = HFlip()\ntransformed = transformer(data)", 
            "title": "HFlip"
        }, 
        {
            "location": "/APIGuide/Transformer/#randomtransformer", 
            "text": "Scala:  val transformer = RandomTransformer(transformer: FeatureTransformer, maxProb: Double)  Python:  transformer = RandomTransformer(transformer, maxProb)  It is a wrapper for transformers to control the transform probability\n *  transformer  transformer to apply randomness\n *  maxProb  max prob  Scala example:  import com.intel.analytics.bigdl.transform.vision.image.augmentation._\n\nval data = ImageFrame.read( /tmp/test.jpg )\nval transformer = RandomTransformer(HFlip(), 0.5)\nval transformed = transformer(data)  Python example:  from bigdl.transform.vision.image import *\ndata = ImageFrame.read( /tmp/test.jpg )\ntransformer = RandomTransformer(HFlip(), 0.5)\ntransformed = transformer(data)", 
            "title": "RandomTransformer"
        }, 
        {
            "location": "/APIGuide/Transformer/#bytestomat", 
            "text": "Scala:  val transformer = BytesToMat(byteKey: String = ImageFeature.bytes)  Python:  transformer = BytesToMat(byte_key= bytes )  Transform byte array(original image file in byte) to OpenCVMat\n*  byteKey : key that maps byte array  Scala example:  import com.intel.analytics.bigdl.transform.vision.image.BytesToMat\n\nval data = ImageFrame.read( /tmp/test.jpg )\nval transformer = BytesToMat()\nval transformed = transformer(data)  Python example:  from bigdl.transform.vision.image import *\ndata = ImageFrame.read( /tmp/test.jpg )\ntransformer = BytesToMat()\ntransformed = transformer(data)", 
            "title": "BytesToMat"
        }, 
        {
            "location": "/APIGuide/Transformer/#mattofloats", 
            "text": "Scala:  val transformer = MatToFloats(validHeight: Int, validWidth: Int, validChannels: Int,\n                    outKey: String = ImageFeature.floats, shareBuffer: Boolean = true)  Python:  transformer = MatToFloats(valid_height=300, valid_width=300, valid_channel=300,\n                                          out_key =  floats , share_buffer=True)  Transform OpenCVMat to float array, note that in this transformer, the mat is released.\n *  validHeight  valid height in case the mat is invalid\n *  validWidth  valid width in case the mat is invalid\n *  validChannels  valid channel in case the mat is invalid\n *  outKey  key to store float array\n *  shareBuffer  share buffer of output  Scala example:  import com.intel.analytics.bigdl.transform.vision.image.MatToFloats\n\nval data = ImageFrame.read( /tmp/test.jpg )\nval transformer = MatToFloats()\nval transformed = transformer(data)  Python example:  from bigdl.transform.vision.image import *\ndata = ImageFrame.read( /tmp/test.jpg )\ntransformer = MatToFloats()\ntransformed = transformer(data)", 
            "title": "MatToFloats"
        }, 
        {
            "location": "/APIGuide/Transformer/#mattotensor", 
            "text": "Scala:  val transformer = MatToFloats(toRGB: Boolean = false,\n                               tensorKey: String = ImageFeature.imageTensor)  Python:  transformer = MatToFloats(to_rgb=False, tensor_key= imageTensor )  Transform opencv mat to tensor, note that in this transformer, the mat is released.\n *  toRGB  BGR to RGB (default is BGR)\n *  tensorKey  key to store transformed tensor  Scala example:  import com.intel.analytics.bigdl.transform.vision.image.MatToTensor\n\nval data = ImageFrame.read( /tmp/test.jpg )\nval transformer = MatToTensor[Float]()\nval transformed = transformer(data)  Python example:  from bigdl.transform.vision.image import *\ndata = ImageFrame.read( /tmp/test.jpg )\ntransformer = MatToTensor()\ntransformed = transformer(data)", 
            "title": "MatToTensor"
        }, 
        {
            "location": "/APIGuide/Transformer/#imageframetosample", 
            "text": "Scala:  val transformer = ImageFrameToSample(inputKeys: Array[String] = Array(ImageFeature.imageTensor),\n                               targetKeys: Array[String] = null,\n                               sampleKey: String = ImageFeature.sample)  Python:  transformer = ImageFrameToSample(input_keys=[ imageTensor ], target_keys=None,\n                                           sample_key= sample )  Transforms tensors that map inputKeys and targetKeys to sample,\nnote that in this transformer, the mat has been released.\n  *  inputKeys  keys that maps inputs (each input should be a tensor)\n  *  targetKeys  keys that maps targets (each target should be a tensor)\n  *  sampleKey  key to store sample  Note that you may need to chain  MatToTensor  before  ImageFrameToSample ,\nsince  ImageFrameToSample  requires all inputkeys map Tensor type  Scala example:  import com.intel.analytics.bigdl.transform.vision.image._\n\nval data = ImageFrame.read( /tmp/test.jpg )\nval transformer = MatToTensor[Float]()\nval toSample = ImageFrameToSample[Float]()\nval transformed = transformer(data)\ntoSample(transformed)  Python example:  from bigdl.transform.vision.image import *\ndata = ImageFrame.read( /tmp/test.jpg )\ntransformer = MatToTensor()\nto_sample = ImageFrameToSample()\ntransformed = transformer(data)\nto_sample(transformed)", 
            "title": "ImageFrameToSample"
        }, 
        {
            "location": "/APIGuide/Module/", 
            "text": "Model Save\n\n\nBigDL supports saving models to local file system, HDFS and AWS S3. After a model is created, you can use \nsaveModule\n (Scala) or 'saveModel' (python) on created model to save it. Below example shows how to save a model.\n\n\nScala example\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nval model = Sequential().add(Linear(10, 5)).add(Sigmoid()).add(SoftMax())\n//...train\n\nmodel.saveModule(\n/tmp/model.bigdl\n, \n/tmp/model.bin\n, true) //save to local fs\nmodel.saveModule(\nhdfs://...\n) //save to hdfs\nmodel.saveModule(\ns3://...\n) //save to s3\n\n\n\n\n\nPython example\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.util.common import *\nfrom bigdl.optim.optimizer import *\n\nmodel = Sequential().add(Linear(10, 5)).add(Sigmoid()).add(SoftMax())\n//...train\nmodel.saveModel(\n/tmp/model.bigdl\n, \n/tmp/model.bin\n, True) //save to local fs\nmodel.saveModel(\nhdfs://...\n) //save to hdfs\nmodel.saveModel(\ns3://...\n) //save to s3\n\n\n\n\nIn \nmodel.saveModel\n, the first parameter is the path where we want to save our model network, the second parameter is the path where we want to save the model weights, the third parameter is to specify if we need to overwrite the file if it already exists, it's set to false by default\nPlease notice that if the second parameter is not specified, weights will be saved into the same file as model network. Save weights separately usually handles the situation that the model is big in size\n\n\nModel Load\n\n\nLoad BigDL model\n\n\nUse \nModule.loadModule\n(in Scala) or \nModel.loadModel\n (in Python) to load an existing model.  \nModule\n (Scala) or \nModel\n(Python) is a utility class provided in BigDL. We just need to specify the model path and optionally weight path if exists where we previously saved the model to load it to memory for resume training or prediction purpose.\n\n\nScala example\n\n\nval model = Module.loadModule(\n/tmp/model.bigdl\n, \n/tmp/model.bin\n) //load from local fs\nval model = Module.loadModule(\nhdfs://...\n) //load from hdfs\nval model = Module.loadModule(\ns3://...\n) //load from s3\n\n\n\n\nPython example\n\n\nmodel = Model.loadModel(\n/tmp/model.bigdl\n, \n/tmp/model.bin\n) //load from local fs\nmodel = Model.loadModel(\nhdfs://...\n) //load from hdfs\nmodel = Model.loadModel(\ns3://...\n) //load from s3\n\n\n\n\nLoad Tensorflow model\n\n\nBigDL also provides utilities to load tensorflow model. See \ntensorflow support\n\nfor more information.\n\n\nIf we already have a freezed graph protobuf file, we can use the \nloadTF\n api directly to\nload the tensorflow model. \n\n\nOtherwise, we should first use the \nexport_tf_checkpoint.py\n script provided by BigDL's distribution\npackage, or the \ndump_model\n function defined in \nhere\n to\ngenerate the model definition file (\nmodel.pb\n) and variable binary file (\nmodel.bin\n). \n\n\nUse Script\n\n\nGRAPH_META_FILE=/tmp/tensorflow/model.ckpt.meta\nCKPT_FILE_PREFIX=/tmp/tensorflow/model.ckpt\nSAVE_PATH=/tmp/model/\npython export_tf_checkpoint.py $GRAPH_META_FILE $CKPT_FILE_PREFIX $SAVE_PATH\n\n\n\n\nUse python function\n\n\nimport tensorflow as tf\n\n# This is your model definition.\nxs = tf.placeholder(tf.float32, [None, 1])\n\nW1 = tf.Variable(tf.zeros([1,10])+0.2)\nb1 = tf.Variable(tf.zeros([10])+0.1)\nWx_plus_b1 = tf.nn.bias_add(tf.matmul(xs,W1), b1)\noutput = tf.nn.tanh(Wx_plus_b1, name=\noutput\n)\n\n# Adding the following lines right after your model definition \nfrom bigdl.util.tf_utils import dump_model\ndump_model_path = \n/tmp/model\n\n# This line of code will create a Session and initialized all the Variable and\n# save the model definition and variable to dump_model_path as BigDL readable format.\ndump_model(path=dump_model_path)\n\n\n\n\nThen we can use the \nloadTF\n api to load the tensorflow model into BigDL.\n\n\nScala example\n\n\nval modelPath = \n/tmp/model/model.pb\n\nval binPath = \n/tmp/model/model.bin\n\nval inputs = Seq(\nPlaceholder\n)\nval outputs = Seq(\noutput\n)\n\n// For tensorflow freezed graph or graph without Variables\nval model = Module.loadTF(modelPath, inputs, outputs, ByteOrder.LITTLE_ENDIAN)\n\n// For tensorflow graph with Variables\nval model = Module.loadTF(modelPath, inputs, outputs, ByteOrder.LITTLE_ENDIAN, Some(binPath))\n\n\n\n\nPython example\n\n\nmodel_def = \n/tmp/model/model.pb\n\nmodel_variable = \n/tmp/model/model.bin\n\ninputs = [\nPlaceholder\n]\noutputs = [\noutput\n]\n# For tensorflow freezed graph or graph without Variables\nmodel = Model.load_tensorflow(model_def, inputs, outputs, byte_order = \nlittle_endian\n, bigdl_type=\nfloat\n)\n\n# For tensorflow graph with Variables\nmodel = Model.load_tensorflow(model_def, inputs, outputs, byte_order = \nlittle_endian\n, bigdl_type=\nfloat\n, bin_file=model_variable)\n\n\n\n\nLoad Keras model\n\n\nFor \nPython\n users, BigDL also supports loading pre-defined Keras models. See \nkeras support\n for more details.\n\n\nNote that the Keras version we support and test is \nKeras 1.2.2\n with TensorFlow backend.\n\n\nA Keras model definition in \nJSON\n file can be loaded as a BigDL model.\nSaved weights in \nHDF5\n file can also be loaded together with the architecture of a Keras model.\n\n\nYou can directly call the API \nModel.load_keras\n to load a Keras model into BigDL.\n\n\nRemark\n: \nkeras==1.2.2\n is required. If you need to load a HDF5 file, you also need to install \nh5py\n. These packages can be installed via \npip\n easily.\n\n\nfrom bigdl.nn.layer import *\n\nbigdl_model = Model.load_keras(json_path=None, hdf5_path=None, by_name=False)\n\n\n\n\nModel Evaluation\n\n\nScala\n\n\nmodel.evaluate(dataset, vMethods, batchSize = None)\n\n\n\n\nPython\n\n\nmodel.evaluate(val_rdd, batch_size, val_methods)\n\n\n\n\nUse \nevaluate\n on the model for evaluation. The parameter \ndataset\n (Scala) or \nval_rdd\n (Python) is the validation dataset, and \nvMethods\n (Scala) or \nval_methods\n(Python) is an array of ValidationMethods. Refer to \nMetrics\n for the list of defined ValidationMethods.\n\n\nScala example\n\n\nimport com.intel.analytics.bigdl.dataset.Sample\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.optim.Top1Accuracy\nimport com.intel.analytics.bigdl.tensor.Tensor\n\n//create some dummy dataset for evaluation\nval feature = Tensor(10).rand()\nval label = Tensor(1).randn()\n\nval testSample = Sample(feature, label)\n//sc is is the SparkContxt instance\nval testSet = sc.parallelize(Seq(testSample))\n\n//train a new model or load an existing model\n//val model=...\nval evaluateResult = model.evaluate(testSet, Array(new Top1Accuracy))\n\n\n\n\nPython example\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.util.common import *\nfrom bigdl.optim.optimizer import *\nimport numpy as np\n\nsc = SparkContext.getOrCreate(conf=create_spark_conf())\ninit_engine()\n\nsamples=[Sample.from_ndarray(np.array([1.0, 2.0]), np.array([2.0]))]\ntestSet = sc.parallelize(samples,1)\n\n//You can train a model or load an existing model before evaluation.\nmodel = Linear(2, 1)\n\nevaluateResult = model.evaluate(testSet, 1, [Top1Accuracy()])\nprint(evaluateResult[0])\n\n\n\n\nModel Prediction\n\n\nScala\n\n\nmodel.predict(dataset)\nmodel.predictClass(dataset)\n\n\n\n\nPython\n\n\nmodel.predict(data_rdd)\nmodel.predict_class(data_rdd)\n\n\n\n\nUse \npredict\n or \npredictClass\n or \npredict_class\n on model for Prediction. \npredict\n returns return the probability distribution of each class, and \npredictClass\n/\npredict_class\n returns the predict label. They both accepts the test dataset as parameter.\n\n\nPlease note that the sequence and the partitions of the output rdd will keep the same with input. So you can zip the output rdd with input rdd to get a (data, result) pair rdd.\n\n\nScala example\n\n\nimport com.intel.analytics.bigdl.dataset.Sample\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.optim.Top1Accuracy\nimport com.intel.analytics.bigdl.tensor.Tensor\n\n//create some dummy dataset for prediction as example\nval feature = Tensor(10).rand()\nval predictSample = Sample(feature)\nval predictSet = sc.parallelize(Seq(predictSample))\n\n//train a new model or load an existing model\n//val model=...\nval predictResult = model.predict(predictSet)\n\n\n\n\nPython example\n\n\n from bigdl.nn.layer import *\n from bigdl.util.common import *\n from bigdl.optim.optimizer import *\n import numpy as np\n\n samples=[Sample.from_ndarray(np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]), np.  array([2.0]))]\n\n predictSet = sc.parallelize(samples)\n\n //train a model or load an existing model...\n //model = ...\n predictResult = model.predict(predictSet)\n\n\n\n\nModule Freeze\n\n\nTo \"freeze\" a module means to exclude some layers of model from training.\n\n\nmodule.freeze(\nlayer1\n, \nlayer2\n)\nmodule.unFreeze(\nlayer1\n, \nlayer2\n)\nmodule.stopGradient(Array(\nlayer1\n))\n\n\n\n\n\n\nThe whole module can be \"freezed\" by calling \nfreeze()\n. If a module is freezed,\nits parameters(weight/bias, if exists) are not changed in training process.\nIf module names are passed, then layers that match the given names will be freezed.\n\n\nThe whole module can be \"unFreezed\" by calling \nunFreeze()\n.\nIf module names are provided, then layers that match the given names will be unFreezed.\n\n\nstop the input gradient of layers that match the given names. Their input gradient are not computed.\nAnd they will not contributed to the input gradient computation of layers that depend on them.\n\n\n\n\nNote that stopGradient is only supported in Graph model.\n\n\nPython\n\n\nmodule.freeze([\nlayer1\n, \nlayer2\n])\nmodule.unfreeze([\nlayer1\n, \nlayer2\n])\nmodule.stop_gradient([\nlayer1\n])\n\n\n\n\nScala\n\nOriginal model without \"freeze\" or \"stop gradient\"\n\n\nval reshape = Reshape(Array(4)).inputs()\nval fc1 = Linear(4, 2).setName(\nfc1\n).inputs()\nval fc2 = Linear(4, 2).setName(\nfc2\n).inputs(reshape)\nval cadd_1 = CAddTable().setName(\ncadd\n).inputs(fc1, fc2)\nval output1_1 = ReLU().inputs(cadd_1)\nval output2_1 = Threshold(10.0).inputs(cadd_1)\n\nval model = Graph(Array(reshape, fc1), Array(output1_1, output2_1))\n\nval input = T(Tensor(T(0.1f, 0.2f, -0.3f, -0.4f)),\n  Tensor(T(0.5f, 0.4f, -0.2f, -0.1f)))\nval gradOutput = T(Tensor(T(1.0f, 2.0f)), Tensor(T(3.0f, 4.0f)))\n\nfc1.element.getParameters()._1.apply1(_ =\n 1.0f)\nfc2.element.getParameters()._1.apply1(_ =\n 2.0f)\nmodel.zeroGradParameters()\nprintln(\noutput1: \\n\n, model.forward(input))\nmodel.backward(input, gradOutput)\nmodel.updateParameters(1)\nprintln(\nfc2 weight \\n\n, fc2.element.parameters()._1(0))\n\n\n\n\n(output1:\n, {\n    2: 0.0\n       0.0\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    1: 2.8\n       2.8\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n })\n(fc2 weight\n,1.9    1.8 2.3 2.4\n1.8 1.6 2.6 2.8\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4])\n\n\n\n\n\"Freeze\" \nfc2\n, the parameters of \nfc2\n is not changed.\n\n\nfc1.element.getParameters()._1.apply1(_ =\n 1.0f)\nfc2.element.getParameters()._1.apply1(_ =\n 2.0f)\nmodel.zeroGradParameters()\nmodel.freeze(\nfc2\n)\nprintln(\noutput2: \\n\n, model.forward(input))\nmodel.backward(input, gradOutput)\nmodel.updateParameters(1)\nprintln(\nfc2 weight \\n\n, fc2.element.parameters()._1(0))\n\n\n\n\n(output2:\n, {\n    2: 0.0\n       0.0\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    1: 2.8\n       2.8\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n })\n(fc2 weight\n,2.0    2.0 2.0 2.0\n2.0 2.0 2.0 2.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4])\n\n\n\n\n\"unFreeze\" \nfc2\n, the parameters of \nfc2\n will be updated.\n\n\nfc1.element.getParameters()._1.apply1(_ =\n 1.0f)\nfc2.element.getParameters()._1.apply1(_ =\n 2.0f)\nmodel.zeroGradParameters()\nmodel.unFreeze()\nprintln(\noutput3: \\n\n, model.forward(input))\nmodel.backward(input, gradOutput)\nmodel.updateParameters(1)\nprintln(\nfc2 weight \\n\n, fc2.element.parameters()._1(0))\n\n\n\n\n(output3:\n, {\n    2: 0.0\n       0.0\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    1: 2.8\n       2.8\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n })\n(fc2 weight\n,1.9    1.8 2.3 2.4\n1.8 1.6 2.6 2.8\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4])\n\n\n\n\n\"stop gradient\" at \ncadd\n, the parameters of \nfc1\n and \nfc2\n are not changed.\n\n\nfc1.element.getParameters()._1.apply1(_ =\n 1.0f)\nfc2.element.getParameters()._1.apply1(_ =\n 2.0f)\nmodel.stopGradient(Array(\ncadd\n))\nmodel.zeroGradParameters()\nprintln(\noutput4: \\n\n, model.forward(input))\nmodel.backward(input, gradOutput)\nmodel.updateParameters(1)\nprintln(\nfc1 weight \\n\n, fc1.element.parameters()._1(0))\nprintln(\nfc2 weight \\n\n, fc2.element.parameters()._1(0))\n\n\n\n\n(output4:\n, {\n    2: 0.0\n       0.0\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    1: 2.8\n       2.8\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n })\n(fc1 weight\n,1.0    1.0 1.0 1.0\n1.0 1.0 1.0 1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4])\n(fc2 weight\n,2.0    2.0 2.0 2.0\n2.0 2.0 2.0 2.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4])\n\n\n\n\nPython\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nreshape = Reshape([4])()\nfc1 = Linear(4, 2).set_name(\nfc1\n)()\nfc2 = Linear(4, 2).set_name(\nfc2\n)(reshape)\ncadd = CAddTable().set_name(\ncadd\n)([fc1, fc2])\noutput1 = ReLU()(cadd)\noutput2 = Threshold(10.0)(cadd)\nmodel = Model([reshape, fc1], [output1, output2])\n\ninput = [\n    np.array([0.1, 0.2, -0.3, -0.4]),\n    np.array([0.5, 0.4, -0.2, -0.1])]\ngradOutput = [\n    np.array([1.0, 2.0]), np.array([3.0, 4.0])]\n\nfc1.element().set_weights([np.array([[1,1,1,1],[1,1,1,1]]), np.array([1,1])])\nfc2.element().set_weights([np.array([[2,2,2,2],[2,2,2,2]]), np.array([2,2])])\nmodel.zero_grad_parameters()\noutput = model.forward(input)\nprint \noutput1: \n, output\ngradInput = model.backward(input, gradOutput)\nmodel.update_parameters(1.0)\nprint \nfc2 weight \\n\n, fc2.element().parameters()['fc2']['weight']\n\n\n\n\n output1\n[array([ 2.79999995,  2.79999995], dtype=float32), array([ 0.,  0.], dtype=float32)]\n\n\n fc2 weight\n[[ 1.89999998  1.79999995  2.29999995  2.4000001 ]\n [ 1.79999995  1.60000002  2.5999999   2.79999995]]\n\n\n\n\nfc1.element().set_weights([np.array([[1,1,1,1],[1,1,1,1]]), np.array([1,1])])\nfc2.element().set_weights([np.array([[2,2,2,2],[2,2,2,2]]), np.array([2,2])])\nm3 = model.freeze([\nfc2\n])\nmodel.zero_grad_parameters()\noutput = model.forward(input)\nprint \noutput2 \n, output\ngradInput = model.backward(input, gradOutput)\nmodel.update_parameters(1.0)\nprint \nfc2 weight \\n\n, fc2.element().parameters()['fc2']['weight']\n\n\n\n\n output2\n[array([ 2.79999995,  2.79999995], dtype=float32), array([ 0.,  0.], dtype=float32)]\n\n\n fc2 weight\n[[ 2.  2.  2.  2.]\n [ 2.  2.  2.  2.]]\n\n\n\n\nfc1.element().set_weights([np.array([[1,1,1,1],[1,1,1,1]]), np.array([1,1])])\nfc2.element().set_weights([np.array([[2,2,2,2],[2,2,2,2]]), np.array([2,2])])\nm3 = model.unfreeze()\nmodel.zero_grad_parameters()\noutput = model.forward(input)\nprint \noutput3 \n, output\ngradInput = model.backward(input, gradOutput)\nmodel.update_parameters(1.0)\nprint \nfc2 weight \\n\n, fc2.element().parameters()['fc2']['weight']\n\n\n\n\n output3\n[array([ 2.79999995,  2.79999995], dtype=float32), array([ 0.,  0.], dtype=float32)]\n\n\n fc2 weight\n[[ 1.89999998  1.79999995  2.29999995  2.4000001 ]\n [ 1.79999995  1.60000002  2.5999999   2.79999995]]\n\n\n\n\nm3 = model.stop_gradient([\ncadd\n])\nmodel.zero_grad_parameters()\noutput = model.forward(input)\nprint \noutput4 \n, output\ngradInput = model.backward(input, gradOutput)\nmodel.update_parameters(1.0)\nprint \nfc1 weight \\n\n, fc1.element().parameters()['fc1']['weight']\nprint \nfc2 weight \\n\n, fc2.element().parameters()['fc2']['weight']\n\n\n\n\n output4\n[array([ 2.79999995,  2.79999995], dtype=float32), array([ 0.,  0.], dtype=float32)]\n\n\n fc1 weight\n[[ 1.  1.  1.  1.]\n [ 1.  1.  1.  1.]]\n\n\n fc2 weight\n[[ 2.  2.  2.  2.]\n [ 2.  2.  2.  2.]]\n\n\n\n\nCaffe Model Support\n\n\nLoad Caffe model\n\n\nScala:\n\n\nModule.loadCaffeModel(defPath, modelPath)\n\n\n\n\nPython:\n\n\nModel.load_caffe_model(defPath, modelPath)\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.Module\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = Module.loadCaffeModel(\n/tmp/deploy.prototxt\n, \n/tmp/caffe.caffemodel\n)\n\n\n\n\nIn above \ndefPath\n specifies the path for the network deploy file while \nmodelPath\n specifies the path for the weight file \n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nmodel = Model.load_caffe_model(\n/tmp/deploy.prototxt\n, \n/tmp/caffe.caffemodel\n)\n\n\n\n\nLoad weight from Caffe into pre-defined model\n\n\nScala:\n\n\nModule.loadCaffe(model, defPath, modelPath, match_all = true)\n\n\n\n\nPython:\n\n\nModel.load_caffe(model, defPath, modelPath, match_all = True)\n\n\n\n\nmodel\n is pre-defined BigDL model. Similar to \nloadCaffeModel\n, \ndefPath\n and \nmodelPath\n specify network deploy file and weight file,\nthe 4th parameter \nmatch_all\n specifies if layer definition should be exactly matched between pre-defined \nmodel\n and the one from \ndefPath\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.Module\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = Sequential().add(Linear(3, 4))\nval loadedModel = Module.loadCaffe(model, \n/tmp/deploy.prototxt\n, \n/tmp/caffe.caffemodel\n, true)\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nmodel = Sequential().add(Linear(3, 4))\nloadedModel = Model.load_caffe(model, \n/tmp/deploy.prototxt\n, \n/tmp/caffe.caffemodel\n, True)\n\n\n\n\nSave BigDL model as Caffe model\n\n\nScala:\n\n\nbigdlModel.saveCaffe(prototxtPath, modelPath, useV2 = true, overwrite = false)\n\n\n\n\nPython:\n\n\nbigdl_model.save_caffe(prototxt_path, model_path, use_v2 = True, overwrite = False)\n\n\n\n\nprototxtPath\n defines where to store the network, \nmodelPath\n defines where to store the weight, \nuseV2\n \ndefines whether to store as V2Layer format, and \noverwrite\n defines whether to overwrite if the files already exist.\n\n\nOnly Graph model is supported for now.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.Module\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nval linear = Linear(3, 4)\nval model = Graph(linear.inputs(), linear.inputs())\nmodel.saveCaffe(\n/tmp/linear.prototxt\n, \n/tmp/linear.caffemodel\n, true, true)\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nlinear = Linear(3, 4)\nmodel = Graph(linear.inputs(), linear.inputs())\nmodel.save_caffe(model, \n/tmp/linear.prototxt\n, \n/tmp/linear.caffemodel\n, True, True)", 
            "title": "Model"
        }, 
        {
            "location": "/APIGuide/Module/#model-save", 
            "text": "BigDL supports saving models to local file system, HDFS and AWS S3. After a model is created, you can use  saveModule  (Scala) or 'saveModel' (python) on created model to save it. Below example shows how to save a model.  Scala example  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nval model = Sequential().add(Linear(10, 5)).add(Sigmoid()).add(SoftMax())\n//...train\n\nmodel.saveModule( /tmp/model.bigdl ,  /tmp/model.bin , true) //save to local fs\nmodel.saveModule( hdfs://... ) //save to hdfs\nmodel.saveModule( s3://... ) //save to s3  Python example  from bigdl.nn.layer import *\nfrom bigdl.util.common import *\nfrom bigdl.optim.optimizer import *\n\nmodel = Sequential().add(Linear(10, 5)).add(Sigmoid()).add(SoftMax())\n//...train\nmodel.saveModel( /tmp/model.bigdl ,  /tmp/model.bin , True) //save to local fs\nmodel.saveModel( hdfs://... ) //save to hdfs\nmodel.saveModel( s3://... ) //save to s3  In  model.saveModel , the first parameter is the path where we want to save our model network, the second parameter is the path where we want to save the model weights, the third parameter is to specify if we need to overwrite the file if it already exists, it's set to false by default\nPlease notice that if the second parameter is not specified, weights will be saved into the same file as model network. Save weights separately usually handles the situation that the model is big in size", 
            "title": "Model Save"
        }, 
        {
            "location": "/APIGuide/Module/#model-load", 
            "text": "", 
            "title": "Model Load"
        }, 
        {
            "location": "/APIGuide/Module/#load-bigdl-model", 
            "text": "Use  Module.loadModule (in Scala) or  Model.loadModel  (in Python) to load an existing model.   Module  (Scala) or  Model (Python) is a utility class provided in BigDL. We just need to specify the model path and optionally weight path if exists where we previously saved the model to load it to memory for resume training or prediction purpose.  Scala example  val model = Module.loadModule( /tmp/model.bigdl ,  /tmp/model.bin ) //load from local fs\nval model = Module.loadModule( hdfs://... ) //load from hdfs\nval model = Module.loadModule( s3://... ) //load from s3  Python example  model = Model.loadModel( /tmp/model.bigdl ,  /tmp/model.bin ) //load from local fs\nmodel = Model.loadModel( hdfs://... ) //load from hdfs\nmodel = Model.loadModel( s3://... ) //load from s3", 
            "title": "Load BigDL model"
        }, 
        {
            "location": "/APIGuide/Module/#load-tensorflow-model", 
            "text": "BigDL also provides utilities to load tensorflow model. See  tensorflow support \nfor more information.  If we already have a freezed graph protobuf file, we can use the  loadTF  api directly to\nload the tensorflow model.   Otherwise, we should first use the  export_tf_checkpoint.py  script provided by BigDL's distribution\npackage, or the  dump_model  function defined in  here  to\ngenerate the model definition file ( model.pb ) and variable binary file ( model.bin ).   Use Script  GRAPH_META_FILE=/tmp/tensorflow/model.ckpt.meta\nCKPT_FILE_PREFIX=/tmp/tensorflow/model.ckpt\nSAVE_PATH=/tmp/model/\npython export_tf_checkpoint.py $GRAPH_META_FILE $CKPT_FILE_PREFIX $SAVE_PATH  Use python function  import tensorflow as tf\n\n# This is your model definition.\nxs = tf.placeholder(tf.float32, [None, 1])\n\nW1 = tf.Variable(tf.zeros([1,10])+0.2)\nb1 = tf.Variable(tf.zeros([10])+0.1)\nWx_plus_b1 = tf.nn.bias_add(tf.matmul(xs,W1), b1)\noutput = tf.nn.tanh(Wx_plus_b1, name= output )\n\n# Adding the following lines right after your model definition \nfrom bigdl.util.tf_utils import dump_model\ndump_model_path =  /tmp/model \n# This line of code will create a Session and initialized all the Variable and\n# save the model definition and variable to dump_model_path as BigDL readable format.\ndump_model(path=dump_model_path)  Then we can use the  loadTF  api to load the tensorflow model into BigDL.  Scala example  val modelPath =  /tmp/model/model.pb \nval binPath =  /tmp/model/model.bin \nval inputs = Seq( Placeholder )\nval outputs = Seq( output )\n\n// For tensorflow freezed graph or graph without Variables\nval model = Module.loadTF(modelPath, inputs, outputs, ByteOrder.LITTLE_ENDIAN)\n\n// For tensorflow graph with Variables\nval model = Module.loadTF(modelPath, inputs, outputs, ByteOrder.LITTLE_ENDIAN, Some(binPath))  Python example  model_def =  /tmp/model/model.pb \nmodel_variable =  /tmp/model/model.bin \ninputs = [ Placeholder ]\noutputs = [ output ]\n# For tensorflow freezed graph or graph without Variables\nmodel = Model.load_tensorflow(model_def, inputs, outputs, byte_order =  little_endian , bigdl_type= float )\n\n# For tensorflow graph with Variables\nmodel = Model.load_tensorflow(model_def, inputs, outputs, byte_order =  little_endian , bigdl_type= float , bin_file=model_variable)", 
            "title": "Load Tensorflow model"
        }, 
        {
            "location": "/APIGuide/Module/#load-keras-model", 
            "text": "For  Python  users, BigDL also supports loading pre-defined Keras models. See  keras support  for more details.  Note that the Keras version we support and test is  Keras 1.2.2  with TensorFlow backend.  A Keras model definition in  JSON  file can be loaded as a BigDL model.\nSaved weights in  HDF5  file can also be loaded together with the architecture of a Keras model.  You can directly call the API  Model.load_keras  to load a Keras model into BigDL.  Remark :  keras==1.2.2  is required. If you need to load a HDF5 file, you also need to install  h5py . These packages can be installed via  pip  easily.  from bigdl.nn.layer import *\n\nbigdl_model = Model.load_keras(json_path=None, hdf5_path=None, by_name=False)", 
            "title": "Load Keras model"
        }, 
        {
            "location": "/APIGuide/Module/#model-evaluation", 
            "text": "Scala  model.evaluate(dataset, vMethods, batchSize = None)  Python  model.evaluate(val_rdd, batch_size, val_methods)  Use  evaluate  on the model for evaluation. The parameter  dataset  (Scala) or  val_rdd  (Python) is the validation dataset, and  vMethods  (Scala) or  val_methods (Python) is an array of ValidationMethods. Refer to  Metrics  for the list of defined ValidationMethods.  Scala example  import com.intel.analytics.bigdl.dataset.Sample\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.optim.Top1Accuracy\nimport com.intel.analytics.bigdl.tensor.Tensor\n\n//create some dummy dataset for evaluation\nval feature = Tensor(10).rand()\nval label = Tensor(1).randn()\n\nval testSample = Sample(feature, label)\n//sc is is the SparkContxt instance\nval testSet = sc.parallelize(Seq(testSample))\n\n//train a new model or load an existing model\n//val model=...\nval evaluateResult = model.evaluate(testSet, Array(new Top1Accuracy))  Python example  from bigdl.nn.layer import *\nfrom bigdl.util.common import *\nfrom bigdl.optim.optimizer import *\nimport numpy as np\n\nsc = SparkContext.getOrCreate(conf=create_spark_conf())\ninit_engine()\n\nsamples=[Sample.from_ndarray(np.array([1.0, 2.0]), np.array([2.0]))]\ntestSet = sc.parallelize(samples,1)\n\n//You can train a model or load an existing model before evaluation.\nmodel = Linear(2, 1)\n\nevaluateResult = model.evaluate(testSet, 1, [Top1Accuracy()])\nprint(evaluateResult[0])", 
            "title": "Model Evaluation"
        }, 
        {
            "location": "/APIGuide/Module/#model-prediction", 
            "text": "Scala  model.predict(dataset)\nmodel.predictClass(dataset)  Python  model.predict(data_rdd)\nmodel.predict_class(data_rdd)  Use  predict  or  predictClass  or  predict_class  on model for Prediction.  predict  returns return the probability distribution of each class, and  predictClass / predict_class  returns the predict label. They both accepts the test dataset as parameter.  Please note that the sequence and the partitions of the output rdd will keep the same with input. So you can zip the output rdd with input rdd to get a (data, result) pair rdd.  Scala example  import com.intel.analytics.bigdl.dataset.Sample\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.optim.Top1Accuracy\nimport com.intel.analytics.bigdl.tensor.Tensor\n\n//create some dummy dataset for prediction as example\nval feature = Tensor(10).rand()\nval predictSample = Sample(feature)\nval predictSet = sc.parallelize(Seq(predictSample))\n\n//train a new model or load an existing model\n//val model=...\nval predictResult = model.predict(predictSet)  Python example   from bigdl.nn.layer import *\n from bigdl.util.common import *\n from bigdl.optim.optimizer import *\n import numpy as np\n\n samples=[Sample.from_ndarray(np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]), np.  array([2.0]))]\n\n predictSet = sc.parallelize(samples)\n\n //train a model or load an existing model...\n //model = ...\n predictResult = model.predict(predictSet)", 
            "title": "Model Prediction"
        }, 
        {
            "location": "/APIGuide/Module/#module-freeze", 
            "text": "To \"freeze\" a module means to exclude some layers of model from training.  module.freeze( layer1 ,  layer2 )\nmodule.unFreeze( layer1 ,  layer2 )\nmodule.stopGradient(Array( layer1 ))   The whole module can be \"freezed\" by calling  freeze() . If a module is freezed,\nits parameters(weight/bias, if exists) are not changed in training process.\nIf module names are passed, then layers that match the given names will be freezed.  The whole module can be \"unFreezed\" by calling  unFreeze() .\nIf module names are provided, then layers that match the given names will be unFreezed.  stop the input gradient of layers that match the given names. Their input gradient are not computed.\nAnd they will not contributed to the input gradient computation of layers that depend on them.   Note that stopGradient is only supported in Graph model.  Python  module.freeze([ layer1 ,  layer2 ])\nmodule.unfreeze([ layer1 ,  layer2 ])\nmodule.stop_gradient([ layer1 ])  Scala \nOriginal model without \"freeze\" or \"stop gradient\"  val reshape = Reshape(Array(4)).inputs()\nval fc1 = Linear(4, 2).setName( fc1 ).inputs()\nval fc2 = Linear(4, 2).setName( fc2 ).inputs(reshape)\nval cadd_1 = CAddTable().setName( cadd ).inputs(fc1, fc2)\nval output1_1 = ReLU().inputs(cadd_1)\nval output2_1 = Threshold(10.0).inputs(cadd_1)\n\nval model = Graph(Array(reshape, fc1), Array(output1_1, output2_1))\n\nval input = T(Tensor(T(0.1f, 0.2f, -0.3f, -0.4f)),\n  Tensor(T(0.5f, 0.4f, -0.2f, -0.1f)))\nval gradOutput = T(Tensor(T(1.0f, 2.0f)), Tensor(T(3.0f, 4.0f)))\n\nfc1.element.getParameters()._1.apply1(_ =  1.0f)\nfc2.element.getParameters()._1.apply1(_ =  2.0f)\nmodel.zeroGradParameters()\nprintln( output1: \\n , model.forward(input))\nmodel.backward(input, gradOutput)\nmodel.updateParameters(1)\nprintln( fc2 weight \\n , fc2.element.parameters()._1(0))  (output1:\n, {\n    2: 0.0\n       0.0\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    1: 2.8\n       2.8\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n })\n(fc2 weight\n,1.9    1.8 2.3 2.4\n1.8 1.6 2.6 2.8\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4])  \"Freeze\"  fc2 , the parameters of  fc2  is not changed.  fc1.element.getParameters()._1.apply1(_ =  1.0f)\nfc2.element.getParameters()._1.apply1(_ =  2.0f)\nmodel.zeroGradParameters()\nmodel.freeze( fc2 )\nprintln( output2: \\n , model.forward(input))\nmodel.backward(input, gradOutput)\nmodel.updateParameters(1)\nprintln( fc2 weight \\n , fc2.element.parameters()._1(0))  (output2:\n, {\n    2: 0.0\n       0.0\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    1: 2.8\n       2.8\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n })\n(fc2 weight\n,2.0    2.0 2.0 2.0\n2.0 2.0 2.0 2.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4])  \"unFreeze\"  fc2 , the parameters of  fc2  will be updated.  fc1.element.getParameters()._1.apply1(_ =  1.0f)\nfc2.element.getParameters()._1.apply1(_ =  2.0f)\nmodel.zeroGradParameters()\nmodel.unFreeze()\nprintln( output3: \\n , model.forward(input))\nmodel.backward(input, gradOutput)\nmodel.updateParameters(1)\nprintln( fc2 weight \\n , fc2.element.parameters()._1(0))  (output3:\n, {\n    2: 0.0\n       0.0\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    1: 2.8\n       2.8\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n })\n(fc2 weight\n,1.9    1.8 2.3 2.4\n1.8 1.6 2.6 2.8\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4])  \"stop gradient\" at  cadd , the parameters of  fc1  and  fc2  are not changed.  fc1.element.getParameters()._1.apply1(_ =  1.0f)\nfc2.element.getParameters()._1.apply1(_ =  2.0f)\nmodel.stopGradient(Array( cadd ))\nmodel.zeroGradParameters()\nprintln( output4: \\n , model.forward(input))\nmodel.backward(input, gradOutput)\nmodel.updateParameters(1)\nprintln( fc1 weight \\n , fc1.element.parameters()._1(0))\nprintln( fc2 weight \\n , fc2.element.parameters()._1(0))  (output4:\n, {\n    2: 0.0\n       0.0\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    1: 2.8\n       2.8\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n })\n(fc1 weight\n,1.0    1.0 1.0 1.0\n1.0 1.0 1.0 1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4])\n(fc2 weight\n,2.0    2.0 2.0 2.0\n2.0 2.0 2.0 2.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4])  Python  from bigdl.nn.layer import *\nimport numpy as np\n\nreshape = Reshape([4])()\nfc1 = Linear(4, 2).set_name( fc1 )()\nfc2 = Linear(4, 2).set_name( fc2 )(reshape)\ncadd = CAddTable().set_name( cadd )([fc1, fc2])\noutput1 = ReLU()(cadd)\noutput2 = Threshold(10.0)(cadd)\nmodel = Model([reshape, fc1], [output1, output2])\n\ninput = [\n    np.array([0.1, 0.2, -0.3, -0.4]),\n    np.array([0.5, 0.4, -0.2, -0.1])]\ngradOutput = [\n    np.array([1.0, 2.0]), np.array([3.0, 4.0])]\n\nfc1.element().set_weights([np.array([[1,1,1,1],[1,1,1,1]]), np.array([1,1])])\nfc2.element().set_weights([np.array([[2,2,2,2],[2,2,2,2]]), np.array([2,2])])\nmodel.zero_grad_parameters()\noutput = model.forward(input)\nprint  output1:  , output\ngradInput = model.backward(input, gradOutput)\nmodel.update_parameters(1.0)\nprint  fc2 weight \\n , fc2.element().parameters()['fc2']['weight']   output1\n[array([ 2.79999995,  2.79999995], dtype=float32), array([ 0.,  0.], dtype=float32)]  fc2 weight\n[[ 1.89999998  1.79999995  2.29999995  2.4000001 ]\n [ 1.79999995  1.60000002  2.5999999   2.79999995]]  fc1.element().set_weights([np.array([[1,1,1,1],[1,1,1,1]]), np.array([1,1])])\nfc2.element().set_weights([np.array([[2,2,2,2],[2,2,2,2]]), np.array([2,2])])\nm3 = model.freeze([ fc2 ])\nmodel.zero_grad_parameters()\noutput = model.forward(input)\nprint  output2  , output\ngradInput = model.backward(input, gradOutput)\nmodel.update_parameters(1.0)\nprint  fc2 weight \\n , fc2.element().parameters()['fc2']['weight']   output2\n[array([ 2.79999995,  2.79999995], dtype=float32), array([ 0.,  0.], dtype=float32)]  fc2 weight\n[[ 2.  2.  2.  2.]\n [ 2.  2.  2.  2.]]  fc1.element().set_weights([np.array([[1,1,1,1],[1,1,1,1]]), np.array([1,1])])\nfc2.element().set_weights([np.array([[2,2,2,2],[2,2,2,2]]), np.array([2,2])])\nm3 = model.unfreeze()\nmodel.zero_grad_parameters()\noutput = model.forward(input)\nprint  output3  , output\ngradInput = model.backward(input, gradOutput)\nmodel.update_parameters(1.0)\nprint  fc2 weight \\n , fc2.element().parameters()['fc2']['weight']   output3\n[array([ 2.79999995,  2.79999995], dtype=float32), array([ 0.,  0.], dtype=float32)]  fc2 weight\n[[ 1.89999998  1.79999995  2.29999995  2.4000001 ]\n [ 1.79999995  1.60000002  2.5999999   2.79999995]]  m3 = model.stop_gradient([ cadd ])\nmodel.zero_grad_parameters()\noutput = model.forward(input)\nprint  output4  , output\ngradInput = model.backward(input, gradOutput)\nmodel.update_parameters(1.0)\nprint  fc1 weight \\n , fc1.element().parameters()['fc1']['weight']\nprint  fc2 weight \\n , fc2.element().parameters()['fc2']['weight']   output4\n[array([ 2.79999995,  2.79999995], dtype=float32), array([ 0.,  0.], dtype=float32)]  fc1 weight\n[[ 1.  1.  1.  1.]\n [ 1.  1.  1.  1.]]  fc2 weight\n[[ 2.  2.  2.  2.]\n [ 2.  2.  2.  2.]]", 
            "title": "Module Freeze"
        }, 
        {
            "location": "/APIGuide/Module/#caffe-model-support", 
            "text": "", 
            "title": "Caffe Model Support"
        }, 
        {
            "location": "/APIGuide/Module/#load-caffe-model", 
            "text": "Scala:  Module.loadCaffeModel(defPath, modelPath)  Python:  Model.load_caffe_model(defPath, modelPath)  Scala example:  import com.intel.analytics.bigdl.nn.Module\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = Module.loadCaffeModel( /tmp/deploy.prototxt ,  /tmp/caffe.caffemodel )  In above  defPath  specifies the path for the network deploy file while  modelPath  specifies the path for the weight file   Python example:  from bigdl.nn.layer import *\nmodel = Model.load_caffe_model( /tmp/deploy.prototxt ,  /tmp/caffe.caffemodel )", 
            "title": "Load Caffe model"
        }, 
        {
            "location": "/APIGuide/Module/#load-weight-from-caffe-into-pre-defined-model", 
            "text": "Scala:  Module.loadCaffe(model, defPath, modelPath, match_all = true)  Python:  Model.load_caffe(model, defPath, modelPath, match_all = True)  model  is pre-defined BigDL model. Similar to  loadCaffeModel ,  defPath  and  modelPath  specify network deploy file and weight file,\nthe 4th parameter  match_all  specifies if layer definition should be exactly matched between pre-defined  model  and the one from  defPath  Scala example:  import com.intel.analytics.bigdl.nn.Module\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = Sequential().add(Linear(3, 4))\nval loadedModel = Module.loadCaffe(model,  /tmp/deploy.prototxt ,  /tmp/caffe.caffemodel , true)  Python example:  from bigdl.nn.layer import *\nmodel = Sequential().add(Linear(3, 4))\nloadedModel = Model.load_caffe(model,  /tmp/deploy.prototxt ,  /tmp/caffe.caffemodel , True)", 
            "title": "Load weight from Caffe into pre-defined model"
        }, 
        {
            "location": "/APIGuide/Module/#save-bigdl-model-as-caffe-model", 
            "text": "Scala:  bigdlModel.saveCaffe(prototxtPath, modelPath, useV2 = true, overwrite = false)  Python:  bigdl_model.save_caffe(prototxt_path, model_path, use_v2 = True, overwrite = False)  prototxtPath  defines where to store the network,  modelPath  defines where to store the weight,  useV2  \ndefines whether to store as V2Layer format, and  overwrite  defines whether to overwrite if the files already exist.  Only Graph model is supported for now.  Scala example:  import com.intel.analytics.bigdl.nn.Module\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nval linear = Linear(3, 4)\nval model = Graph(linear.inputs(), linear.inputs())\nmodel.saveCaffe( /tmp/linear.prototxt ,  /tmp/linear.caffemodel , true, true)  Python example:  from bigdl.nn.layer import *\nlinear = Linear(3, 4)\nmodel = Graph(linear.inputs(), linear.inputs())\nmodel.save_caffe(model,  /tmp/linear.prototxt ,  /tmp/linear.caffemodel , True, True)", 
            "title": "Save BigDL model as Caffe model"
        }, 
        {
            "location": "/APIGuide/Layers/Containers/", 
            "text": "Sequential\n\n\nScala:\n\n\nval module = Sequential()\n\n\n\n\nPython:\n\n\nseq = Sequential()\n\n\n\n\nSequential provides a means to plug layers together\nin a feed-forward fully connected manner.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nimport com.intel.analytics.bigdl.nn.{Sequential, Linear}\n\nval module = Sequential()\nmodule.add(Linear(10, 25))\nmodule.add(Linear(25, 10))\n\nval input = Tensor(10).range(1, 10, 1)\nval gradOutput = Tensor(10).range(1, 10, 1)\n\nval output = module.forward(input).toTensor\nval gradInput = module.backward(input, gradOutput).toTensor\n\nprintln(output)\nprintln(gradInput)\n\n\n\n\nGives the output,\n\n\n-2.3750305\n2.4512818\n1.6998017\n-0.47432393\n4.3048754\n-0.044168986\n-1.1643536\n0.60341483\n2.0216258\n2.1190155\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 10]\n\n\n\n\nGives the gradInput,\n\n\n2.593382\n-1.4137214\n-1.8271983\n1.229643\n0.51384985\n1.509845\n2.9537349\n1.088281\n0.2618509\n1.4840821\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 10]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nseq = Sequential()\nseq.add(Linear(10, 25))\nseq.add(Linear(25, 10))\n\ninput = np.arange(1, 11, 1).astype(\nfloat32\n)\ninput = input.reshape(1, 10)\n\noutput = seq.forward(input)\nprint output\n\ngradOutput = np.arange(1, 11, 1).astype(\nfloat32\n)\ngradOutput = gradOutput.reshape(1, 10)\n\ngradInput = seq.backward(input, gradOutput)\nprint gradInput\n\n\n\n\nGives the output,\n\n\n[array([[ 1.08462083, -2.03257799, -0.5400058 ,  0.27452484,  1.85562158,\n         1.64338267,  2.45694995,  1.70170391, -2.12998056, -1.28924525]], dtype=float32)]\n\n\n\n\nGives the gradInput,\n\n\n\n[array([[ 1.72007763,  1.64403224,  2.52977395, -1.00021958,  0.1134415 ,\n         2.06711197,  2.29631734, -3.39587498,  1.01093054, -0.54482007]], dtype=float32)]\n\n\n\n\nGraph\n\n\nScala:\n\n\nval graph = Graph(Array(Node), Array(Node))\n\n\n\n\nPython:\n\n\nmodel = Model([Node], [Node])\n\n\n\n\nA graph container. Each node can have multiple inputs. The output of the node should be a tensor.\n The output tensor can be connected to multiple nodes. So the module in each node can have a\n tensor or table input, and should have a tensor output.\n\n\nThe graph container can have multiple inputs and multiple outputs. If there's one input, the\n input data fed to the graph module should be a tensor. If there're multiple inputs, the input\n data fed to the graph module should be a table, which is actually an sequence of tensor. The\n order of the input tensors should be same with the order of the input nodes. This is also\n applied to the gradient from the module in the back propagation.\n\n\nAll of the input modules must accept a tensor input. If your input module accept multiple\n tensors as input, you should add some \nInput layer\n before\n it as input nodes and connect the output of the Input modules to that module.\n\n\nIf there's one output, the module output is a tensor. If there're multiple outputs, the module\n output is a table, which is actually an sequence of tensor. The order of the output tensors is\n same with the order of the output modules. This is also applied to the gradient passed to the\n module in the back propagation.\n\n\nAll inputs should be able to connect to outputs through some paths in the graph. It is\n allowed that some successors of the inputs node are not connect to outputs. If so, these nodes\n will be excluded in the computation.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\n\nval input1 = Input()\nval input2 = Input()\nval cadd = CAddTable().inputs(input1, input2)\nval graph = Graph(Array(input1, input2), cadd)\n\nval output = graph.forward(T(Tensor(T(0.1f, 0.2f, -0.3f, -0.4f)),\n    Tensor(T(0.5f, 0.4f, -0.2f, -0.1f))))\nval gradInput = graph.backward(T(Tensor(T(0.1f, 0.2f, -0.3f, -0.4f)),\n    Tensor(T(0.5f, 0.4f, -0.2f, -0.1f))),\n    Tensor(T(0.1f, 0.2f, 0.3f, 0.4f)))\n\n\n println(output)\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.6\n0.6\n-0.5\n-0.5\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\n\n\n println(gradInput)\ngradInput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n {\n        2: 0.1\n           0.2\n           0.3\n           0.4\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\n        1: 0.1\n           0.2\n           0.3\n           0.4\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\n }\n\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\n\ninput1 = Input()\ninput2 = Input()\ncadd = CAddTable()([input1, input2])\nmodel = Model([input1, input2], [cadd])\noutput = model.forward([\n    np.array([0.1, 0.2, -0.3, -0.4]),\n    np.array([0.5, 0.4, -0.2, -0.1])])\n\n\n output\narray([ 0.60000002,  0.60000002, -0.5       , -0.5       ], dtype=float32)\n\ngradInput = model.backward([\n        np.array([0.1, 0.2, -0.3, -0.4]),\n        np.array([0.5, 0.4, -0.2, -0.1])\n    ],\n    np.array([0.1, 0.2, 0.3, 0.4])\n)\n\n\n gradInput\n[array([ 0.1       ,  0.2       ,  0.30000001,  0.40000001], dtype=float32),\n    array([ 0.1       ,  0.2       ,  0.30000001,  0.40000001], dtype=float32)]\n\n\n\n\n\n\nConcat\n\n\nScala:\n\n\nval module = Concat(dimension)\n\n\n\n\nPython:\n\n\nmodule = Concat(dimension)\n\n\n\n\nConcat is a container who concatenates the output of it's submodules along the\nprovided \ndimension\n: all submodules take the same inputs, and their output is\nconcatenated.\n\n\n                 +----Concat----+\n            +----\n  submodule1  -----+\n            |    |              |    |\n input -----+----\n  submodule2  -----+----\n output\n            |    |              |    |\n            +----\n  submodule3  -----+\n                 +--------------+\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval mlp = Concat(2)\nmlp.add(Linear(3,2))\nmlp.add(Linear(3,4))\n\nprintln(mlp.forward(Tensor(2, 3).rand()))\n\n\n\n\nGives the output,\n\n\n-0.17087375 0.12954286  0.15685591  -0.027277306    0.38549712  -0.20375136\n-0.9473443  0.030516684 0.23380546  0.625985    -0.031360716    0.40449825\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x6]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmlp = Concat(2)\nmlp.add(Linear(3,2))\nmlp.add(Linear(3,4))\nprint(mlp.forward(np.array([[1, 2, 3], [1, 2, 3]])))\n\n\n\n\nGives the output,\n\n\n[array([\n[-0.71994132,  2.17439198, -1.46522939,  0.64588934,  2.61534023, -2.39528942],\n[-0.89125222,  5.49583197, -2.8865242 ,  1.44914722,  5.26639175, -6.26586771]]\n      dtype=float32)]\n\n\n\n\n\nParallelTable\n\n\nScala:\n\n\nval module = ParallelTable()\n\n\n\n\nPython:\n\n\nmodule = ParallelTable()\n\n\n\n\nIt is a container module that applies the i-th member module to the i-th\n input, and outputs an output in the form of Table\n\n\n+----------+         +-----------+\n| {input1, +---------\n {member1, |\n|          |         |           |\n|  input2, +---------\n  member2, |\n|          |         |           |\n|  input3} +---------\n  member3} |\n+----------+         +-----------+\n\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = ParallelTable()\nval log = Log()\nval exp = Exp()\nmodule.add(log)\nmodule.add(exp)\nval input1 = Tensor(3, 3).rand(0, 1)\nval input2 = Tensor(3).rand(0, 1)\nval input = T(1 -\n input1, 2 -\n input2)\n\n print(module.forward(input))\n {\n        2: 2.6996834\n           2.0741253\n           1.0625387\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n        1: -1.073425    -0.6672964      -1.8160943\n           -0.54094607  -1.3029919      -1.7064717\n           -0.66175103  -0.08288143     -1.1840979\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n }\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\n\nmodule = ParallelTable()\nlog = Log()\nexp = Exp()\nmodule.add(log)\nmodule.add(exp)\ninput1 = np.random.rand(3,3)\ninput2 = np.random.rand(3)\n\nmodule.forward([input1, input2])\n[array([[-1.27472472, -2.18216252, -0.60752904],\n        [-2.76213861, -1.77966928, -0.13652121],\n        [-1.47725129, -0.03578046, -1.37736678]], dtype=float32),\n array([ 1.10634041,  1.46384597,  1.96525407], dtype=float32)]\n\n\n\n\nConcatTable\n\n\nScala:\n\n\nval module = ConcatTable()\n\n\n\n\nPython:\n\n\nmodule = ConcatTable()\n\n\n\n\nConcateTable is a container module like Concate. Applies an input\nto each member module, input can be a tensor or a table.\n\n\nConcateTable usually works with CAddTable and CMulTable to\n implement element wise add/multiply on outputs of two modules.\n\n\n                   +-----------+\n             +----\n {member1, |\n+-------+    |    |           |\n| input +----+----\n  member2, |\n+-------+    |    |           |\n   or        +----\n  member3} |\n {input}          +-----------+\n\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval mlp = ConcatTable()\nmlp.add(Linear(3, 2))\nmlp.add(Linear(3, 4))\n\n\n print(mlp.forward(Tensor(2, 3).rand()))\n\n{\n    2: -0.37111914  0.8542446   -0.362602   -0.75522065 \n       -0.28713673  0.6021913   -0.16525984 -0.44689763 \n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]\n    1: -0.79941726  0.8303885   \n       -0.8342782   0.89961016  \n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n }\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\n\nmlp = ConcatTable()\nmlp.add(Linear(3, 2))   \nmlp.add(Linear(3, 4))\n\n mlp.forward(np.array([[1, 2, 3], [1, 2, 3]]))\nout: [array([[ 1.16408789, -0.1508013 ],\n             [ 1.16408789, -0.1508013 ]], dtype=float32),\n      array([[-0.24672163, -0.56958938, -0.51390374,  0.64546645],\n             [-0.24672163, -0.56958938, -0.51390374,  0.64546645]], dtype=float32)]\n\n\n\n\n\nBottle\n\n\nScala:\n\n\nval model = Bottle(module, nInputDim, nOutputDim)\n\n\n\n\nPython:\n\n\nmodel = Bottle(module, nInputDim, nOutputDim)\n\n\n\n\nBottle allows varying dimensionality input to be forwarded through any module that accepts input of nInputDim dimensions, and generates output of nOutputDim dimensions.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = Bottle(Linear(3, 2), 2, 2)\nval input = Tensor(2, 3, 3).rand()\n\nscala\n print(input)\n(1,.,.) =\n0.7843752   0.17286697  0.20767091  \n0.8594811   0.9100018   0.8448141   \n0.7683892   0.36661968  0.76637685  \n\n(2,.,.) =\n0.7163263   0.083962396 0.81222403  \n0.7947034   0.09976136  0.114404656 \n0.14890474  0.43289232  0.1489096   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3x3] \n\nval output = model.forward(input)\n\nscala\n print(output)\n(1,.,.) =\n-0.31146684 0.40719786  \n-0.51778656 0.58715886  \n-0.51676923 0.4027511   \n\n(2,.,.) =\n-0.5498678  0.29658738  \n-0.280177   0.39901164  \n-0.2387946  0.24809375  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x2]\n\n\n\n\nPython example:\n\n\nmodel = Bottle(Linear(3, 2), 2, 2)\n\ninput = np.random.randn(2, 3, 3)\noutput = model.forward(input)\n\n\n print(input)\n[[[ 0.42370589 -1.7938942   0.56666373]\n  [-1.78501381  0.55676471 -0.50150367]\n  [-1.59262182  0.82079469  1.1873599 ]]\n\n [[ 0.95799792 -0.71447244  1.05344083]\n  [-0.07838376 -0.88780484 -1.80491177]\n  [ 0.99996222  1.39876002 -0.16326094]]]\n\n print(output)\n[[[ 0.26298434  0.74947536]\n  [-1.24375117 -0.33148435]\n  [-1.35218966  0.17042145]]\n\n [[ 0.08041853  0.91245329]\n  [-0.08317742 -0.13909879]\n  [-0.52287608  0.3667658 ]]]\n\n\n\n\nMapTable\n\n\nScala:\n\n\nval mod = MapTable(module=null)\n\n\n\n\nPython:\n\n\nmod = MapTable(module=None)\n\n\n\n\nThis class is a container for a single module which will be applied\nto all input elements. The member module is cloned as necessary to\nprocess all input elements.\n\n\nmodule\n a member module.  \n\n\n+----------+         +-----------+\n| {input1, +---------\n {member,  |\n|          |         |           |\n|  input2, +---------\n  clone,   |\n|          |         |           |\n|  input3} +---------\n  clone}   |\n+----------+         +-----------+\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T \n\nval map = MapTable()\nmap.add(Linear(10, 3))\nval input = T(\n      Tensor(10).randn(),\n      Tensor(10).randn())\n\n print(map.forward(input))\n{\n    2: 0.2444828\n       -1.1700082\n       0.15887381\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n    1: 0.06696482\n       0.18692614\n       -1.432079\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n }\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\n\nmap = MapTable()\nmap.add(Linear(10, 3))\ninput = [np.random.rand(10), np.random.rand(10)]\n\nmap.forward(input)\n[array([ 0.69586945, -0.70547599, -0.05802459], dtype=float32),\n array([ 0.47995114, -0.67459631, -0.52500772], dtype=float32)]\n\n\n\n\nContainer\n\n\nContainer is a subclass of abstract class AbstractModule, which\ndeclares methods defined in all containers. A container usually\ncontains some other modules in the \nmodules\n variable. It overrides\nmany module methods such that calls are propagated to the contained\nmodules.", 
            "title": "Containers"
        }, 
        {
            "location": "/APIGuide/Layers/Containers/#sequential", 
            "text": "Scala:  val module = Sequential()  Python:  seq = Sequential()  Sequential provides a means to plug layers together\nin a feed-forward fully connected manner.  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nimport com.intel.analytics.bigdl.nn.{Sequential, Linear}\n\nval module = Sequential()\nmodule.add(Linear(10, 25))\nmodule.add(Linear(25, 10))\n\nval input = Tensor(10).range(1, 10, 1)\nval gradOutput = Tensor(10).range(1, 10, 1)\n\nval output = module.forward(input).toTensor\nval gradInput = module.backward(input, gradOutput).toTensor\n\nprintln(output)\nprintln(gradInput)  Gives the output,  -2.3750305\n2.4512818\n1.6998017\n-0.47432393\n4.3048754\n-0.044168986\n-1.1643536\n0.60341483\n2.0216258\n2.1190155\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 10]  Gives the gradInput,  2.593382\n-1.4137214\n-1.8271983\n1.229643\n0.51384985\n1.509845\n2.9537349\n1.088281\n0.2618509\n1.4840821\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 10]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nseq = Sequential()\nseq.add(Linear(10, 25))\nseq.add(Linear(25, 10))\n\ninput = np.arange(1, 11, 1).astype( float32 )\ninput = input.reshape(1, 10)\n\noutput = seq.forward(input)\nprint output\n\ngradOutput = np.arange(1, 11, 1).astype( float32 )\ngradOutput = gradOutput.reshape(1, 10)\n\ngradInput = seq.backward(input, gradOutput)\nprint gradInput  Gives the output,  [array([[ 1.08462083, -2.03257799, -0.5400058 ,  0.27452484,  1.85562158,\n         1.64338267,  2.45694995,  1.70170391, -2.12998056, -1.28924525]], dtype=float32)]  Gives the gradInput,  \n[array([[ 1.72007763,  1.64403224,  2.52977395, -1.00021958,  0.1134415 ,\n         2.06711197,  2.29631734, -3.39587498,  1.01093054, -0.54482007]], dtype=float32)]", 
            "title": "Sequential"
        }, 
        {
            "location": "/APIGuide/Layers/Containers/#graph", 
            "text": "Scala:  val graph = Graph(Array(Node), Array(Node))  Python:  model = Model([Node], [Node])  A graph container. Each node can have multiple inputs. The output of the node should be a tensor.\n The output tensor can be connected to multiple nodes. So the module in each node can have a\n tensor or table input, and should have a tensor output.  The graph container can have multiple inputs and multiple outputs. If there's one input, the\n input data fed to the graph module should be a tensor. If there're multiple inputs, the input\n data fed to the graph module should be a table, which is actually an sequence of tensor. The\n order of the input tensors should be same with the order of the input nodes. This is also\n applied to the gradient from the module in the back propagation.  All of the input modules must accept a tensor input. If your input module accept multiple\n tensors as input, you should add some  Input layer  before\n it as input nodes and connect the output of the Input modules to that module.  If there's one output, the module output is a tensor. If there're multiple outputs, the module\n output is a table, which is actually an sequence of tensor. The order of the output tensors is\n same with the order of the output modules. This is also applied to the gradient passed to the\n module in the back propagation.  All inputs should be able to connect to outputs through some paths in the graph. It is\n allowed that some successors of the inputs node are not connect to outputs. If so, these nodes\n will be excluded in the computation.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\n\nval input1 = Input()\nval input2 = Input()\nval cadd = CAddTable().inputs(input1, input2)\nval graph = Graph(Array(input1, input2), cadd)\n\nval output = graph.forward(T(Tensor(T(0.1f, 0.2f, -0.3f, -0.4f)),\n    Tensor(T(0.5f, 0.4f, -0.2f, -0.1f))))\nval gradInput = graph.backward(T(Tensor(T(0.1f, 0.2f, -0.3f, -0.4f)),\n    Tensor(T(0.5f, 0.4f, -0.2f, -0.1f))),\n    Tensor(T(0.1f, 0.2f, 0.3f, 0.4f)))  println(output)\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.6\n0.6\n-0.5\n-0.5\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]  println(gradInput)\ngradInput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n {\n        2: 0.1\n           0.2\n           0.3\n           0.4\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\n        1: 0.1\n           0.2\n           0.3\n           0.4\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\n }  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\n\ninput1 = Input()\ninput2 = Input()\ncadd = CAddTable()([input1, input2])\nmodel = Model([input1, input2], [cadd])\noutput = model.forward([\n    np.array([0.1, 0.2, -0.3, -0.4]),\n    np.array([0.5, 0.4, -0.2, -0.1])])  output\narray([ 0.60000002,  0.60000002, -0.5       , -0.5       ], dtype=float32)\n\ngradInput = model.backward([\n        np.array([0.1, 0.2, -0.3, -0.4]),\n        np.array([0.5, 0.4, -0.2, -0.1])\n    ],\n    np.array([0.1, 0.2, 0.3, 0.4])\n)  gradInput\n[array([ 0.1       ,  0.2       ,  0.30000001,  0.40000001], dtype=float32),\n    array([ 0.1       ,  0.2       ,  0.30000001,  0.40000001], dtype=float32)]", 
            "title": "Graph"
        }, 
        {
            "location": "/APIGuide/Layers/Containers/#concat", 
            "text": "Scala:  val module = Concat(dimension)  Python:  module = Concat(dimension)  Concat is a container who concatenates the output of it's submodules along the\nprovided  dimension : all submodules take the same inputs, and their output is\nconcatenated.                   +----Concat----+\n            +----   submodule1  -----+\n            |    |              |    |\n input -----+----   submodule2  -----+----  output\n            |    |              |    |\n            +----   submodule3  -----+\n                 +--------------+  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval mlp = Concat(2)\nmlp.add(Linear(3,2))\nmlp.add(Linear(3,4))\n\nprintln(mlp.forward(Tensor(2, 3).rand()))  Gives the output,  -0.17087375 0.12954286  0.15685591  -0.027277306    0.38549712  -0.20375136\n-0.9473443  0.030516684 0.23380546  0.625985    -0.031360716    0.40449825\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x6]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmlp = Concat(2)\nmlp.add(Linear(3,2))\nmlp.add(Linear(3,4))\nprint(mlp.forward(np.array([[1, 2, 3], [1, 2, 3]])))  Gives the output,  [array([\n[-0.71994132,  2.17439198, -1.46522939,  0.64588934,  2.61534023, -2.39528942],\n[-0.89125222,  5.49583197, -2.8865242 ,  1.44914722,  5.26639175, -6.26586771]]\n      dtype=float32)]", 
            "title": "Concat"
        }, 
        {
            "location": "/APIGuide/Layers/Containers/#paralleltable", 
            "text": "Scala:  val module = ParallelTable()  Python:  module = ParallelTable()  It is a container module that applies the i-th member module to the i-th\n input, and outputs an output in the form of Table  +----------+         +-----------+\n| {input1, +---------  {member1, |\n|          |         |           |\n|  input2, +---------   member2, |\n|          |         |           |\n|  input3} +---------   member3} |\n+----------+         +-----------+  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = ParallelTable()\nval log = Log()\nval exp = Exp()\nmodule.add(log)\nmodule.add(exp)\nval input1 = Tensor(3, 3).rand(0, 1)\nval input2 = Tensor(3).rand(0, 1)\nval input = T(1 -  input1, 2 -  input2)  print(module.forward(input))\n {\n        2: 2.6996834\n           2.0741253\n           1.0625387\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n        1: -1.073425    -0.6672964      -1.8160943\n           -0.54094607  -1.3029919      -1.7064717\n           -0.66175103  -0.08288143     -1.1840979\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n }  Python example:  from bigdl.nn.layer import *\n\nmodule = ParallelTable()\nlog = Log()\nexp = Exp()\nmodule.add(log)\nmodule.add(exp)\ninput1 = np.random.rand(3,3)\ninput2 = np.random.rand(3) module.forward([input1, input2])\n[array([[-1.27472472, -2.18216252, -0.60752904],\n        [-2.76213861, -1.77966928, -0.13652121],\n        [-1.47725129, -0.03578046, -1.37736678]], dtype=float32),\n array([ 1.10634041,  1.46384597,  1.96525407], dtype=float32)]", 
            "title": "ParallelTable"
        }, 
        {
            "location": "/APIGuide/Layers/Containers/#concattable", 
            "text": "Scala:  val module = ConcatTable()  Python:  module = ConcatTable()  ConcateTable is a container module like Concate. Applies an input\nto each member module, input can be a tensor or a table.  ConcateTable usually works with CAddTable and CMulTable to\n implement element wise add/multiply on outputs of two modules.                     +-----------+\n             +----  {member1, |\n+-------+    |    |           |\n| input +----+----   member2, |\n+-------+    |    |           |\n   or        +----   member3} |\n {input}          +-----------+  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval mlp = ConcatTable()\nmlp.add(Linear(3, 2))\nmlp.add(Linear(3, 4))  print(mlp.forward(Tensor(2, 3).rand()))\n\n{\n    2: -0.37111914  0.8542446   -0.362602   -0.75522065 \n       -0.28713673  0.6021913   -0.16525984 -0.44689763 \n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]\n    1: -0.79941726  0.8303885   \n       -0.8342782   0.89961016  \n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n }  Python example:  from bigdl.nn.layer import *\n\nmlp = ConcatTable()\nmlp.add(Linear(3, 2))   \nmlp.add(Linear(3, 4))  mlp.forward(np.array([[1, 2, 3], [1, 2, 3]]))\nout: [array([[ 1.16408789, -0.1508013 ],\n             [ 1.16408789, -0.1508013 ]], dtype=float32),\n      array([[-0.24672163, -0.56958938, -0.51390374,  0.64546645],\n             [-0.24672163, -0.56958938, -0.51390374,  0.64546645]], dtype=float32)]", 
            "title": "ConcatTable"
        }, 
        {
            "location": "/APIGuide/Layers/Containers/#bottle", 
            "text": "Scala:  val model = Bottle(module, nInputDim, nOutputDim)  Python:  model = Bottle(module, nInputDim, nOutputDim)  Bottle allows varying dimensionality input to be forwarded through any module that accepts input of nInputDim dimensions, and generates output of nOutputDim dimensions.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = Bottle(Linear(3, 2), 2, 2)\nval input = Tensor(2, 3, 3).rand()\n\nscala  print(input)\n(1,.,.) =\n0.7843752   0.17286697  0.20767091  \n0.8594811   0.9100018   0.8448141   \n0.7683892   0.36661968  0.76637685  \n\n(2,.,.) =\n0.7163263   0.083962396 0.81222403  \n0.7947034   0.09976136  0.114404656 \n0.14890474  0.43289232  0.1489096   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3x3] \n\nval output = model.forward(input)\n\nscala  print(output)\n(1,.,.) =\n-0.31146684 0.40719786  \n-0.51778656 0.58715886  \n-0.51676923 0.4027511   \n\n(2,.,.) =\n-0.5498678  0.29658738  \n-0.280177   0.39901164  \n-0.2387946  0.24809375  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x2]  Python example:  model = Bottle(Linear(3, 2), 2, 2)\n\ninput = np.random.randn(2, 3, 3)\noutput = model.forward(input)  print(input)\n[[[ 0.42370589 -1.7938942   0.56666373]\n  [-1.78501381  0.55676471 -0.50150367]\n  [-1.59262182  0.82079469  1.1873599 ]]\n\n [[ 0.95799792 -0.71447244  1.05344083]\n  [-0.07838376 -0.88780484 -1.80491177]\n  [ 0.99996222  1.39876002 -0.16326094]]]  print(output)\n[[[ 0.26298434  0.74947536]\n  [-1.24375117 -0.33148435]\n  [-1.35218966  0.17042145]]\n\n [[ 0.08041853  0.91245329]\n  [-0.08317742 -0.13909879]\n  [-0.52287608  0.3667658 ]]]", 
            "title": "Bottle"
        }, 
        {
            "location": "/APIGuide/Layers/Containers/#maptable", 
            "text": "Scala:  val mod = MapTable(module=null)  Python:  mod = MapTable(module=None)  This class is a container for a single module which will be applied\nto all input elements. The member module is cloned as necessary to\nprocess all input elements.  module  a member module.    +----------+         +-----------+\n| {input1, +---------  {member,  |\n|          |         |           |\n|  input2, +---------   clone,   |\n|          |         |           |\n|  input3} +---------   clone}   |\n+----------+         +-----------+  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T \n\nval map = MapTable()\nmap.add(Linear(10, 3))\nval input = T(\n      Tensor(10).randn(),\n      Tensor(10).randn())  print(map.forward(input))\n{\n    2: 0.2444828\n       -1.1700082\n       0.15887381\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n    1: 0.06696482\n       0.18692614\n       -1.432079\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n }  Python example:  from bigdl.nn.layer import *\n\nmap = MapTable()\nmap.add(Linear(10, 3))\ninput = [np.random.rand(10), np.random.rand(10)] map.forward(input)\n[array([ 0.69586945, -0.70547599, -0.05802459], dtype=float32),\n array([ 0.47995114, -0.67459631, -0.52500772], dtype=float32)]", 
            "title": "MapTable"
        }, 
        {
            "location": "/APIGuide/Layers/Containers/#container", 
            "text": "Container is a subclass of abstract class AbstractModule, which\ndeclares methods defined in all containers. A container usually\ncontains some other modules in the  modules  variable. It overrides\nmany module methods such that calls are propagated to the contained\nmodules.", 
            "title": "Container"
        }, 
        {
            "location": "/APIGuide/Layers/Simple-Layers/", 
            "text": "Linear\n\n\nScala:\n\n\nval module = Linear(\n  inputSize,\n  outputSize,\n  withBias = true,\n  wRegularizer = null,\n  bRegularizer = null,\n  initWeight = null,\n  initBias = null,\n  initGradWeight = null,\n  initGradBias = null)\n\n\n\n\nPython:\n\n\nmodule = Linear(\n  input_size,\n  output_size,\n  init_method=\ndefault\n,\n  with_bias=True,\n  wRegularizer=None,\n  bRegularizer=None,\n  init_weight=None,\n  init_bias=None,\n  init_grad_weight=None,\n  init_grad_bias=None)\n\n\n\n\nThe \nLinear\n module applies a linear transformation to the input data,\ni.e. \ny = Wx + b\n. The \ninput\n given in \nforward(input)\n must be either\na vector (1D tensor) or matrix (2D tensor). If the input is a vector, it must\nhave the size of \ninputSize\n. If it is a matrix, then each row is assumed to be\nan input sample of given batch (the number of rows means the batch size and\nthe number of columns should be equal to the \ninputSize\n).\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = Linear(3, 5)\n\nprintln(module.forward(Tensor.range(1, 3, 1)))\n\n\n\n\nGives the output,\n\n\ncom.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.79338956\n-2.3417668\n-2.7557678\n-0.07507719\n-1.009765\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Linear(3, 5)\n\nprint(module.forward(np.arange(1, 4, 1)))\n\n\n\n\nGives the output,\n\n\n[array([ 0.31657887, -1.11062765, -1.16235781, -0.67723978,  0.74650359], dtype=float32)]\n\n\n\n\n\n\nReverse\n\n\nScala:\n\n\nval m = Reverse(dim = 1, isInplace = false)\n\n\n\n\nPython:\n\n\nm = Reverse(dimension=1)\n\n\n\n\nReverse the input w.r.t given dimension.\n The input can be a Tensor or Table. \nDimension\n is one-based index.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\ndef randomn(): Float = RandomGenerator.RNG.uniform(0, 1)\nval input = Tensor(2, 3)\ninput.apply1(x =\n randomn().toFloat)\nprintln(\ninput:\n)\nprintln(input)\nval layer = new Reverse(1)\nprintln(\noutput:\n)\nprintln(layer.forward(input))\n\n\n\n\ninput:\n0.17271264898590744 0.019822501810267568    0.18107921979390085 \n0.4003877849318087  0.5567442716564983  0.14120339532382786 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\noutput:\n0.4003877849318087  0.5567442716564983  0.14120339532382786 \n0.17271264898590744 0.019822501810267568    0.18107921979390085 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\n\nPython example:\n\n\ninput = np.random.random((2,3))\nlayer = Reverse(1)\nprint(\ninput:\n)\nprint(input)\nprint(\noutput:\n)\nprint(layer.forward(input))\n\n\n\n\ncreating: createReverse\ninput:\n[[ 0.89089717  0.07629756  0.30863782]\n [ 0.16066851  0.06421963  0.96719367]]\noutput:\n[[ 0.16066851  0.06421963  0.96719366]\n [ 0.89089715  0.07629756  0.30863783]]\n\n\n\n\n\n\n\n\nReshape\n\n\nScala:\n\n\nval reshape = Reshape(size, batchMode)\n\n\n\n\nPython:\n\n\nreshape = Reshape(size, batch_mode)\n\n\n\n\nThe \nforward(input)\n reshape the input tensor into \nsize(0) * size(1) * ...\n tensor,\ntaking the elements row-wise.\n\n\nparameters:\n\n \nsize\n the size after reshape\n\n \nbatchMode\n It is a optional argument. If it is set to \nSome(true)\n,\n                  the first dimension of input is considered as batch dimension,\n                  and thus keep this dimension size fixed. This is necessary\n                  when dealing with batch sizes of one. When set to \nSome(false)\n,\n                  it forces the entire input (including the first dimension) to be reshaped\n                  to the input size. Default is \nNone\n, which means the module considers\n                  inputs with more elements than the product of provided sizes (\nsize(0) *\n                  size(1) * ..\n) to be batches, otherwise in no batch mode.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval reshape = Reshape(Array(3, 2))\nval input = Tensor(2, 2, 3).rand()\nval output = reshape.forward(input)\n-\n print(output.size().toList)      \nList(2, 3, 2)\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nreshape =  Reshape([3, 2])\ninput = np.random.rand(2, 2, 3)\noutput = reshape.forward(input)\n-\n print output[0].shape\n(2, 3, 2)\n\n\n\n\n\n\nIndex\n\n\nScala:\n\n\nval model = Index(dimension)\n\n\n\n\nPython:\n\n\nmodel = Index(dimension)\n\n\n\n\nApplies the Tensor index operation along the given dimension.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\n\nval input1 = Tensor(3).rand()\nval input2 = Tensor(4)\ninput2(Array(1)) = 1.0f\ninput2(Array(2)) = 2.0f\ninput2(Array(3)) = 2.0f\ninput2(Array(4)) = 3.0f\n\nval input = T(input1, input2)\nval model = Index(1)\nval output = model.forward(input)\n\nscala\n print(input)\n {\n    2: 1.0\n       2.0\n       2.0\n       3.0\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 4]\n    1: 0.124325536\n       0.8768922\n       0.6378146\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n }\nscala\n print(output)\n0.124325536\n0.8768922\n0.8768922\n0.6378146\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\ninput1 = np.random.randn(3)\ninput2 = np.array([1, 2, 2, 3])\ninput = [input1, input2]\n\nmodel = Index(1)\noutput = model.forward(input)\n\n\n print(input)\n[array([-0.45804847, -0.20176707,  0.50963248]), array([1, 2, 2, 3])]\n\n\n print(output)\n[-0.45804846 -0.20176707 -0.20176707  0.50963247]\n\n\n\n\n\n\nIdentity\n\n\nScala:\n\n\nval identity = Identity()\n\n\n\n\nPython:\n\n\nidentity = Identity()\n\n\n\n\nIdentity just return input as the output which is useful in same parallel container to get an origin input\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval identity = Identity()\n\nval input = Tensor(3, 3).rand()\n\n print(input)\n0.043098174 0.1035049   0.7522675   \n0.9999951   0.794151    0.18344955  \n0.9419861   0.02398399  0.6228095   \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n\n\n print(identity.forward(input))\n0.043098174 0.1035049   0.7522675   \n0.9999951   0.794151    0.18344955  \n0.9419861   0.02398399  0.6228095   \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nidentity = Identity()\n\n  identity.forward(np.array([[1, 2, 3], [4, 5, 6]]))\n[array([[ 1.,  2.,  3.],\n       [ 4.,  5.,  6.]], dtype=float32)]\n\n\n\n\n\n\n\nNarrow\n\n\nScala:\n\n\nval layer = Narrow(dimension, offset, length = 1)\n\n\n\n\nPython:\n\n\nlayer = Narrow(dimension, offset, length=1)\n\n\n\n\nNarrow is an application of narrow operation in a module.\nThe module further supports a negative length in order to handle inputs with an unknown size.\n\n\nParameters:\n\n \ndimension\n narrow along this dimension\n\n \noffset\n the start index on the given dimension\n* \nlength\n length to narrow, default value is 1\n\n\nScala Example\n\n\nimport com.intel.analytics.bigdl.nn.Narrow\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval layer = Narrow(2, 2)\nval input = Tensor(T(\n  T(-1f, 2f, 3f),\n  T(-2f, 3f, 4f),\n  T(-3f, 4f, 5f)\n))\n\nval gradOutput = Tensor(T(3f, 4f, 5f))\n\nval output = layer.forward(input)\n2.0\n3.0\n4.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x1]\n\nval grad = layer.backward(input, gradOutput)\n0.0 3.0 0.0\n0.0 4.0 0.0\n0.0 5.0 0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\nPython Example\n\n\nlayer = Narrow(2, 2)\ninput = np.array([\n  [-1.0, 2.0, 3.0],\n  [-2.0, 3.0, 4.0],\n  [-3.0, 4.0, 5.0]\n])\n\ngradOutput = np.array([3.0, 4.0, 5.0])\n\noutput = layer.forward(input)\ngrad = layer.backward(input, gradOutput)\n\nprint output\n[[ 2.]\n [ 3.]\n [ 4.]]\n\nprint grad\n[[ 0.  3.  0.]\n [ 0.  4.  0.]\n [ 0.  5.  0.]]\n\n\n\n\n\n\nUnsqueeze\n\n\nScala:\n\n\nval layer = Unsqueeze(dim)\n\n\n\n\nPython:\n\n\nlayer = Unsqueeze(dim)\n\n\n\n\nInsert singleton dim (i.e., dimension 1) at position pos. For an input with \ndim = input.dim()\n,\nthere are \ndim + 1\n possible positions to insert the singleton dimension. The dim starts from 1.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval layer = Unsqueeze(2)\nval input = Tensor(2, 2, 2).rand\nval gradOutput = Tensor(2, 1, 2, 2).rand\nval output = layer.forward(input)\nval gradInput = layer.backward(input, gradOutput)\n\n\n println(input.size)\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2]\n\n\n println(gradOutput.size)\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x2x2]\n\n\n println(output.size)\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x2x2]\n\n\n println(gradInput.size)\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nlayer = Unsqueeze(2)\ninput = np.random.uniform(0, 1, (2, 2, 2)).astype(\nfloat32\n)\ngradOutput = np.random.uniform(0, 1, (2, 1, 2, 2)).astype(\nfloat32\n)\n\noutput = layer.forward(input)\ngradInput = layer.backward(input, gradOutput)\n\n\n output\n[array([[[[ 0.97488612,  0.43463323],\n          [ 0.39069486,  0.0949123 ]]],\n\n\n        [[[ 0.19310953,  0.73574477],\n          [ 0.95347691,  0.37380624]]]], dtype=float32)]\n\n gradInput\n[array([[[ 0.9995622 ,  0.69787127],\n         [ 0.65975296,  0.87002522]],\n\n        [[ 0.76349133,  0.96734989],\n         [ 0.88068211,  0.07284366]]], dtype=float32)]\n\n\n\n\n\n\nSqueeze\n\n\nScala:\n\n\nval module = Squeeze(dims=null, numInputDims=Int.MinValue)\n\n\n\n\nPython:\n\n\nmodule = Squeeze(dims, numInputDims=-2147483648)\n\n\n\n\nDelete all singleton dimensions or a specific singleton dimension.\n\n\n\n\ndims\n Optional. If this dimension is singleton dimension, it will be deleted.\n           The first index starts from 1. Default: delete all dimensions.\n\n\nnum_input_dims\n Optional. If in a batch model, set to the inputDims.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = Squeeze(2)\n\n print(layer.forward(Tensor(2, 1, 3).rand()))\n0.43709445  0.42752415  0.43069172  \n0.67029667  0.95641375  0.28823504  \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\n\nlayer = Squeeze(2)\n\nlayer.forward(np.array([[[1, 2, 3]], [[1, 2, 3]]]))\nout: array([[ 1.,  2.,  3.],\n            [ 1.,  2.,  3.]], dtype=float32)\n\n\n\n\n\n\n\nSelect\n\n\nScala:\n\n\nval layer = Select(dim, index)\n\n\n\n\nPython:\n\n\nlayer = Select(dim, index)\n\n\n\n\nA Simple layer selecting an index of the input tensor in the given dimension.\nPlease note that the index and dimension start from 1. In collaborative filtering, it can used together with LookupTable to create embeddings for users or items.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = Select(1, 2)\nlayer.forward(Tensor(T(\n  T(1.0f, 2.0f, 3.0f),\n  T(4.0f, 5.0f, 6.0f),\n  T(7.0f, 8.0f, 9.0f)\n)))\n\nlayer.backward(Tensor(T(\n  T(1.0f, 2.0f, 3.0f),\n  T(4.0f, 5.0f, 6.0f),\n  T(7.0f, 8.0f, 9.0f)\n)), Tensor(T(0.1f, 0.2f, 0.3f)))\n\n\n\n\nGives the output,\n\n\n4.0\n5.0\n6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n\n0.0     0.0     0.0\n0.1     0.2     0.3\n0.0     0.0     0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import Select\nimport numpy as np\n\nlayer = Select(1, 2)\nlayer.forward(np.array([\n  [1.0, 2.0, 3.0],\n  [4.0, 5.0, 6.0],\n  [7.0, 8.0, 9.0]\n]))\nlayer.backward(np.array([\n  [1.0, 2.0, 3.0],\n  [4.0, 5.0, 6.0],\n  [7.0, 8.0, 9.0]\n]), np.array([0.1, 0.2, 0.3]))\n\n\n\n\nGives the output,\n\n\narray([ 4.,  5.,  6.], dtype=float32)\n\narray([[ 0.        ,  0.        ,  0.        ],\n       [ 0.1       ,  0.2       ,  0.30000001],\n       [ 0.        ,  0.        ,  0.        ]], dtype=float32)\n\n\n\n\n\n\nMaskedSelect\n\n\nScala:\n\n\nval module = MaskedSelect()\n\n\n\n\nPython:\n\n\nmodule = MaskedSelect()\n\n\n\n\nPerforms a torch.MaskedSelect on a Tensor. The mask is supplied as a tabular argument\n with the input on the forward and backward passes.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport scala.util.Random\n\n\nval layer = MaskedSelect()\nval input1 = Tensor(2, 2).apply1(e =\n Random.nextFloat())\nval mask = Tensor(2, 2)\nmask(Array(1, 1)) = 1\nmask(Array(1, 2)) = 0\nmask(Array(2, 1)) = 0\nmask(Array(2, 2)) = 1\nval input = T()\ninput(1.0) = input1\ninput(2.0) = mask\n\n print(layer.forward(input))\n0.2577119\n0.5061479\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\n\nlayer = MaskedSelect()\ninput1 = np.random.rand(2,2)\nmask = np.array([[1,0], [0, 1]])\n\nlayer.forward([input1, mask])\narray([ 0.1525335 ,  0.05474588], dtype=float32)\n\n\n\n\n\n\nTranspose\n\n\nScala:\n\n\nval module = Transpose(permutations)\n\n\n\n\nPython:\n\n\nmodule = Transpose(permutations)\n\n\n\n\nConcat is a layer who transpose input along specified dimensions.\npermutations are dimension pairs that need to swap.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval input = Tensor(2, 3).rand()\nval layer = Transpose(Array((1, 2)))\nval output = layer.forward(input)\n\n\n input\n0.6653826   0.25350887  0.33434764  \n0.9618287   0.5484164   0.64844745  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\n\n output\n0.6653826   0.9618287   \n0.25350887  0.5484164   \n0.33434764  0.64844745  \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x2]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nlayer = Transpose([(1,2)])\ninput = np.array([[0.6653826, 0.25350887, 0.33434764], [0.9618287, 0.5484164, 0.64844745]])\noutput = layer.forward(input)\n\n\n output\n[array([[ 0.66538262,  0.96182871],\n       [ 0.25350887,  0.54841638],\n       [ 0.33434764,  0.64844745]], dtype=float32)]\n\n\n\n\n\n\n\nInferReshape\n\n\nScala:\n\n\nval layer = InferReshape(size, batchMode = false)\n\n\n\n\nPython:\n\n\nlayer = InferReshape(size, batch_mode=False)\n\n\n\n\nReshape the input tensor with automatic size inference support.\nPositive numbers in the \nsize\n argument are used to reshape the input to the\ncorresponding dimension size.\n\n\nThere are also two special values allowed in \nsize\n:\n\n\n\n\n0\n means keep the corresponding dimension size of the input unchanged.\n      i.e., if the 1st dimension size of the input is 2,\n      the 1st dimension size of output will be set as 2 as well.\n\n\n-1\n means infer this dimension size from other dimensions.\n      This dimension size is calculated by keeping the amount of output elements\n      consistent with the input.\n      Only one \n-1\n is allowable in \nsize\n.\n\n\n\n\nFor example,\n\n\n   Input tensor with size: (4, 5, 6, 7)\n   -\n InferReshape(Array(4, 0, 3, -1))\n   Output tensor with size: (4, 5, 3, 14)\n\n\n\n\nThe 1st and 3rd dim are set to given sizes, keep the 2nd dim unchanged,\nand inferred the last dim as 14.\n\n\nParameters:\n\n \nsize\n the target tensor size\n\n \nbatchMode\n whether in batch mode\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.InferReshape\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nval layer = InferReshape(Array(0, 3, -1))\nval input = Tensor(1, 2, 3).rand()\nval gradOutput = Tensor(1, 3, 2).rand()\n\nval output = layer.forward(input)\nval grad = layer.backward(input, gradOutput)\n\nprintln(output)\n(1,.,.) =\n0.8170822   0.40073588\n0.49389255  0.3782435\n0.42660004  0.5917206\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x2]\n\nprintln(grad)\n(1,.,.) =\n0.8294597   0.57101834  0.90910035\n0.32783163  0.30494633  0.7339092\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x3]\n\n\n\n\nPython example:\n\n\nlayer = InferReshape([0, 3, -1])\ninput = np.random.rand(1, 2, 3)\n\ngradOutput = np.random.rand(1, 3, 2)\n\noutput = layer.forward(input)\ngrad = layer.backward(input, gradOutput)\n\nprint output\n[[[ 0.68635464  0.21277553]\n  [ 0.13390459  0.65662414]\n  [ 0.1021723   0.92319047]]]\n\nprint grad\n[[[ 0.84927064  0.55205333  0.25077972]\n  [ 0.76105869  0.30828172  0.1237276 ]]]\n\n\n\n\n\n\nReplicate\n\n\nScala:\n\n\nval module = Replicate(\n  nFeatures,\n  dim = 1,\n  nDim = Int.MaxValue)\n\n\n\n\nPython:\n\n\nmodule = Replicate(\n  n_features,\n  dim=1,\n  n_dim=INTMAX)\n\n\n\n\nReplicate repeats input \nnFeatures\n times along its \ndim\n dimension\n\n\nNotice: No memory copy, it set the stride along the \ndim\n-th dimension to zero.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = Replicate(4, 1, 2)\n\nprintln(module.forward(Tensor.range(1, 6, 1).resize(1, 2, 3)))\n\n\n\n\nGives the output,\n\n\ncom.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n1.0 2.0 3.0\n4.0 5.0 6.0\n\n(1,2,.,.) =\n1.0 2.0 3.0\n4.0 5.0 6.0\n\n(1,3,.,.) =\n1.0 2.0 3.0\n4.0 5.0 6.0\n\n(1,4,.,.) =\n1.0 2.0 3.0\n4.0 5.0 6.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x4x2x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Replicate(4, 1, 2)\n\nprint(module.forward(np.arange(1, 7, 1).reshape(1, 2, 3)))\n\n\n\n\nGives the output, \n\n\n[array([[[[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.]],\n\n        [[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.]],\n\n        [[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.]],\n\n        [[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.]]]], dtype=float32)]\n\n\n\n\nView\n\n\nScala:\n\n\nval view = View(2, 8)\n\n\n\n\nor\n\n\nval view = View(Array(2, 8))\n\n\n\n\nPython:\n\n\nview = View([2, 8])\n\n\n\n\nThis module creates a new view of the input tensor using the sizes passed to the constructor.\nThe method setNumInputDims() allows to specify the expected number of dimensions of the inputs\nof the modules. This makes it possible to use minibatch inputs\nwhen using a size -1 for one of the dimensions.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.View\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval view = View(2, 8)\n\nval input = Tensor(4, 4).randn()\nval gradOutput = Tensor(2, 8).randn()\n\nval output = view.forward(input)\nval gradInput = view.backward(input, gradOutput)\n\n\n\n\nGives the output,\n\n\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.43037438     1.2982363       -1.4723133      -0.2602826      0.7178128       -1.8763185      0.88629466      0.8346704\n0.20963766      -0.9349786      1.0376515       1.3153045       1.5450214       1.084113        -0.29929757     -0.18356979\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8]\n\n\n\n\nGives the gradInput,\n\n\ngradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.7360089       0.9133299       0.40443268      -0.94965595\n0.80520976      -0.09671917     -0.5498001      -0.098691925\n-2.3119886      -0.8455147      0.75891125      1.2985301\n0.5023749       1.4983269       0.42038065      -1.7002305\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nview = View([2, 8])\n\ninput = np.random.uniform(0, 1, [4, 4]).astype(\nfloat32\n)\ngradOutput = np.random.uniform(0, 1, [2, 8]).astype(\nfloat32\n)\n\noutput = view.forward(input)\ngradInput = view.backward(input, gradOutput)\n\nprint output\nprint gradInput\n\n\n\n\n\n\nContiguous\n\n\nBe used to make input, gradOutput both contiguous\n\n\nScala:\n\n\nval contiguous = Contiguous()\n\n\n\n\nPython:\n\n\ncontiguous = Contiguous()\n\n\n\n\nUsed to make input, gradOutput both contiguous\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.Contiguous\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval input = Tensor(5).range(1, 5, 1)\nval contiguous = new Contiguous()\nval output = contiguous.forward(input)\nprintln(output)\n\nval gradOutput = Tensor(5).range(2, 6, 1)\nval gradInput = contiguous.backward(input, gradOutput)\nprintln(gradOutput)\n\n\n\n\nGives the output,\n\n\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0\n2.0\n3.0\n4.0\n5.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n\n\n\n\nGives the gradInput,\n\n\ngradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n2.0\n3.0\n4.0\n5.0\n6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ncontiguous = Contiguous()\n\ninput = np.arange(1, 6, 1).astype(\nfloat32\n)\ninput = input.reshape(1, 5)\n\noutput = contiguous.forward(input)\nprint output\n\ngradOutput = np.arange(2, 7, 1).astype(\nfloat32\n)\ngradOutput = gradOutput.reshape(1, 5)\n\ngradInput = contiguous.backward(input, gradOutput)\nprint gradInput\n\n\n\n\n\nGives the output,\n\n\n[array([[ 1.,  2.,  3.,  4.,  5.]], dtype=float32)]\n\n\n\n\nGives the gradInput,\n\n\n[array([[ 2.,  3.,  4.,  5.,  6.]], dtype=float32)]\n\n\n\n\nGaussianSampler\n\n\nTakes {mean, log_variance} as input and samples from the Gaussian distribution\n\n\nScala:\n\n\nval sampler = GaussianSampler()\n\n\n\n\nPython:\n\n\nsampler = GaussianSampler()\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.GaussianSampler\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.RandomGenerator._\nimport com.intel.analytics.bigdl.utils.T\n\nval input1 = Tensor[Float](2, 3).range(1, 6, 1)\nval input2 = Tensor[Float](2, 3).range(1, 12, 2)\nval input = T(input1, input2)\n\nval gradOutput = Tensor[Float](2, 3).range(2, 13, 2)\n\nval sampler = new GaussianSampler()\nval output = sampler.forward(input)\nprintln(output)\n\nval gradInput = sampler.backward(input, gradOutput)\nprintln(gradOutput)\n\n\n\n\nGives the output,\n\n\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] = \n4.507061    9.247583    -14.053247  \n34.783264   -70.69336   -333.97656  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\n\n\n\nGives the gradInput,\n\n\ngradInput: com.intel.analytics.bigdl.utils.Table = \n {\n    1: 2.0  4.0     6.0 \n       8.0  10.0    12.0    \n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    2: 3.5070612    14.495168   -51.159744  \n       123.13305    -378.4668   -2039.8594  \n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n }\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\nimport numpy as np\n\nsampler = GaussianSampler()\n\ninput1 = np.arange(1, 7, 1).astype(\nfloat32\n)\ninput2 = np.arange(1, 12, 2).astype(\nfloat32\n)\ninput2 = input1.reshape(2, 3)\ninput2 = input2.reshape(2, 3)\ninput = [input1, input2]\n\ngradOutput = np.arange(2, 13, 2).astype(\nfloat32\n)\ngradOutput = gradOutput.reshape(2, 3)\n\noutput = sampler.forward(input)\ngradInput = sampler.backward(input, gradOutput)\n\n\n\n\n\nGives the output,\n\n\n print output\n[[ 1.73362803  2.99371576  0.44359136]\n [ 0.04700017  2.85183263  3.04418468]]\n\n\n\n\nGives the gradInput,\n\n\n print gradInput\n[array([[  2.,   4.,   6.],\n       [  8.,  10.,  12.]], dtype=float32), array([[  0.73362803,   1.98743176,  -7.66922569],\n       [-15.81199932, -10.7408371 , -17.73489189]], dtype=float32)]\n\n\n\n\nMasking\n\n\nUse a mask value to skip timesteps for a sequence\n\n\nScala:\n\n\nval mask = Masking(0.0)\n\n\n\n\nPython:\n\n\nmask = Masking(0.0)\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.Masking\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval batchSize = 3\nval times = 5\nval features = 2\nval inputData = Array[Double](1.0, 1, 2, 2, 3, 3, 4, 4, 5, 5, -1, 1, 2, 2, 3, 3, 4, 4, 5, 5,\n  1, 1, -1, -1, 3, 3, 4, 4, 5, 5)\nval input = Tensor[Double](inputData, Array(batchSize, times, features))\nval gradOutput = Tensor[Double](Array(batchSize, times, features)).fill(1.0)\nval maskValue = -1\n\nval mask = Masking(maskValue)\nval output = mask.forward(input)\nprintln(output)\n\nval gradInput = mask.backward(input, gradOutput)\nprintln(gradOutput)\n\n\n\n\nGives the output,\n\n\noutput: = \n(1,.,.) =\n1.0 1.0 \n2.0 2.0 \n3.0 3.0 \n4.0 4.0 \n5.0 5.0 \n\n(2,.,.) =\n-1.0    1.0 \n2.0 2.0 \n3.0 3.0 \n4.0 4.0 \n5.0 5.0 \n\n(3,.,.) =\n1.0 1.0 \n0.0 0.0 \n3.0 3.0 \n4.0 4.0 \n5.0 5.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcD$sp of size 3x5x2]\n\n\n\n\nGives the gradInput,\n\n\ngradInput: \n(1,.,.) =\n1.0 1.0 \n1.0 1.0 \n1.0 1.0 \n1.0 1.0 \n1.0 1.0 \n\n(2,.,.) =\n1.0 1.0 \n1.0 1.0 \n1.0 1.0 \n1.0 1.0 \n1.0 1.0 \n\n(3,.,.) =\n1.0 1.0 \n0.0 0.0 \n1.0 1.0 \n1.0 1.0 \n1.0 1.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcD$sp of size 3x5x2]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.util.common import *\nimport numpy as np\n\nn_samples = 3\nn_timesteps = 7\nn_features = 2\nmask_value = -1.0\ninput = np.array([1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, -1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7,\n                 1, 1, 2, 2, 3, 3, -1, -1, 5, 5, 6, 6, 7, 7]).reshape(n_samples, n_timesteps, n_features)\ngradOutput = np.ones((n_samples, n_timesteps, n_features))\nmodel = Sequential()\nmodel.add(Masking(mask_value=mask_value))\n\noutput = model.forward(input)\ngradInput = model.backward(input, gradOutput)\n\n\n\n\n\nGives the output,\n\n\n print output\n[[[ 1.  1.]\n  [ 2.  2.]\n  [ 3.  3.]\n  [ 4.  4.]\n  [ 5.  5.]\n  [ 6.  6.]\n  [ 7.  7.]]\n\n [[-1.  1.]\n  [ 2.  2.]\n  [ 3.  3.]\n  [ 4.  4.]\n  [ 5.  5.]\n  [ 6.  6.]\n  [ 7.  7.]]\n\n [[ 1.  1.]\n  [ 2.  2.]\n  [ 3.  3.]\n  [ 0.  0.]\n  [ 5.  5.]\n  [ 6.  6.]\n  [ 7.  7.]]]\n\n\n\n\nGives the gradInput,\n\n\n print gradInput\n[[[ 1.  1.]\n  [ 1.  1.]\n  [ 1.  1.]\n  [ 1.  1.]\n  [ 1.  1.]\n  [ 1.  1.]\n  [ 1.  1.]]\n\n [[ 1.  1.]\n  [ 1.  1.]\n  [ 1.  1.]\n  [ 1.  1.]\n  [ 1.  1.]\n  [ 1.  1.]\n  [ 1.  1.]]\n\n [[ 1.  1.]\n  [ 1.  1.]\n  [ 1.  1.]\n  [ 0.  0.]\n  [ 1.  1.]\n  [ 1.  1.]\n  [ 1.  1.]]]\n\n\n\n\nMaxout ##\n\n\nScala:\n\n\nval maxout = Maxout(2, 5, 3,\n                    withBias = true,\n                    wRegularizer = null,\n                    bRegularizer = null,\n                    initWeight = null,\n                    initBias = null)\n\n\n\n\nPython:\n\n\nmaxout = Maxout(2, 5, 3,\n                 with_bias = True,\n                 w_regularizer=None,\n                 b_regularizer=None,\n                 init_weight=None,\n                 init_bias=None)\n\n\n\n\nMaxout layer select the element-wise maximum value of maxoutNumber Linear(inputSize, outputSize) layers\n\n\nparameters:\n\n \ninputSize\n the size the each input sample\n\n \noutputSize\n the size of the module output of each sample\n\n \nmaxoutNumber\n number of Linear layers to use\n\n \nwithBias\n whether use bias in Linear\n\n \nwRegularizer\n instance of \n[Regularizer]\n, applied to the input weights matrices.\n\n \nbRegularizer\n instance of [[Regularizer]] applied to the bias.\n\n \ninitWeight\n initial weight\n\n \ninitBias\n initial bias\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.Maxout\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval input_size = 2\nval batch_size = 3\nval output_size = 5\nval maxout_number = 3\n\nval input = Tensor[Float](batch_size, input_size).rand()\nval layer = Maxout[Float](input_size, output_size, maxout_number)\nval output = layer.forward(input)\nval gradOutput = Tensor[Float](batch_size, output_size)\nval gradInput = layer.backward(input, gradOutput)\n\n\n\n\nGives the output,\n\n\n0.19078568  0.94480306  0.25038794  0.8114594   0.7753764   \n0.2822805   0.9095781   0.2815394   0.82958585  0.784589    \n0.35188058  0.7629706   0.18096384  0.7100433   0.6680352   \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x5]\n\n\n\n\nGives the gradInput,\n\n\ngradInput: \n-0.18932924 0.9426162   \n-0.3118648  0.67255044  \n-0.31795382 1.944398    \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.util.common import *\nimport numpy as np\n\nval input_size = 2\nval batch_size = 3\nval output_size = 5\nval maxout_number = 3\n\nval input = Tensor[Float](batch_size, input_size).rand()\nval layer = Maxout[Float](input_size, output_size, maxout_number)\nval output = layer.forward(input)\nval gradOutput = Tensor[Float](batch_size, output_size).rand()\nval gradInput = layer.backward(input, gradOutput)\n\n\n\n\n\nGives the output,\n\n\n print output\n[[ 0.12344513  0.19081372  0.15130989  0.6341747   0.70982581]\n [ 0.04154952 -0.13281995  0.2648508   0.36793122  0.67043799]\n [ 0.41355255  0.17691913  0.15496807  0.5880245   0.74583203]]\n\n\n\n\nGives the gradInput,\n\n\n print gradInput\n[[ 0.53398496  0.01809531]\n [-0.20667852  0.4962275 ]\n [ 0.37912956  0.08742841]]\n\n\n\n\nCropping2D\n\n\nScala:\n\n\nval module = Cropping2D(heightCrop, widthCrop, dataFormat=DataFormat.NCHW)\n\n\n\n\nPython:\n\n\nm = Cropping2D(heightCrop, widthCrop, data_format=\nNCHW\n)\n\n\n\n\nCropping layer for 2D input (e.g. picture). It crops along spatial dimensions, i.e. width and height.\n    # Arguments\n        heightCrop: Array of length 2. How many units should be trimmed off at the\n                    beginning and end of the height dimension.\n        widthCrop: Array of length 2. How many units should be trimmed off at the\n                   beginning and end of the width dimension\n        dataFormat: DataFormat.NCHW or DataFormat.NHWC.\n    # Input shape\n        4D tensor with shape:\n        \n(samples, depth, first_axis_to_crop, second_axis_to_crop)\n\n    # Output shape\n        4D tensor with shape:\n        \n(samples, depth, first_cropped_axis, second_cropped_axis)\n\n\nScala example:\n\n\n\nscala \n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval module = Cropping2D(Array(1, 1), Array(1, 1))\nval input = Tensor(2, 1, 3, 3).rand()\nval output = module.forward(input)\n\n\n input\n(1,1,.,.) =\n0.024445634 0.73160243  0.1408418   \n0.95527077  0.51474196  0.89850646  \n0.3730063   0.40874788  0.7043526   \n\n(2,1,.,.) =\n0.8549189   0.5019415   0.96255547  \n0.83960533  0.3738476   0.12785637  \n0.08048103  0.6209139   0.6762928   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x1x3x3]\n\n\n output\n(1,1,.,.) =\n0.51474196  \n\n(2,1,.,.) =\n0.3738476   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x1x1]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\ninput = np.random.rand(2, 1, 3, 3)\nprint (\ninput is :\n,input)\n\nm = Cropping2D([1, 1], [1, 1])\nout = m.forward(input)\nprint (\noutput m is :\n,out)\n\n\n\n\nGives the output,\n\n\ninput is : [[[[ 0.54167415  0.59110695  0.583436  ]\n   [ 0.7401184   0.93070248  0.88311626]\n   [ 0.08472445  0.90583803  0.83751593]]]\n\n\n [[[ 0.98047837  0.13156681  0.73104089]\n   [ 0.15081809  0.1791556   0.18849927]\n   [ 0.12054713  0.75931796  0.40090047]]]]\ncreating: createCropping2D\noutput m is : [[[[ 0.93070251]]]\n\n\n [[[ 0.1791556 ]]]]\n\n\n\n\nCropping3D\n\n\nScala:\n\n\nval module = Cropping3D(dim1Crop, dim2Crop, dim3Crop, dataFormat=\nchannel_first\n)\n\n\n\n\nPython:\n\n\nm = Cropping3D(dim1Crop, dim2Crop, dim3Crop, dataFormat=\nchannel_first\n)\n\n\n\n\nCropping layer for 3D data (e.g. spatial or spatio-temporal).\n    # Arguments\n        dim1Crop, dim2Crop, dim3Crop: each is an Array of two int, specifies how\n                                      many units should be trimmed off at the\n                                      beginning and end of the 3 cropping dimensions.\n        dataFormat: Cropping3D.CHANNEL_FIRST or Cropping3D.CHANNEL_LAST\n\n\nScala example:\n\n\n\nscala \n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval module = Cropping3D(Array(1, 1), Array(1, 1), Array(1, 1))\nval input = Tensor(2, 1, 3, 3, 3).rand()\nval output = module.forward(input)\n\n\n input\n(1,1,1,.,.) =\n0.33822843  0.83652526  0.6983564   \n0.40552914  0.50253755  0.26770833  \n0.12843947  0.7388038   0.8611642   \n\n(1,1,2,.,.) =\n0.52169484  0.98340595  0.37585744  \n0.47124776  0.1858571   0.20025288  \n0.24735944  0.68807006  0.12379094  \n\n(1,1,3,.,.) =\n0.3149784   0.43712634  0.9625379   \n0.37466723  0.8551855   0.7831635   \n0.979082    0.6115703   0.09862939  \n\n(2,1,1,.,.) =\n0.8603551   0.64941335  0.382916    \n0.9402129   0.83625364  0.41554055  \n0.9974375   0.7845985   0.4631692   \n\n(2,1,2,.,.) =\n0.41448194  0.06975327  0.68035746  \n0.6495608   0.95513606  0.5103921   \n0.4187052   0.676009    0.00466285  \n\n(2,1,3,.,.) =\n0.043842442 0.9419528   0.9560404   \n0.8702963   0.4117603   0.91820705  \n0.39294028  0.010171742 0.23027366  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x1x3x3x3]\n\n\n output\n(1,1,1,.,.) =\n0.1858571   \n\n(2,1,1,.,.) =\n0.95513606  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x1x1x1]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\ninput = np.random.rand(2, 1, 3, 3, 3)\nprint (\ninput is :\n,input)\n\nm = Cropping3D([1, 1], [1, 1], [1, 1])\nout = m.forward(input)\nprint (\noutput m is :\n,out)\n\n\n\n\nGives the output,\n\n\ninput is : [[[[[ 0.00484727  0.64335228  0.21672991]\n    [ 0.6667991   0.90280284  0.17537352]\n    [ 0.17573056  0.51962225  0.7946977 ]]\n\n   [[ 0.54374072  0.02084648  0.817017  ]\n    [ 0.10707117  0.96247797  0.97634706]\n    [ 0.23012049  0.7498735   0.67309293]]\n\n   [[ 0.22704888  0.31254715  0.59703825]\n    [ 0.61084924  0.55686219  0.55321829]\n    [ 0.75911533  0.00731942  0.20643018]]]]\n\n\n\n [[[[ 0.89015703  0.28932907  0.80356569]\n    [ 0.55100695  0.66712567  0.00770912]\n    [ 0.91482596  0.43556021  0.96402856]]\n\n   [[ 0.36694364  0.27634374  0.52885899]\n    [ 0.40754185  0.79033726  0.42423772]\n    [ 0.20636923  0.72467024  0.80372414]]\n\n   [[ 0.50318154  0.54954067  0.71939314]\n    [ 0.52834256  0.26762247  0.32269808]\n    [ 0.53824181  0.42523858  0.95246198]]]]]\ncreating: createCropping3D\noutput m is : [[[[[ 0.96247798]]]]\n\n\n\n [[[[ 0.79033726]]]]]", 
            "title": "Simple Layers"
        }, 
        {
            "location": "/APIGuide/Layers/Simple-Layers/#linear", 
            "text": "Scala:  val module = Linear(\n  inputSize,\n  outputSize,\n  withBias = true,\n  wRegularizer = null,\n  bRegularizer = null,\n  initWeight = null,\n  initBias = null,\n  initGradWeight = null,\n  initGradBias = null)  Python:  module = Linear(\n  input_size,\n  output_size,\n  init_method= default ,\n  with_bias=True,\n  wRegularizer=None,\n  bRegularizer=None,\n  init_weight=None,\n  init_bias=None,\n  init_grad_weight=None,\n  init_grad_bias=None)  The  Linear  module applies a linear transformation to the input data,\ni.e.  y = Wx + b . The  input  given in  forward(input)  must be either\na vector (1D tensor) or matrix (2D tensor). If the input is a vector, it must\nhave the size of  inputSize . If it is a matrix, then each row is assumed to be\nan input sample of given batch (the number of rows means the batch size and\nthe number of columns should be equal to the  inputSize ).  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = Linear(3, 5)\n\nprintln(module.forward(Tensor.range(1, 3, 1)))  Gives the output,  com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.79338956\n-2.3417668\n-2.7557678\n-0.07507719\n-1.009765\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Linear(3, 5)\n\nprint(module.forward(np.arange(1, 4, 1)))  Gives the output,  [array([ 0.31657887, -1.11062765, -1.16235781, -0.67723978,  0.74650359], dtype=float32)]", 
            "title": "Linear"
        }, 
        {
            "location": "/APIGuide/Layers/Simple-Layers/#reverse", 
            "text": "Scala:  val m = Reverse(dim = 1, isInplace = false)  Python:  m = Reverse(dimension=1)  Reverse the input w.r.t given dimension.\n The input can be a Tensor or Table.  Dimension  is one-based index.  Scala example:  import com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\ndef randomn(): Float = RandomGenerator.RNG.uniform(0, 1)\nval input = Tensor(2, 3)\ninput.apply1(x =  randomn().toFloat)\nprintln( input: )\nprintln(input)\nval layer = new Reverse(1)\nprintln( output: )\nprintln(layer.forward(input))  input:\n0.17271264898590744 0.019822501810267568    0.18107921979390085 \n0.4003877849318087  0.5567442716564983  0.14120339532382786 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\noutput:\n0.4003877849318087  0.5567442716564983  0.14120339532382786 \n0.17271264898590744 0.019822501810267568    0.18107921979390085 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  input = np.random.random((2,3))\nlayer = Reverse(1)\nprint( input: )\nprint(input)\nprint( output: )\nprint(layer.forward(input))  creating: createReverse\ninput:\n[[ 0.89089717  0.07629756  0.30863782]\n [ 0.16066851  0.06421963  0.96719367]]\noutput:\n[[ 0.16066851  0.06421963  0.96719366]\n [ 0.89089715  0.07629756  0.30863783]]", 
            "title": "Reverse"
        }, 
        {
            "location": "/APIGuide/Layers/Simple-Layers/#reshape", 
            "text": "Scala:  val reshape = Reshape(size, batchMode)  Python:  reshape = Reshape(size, batch_mode)  The  forward(input)  reshape the input tensor into  size(0) * size(1) * ...  tensor,\ntaking the elements row-wise.  parameters:   size  the size after reshape   batchMode  It is a optional argument. If it is set to  Some(true) ,\n                  the first dimension of input is considered as batch dimension,\n                  and thus keep this dimension size fixed. This is necessary\n                  when dealing with batch sizes of one. When set to  Some(false) ,\n                  it forces the entire input (including the first dimension) to be reshaped\n                  to the input size. Default is  None , which means the module considers\n                  inputs with more elements than the product of provided sizes ( size(0) *\n                  size(1) * .. ) to be batches, otherwise in no batch mode.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval reshape = Reshape(Array(3, 2))\nval input = Tensor(2, 2, 3).rand()\nval output = reshape.forward(input)\n-  print(output.size().toList)      \nList(2, 3, 2)  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nreshape =  Reshape([3, 2])\ninput = np.random.rand(2, 2, 3)\noutput = reshape.forward(input)\n-  print output[0].shape\n(2, 3, 2)", 
            "title": "Reshape"
        }, 
        {
            "location": "/APIGuide/Layers/Simple-Layers/#index", 
            "text": "Scala:  val model = Index(dimension)  Python:  model = Index(dimension)  Applies the Tensor index operation along the given dimension.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\n\nval input1 = Tensor(3).rand()\nval input2 = Tensor(4)\ninput2(Array(1)) = 1.0f\ninput2(Array(2)) = 2.0f\ninput2(Array(3)) = 2.0f\ninput2(Array(4)) = 3.0f\n\nval input = T(input1, input2)\nval model = Index(1)\nval output = model.forward(input)\n\nscala  print(input)\n {\n    2: 1.0\n       2.0\n       2.0\n       3.0\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 4]\n    1: 0.124325536\n       0.8768922\n       0.6378146\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n }\nscala  print(output)\n0.124325536\n0.8768922\n0.8768922\n0.6378146\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\ninput1 = np.random.randn(3)\ninput2 = np.array([1, 2, 2, 3])\ninput = [input1, input2]\n\nmodel = Index(1)\noutput = model.forward(input)  print(input)\n[array([-0.45804847, -0.20176707,  0.50963248]), array([1, 2, 2, 3])]  print(output)\n[-0.45804846 -0.20176707 -0.20176707  0.50963247]", 
            "title": "Index"
        }, 
        {
            "location": "/APIGuide/Layers/Simple-Layers/#identity", 
            "text": "Scala:  val identity = Identity()  Python:  identity = Identity()  Identity just return input as the output which is useful in same parallel container to get an origin input  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval identity = Identity()\n\nval input = Tensor(3, 3).rand()  print(input)\n0.043098174 0.1035049   0.7522675   \n0.9999951   0.794151    0.18344955  \n0.9419861   0.02398399  0.6228095   \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]  print(identity.forward(input))\n0.043098174 0.1035049   0.7522675   \n0.9999951   0.794151    0.18344955  \n0.9419861   0.02398399  0.6228095   \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]  Python example:  from bigdl.nn.layer import *\nidentity = Identity()   identity.forward(np.array([[1, 2, 3], [4, 5, 6]]))\n[array([[ 1.,  2.,  3.],\n       [ 4.,  5.,  6.]], dtype=float32)]", 
            "title": "Identity"
        }, 
        {
            "location": "/APIGuide/Layers/Simple-Layers/#narrow", 
            "text": "Scala:  val layer = Narrow(dimension, offset, length = 1)  Python:  layer = Narrow(dimension, offset, length=1)  Narrow is an application of narrow operation in a module.\nThe module further supports a negative length in order to handle inputs with an unknown size.  Parameters:   dimension  narrow along this dimension   offset  the start index on the given dimension\n*  length  length to narrow, default value is 1  Scala Example  import com.intel.analytics.bigdl.nn.Narrow\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval layer = Narrow(2, 2)\nval input = Tensor(T(\n  T(-1f, 2f, 3f),\n  T(-2f, 3f, 4f),\n  T(-3f, 4f, 5f)\n))\n\nval gradOutput = Tensor(T(3f, 4f, 5f))\n\nval output = layer.forward(input)\n2.0\n3.0\n4.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x1]\n\nval grad = layer.backward(input, gradOutput)\n0.0 3.0 0.0\n0.0 4.0 0.0\n0.0 5.0 0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python Example  layer = Narrow(2, 2)\ninput = np.array([\n  [-1.0, 2.0, 3.0],\n  [-2.0, 3.0, 4.0],\n  [-3.0, 4.0, 5.0]\n])\n\ngradOutput = np.array([3.0, 4.0, 5.0])\n\noutput = layer.forward(input)\ngrad = layer.backward(input, gradOutput)\n\nprint output\n[[ 2.]\n [ 3.]\n [ 4.]]\n\nprint grad\n[[ 0.  3.  0.]\n [ 0.  4.  0.]\n [ 0.  5.  0.]]", 
            "title": "Narrow"
        }, 
        {
            "location": "/APIGuide/Layers/Simple-Layers/#unsqueeze", 
            "text": "Scala:  val layer = Unsqueeze(dim)  Python:  layer = Unsqueeze(dim)  Insert singleton dim (i.e., dimension 1) at position pos. For an input with  dim = input.dim() ,\nthere are  dim + 1  possible positions to insert the singleton dimension. The dim starts from 1.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval layer = Unsqueeze(2)\nval input = Tensor(2, 2, 2).rand\nval gradOutput = Tensor(2, 1, 2, 2).rand\nval output = layer.forward(input)\nval gradInput = layer.backward(input, gradOutput)  println(input.size)\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2]  println(gradOutput.size)\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x2x2]  println(output.size)\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x2x2]  println(gradInput.size)\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nlayer = Unsqueeze(2)\ninput = np.random.uniform(0, 1, (2, 2, 2)).astype( float32 )\ngradOutput = np.random.uniform(0, 1, (2, 1, 2, 2)).astype( float32 )\n\noutput = layer.forward(input)\ngradInput = layer.backward(input, gradOutput)  output\n[array([[[[ 0.97488612,  0.43463323],\n          [ 0.39069486,  0.0949123 ]]],\n\n\n        [[[ 0.19310953,  0.73574477],\n          [ 0.95347691,  0.37380624]]]], dtype=float32)]  gradInput\n[array([[[ 0.9995622 ,  0.69787127],\n         [ 0.65975296,  0.87002522]],\n\n        [[ 0.76349133,  0.96734989],\n         [ 0.88068211,  0.07284366]]], dtype=float32)]", 
            "title": "Unsqueeze"
        }, 
        {
            "location": "/APIGuide/Layers/Simple-Layers/#squeeze", 
            "text": "Scala:  val module = Squeeze(dims=null, numInputDims=Int.MinValue)  Python:  module = Squeeze(dims, numInputDims=-2147483648)  Delete all singleton dimensions or a specific singleton dimension.   dims  Optional. If this dimension is singleton dimension, it will be deleted.\n           The first index starts from 1. Default: delete all dimensions.  num_input_dims  Optional. If in a batch model, set to the inputDims.   Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = Squeeze(2)  print(layer.forward(Tensor(2, 1, 3).rand()))\n0.43709445  0.42752415  0.43069172  \n0.67029667  0.95641375  0.28823504  \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  from bigdl.nn.layer import *\n\nlayer = Squeeze(2) layer.forward(np.array([[[1, 2, 3]], [[1, 2, 3]]]))\nout: array([[ 1.,  2.,  3.],\n            [ 1.,  2.,  3.]], dtype=float32)", 
            "title": "Squeeze"
        }, 
        {
            "location": "/APIGuide/Layers/Simple-Layers/#select", 
            "text": "Scala:  val layer = Select(dim, index)  Python:  layer = Select(dim, index)  A Simple layer selecting an index of the input tensor in the given dimension.\nPlease note that the index and dimension start from 1. In collaborative filtering, it can used together with LookupTable to create embeddings for users or items.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = Select(1, 2)\nlayer.forward(Tensor(T(\n  T(1.0f, 2.0f, 3.0f),\n  T(4.0f, 5.0f, 6.0f),\n  T(7.0f, 8.0f, 9.0f)\n)))\n\nlayer.backward(Tensor(T(\n  T(1.0f, 2.0f, 3.0f),\n  T(4.0f, 5.0f, 6.0f),\n  T(7.0f, 8.0f, 9.0f)\n)), Tensor(T(0.1f, 0.2f, 0.3f)))  Gives the output,  4.0\n5.0\n6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n\n0.0     0.0     0.0\n0.1     0.2     0.3\n0.0     0.0     0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  from bigdl.nn.layer import Select\nimport numpy as np\n\nlayer = Select(1, 2)\nlayer.forward(np.array([\n  [1.0, 2.0, 3.0],\n  [4.0, 5.0, 6.0],\n  [7.0, 8.0, 9.0]\n]))\nlayer.backward(np.array([\n  [1.0, 2.0, 3.0],\n  [4.0, 5.0, 6.0],\n  [7.0, 8.0, 9.0]\n]), np.array([0.1, 0.2, 0.3]))  Gives the output,  array([ 4.,  5.,  6.], dtype=float32)\n\narray([[ 0.        ,  0.        ,  0.        ],\n       [ 0.1       ,  0.2       ,  0.30000001],\n       [ 0.        ,  0.        ,  0.        ]], dtype=float32)", 
            "title": "Select"
        }, 
        {
            "location": "/APIGuide/Layers/Simple-Layers/#maskedselect", 
            "text": "Scala:  val module = MaskedSelect()  Python:  module = MaskedSelect()  Performs a torch.MaskedSelect on a Tensor. The mask is supplied as a tabular argument\n with the input on the forward and backward passes.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport scala.util.Random\n\n\nval layer = MaskedSelect()\nval input1 = Tensor(2, 2).apply1(e =  Random.nextFloat())\nval mask = Tensor(2, 2)\nmask(Array(1, 1)) = 1\nmask(Array(1, 2)) = 0\nmask(Array(2, 1)) = 0\nmask(Array(2, 2)) = 1\nval input = T()\ninput(1.0) = input1\ninput(2.0) = mask  print(layer.forward(input))\n0.2577119\n0.5061479\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2]  Python example:  from bigdl.nn.layer import *\n\nlayer = MaskedSelect()\ninput1 = np.random.rand(2,2)\nmask = np.array([[1,0], [0, 1]]) layer.forward([input1, mask])\narray([ 0.1525335 ,  0.05474588], dtype=float32)", 
            "title": "MaskedSelect"
        }, 
        {
            "location": "/APIGuide/Layers/Simple-Layers/#transpose", 
            "text": "Scala:  val module = Transpose(permutations)  Python:  module = Transpose(permutations)  Concat is a layer who transpose input along specified dimensions.\npermutations are dimension pairs that need to swap.  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval input = Tensor(2, 3).rand()\nval layer = Transpose(Array((1, 2)))\nval output = layer.forward(input)  input\n0.6653826   0.25350887  0.33434764  \n0.9618287   0.5484164   0.64844745  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]  output\n0.6653826   0.9618287   \n0.25350887  0.5484164   \n0.33434764  0.64844745  \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x2]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nlayer = Transpose([(1,2)])\ninput = np.array([[0.6653826, 0.25350887, 0.33434764], [0.9618287, 0.5484164, 0.64844745]])\noutput = layer.forward(input)  output\n[array([[ 0.66538262,  0.96182871],\n       [ 0.25350887,  0.54841638],\n       [ 0.33434764,  0.64844745]], dtype=float32)]", 
            "title": "Transpose"
        }, 
        {
            "location": "/APIGuide/Layers/Simple-Layers/#inferreshape", 
            "text": "Scala:  val layer = InferReshape(size, batchMode = false)  Python:  layer = InferReshape(size, batch_mode=False)  Reshape the input tensor with automatic size inference support.\nPositive numbers in the  size  argument are used to reshape the input to the\ncorresponding dimension size.  There are also two special values allowed in  size :   0  means keep the corresponding dimension size of the input unchanged.\n      i.e., if the 1st dimension size of the input is 2,\n      the 1st dimension size of output will be set as 2 as well.  -1  means infer this dimension size from other dimensions.\n      This dimension size is calculated by keeping the amount of output elements\n      consistent with the input.\n      Only one  -1  is allowable in  size .   For example,     Input tensor with size: (4, 5, 6, 7)\n   -  InferReshape(Array(4, 0, 3, -1))\n   Output tensor with size: (4, 5, 3, 14)  The 1st and 3rd dim are set to given sizes, keep the 2nd dim unchanged,\nand inferred the last dim as 14.  Parameters:   size  the target tensor size   batchMode  whether in batch mode  Scala example:  import com.intel.analytics.bigdl.nn.InferReshape\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nval layer = InferReshape(Array(0, 3, -1))\nval input = Tensor(1, 2, 3).rand()\nval gradOutput = Tensor(1, 3, 2).rand()\n\nval output = layer.forward(input)\nval grad = layer.backward(input, gradOutput)\n\nprintln(output)\n(1,.,.) =\n0.8170822   0.40073588\n0.49389255  0.3782435\n0.42660004  0.5917206\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x2]\n\nprintln(grad)\n(1,.,.) =\n0.8294597   0.57101834  0.90910035\n0.32783163  0.30494633  0.7339092\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x3]  Python example:  layer = InferReshape([0, 3, -1])\ninput = np.random.rand(1, 2, 3)\n\ngradOutput = np.random.rand(1, 3, 2)\n\noutput = layer.forward(input)\ngrad = layer.backward(input, gradOutput)\n\nprint output\n[[[ 0.68635464  0.21277553]\n  [ 0.13390459  0.65662414]\n  [ 0.1021723   0.92319047]]]\n\nprint grad\n[[[ 0.84927064  0.55205333  0.25077972]\n  [ 0.76105869  0.30828172  0.1237276 ]]]", 
            "title": "InferReshape"
        }, 
        {
            "location": "/APIGuide/Layers/Simple-Layers/#replicate", 
            "text": "Scala:  val module = Replicate(\n  nFeatures,\n  dim = 1,\n  nDim = Int.MaxValue)  Python:  module = Replicate(\n  n_features,\n  dim=1,\n  n_dim=INTMAX)  Replicate repeats input  nFeatures  times along its  dim  dimension  Notice: No memory copy, it set the stride along the  dim -th dimension to zero.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = Replicate(4, 1, 2)\n\nprintln(module.forward(Tensor.range(1, 6, 1).resize(1, 2, 3)))  Gives the output,  com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n1.0 2.0 3.0\n4.0 5.0 6.0\n\n(1,2,.,.) =\n1.0 2.0 3.0\n4.0 5.0 6.0\n\n(1,3,.,.) =\n1.0 2.0 3.0\n4.0 5.0 6.0\n\n(1,4,.,.) =\n1.0 2.0 3.0\n4.0 5.0 6.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x4x2x3]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Replicate(4, 1, 2)\n\nprint(module.forward(np.arange(1, 7, 1).reshape(1, 2, 3)))  Gives the output,   [array([[[[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.]],\n\n        [[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.]],\n\n        [[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.]],\n\n        [[ 1.,  2.,  3.],\n         [ 4.,  5.,  6.]]]], dtype=float32)]", 
            "title": "Replicate"
        }, 
        {
            "location": "/APIGuide/Layers/Simple-Layers/#view", 
            "text": "Scala:  val view = View(2, 8)  or  val view = View(Array(2, 8))  Python:  view = View([2, 8])  This module creates a new view of the input tensor using the sizes passed to the constructor.\nThe method setNumInputDims() allows to specify the expected number of dimensions of the inputs\nof the modules. This makes it possible to use minibatch inputs\nwhen using a size -1 for one of the dimensions.  Scala example:  import com.intel.analytics.bigdl.nn.View\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval view = View(2, 8)\n\nval input = Tensor(4, 4).randn()\nval gradOutput = Tensor(2, 8).randn()\n\nval output = view.forward(input)\nval gradInput = view.backward(input, gradOutput)  Gives the output,  output: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.43037438     1.2982363       -1.4723133      -0.2602826      0.7178128       -1.8763185      0.88629466      0.8346704\n0.20963766      -0.9349786      1.0376515       1.3153045       1.5450214       1.084113        -0.29929757     -0.18356979\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8]  Gives the gradInput,  gradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.7360089       0.9133299       0.40443268      -0.94965595\n0.80520976      -0.09671917     -0.5498001      -0.098691925\n-2.3119886      -0.8455147      0.75891125      1.2985301\n0.5023749       1.4983269       0.42038065      -1.7002305  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nview = View([2, 8])\n\ninput = np.random.uniform(0, 1, [4, 4]).astype( float32 )\ngradOutput = np.random.uniform(0, 1, [2, 8]).astype( float32 )\n\noutput = view.forward(input)\ngradInput = view.backward(input, gradOutput)\n\nprint output\nprint gradInput", 
            "title": "View"
        }, 
        {
            "location": "/APIGuide/Layers/Simple-Layers/#contiguous", 
            "text": "Be used to make input, gradOutput both contiguous  Scala:  val contiguous = Contiguous()  Python:  contiguous = Contiguous()  Used to make input, gradOutput both contiguous  Scala example:  import com.intel.analytics.bigdl.nn.Contiguous\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval input = Tensor(5).range(1, 5, 1)\nval contiguous = new Contiguous()\nval output = contiguous.forward(input)\nprintln(output)\n\nval gradOutput = Tensor(5).range(2, 6, 1)\nval gradInput = contiguous.backward(input, gradOutput)\nprintln(gradOutput)  Gives the output,  output: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0\n2.0\n3.0\n4.0\n5.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]  Gives the gradInput,  gradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n2.0\n3.0\n4.0\n5.0\n6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ncontiguous = Contiguous()\n\ninput = np.arange(1, 6, 1).astype( float32 )\ninput = input.reshape(1, 5)\n\noutput = contiguous.forward(input)\nprint output\n\ngradOutput = np.arange(2, 7, 1).astype( float32 )\ngradOutput = gradOutput.reshape(1, 5)\n\ngradInput = contiguous.backward(input, gradOutput)\nprint gradInput  Gives the output,  [array([[ 1.,  2.,  3.,  4.,  5.]], dtype=float32)]  Gives the gradInput,  [array([[ 2.,  3.,  4.,  5.,  6.]], dtype=float32)]", 
            "title": "Contiguous"
        }, 
        {
            "location": "/APIGuide/Layers/Simple-Layers/#gaussiansampler", 
            "text": "Takes {mean, log_variance} as input and samples from the Gaussian distribution  Scala:  val sampler = GaussianSampler()  Python:  sampler = GaussianSampler()  Scala example:  import com.intel.analytics.bigdl.nn.GaussianSampler\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.RandomGenerator._\nimport com.intel.analytics.bigdl.utils.T\n\nval input1 = Tensor[Float](2, 3).range(1, 6, 1)\nval input2 = Tensor[Float](2, 3).range(1, 12, 2)\nval input = T(input1, input2)\n\nval gradOutput = Tensor[Float](2, 3).range(2, 13, 2)\n\nval sampler = new GaussianSampler()\nval output = sampler.forward(input)\nprintln(output)\n\nval gradInput = sampler.backward(input, gradOutput)\nprintln(gradOutput)  Gives the output,  output: com.intel.analytics.bigdl.tensor.Tensor[Float] = \n4.507061    9.247583    -14.053247  \n34.783264   -70.69336   -333.97656  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]  Gives the gradInput,  gradInput: com.intel.analytics.bigdl.utils.Table = \n {\n    1: 2.0  4.0     6.0 \n       8.0  10.0    12.0    \n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    2: 3.5070612    14.495168   -51.159744  \n       123.13305    -378.4668   -2039.8594  \n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n }  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\nimport numpy as np\n\nsampler = GaussianSampler()\n\ninput1 = np.arange(1, 7, 1).astype( float32 )\ninput2 = np.arange(1, 12, 2).astype( float32 )\ninput2 = input1.reshape(2, 3)\ninput2 = input2.reshape(2, 3)\ninput = [input1, input2]\n\ngradOutput = np.arange(2, 13, 2).astype( float32 )\ngradOutput = gradOutput.reshape(2, 3)\n\noutput = sampler.forward(input)\ngradInput = sampler.backward(input, gradOutput)  Gives the output,   print output\n[[ 1.73362803  2.99371576  0.44359136]\n [ 0.04700017  2.85183263  3.04418468]]  Gives the gradInput,   print gradInput\n[array([[  2.,   4.,   6.],\n       [  8.,  10.,  12.]], dtype=float32), array([[  0.73362803,   1.98743176,  -7.66922569],\n       [-15.81199932, -10.7408371 , -17.73489189]], dtype=float32)]", 
            "title": "GaussianSampler"
        }, 
        {
            "location": "/APIGuide/Layers/Simple-Layers/#masking", 
            "text": "Use a mask value to skip timesteps for a sequence  Scala:  val mask = Masking(0.0)  Python:  mask = Masking(0.0)  Scala example:  import com.intel.analytics.bigdl.nn.Masking\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval batchSize = 3\nval times = 5\nval features = 2\nval inputData = Array[Double](1.0, 1, 2, 2, 3, 3, 4, 4, 5, 5, -1, 1, 2, 2, 3, 3, 4, 4, 5, 5,\n  1, 1, -1, -1, 3, 3, 4, 4, 5, 5)\nval input = Tensor[Double](inputData, Array(batchSize, times, features))\nval gradOutput = Tensor[Double](Array(batchSize, times, features)).fill(1.0)\nval maskValue = -1\n\nval mask = Masking(maskValue)\nval output = mask.forward(input)\nprintln(output)\n\nval gradInput = mask.backward(input, gradOutput)\nprintln(gradOutput)  Gives the output,  output: = \n(1,.,.) =\n1.0 1.0 \n2.0 2.0 \n3.0 3.0 \n4.0 4.0 \n5.0 5.0 \n\n(2,.,.) =\n-1.0    1.0 \n2.0 2.0 \n3.0 3.0 \n4.0 4.0 \n5.0 5.0 \n\n(3,.,.) =\n1.0 1.0 \n0.0 0.0 \n3.0 3.0 \n4.0 4.0 \n5.0 5.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcD$sp of size 3x5x2]  Gives the gradInput,  gradInput: \n(1,.,.) =\n1.0 1.0 \n1.0 1.0 \n1.0 1.0 \n1.0 1.0 \n1.0 1.0 \n\n(2,.,.) =\n1.0 1.0 \n1.0 1.0 \n1.0 1.0 \n1.0 1.0 \n1.0 1.0 \n\n(3,.,.) =\n1.0 1.0 \n0.0 0.0 \n1.0 1.0 \n1.0 1.0 \n1.0 1.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcD$sp of size 3x5x2]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.util.common import *\nimport numpy as np\n\nn_samples = 3\nn_timesteps = 7\nn_features = 2\nmask_value = -1.0\ninput = np.array([1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, -1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7,\n                 1, 1, 2, 2, 3, 3, -1, -1, 5, 5, 6, 6, 7, 7]).reshape(n_samples, n_timesteps, n_features)\ngradOutput = np.ones((n_samples, n_timesteps, n_features))\nmodel = Sequential()\nmodel.add(Masking(mask_value=mask_value))\n\noutput = model.forward(input)\ngradInput = model.backward(input, gradOutput)  Gives the output,   print output\n[[[ 1.  1.]\n  [ 2.  2.]\n  [ 3.  3.]\n  [ 4.  4.]\n  [ 5.  5.]\n  [ 6.  6.]\n  [ 7.  7.]]\n\n [[-1.  1.]\n  [ 2.  2.]\n  [ 3.  3.]\n  [ 4.  4.]\n  [ 5.  5.]\n  [ 6.  6.]\n  [ 7.  7.]]\n\n [[ 1.  1.]\n  [ 2.  2.]\n  [ 3.  3.]\n  [ 0.  0.]\n  [ 5.  5.]\n  [ 6.  6.]\n  [ 7.  7.]]]  Gives the gradInput,   print gradInput\n[[[ 1.  1.]\n  [ 1.  1.]\n  [ 1.  1.]\n  [ 1.  1.]\n  [ 1.  1.]\n  [ 1.  1.]\n  [ 1.  1.]]\n\n [[ 1.  1.]\n  [ 1.  1.]\n  [ 1.  1.]\n  [ 1.  1.]\n  [ 1.  1.]\n  [ 1.  1.]\n  [ 1.  1.]]\n\n [[ 1.  1.]\n  [ 1.  1.]\n  [ 1.  1.]\n  [ 0.  0.]\n  [ 1.  1.]\n  [ 1.  1.]\n  [ 1.  1.]]]", 
            "title": "Masking"
        }, 
        {
            "location": "/APIGuide/Layers/Simple-Layers/#maxout", 
            "text": "Scala:  val maxout = Maxout(2, 5, 3,\n                    withBias = true,\n                    wRegularizer = null,\n                    bRegularizer = null,\n                    initWeight = null,\n                    initBias = null)  Python:  maxout = Maxout(2, 5, 3,\n                 with_bias = True,\n                 w_regularizer=None,\n                 b_regularizer=None,\n                 init_weight=None,\n                 init_bias=None)  Maxout layer select the element-wise maximum value of maxoutNumber Linear(inputSize, outputSize) layers  parameters:   inputSize  the size the each input sample   outputSize  the size of the module output of each sample   maxoutNumber  number of Linear layers to use   withBias  whether use bias in Linear   wRegularizer  instance of  [Regularizer] , applied to the input weights matrices.   bRegularizer  instance of [[Regularizer]] applied to the bias.   initWeight  initial weight   initBias  initial bias  Scala example:  import com.intel.analytics.bigdl.nn.Maxout\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval input_size = 2\nval batch_size = 3\nval output_size = 5\nval maxout_number = 3\n\nval input = Tensor[Float](batch_size, input_size).rand()\nval layer = Maxout[Float](input_size, output_size, maxout_number)\nval output = layer.forward(input)\nval gradOutput = Tensor[Float](batch_size, output_size)\nval gradInput = layer.backward(input, gradOutput)  Gives the output,  0.19078568  0.94480306  0.25038794  0.8114594   0.7753764   \n0.2822805   0.9095781   0.2815394   0.82958585  0.784589    \n0.35188058  0.7629706   0.18096384  0.7100433   0.6680352   \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x5]  Gives the gradInput,  gradInput: \n-0.18932924 0.9426162   \n-0.3118648  0.67255044  \n-0.31795382 1.944398    \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.util.common import *\nimport numpy as np\n\nval input_size = 2\nval batch_size = 3\nval output_size = 5\nval maxout_number = 3\n\nval input = Tensor[Float](batch_size, input_size).rand()\nval layer = Maxout[Float](input_size, output_size, maxout_number)\nval output = layer.forward(input)\nval gradOutput = Tensor[Float](batch_size, output_size).rand()\nval gradInput = layer.backward(input, gradOutput)  Gives the output,   print output\n[[ 0.12344513  0.19081372  0.15130989  0.6341747   0.70982581]\n [ 0.04154952 -0.13281995  0.2648508   0.36793122  0.67043799]\n [ 0.41355255  0.17691913  0.15496807  0.5880245   0.74583203]]  Gives the gradInput,   print gradInput\n[[ 0.53398496  0.01809531]\n [-0.20667852  0.4962275 ]\n [ 0.37912956  0.08742841]]", 
            "title": "Maxout ##"
        }, 
        {
            "location": "/APIGuide/Layers/Simple-Layers/#cropping2d", 
            "text": "Scala:  val module = Cropping2D(heightCrop, widthCrop, dataFormat=DataFormat.NCHW)  Python:  m = Cropping2D(heightCrop, widthCrop, data_format= NCHW )  Cropping layer for 2D input (e.g. picture). It crops along spatial dimensions, i.e. width and height.\n    # Arguments\n        heightCrop: Array of length 2. How many units should be trimmed off at the\n                    beginning and end of the height dimension.\n        widthCrop: Array of length 2. How many units should be trimmed off at the\n                   beginning and end of the width dimension\n        dataFormat: DataFormat.NCHW or DataFormat.NHWC.\n    # Input shape\n        4D tensor with shape:\n         (samples, depth, first_axis_to_crop, second_axis_to_crop) \n    # Output shape\n        4D tensor with shape:\n         (samples, depth, first_cropped_axis, second_cropped_axis)  Scala example:  \nscala  \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval module = Cropping2D(Array(1, 1), Array(1, 1))\nval input = Tensor(2, 1, 3, 3).rand()\nval output = module.forward(input)  input\n(1,1,.,.) =\n0.024445634 0.73160243  0.1408418   \n0.95527077  0.51474196  0.89850646  \n0.3730063   0.40874788  0.7043526   \n\n(2,1,.,.) =\n0.8549189   0.5019415   0.96255547  \n0.83960533  0.3738476   0.12785637  \n0.08048103  0.6209139   0.6762928   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x1x3x3]  output\n(1,1,.,.) =\n0.51474196  \n\n(2,1,.,.) =\n0.3738476   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x1x1]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\ninput = np.random.rand(2, 1, 3, 3)\nprint ( input is : ,input)\n\nm = Cropping2D([1, 1], [1, 1])\nout = m.forward(input)\nprint ( output m is : ,out)  Gives the output,  input is : [[[[ 0.54167415  0.59110695  0.583436  ]\n   [ 0.7401184   0.93070248  0.88311626]\n   [ 0.08472445  0.90583803  0.83751593]]]\n\n\n [[[ 0.98047837  0.13156681  0.73104089]\n   [ 0.15081809  0.1791556   0.18849927]\n   [ 0.12054713  0.75931796  0.40090047]]]]\ncreating: createCropping2D\noutput m is : [[[[ 0.93070251]]]\n\n\n [[[ 0.1791556 ]]]]", 
            "title": "Cropping2D"
        }, 
        {
            "location": "/APIGuide/Layers/Simple-Layers/#cropping3d", 
            "text": "Scala:  val module = Cropping3D(dim1Crop, dim2Crop, dim3Crop, dataFormat= channel_first )  Python:  m = Cropping3D(dim1Crop, dim2Crop, dim3Crop, dataFormat= channel_first )  Cropping layer for 3D data (e.g. spatial or spatio-temporal).\n    # Arguments\n        dim1Crop, dim2Crop, dim3Crop: each is an Array of two int, specifies how\n                                      many units should be trimmed off at the\n                                      beginning and end of the 3 cropping dimensions.\n        dataFormat: Cropping3D.CHANNEL_FIRST or Cropping3D.CHANNEL_LAST  Scala example:  \nscala  \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval module = Cropping3D(Array(1, 1), Array(1, 1), Array(1, 1))\nval input = Tensor(2, 1, 3, 3, 3).rand()\nval output = module.forward(input)  input\n(1,1,1,.,.) =\n0.33822843  0.83652526  0.6983564   \n0.40552914  0.50253755  0.26770833  \n0.12843947  0.7388038   0.8611642   \n\n(1,1,2,.,.) =\n0.52169484  0.98340595  0.37585744  \n0.47124776  0.1858571   0.20025288  \n0.24735944  0.68807006  0.12379094  \n\n(1,1,3,.,.) =\n0.3149784   0.43712634  0.9625379   \n0.37466723  0.8551855   0.7831635   \n0.979082    0.6115703   0.09862939  \n\n(2,1,1,.,.) =\n0.8603551   0.64941335  0.382916    \n0.9402129   0.83625364  0.41554055  \n0.9974375   0.7845985   0.4631692   \n\n(2,1,2,.,.) =\n0.41448194  0.06975327  0.68035746  \n0.6495608   0.95513606  0.5103921   \n0.4187052   0.676009    0.00466285  \n\n(2,1,3,.,.) =\n0.043842442 0.9419528   0.9560404   \n0.8702963   0.4117603   0.91820705  \n0.39294028  0.010171742 0.23027366  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x1x3x3x3]  output\n(1,1,1,.,.) =\n0.1858571   \n\n(2,1,1,.,.) =\n0.95513606  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x1x1x1]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\ninput = np.random.rand(2, 1, 3, 3, 3)\nprint ( input is : ,input)\n\nm = Cropping3D([1, 1], [1, 1], [1, 1])\nout = m.forward(input)\nprint ( output m is : ,out)  Gives the output,  input is : [[[[[ 0.00484727  0.64335228  0.21672991]\n    [ 0.6667991   0.90280284  0.17537352]\n    [ 0.17573056  0.51962225  0.7946977 ]]\n\n   [[ 0.54374072  0.02084648  0.817017  ]\n    [ 0.10707117  0.96247797  0.97634706]\n    [ 0.23012049  0.7498735   0.67309293]]\n\n   [[ 0.22704888  0.31254715  0.59703825]\n    [ 0.61084924  0.55686219  0.55321829]\n    [ 0.75911533  0.00731942  0.20643018]]]]\n\n\n\n [[[[ 0.89015703  0.28932907  0.80356569]\n    [ 0.55100695  0.66712567  0.00770912]\n    [ 0.91482596  0.43556021  0.96402856]]\n\n   [[ 0.36694364  0.27634374  0.52885899]\n    [ 0.40754185  0.79033726  0.42423772]\n    [ 0.20636923  0.72467024  0.80372414]]\n\n   [[ 0.50318154  0.54954067  0.71939314]\n    [ 0.52834256  0.26762247  0.32269808]\n    [ 0.53824181  0.42523858  0.95246198]]]]]\ncreating: createCropping3D\noutput m is : [[[[[ 0.96247798]]]]\n\n\n\n [[[[ 0.79033726]]]]]", 
            "title": "Cropping3D"
        }, 
        {
            "location": "/APIGuide/Layers/Convolution-Layers/", 
            "text": "SpatialConvolution\n\n\nScala:\n\n\nval m = SpatialConvolution(nInputPlane,nOutputPlane,kernelW,kernelH,strideW=1,strideH=1,padW=0,padH=0,nGroup=1,propagateBack=true,wRegularizer=null,bRegularizer=null,initWeight=null, initBias=null, initGradWeight=null, initGradBias=null, withBias=true, dataFormat=DataFormat.NCHW)\n\n\n\n\nPython:\n\n\nm = SpatialConvolution(n_input_plane,n_output_plane,kernel_w,kernel_h,stride_w=1,stride_h=1,pad_w=0,pad_h=0,n_group=1,propagate_back=True,wRegularizer=None,bRegularizer=None,init_weight=None,init_bias=None,init_grad_weight=None,init_grad_bias=None, with_bias=True, data_format=\nNCHW\n)\n\n\n\n\nSpatialConvolution is a module that applies a 2D convolution over an input image.\n\n\nThe input tensor in \nforward(input)\n is expected to be\neither a 4D tensor (\nbatch x nInputPlane x height x width\n) or a 3D tensor (\nnInputPlane x height x width\n). The convolution is performed on the last two dimensions.\noutput of \nforward(input)\n is also expected to be a 4D tensor (\nbatch x outputPlane x height x width\n)\nor a 3D tensor (\noutputPlane x height x width\n)..\n\n\nAs for padding, when padW and padH are both -1, we use a padding algorithm similar to the \"SAME\" padding of tensorflow. That is\n\n\n outHeight = Math.ceil(inHeight.toFloat/strideH.toFloat)\n outWidth = Math.ceil(inWidth.toFloat/strideW.toFloat)\n\n padAlongHeight = Math.max(0, (outHeight - 1) * strideH + kernelH - inHeight)\n padAlongWidth = Math.max(0, (outWidth - 1) * strideW + kernelW - inWidth)\n\n padTop = padAlongHeight / 2\n padLeft = padAlongWidth / 2\n\n\n\n\nDetailed parameter explanation for the constructor.\n\n\n\n\nnInputPlane\n The number of expected input planes in the image given into forward()\n\n\nnOutputPlane\n The number of output planes the convolution layer will produce.\n\n\nkernelW\n The kernel width of the convolution\n\n\nkernelH\n The kernel height of the convolution\n\n\nstrideW\n The step of the convolution in the width dimension.\n\n\nstrideH\n The step of the convolution in the height dimension\n\n\npadW\n  padding to be added to width to the input.\n\n\npadH\n padding to be added to height to the input.\n\n\nnGroup\n Kernel group number\n\n\npropagateBack\n whether to propagate gradient back\n\n\nwRegularizer\n regularizer on weight. an instance of [[Regularizer]] (e.g. L1 or L2)\n\n\nbRegularizer\n regularizer on bias. an instance of [[Regularizer]] (e.g. L1 or L2).\n\n\ninitWeight\n weight initializer\n\n\ninitBias\n  bias initializer\n\n\ninitGradWeight\n weight gradient initializer\n\n\ninitGradBias\n bias gradient initializer\n\n\nwith_bias\n the optional initial value for if need bias\n\n\ndata_format\n a string value (or DataFormat Object in Scala) of \"NHWC\" or \"NCHW\" to specify the input data format of this layer. In \"NHWC\" format\n                        data is stored in the order of [batch_size, height, width, channels], in \"NCHW\" format data is stored\n                        in the order of [batch_size, channels, height, width].\n\n\n\n\nScala example:\n\n\n\nscala\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval m = SpatialConvolution(2,1,2,2,1,1,0,0)\nm.setInitMethod(weightInitMethod = BilinearFiller, biasInitMethod = Zeros)\nval params = m.getParameters()\n\nscala\n print(params)\n(1.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 9],0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 9])\n\nscala\n\nval input = Tensor(1,2,3,3).randn()\nval output = m.forward(input)\nval gradOut = Tensor(1,1,2,2).fill(0.2f)\nval gradIn = m.backward(input,gradOut)\n\nscala\n print(input)\n(1,1,.,.) =\n-0.37011376     0.13565119      -0.73574775\n-0.19486316     -0.4430604      -0.62543416\n0.7017611       -0.6441595      -1.2953792\n\n(1,2,.,.) =\n-0.9903588      0.5669722       0.2630131\n0.03392942      -0.6984676      -0.12389368\n0.78704715      0.5411976       -1.3877676\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x2x3x3]\n\nscala\n print(output)\n(1,1,.,.) =\n-1.3604726      0.70262337\n-0.16093373     -1.141528\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x2]\n\nscala\n print(gradOut)\n(1,1,.,.) =\n0.2     0.2\n0.2     0.2\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x1x2x2]\n\nscala\n print(gradIn)\n(1,1,.,.) =\n0.2     0.2     0.0\n0.2     0.2     0.0\n0.0     0.0     0.0\n\n(1,2,.,.) =\n0.2     0.2     0.0\n0.2     0.2     0.0\n0.0     0.0     0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x3x3]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\ninput = np.random.rand(1,3,3,3)\nprint \ninput is :\n,input\n\nm = SpatialConvolution(3,1,2,2,1,1,0,0)\nout = m.forward(input)\nprint \noutput m is :\n,out\n\ngrad_out = np.random.rand(1,1,2,2)\nprint \ngrad out of m is :\n,grad_out\ngrad_in = m.backward(input,grad_out)\nprint \ngrad input of m is :\n,grad_in\n\n\n\n\nGives the output,\n\n\ninput is : [[[[ 0.75276617  0.44212513  0.90275949]\n   [ 0.78205279  0.77864714  0.83647254]\n   [ 0.76220944  0.22106036  0.68762202]]\n\n  [[ 0.37346971  0.31532213  0.33276243]\n   [ 0.69872884  0.07262236  0.66372462]\n   [ 0.47803013  0.80194459  0.53313873]]\n\n  [[ 0.56196833  0.20599878  0.47575818]\n   [ 0.35454298  0.96910557  0.36234704]\n   [ 0.64017738  0.95762579  0.50073035]]]]\ncreating: createSpatialConvolution\noutput m is : [[[[-1.08398974 -0.67615652]\n   [-0.77027249 -0.82885492]]]]\ngrad out of m is : [[[[ 0.38295452  0.77048361]\n   [ 0.11671955  0.76357513]]]]\ngrad input of m is : [[[[-0.02344826 -0.06515953 -0.03618064]\n   [-0.06770924 -0.22586647 -0.14004168]\n   [-0.01845866 -0.13653883 -0.10325129]]\n\n  [[-0.09294108 -0.14361492  0.08727306]\n   [-0.09885897 -0.21209857  0.29151234]\n   [-0.02149716 -0.10957514  0.20318349]]\n\n  [[-0.05926216 -0.04542646  0.14849319]\n   [-0.09506465 -0.34244278 -0.03763583]\n   [-0.02346931 -0.1815301  -0.18314059]]]]\n\n\n\n\n\n\nVolumetricConvolution\n\n\nScala:\n\n\nval module = VolumetricConvolution(nInputPlane, nOutputPlane, kT, kW, kH,\n  dT=1, dW=1, dH=1, padT=0, padW=0, padH=0, withBias=true, wRegularizer=null, bRegularizer=null)\n\n\n\n\nPython:\n\n\nmodule = VolumetricConvolution(n_input_plane, n_output_plane, k_t, k_w, k_h,\n  d_t=1, d_w=1, d_h=1, pad_t=0, pad_w=0, pad_h=0, with_bias=true, wRegularizer=null, bRegularizer=null)\n\n\n\n\nApplies a 3D convolution over an input image composed of several input planes. The input tensor\nin forward(input) is expected to be a 5D tensor (\nbatch x nInputPlane x depth(time) x height x width\n) or\na 4D tensor (\nnInputPlane x depth x height x width\n).\nOutput of forward(input) is also expected to be a 5D tensor (\nbatch x depth(time) x outputPlane x height x width\n) or\na 4D tensor (\noutputPlane x depth x height x width\n).\nAs for padding, when padW,padH, padT are all -1, we use a padding algorithm similar to the \"SAME\" padding of tensorflow.\n\n\n\n\nnInputPlane\n The number of expected input planes in the image given into forward()\n\n\nnOutputPlane\n The number of output planes the convolution layer will produce.\n\n\nkT\n The kernel size of the convolution in time\n\n\nkW\n The kernel width of the convolution\n\n\nkH\n The kernel height of the convolution\n\n\ndT\n The step of the convolution in the time dimension. Default is 1\n\n\ndW\n The step of the convolution in the width dimension. Default is 1\n\n\ndH\n The step of the convolution in the height dimension. Default is 1\n\n\npadT\n Additional zeros added to the input plane data on both sides of time axis.\n         Default is 0. \n(kT-1)/2\n is often used here.\n\n\npadW\n The additional zeros added per width to the input planes.\n\n\npadH\n The additional zeros added per height to the input planes.\n\n\nwithBias\n whether with bias.\n\n\nwRegularizer\n instance of [[Regularizer]]\n                   (eg. L1 or L2 regularization), applied to the input weights matrices.\n\n\nbRegularizer\n instance of [[Regularizer]]\n                   applied to the bias.\n\n\n\n\nScala example:\n\n\nval layer = VolumetricConvolution(2, 3, 2, 2, 2, dT=1, dW=1, dH=1,\n  padT=0, padW=0, padH=0, withBias=true)\nval input = Tensor(2, 2, 2, 2).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.54846555      0.5549177\n0.43748873      0.6596535\n\n(1,2,.,.) =\n0.87915933      0.5955469\n0.67464 0.40921077\n\n(2,1,.,.) =\n0.24127467      0.49356017\n0.6707502       0.5421975\n\n(2,2,.,.) =\n0.007834963     0.08188637\n0.51387626      0.7376101\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x2x2]\n\nlayer.forward(input)\nres16: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.6680023\n\n(2,1,.,.) =\n0.41926455\n\n(3,1,.,.) =\n-0.029196609\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x1x1x1]\n\n\n\n\nPython example:\n\n\nlayer = VolumetricConvolution(2, 3, 2, 2, 2, d_t=1, d_w=1, d_h=1,\n          pad_t=0, pad_w=0, pad_h=0, with_bias=True, init_method=\ndefault\n,\n          bigdl_type=\nfloat\n)\ninput = np.random.rand(2,2,2,2)\n array([[[[ 0.47639062,  0.76800312],\n         [ 0.28834351,  0.21883535]],\n\n        [[ 0.86097919,  0.89812597],\n         [ 0.43632181,  0.58004824]]],\n\n\n       [[[ 0.65784027,  0.34700039],\n         [ 0.64511955,  0.1660241 ]],\n\n        [[ 0.36060054,  0.71265665],\n         [ 0.51755249,  0.6508298 ]]]])\n\nlayer.forward(input)\narray([[[[ 0.54268712]]],\n\n\n       [[[ 0.17670505]]],\n\n\n       [[[ 0.40953237]]]], dtype=float32)\n\n\n\n\n\n\n\nSpatialDilatedConvolution\n\n\nScala:\n\n\nval layer = SpatialDilatedConvolution(\n  inputPlanes,\n  outputPlanes,\n  kernelW,\n  kernelH,\n  strideW,\n  strideH,\n  paddingW,\n  paddingH,\n  dilationW,\n  dilationH\n)\n\n\n\n\nPython:\n\n\nlayer = SpatialDilatedConvolution(\n  inputPlanes,\n  outputPlanes,\n  kernelW,\n  kernelH,\n  strideW,\n  strideH,\n  paddingW,\n  paddingH,\n  dilationW,\n  dilationH\n)\n\n\n\n\nApply a 2D dilated convolution over an input image.\n\n\nThe input tensor in \nforward(input)\n is expected to be\neither a 4D tensor (\nbatch x nInputPlane x height x width\n) or a 3D tensor (\nnInputPlane x height x width\n).\noutput of \nforward(input)\n is also expected to be a 4D tensor (\nbatch x outputPlane x height x width\n)\nor a 3D tensor (\noutputPlane x height x width\n).\n\n\nFor a normal SpatialConvolution, the kernel will multiply with input\nimage element-by-element contiguous. In dilated convolution, it\u2019s possible\nto have filters that have spaces between each cell. For example, filter w and\nimage x, when dilatiionW and dilationH both = 1, this is normal 2D convolution\n\n\nw(0, 0) * x(0, 0), w(0, 1) * x(0, 1)\nw(1, 0) * x(1, 0), w(1, 1) * x(1, 1)\n\n\n\n\nwhen dilationW and dilationH both = 2\n\n\nw(0, 0) * x(0, 0), w(0, 1) * x(0, 2)\nw(1, 0) * x(2, 0), w(1, 1) * x(2, 2)\n\n\n\n\nwhen dilationW and dilationH both = 3\n\n\nw(0, 0) * x(0, 0), w(0, 1) * x(0, 3)\nw(1, 0) * x(3, 0), w(1, 1) * x(3, 3)\n\n\n\n\nIf input is a 3D tensor nInputPlane x height x width,\n * \nowidth  = floor(width + 2 * padW - dilationW * (kW-1) - 1) / dW + 1\n\n * \noheight = floor(height + 2 * padH - dilationH * (kH-1) - 1) / dH + 1\n\n\nReference Paper:\n\n\n\n\nYu F, Koltun V. Multi-scale context aggregation by dilated convolutions[J].\narXiv preprint arXiv:1511.07122, 2015.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = SpatialDilatedConvolution(1, 1, 2, 2, 1, 1, 0, 0, 2, 2)\nval input = Tensor(T(T(\n  T(1.0f, 2.0f, 3.0f, 4.0f),\n  T(5.0f, 6.0f, 7.0f, 8.0f),\n  T(9.0f, 1.0f, 2.0f, 3.0f),\n  T(4.0f, 5.0f, 6.0f, 7.0f)\n)))\nval filter = Tensor(T(T(T(\n  T(1.0f, 1.0f),\n  T(1.0f, 1.0f)\n))))\nlayer.weight.copy(filter)\nlayer.bias.zero()\nlayer.forward(input)\nlayer.backward(input, Tensor(T(T(\n  T(0.1f, 0.2f),\n  T(0.3f, 0.4f)\n))))\n\n\n\n\nGives the output,\n\n\n(1,.,.) =\n15.0    10.0\n22.0    26.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2]\n\n(1,.,.) =\n0.1     0.2     0.1     0.2\n0.3     0.4     0.3     0.4\n0.1     0.2     0.1     0.2\n0.3     0.4     0.3     0.4\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x4x4]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import SpatialDilatedConvolution\nimport numpy as np\n\nlayer = SpatialDilatedConvolution(1, 1, 2, 2, 1, 1, 0, 0, 2, 2)\ninput = np.array([[\n  [1.0, 2.0, 3.0, 4.0],\n  [5.0, 6.0, 7.0, 8.0],\n  [9.0, 1.0, 2.0, 3.0],\n  [4.0, 5.0, 6.0, 7.0]\n]])\nfilter = np.array([[[\n  [1.0, 1.0],\n  [1.0, 1.0]\n]]])\nbias = np.array([0.0])\nlayer.set_weights([filter, bias])\nlayer.forward(input)\nlayer.backward(input, np.array([[[0.1, 0.2], [0.3, 0.4]]]))\n\n\n\n\nGives the output,\n\n\narray([[[ 15.,  10.],\n        [ 22.,  26.]]], dtype=float32)\n\narray([[[ 0.1       ,  0.2       ,  0.1       ,  0.2       ],\n        [ 0.30000001,  0.40000001,  0.30000001,  0.40000001],\n        [ 0.1       ,  0.2       ,  0.1       ,  0.2       ],\n        [ 0.30000001,  0.40000001,  0.30000001,  0.40000001]]], dtype=float32)\n\n\n\n\n\n\n\nSpatialShareConvolution\n\n\nScala:\n\n\nval layer = SpatialShareConvolution(nInputPlane, nOutputPlane, kW, kH, dW, dH,\n      padW, padH)\n\n\n\n\nPython:\n\n\nlayer = SpatialShareConvolution(nInputPlane, nOutputPlane, kW, kH, dW, dH, padW, padH)\n\n\n\n\nApplies a 2D convolution over an input image composed of several input planes.\n The input tensor in \nforward(input)\n is expected to be\n either a 4D tensor (\nbatch x nInputPlane x height x width\n) or a 3D tensor (\nnInputPlane x height x width\n).\n output of \nforward(input)\n is also expected to be a 4D tensor (\nbatch x outputPlane x height x width\n)\n or a 3D tensor (\noutputPlane x height x width\n).\n\n\nThis layer has been optimized to save memory. If using this layer to construct multiple convolution\n layers, please add sharing script for the fInput and fGradInput. Please refer to the ResNet example.\n\n\nScala example:\n\n\n\n    import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n    import com.intel.analytics.bigdl.nn._\n    import com.intel.analytics.bigdl.tensor._\n\n    val nInputPlane = 1\n    val nOutputPlane = 1\n    val kW = 2\n    val kH = 2\n    val dW = 1\n    val dH = 1\n    val padW = 0\n    val padH = 0\n    val layer = SpatialShareConvolution(nInputPlane, nOutputPlane, kW, kH, dW, dH,\n      padW, padH)\n\n    val inputData = Array(\n      1.0, 2, 3, 1,\n      4, 5, 6, 1,\n      7, 8, 9, 1,\n      1.0, 2, 3, 1,\n      4, 5, 6, 1,\n      7, 8, 9, 1,\n      1.0, 2, 3, 1,\n      4, 5, 6, 1,\n      7, 8, 9, 1\n    )\n\n    val kernelData = Array(\n      2.0, 3,\n      4, 5\n    )\n\n    val biasData = Array(0.0)\n\n    layer.weight.copy(Tensor(Storage(kernelData), 1,\n      Array(nOutputPlane, nInputPlane, kH, kW)))\n    layer.bias.copy(Tensor(Storage(biasData), 1, Array(nOutputPlane)))\n\n    val input = Tensor(Storage(inputData), 1, Array(3, 1, 3, 4))\n    val output = layer.updateOutput(input)\n\n    \n output\nres2: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n49.0    63.0    38.0\n91.0    105.0   56.0\n\n(2,1,.,.) =\n49.0    63.0    38.0\n91.0    105.0   56.0\n\n(3,1,.,.) =\n49.0    63.0    38.0\n91.0    105.0   56.0\n\n\n\n\nPython example:\n\n\nnInputPlane = 1\nnOutputPlane = 1\nkW = 2\nkH = 2\ndW = 1\ndH = 1\npadW = 0\npadH = 0\nlayer = SpatialShareConvolution(nInputPlane, nOutputPlane, kW, kH, dW, dH, padW, padH)\n\ninput = np.array([\n      1.0, 2, 3, 1,\n      4, 5, 6, 1,\n      7, 8, 9, 1,\n      1.0, 2, 3, 1,\n      4, 5, 6, 1,\n      7, 8, 9, 1,\n      1.0, 2, 3, 1,\n      4, 5, 6, 1,\n      7, 8, 9, 1]\n    ).astype(\nfloat32\n).reshape(3, 1, 3, 4)\nlayer.forward(input)\n\n\n print (output)\narray([[[[-3.55372381, -4.0352459 , -2.65861344],\n         [-4.99829054, -5.4798131 , -3.29477644]]],\n\n\n       [[[-3.55372381, -4.0352459 , -2.65861344],\n         [-4.99829054, -5.4798131 , -3.29477644]]],\n\n\n       [[[-3.55372381, -4.0352459 , -2.65861344],\n         [-4.99829054, -5.4798131 , -3.29477644]]]], dtype=float32)\n\n\n\n\n\n\nSpatialFullConvolution\n\n\nScala:\n\n\nval m  = SpatialFullConvolution(nInputPlane, nOutputPlane, kW, kH, dW=1, dH=1, padW=0, padH=0, adjW=0, adjH=0,nGroup=1, noBias=false,wRegularizer=null,bRegularizer=null)\n\n\n\n\nPython:\n\n\nm = SpatialFullConvolution(n_input_plane,n_output_plane,kw,kh,dw=1,dh=1,pad_w=0,pad_h=0,adj_w=0,adj_h=0,n_group=1,no_bias=False,init_method='default',wRegularizer=None,bRegularizer=None)\n\n\n\n\nSpatialFullConvolution is a module that applies a 2D full convolution over an input image. \n\n\nThe input tensor in \nforward(input)\n is expected to be\neither a 4D tensor (\nbatch x nInputPlane x height x width\n) or a 3D tensor (\nnInputPlane x height x width\n).\noutput of \nforward(input)\n is also expected to be a 4D tensor (\nbatch x outputPlane x height x width\n)\nor a 3D tensor (\noutputPlane x height x width\n).\nThe convolution is performed on the last two dimensions. \nadjW\n and \nadjH\n are used to adjust the size of the output image. The size of output tensor of \nforward\n will be :\n\n\n  output width  = (width  - 1) * dW - 2*padW + kW + adjW\n  output height = (height - 1) * dH - 2*padH + kH + adjH\n\n\n\n\nNote, scala API also accepts a table input with two tensors: \nT(convInput, sizeTensor)\n where \nconvInput\n is the standard input tensor, and the size of \nsizeTensor\n is used to set the size of the output (will ignore the \nadjW\n and \nadjH\n values used to construct the module). Use \nSpatialFullConvolution[Table, T](...)\n instead of \nSpatialFullConvolution[Tensor,T](...)\n) for table input.\n\n\nThis module can also be used without a bias by setting parameter \nnoBias = true\n while constructing the module.\n\n\nOther frameworks may call this operation \"In-network Upsampling\", \"Fractionally-strided convolution\", \"Backwards Convolution,\" \"Deconvolution\", or \"Upconvolution.\"\n\n\nReference: Long J, Shelhamer E, Darrell T. Fully convolutional networks for semantic segmentation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015: 3431-3440.\n\n\nDetailed explanation of arguments in constructor. \n\n\n\n\nnInputPlane\n The number of expected input planes in the image given into forward()\n\n\nnOutputPlane\n The number of output planes the convolution layer will produce.\n\n\nkW\n The kernel width of the convolution.\n\n\nkH\n The kernel height of the convolution.\n\n\ndW\n The step of the convolution in the width dimension. Default is 1.\n\n\ndH\n The step of the convolution in the height dimension. Default is 1.\n\n\npadW\n The additional zeros added per width to the input planes. Default is 0.\n\n\npadH\n The additional zeros added per height to the input planes. Default is 0.\n\n\nadjW\n Extra width to add to the output image. Default is 0.\n\n\nadjH\n Extra height to add to the output image. Default is 0.\n\n\nnGroup\n Kernel group number.\n\n\nnoBias\n If bias is needed.\n\n\nwRegularizer\n instance of [[Regularizer]]\n                   (eg. L1 or L2 regularization), applied to the input weights matrices.\n\n\nbRegularizer\n instance of [[Regularizer]]\n                   applied to the bias.\n\n\n\n\nScala example:\n\n\nTensor Input example: \n\n\n\nscala\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval m = SpatialFullConvolution(1, 2, 2, 2, 1, 1,0, 0, 0, 0, 1, false)\n\nval input = Tensor(1,1,3,3).randn()\nval output = m.forward(input)\nval gradOut = Tensor(1,2,4,4).fill(0.1f)\nval gradIn = m.backward(input,gradOut)\n\nscala\n print(input)\n(1,1,.,.) =\n0.18219171      1.3252861       -1.3991559\n0.82611334      1.0313315       0.6075537\n-0.7336061      0.3156875       -0.70616096\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x1x3x3]\n\nscala\n print(output)\n(1,1,.,.) =\n-0.49278542     -0.5823938      -0.8304068      -0.077556044\n-0.5028842      -0.7281958      -1.1927067      -0.34262076\n-0.41680115     -0.41400516     -0.7599415      -0.42024887\n-0.5286566      -0.30015367     -0.5997892      -0.32439864\n\n(1,2,.,.) =\n-0.13131973     -0.5770084      1.1069719       -0.6003375\n-0.40302444     -0.07293816     -0.2654545      0.39749345\n0.37311426      -0.49090374     0.3088816       -0.41700447\n-0.12861171     0.09394867      -0.17229918     0.05556257\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4]\n\nscala\n print(gradOut)\n(1,1,.,.) =\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n\n(1,2,.,.) =\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x2x4x4]\n\nscala\n print(gradIn)\n(1,1,.,.) =\n-0.05955213     -0.05955213     -0.05955213\n-0.05955213     -0.05955213     -0.05955213\n-0.05955213     -0.05955213     -0.05955213\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x3x3]\n\n\n\n\n\n\nTable input Example\n\n\n\nscala\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.{T, Table}\n\nval m = SpatialFullConvolution(1, 2, 2, 2, 1, 1,0, 0, 0, 0, 1, false)\n\nval input1 = Tensor(1, 3, 3).randn()\nval input2 = Tensor(3, 3).fill(2.0f)\nval input = T(input1, input2)\nval output = m.forward(input)\nval gradOut = Tensor(2,4,4).fill(0.1f)\nval gradIn = m.backward(input,gradOut)\n\nscala\n print(input)\n {\n        2: 2.0  2.0     2.0\n           2.0  2.0     2.0\n           2.0  2.0     2.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n        1: (1,.,.) =\n           1.276177     0.62761325      0.2715257\n           -0.030832397 0.5046206       0.6835176\n           -0.5832693   0.17266633      0.7461992\n\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]\n }\n\nscala\n print(output)\n(1,.,.) =\n-0.18339296     0.04208675      -0.17708774     -0.30901802\n-0.1484881      0.23592418      0.115615785     -0.11288056\n-0.47266048     -0.41772115     0.07501307      0.041751802\n-0.4851033      -0.5427048      -0.18293871     -0.12682784\n\n(2,.,.) =\n0.6391188       0.845774        0.41208875      0.13754106\n-0.45785713     0.31221163      0.6006259       0.36563575\n-0.24076991     -0.31931365     0.31651747      0.4836449\n0.24247466      -0.16731171     -0.20887817     0.19513035\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x4]\n\nscala\n print(gradOut)\n(1,.,.) =\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n\n(2,.,.) =\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x4x4]\n\nscala\n print(gradIn)\n {\n        2: 0.0  0.0     0.0\n           0.0  0.0     0.0\n           0.0  0.0     0.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n        1: (1,.,.) =\n           0.16678208   0.16678208      0.16678208\n           0.16678208   0.16678208      0.16678208\n           0.16678208   0.16678208      0.16678208\n\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x3]\n }\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nm = SpatialFullConvolution(1, 2, 2, 2, 1, 1,0, 0, 0, 0, 1, False)\n\nprint \n--------- tensor input---------\n\ntensor_input = np.random.rand(1,3,3)\nprint \ninput is :\n,tensor_input\nout = m.forward(tensor_input)\nprint \noutput m is :\n,out\n\nprint \n----------- table input --------\n\nadj_input=np.empty([3,3])\nadj_input.fill(2.0)\ntable_input = [tensor_input,adj_input]\nprint \ninput is :\n,table_input\nout = m.forward(table_input)\nprint \noutput m is :\n,out\n\n\n\n\nGives the output,\n\n\ncreating: createSpatialFullConvolution\n--------- tensor input---------\ninput is : [[[  9.03998497e-01   4.43054896e-01   6.19571211e-01]\n  [  4.24573060e-01   3.29886286e-04   5.48427154e-02]\n  [  8.99004782e-01   3.25514441e-01   6.85294650e-01]]]\noutput m is : [[[-0.04712385  0.21949144  0.0843184   0.14336972]\n  [-0.28748769  0.39192575  0.00372696  0.27235305]\n  [-0.16292028  0.41943201  0.03476509  0.18813471]\n  [-0.28051955  0.29929382 -0.0689255   0.28749463]]\n\n [[-0.21336153 -0.35994443 -0.29239666 -0.38612381]\n  [-0.33000433 -0.41727966 -0.36827195 -0.34524575]\n  [-0.2410759  -0.38439807 -0.27613443 -0.39401439]\n  [-0.38188276 -0.36746511 -0.37627563 -0.34141305]]]\n----------- table input --------\ninput is : [array([[[  9.03998497e-01,   4.43054896e-01,   6.19571211e-01],\n        [  4.24573060e-01,   3.29886286e-04,   5.48427154e-02],\n        [  8.99004782e-01,   3.25514441e-01,   6.85294650e-01]]]), array([[ 2.,  2.,  2.],\n       [ 2.,  2.,  2.],\n       [ 2.,  2.,  2.]])]\noutput m is : [[[-0.04712385  0.21949144  0.0843184   0.14336972]\n  [-0.28748769  0.39192575  0.00372696  0.27235305]\n  [-0.16292028  0.41943201  0.03476509  0.18813471]\n  [-0.28051955  0.29929382 -0.0689255   0.28749463]]\n\n [[-0.21336153 -0.35994443 -0.29239666 -0.38612381]\n  [-0.33000433 -0.41727966 -0.36827195 -0.34524575]\n  [-0.2410759  -0.38439807 -0.27613443 -0.39401439]\n  [-0.38188276 -0.36746511 -0.37627563 -0.34141305]]]\n\n\n\n\n\n\nSpatialSeparableConvolution\n\n\nScala:\n\n\nval m  = SpatialSeparableConvolution(nInputChannel, nOutputChannel, depthMultiplier, kW, kH, sW = 1, sH = 1, pW = 0, pH = 0, hasBias = True, dataFormat = DataFormat.NCHW, wRegularizer = null, bRegularizer = null, pRegularizer = null, initDepthWeight = null, initPointWeight = null, initBias = null)\n\n\n\n\nPython:\n\n\nm = SpatialSeparableConvolution(n_input_channel, n_output_channel, depth_multiplier, kernel_w, kernel_h, stride_w=1, stride_h=1, pad_w=0, pad_h=0, with_bias=True, data_format=\nNCHW\n, w_regularizer=None, b_regularizer=None, p_regularizer=None)\n\n\n\n\nSeparable convolutions consist in first performing a depthwise spatial convolution (which acts\non each input channel separately) followed by a pointwise convolution which mixes together the\nresulting output channels. The  depthMultiplier argument controls how many output channels are\nenerated per input channel in the depthwise step.\n\n\n\n\nnInputChannel\n The number of expected input planes in the image given into forward()\n\n\nnOutputChannel\n The number of output planes the convolution layer will produce.\n\n\ndepthMultiplier\n how many internal channels are generated per input channel\n\n\nkW\n The kernel width of the convolution.\n\n\nkH\n The kernel height of the convolution.\n\n\nsW\n The step of the convolution in the width dimension.\n\n\nsH\n The step of the convolution in the height dimension.\n\n\npW\n The additional zeros added per width to the input planes. Default is 0.\n\n\npH\n The additional zeros added per height to the input planes. Default is 0.\n\n\nhasBias\n do we use a bias on the output, default is true\n\n\ndataFormat\n image data format, which can be NHWC or NCHW, default value is NCHW\n\n\nwRegularizer\n kernel parameter regularizer\n\n\nbRegularizer\n bias regularizer\n\n\npRegularizer\n point wise kernel parameter regularizer\n\n\ninitDepthWeight\n kernel parameter init tensor\n\n\ninitPointWeight\n point wise kernel parameter init tensor\n\n\ninitBias\n bias init tensor\n\n\n\n\nScala example:\n\n\n\nscala\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.nn.abstractnn.DataFormat\n\nval m = SpatialSeparableConvolution[Float](1, 2, 1, 2, 2, dataFormat = DataFormat.NCHW)\nval input = Tensor(1, 1, 3, 3).randn()\nval output = m.forward(input)\nval gradOut = Tensor(1, 2, 2, 2).fill(0.1f)\nval gradIn = m.backward(input,gradOut)\n\nscala\n print(input)\n(1,1,.,.) =\n-0.6636712      -1.3765892      -1.51044\n0.4502934       -0.38438025     -0.4279503\n-1.5327895      -0.33594692     1.5972415\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x1x3x3]\n\nscala\n print(output)\n(1,1,.,.) =\n-0.2903078      -0.5241474\n-0.17961408     -0.11239494\n\n(1,2,.,.) =\n-1.3147768      -2.3738143\n-0.81345534     -0.5090261\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x2]\n\nscala\n print(gradOut)\n(1,1,.,.) =\n0.1     0.1\n0.1     0.1\n\n(1,2,.,.) =\n0.1     0.1\n0.1     0.1\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x2x2x2]\n\nscala\n print(gradIn)\n(1,1,.,.) =\n0.088415675     0.17780215      0.08938648\n0.15242647      0.26159728      0.109170794\n0.06401079      0.08379511      0.019784318\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x3x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nm = SpatialSeparableConvolution(1, 2, 1, 2, 2)\ntensor_input = np.random.rand(1, 1, 3, 3)\nprint \ninput is :\n,tensor_input\nout = m.forward(tensor_input)\nprint \noutput m is :\n,out\n\n\n\n\nGives the output,\n\n\ncreating: createSpatialFullConvolution\ninput is : [[[[ 0.77269038  0.82476003  0.58228669]\n   [ 0.35123569  0.25496535  0.16736527]\n   [ 0.62138293  0.83156875  0.77565037]]]]\noutput m is : [[[[ 0.91489887  0.81591743]\n   [ 0.84698057  0.76615578]]\n\n  [[ 1.05583775  0.94160837]\n   [ 0.97745675  0.88418102]]]]\n\n\n\n\n\n\nSpatialConvolutionMap\n\n\nScala:\n\n\nval layer = SpatialConvolutionMap(\n  connTable,\n  kW,\n  kH,\n  dW = 1,\n  dH = 1,\n  padW = 0,\n  padH = 0,\n  wRegularizer = null,\n  bRegularizer = null)\n\n\n\n\nPython:\n\n\nlayer = SpatialConvolutionMap(\n  conn_table,\n  kw,\n  kh,\n  dw=1,\n  dh=1,\n  pad_w=0,\n  pad_h=0,\n  wRegularizer=None,\n  bRegularizer=None)\n\n\n\n\nThis class is a generalization of SpatialConvolution.\nIt uses a generic connection table between input and output features.\nThe SpatialConvolution is equivalent to using a full connection table.\n\nA Connection Table is the mapping of input/output feature map, stored in a 2D Tensor. The first column is the input feature maps. The second column is output feature maps.\n\n\nFull Connection table:\n\n\nval conn = SpatialConvolutionMap.full(nin: Int, nout: In)\n\n\n\n\nOne to One connection table:\n\n\nval conn = SpatialConvolutionMap.oneToOne(nfeat: Int)\n\n\n\n\nRandom Connection table:\n\n\nval conn = SpatialConvolutionMap.random(nin: Int, nout: Int, nto: Int)\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval conn = SpatialConvolutionMap.oneToOne(3)\n\n\n\n\nconn\n is\n\n\nconn: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0 1.0\n2.0 2.0\n3.0 3.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\n\n\n\nval module = SpatialConvolutionMap(SpatialConvolutionMap.oneToOne(3), 2, 2)\n\npritnln(module.forward(Tensor.range(1, 48, 1).resize(3, 4, 4)))\n\n\n\n\nGives the output,\n\n\ncom.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n4.5230045   5.8323975   7.1417904\n9.760576    11.069969   12.379362\n14.998148   16.30754    17.616934\n\n(2,.,.) =\n-5.6122046  -5.9227824  -6.233361\n-6.8545156  -7.165093   -7.4756703\n-8.096827   -8.407404   -8.71798\n\n(3,.,.) =\n13.534529   13.908197   14.281864\n15.029203   15.402873   15.77654\n16.523876   16.897545   17.271214\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = SpatialConvolutionMap(np.array([(1, 1), (2, 2), (3, 3)]), 2, 2)\n\nprint(module.forward(np.arange(1, 49, 1).reshape(3, 4, 4)))\n\n\n\n\nGives the output,\n\n\n[array([[[-1.24280548, -1.70889318, -2.17498088],\n        [-3.10715604, -3.57324386, -4.03933144],\n        [-4.97150755, -5.43759441, -5.90368223]],\n\n       [[-5.22062826, -5.54696751, -5.87330723],\n        [-6.52598572, -6.85232496, -7.17866373],\n        [-7.8313427 , -8.15768337, -8.48402214]],\n\n       [[ 0.5065825 ,  0.55170798,  0.59683061],\n        [ 0.68707776,  0.73219943,  0.77732348],\n        [ 0.86757064,  0.91269422,  0.95781779]]], dtype=float32)]\n\n\n\n\n\n\nTemporalConvolution\n\n\nScala:\n\n\nval module = TemporalConvolution(\n  inputFrameSize, outputFrameSize, kernelW, strideW = 1, propagateBack = true,\n  wRegularizer = null, bRegularizer = null, initWeight = null, initBias = null,\n  initGradWeight = null, initGradBias = null\n  )\n\n\n\n\nPython:\n\n\nmodule = TemporalConvolution(\n  input_frame_size, output_frame_size, kernel_w, stride_w = 1, propagate_back = True,\n  w_regularizer = None, b_regularizer = None, init_weight = None, init_bias = None,\n  init_grad_weight = None, init_grad_bias = None\n  )\n\n\n\n\nApplies a 1D convolution over an input sequence composed of nInputFrame frames.\n The input tensor in \nforward(input)\n is expected to be a 3D tensor\n (\nnBatchFrame\n x \nnInputFrame\n x \ninputFrameSize\n) or a 2D tensor\n (\nnInputFrame\n x \ninputFrameSize\n).\n Output of \nforward(input)\n is expected to be a 3D tensor\n (\nnBatchFrame\n x \nnOutputFrame\n x \noutputFrameSize\n) or a 2D tensor\n (\nnOutputFrame\n x \noutputFrameSize\n).\n\n\n\n\ninputFrameSize\n The input frame size expected in sequences given into \nforward()\n.\n\n\noutputFrameSize\n The output frame size the convolution layer will produce.\n\n\nkernelW\n The kernel width of the convolution\n\n\nstrideW\n The step of the convolution in the width dimension.\n\n\npropagateBack\n Whether propagate gradient back, default is true.\n\n\nwRegularizer\n instance of \nRegularizer\n\n                     (eg. L1 or L2 regularization), applied to the input weights matrices.\n\n\nbRegularizer\n instance of \nRegularizer\n\n                     applied to the bias.\n\n\ninitWeight\n Initial weight\n\n\ninitBias\n Initial bias\n\n\ninitGradWeight\n Initial gradient weight\n\n\ninitGradBias\n Initial gradient bias\n\n\nT\n The numeric type in the criterion, usually which are \nFloat\n or \nDouble\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nval seed = 100\nRNG.setSeed(seed)\nval inputFrameSize = 5\nval outputFrameSize = 3\nval kW = 5\nval dW = 2\nval layer = TemporalConvolution(inputFrameSize, outputFrameSize, kW, dW)\n\nRandom.setSeed(seed)\nval input = Tensor(10, 5).apply1(e =\n Random.nextFloat())\nval gradOutput = Tensor(3, 3).apply1(e =\n Random.nextFloat())\n\nval output = layer.updateOutput(input)\n\n println(output)\n2017-07-21 06:18:00 INFO  ThreadPool$:79 - Set mkl threads to 1 on thread 1\n-0.34987333 -0.0063185245   -0.45821175 \n-0.20838472 0.15102878  -0.5656665  \n-0.13935827 -0.099345684    -0.76407385 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nval gradInput = layer.updateGradInput(input, gradOutput)\n\n println(gradInput)\n0.018415622 -0.10201519 -0.15641063 -0.08271551 -0.060939234    \n0.13609992  0.14934899  0.06083451  -0.13943195 -0.11092151 \n-0.14552939 -0.024670592    -0.29887137 -0.14555064 -0.05840567 \n0.09920926  0.2705848   0.016875947 -0.27233958 -0.069991685    \n-0.0024300043   -0.15160085 -0.20593905 -0.2894306  -0.057458147    \n0.06390554  0.07710219  0.105445914 -0.26714328 -0.18871497 \n0.13901645  -0.10651534 0.006758575 -0.08754986 -0.13747974 \n-0.026543075    -0.044046614    0.13146847  -0.01198944 -0.030542556    \n0.18396454  -0.055985756    -0.03506116 -0.02156017 -0.09211717 \n0.0 0.0 0.0 0.0 0.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 10x5]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import TemporalConvolution\nimport numpy as np\ninputFrameSize = 5\noutputFrameSize = 3\nkW = 5\ndW = 2\nlayer = TemporalConvolution(inputFrameSize, outputFrameSize, kW, dW)\n\ninput = np.random.rand(10, 5)\ngradOutput = np.random.rand(3, 3)\n\noutput = layer.forward(input)\n\n print(output)\n[[ 0.43262666  0.52964264 -0.09026626]\n [ 0.46828389  0.3391096   0.04789509]\n [ 0.37985104  0.13899082 -0.05767119]]\n\ngradInput = layer.backward(input, gradOutput)\n\n print(gradInput)\n[[-0.08801709  0.03619258  0.06944641 -0.01570761  0.00682773]\n [-0.02754797  0.07474414 -0.08249797  0.04756897  0.0096445 ]\n [-0.14383194  0.05168077  0.27049363  0.10419817  0.05263135]\n [ 0.12452157 -0.02296585  0.14436334  0.02482709 -0.12260982]\n [ 0.04890725 -0.19043611  0.2909058  -0.10708418  0.07759682]\n [ 0.05745121  0.10499261  0.02989995  0.13047372  0.09119483]\n [-0.09693538 -0.12962547  0.22133902 -0.09149387  0.29208034]\n [ 0.2622599  -0.12875232  0.21714815  0.11484481 -0.00040091]\n [ 0.07558989  0.00072951  0.12860702 -0.27085134  0.10740379]\n [ 0.          0.          0.          0.          0.        ]]\n\n\n\n\n\n\n\nTemporalMaxPooling\n\n\nscala:\n\n\nval m = TemporalMaxPooling(k_w, d_w = k_w)\n\n\n\n\nm = TemporalMaxPooling(k_w, d_w = k_w)\n\n\n\n\nApplies 1D max-pooling operation in \nk_w\n regions by step size \nd_w\n steps.\nInput sequence composed of nInputFrame frames.\nThe input tensor in forward(input) is expected to be a 2D tensor\n(nInputFrame x inputFrameSize) or a 3D tensor (nBatchFrame x nInputFrame x inputFrameSize).\n\n\nIf the input sequence is a 2D tensor of dimension nInputFrame x inputFrameSize,\nthe output sequence will be nOutputFrame x inputFrameSize where\n\n\nnOutputFrame = (nInputFrame - k_w) / d_w + 1\n\n\n\n\n\n\nk_w: kernel width\n\n\nd_w: step size in width\n\n\n\n\nscala\n\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval module = TemporalMaxPooling(4)\nval input = Tensor(1, 8, 5).rand()\nval output = module.forward(input)\nval gradOutput = Tensor(1, 2, 5).rand()\nval gradInput = module.backward(input, gradOutput)\n\nscala\n\nprintln(output)\n(1,.,.) =\n0.6248109817970544  0.7783127573784441  0.8484677821397781  0.6721713887527585  0.9674506767187268  \n0.9587726043537259  0.8359494411852211  0.6541860734578222  0.7671433456707746  0.8246882800012827  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x5]\n\nscala\n\nprintln(gradInput)\n(1,.,.) =\n0.0 0.0 0.0 0.0 0.012729122070595622    \n0.0 0.1717955127824098  0.00636984477750957 0.0 0.0 \n0.0 0.0 0.0 0.24560829368419945 0.0 \n0.8350501179229468  0.0 0.0 0.0 0.0 \n0.0 0.9017464134376496  0.662078354973346   0.4239895506761968  0.0 \n0.09446275723166764 0.0 0.0 0.0 0.974747731583193   \n0.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x8x5]\n\n\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = TemporalMaxPooling(4)\ninput = np.random.rand(1, 8, 5)\noutput = module.forward(input)\ngrad_output = np.random.rand(1, 2, 5)\ngrad_input = module.backward(input, gradOutput)\n\nprint \noutput is :\n,output\nprint \ngradient input m is :\n,grad_input\n\n\n\n\ncreating: createTemporalMaxPooling\noutput is : [[[0.6248109817970544   0.7783127573784441  0.8484677821397781  0.6721713887527585  0.9674506767187268] \n[0.9587726043537259 0.8359494411852211  0.6541860734578222  0.7671433456707746  0.8246882800012827]]]   \ngradient input m is : [[[0.0    0.0 0.0 0.0 0.012729122070595622]   \n[0.0    0.1717955127824098  0.00636984477750957 0.0 0.0]    \n[0.0    0.0 0.0 0.24560829368419945 0.0 ]\n[0.8350501179229468 0.0 0.0 0.0 0.0 ]\n[0.0    0.9017464134376496  0.662078354973346   0.4239895506761968  0.0]    \n[0.09446275723166764    0.0 0.0 0.0 0.974747731583193]  \n[0.0    0.0 0.0 0.0 0.0]    \n[0.0    0.0 0.0 0.0 0.0]]]  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x8x5]\n\n\n\n\n\n\nVolumetricFullConvolution\n\n\nScala:\n\n\nval m  = VolumetricFullConvolution(\n  nInputPlane, nOutputPlane,\n  kT, kW, kH,\n  dT, dW = 1, dH = 1,\n  padT = 0, padW = 0, padH = 0,\n  adjT = 0, adjW = 0, adjH = 0,\n  nGroup=1, noBias=false,wRegularizer=null,bRegularizer=null)\n\n\n\n\nPython:\n\n\nm = VolumetricFullConvolution(\n    n_input_plane, n_output_plane,\n    kt, kw, kh, \n    dt=1, dw=1,dh=1,\n    pad_t=0, pad_w=0, pad_h=0, \n    adj_t=0, adj_w=0,adj_h=0,\n    n_group=1,no_bias=False,init_method='default',wRegularizer=None,bRegularizer=None)\n\n\n\n\nVolumetricFullConvolution\n Apply a 3D full convolution over an 3D input image, a sequence of images, or a video etc.\nThe input tensor is expected to be a 4D or 5D(with batch) tensor. Note that instead\nof setting adjT, adjW and adjH, \nVolumetricConvolution\n also accepts a table input\nwith two tensors: T(convInput, sizeTensor) where convInput is the standard input tensor,\nand the size of sizeTensor is used to set the size of the output (will ignore the adjT, adjW and\nadjH values used to construct the module). This module can be used without a bias by setting\nparameter noBias = true while constructing the module.\n\n\nApplies a 3D convolution over an input image composed of several input planes. The input tensor\nin forward(input) is expected to be a 5D tensor (\nbatch x nInputPlane x depth(time) x height x width\n) or\na 4D tensor (\nnInputPlane x depth x height x width\n).\nOutput of forward(input) is also expected to be a 5D tensor (\nbatch x depth(time) x outputPlane x height x width\n) or\na 4D tensor (\noutputPlane x depth x height x width\n).\n\n\nodepth  = (depth  - 1) * dT - 2*padT + kT + adjT\nowidth  = (width  - 1) * dW - 2*padW + kW + adjW\noheight = (height - 1) * dH - 2*padH + kH + adjH\n\n\n\n\nOther frameworks call this operation \"In-network Upsampling\", \"Fractionally-strided convolution\",\n\"Backwards Convolution,\" \"Deconvolution\", or \"Upconvolution.\"\n\n\nReference Paper: Long J, Shelhamer E, Darrell T. Fully convolutional networks for semantic\nsegmentation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.\n2015: 3431-3440.\n\n\n\n\nnInputPlane The number of expected input planes in the image given into forward()\n\n\nnOutputPlane The number of output planes the convolution layer will produce.\n\n\nkT The kernel depth of the convolution.\n\n\nkW The kernel width of the convolution.\n\n\nkH The kernel height of the convolution.\n\n\ndT The step of the convolution in the depth dimension. Default is 1.\n\n\ndW The step of the convolution in the width dimension. Default is 1.\n\n\ndH The step of the convolution in the height dimension. Default is 1.\n\n\npadT The additional zeros added per depth to the input planes. Default is 0.\n\n\npadW The additional zeros added per width to the input planes. Default is 0.\n\n\npadH The additional zeros added per height to the input planes. Default is 0.\n\n\nadjT Extra depth to add to the output image. Default is 0.\n\n\nadjW Extra width to add to the output image. Default is 0.\n\n\nadjH Extra height to add to the output image. Default is 0.\n\n\nnGroup Kernel group number.\n\n\nnoBias If bias is needed.\n\n\nwRegularizer: instance of \nRegularizer\n\n\n(eg. L1 or L2 regularization), applied to the input weights matrices.\n\n\nbRegularizer: instance of \nRegularizer\n\n                   applied to the bias.\n\n\n\n\nScala example:\n\n\nTensor Input example: \n\n\nscala\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval m = VolumetricFullConvolution(2, 1, 2, 2, 2)\n\nval input = Tensor(1, 2, 2, 3, 3).randn()\nval output = m.forward(input)\nval gradOut = Tensor(1, 1, 3, 4, 4).fill(0.2f)\nval gradIn = m.backward(input, gradOut)\n\nscala\n println(input)\n(1,1,1,.,.) =\n0.3903321   -0.90453357 1.735308    \n-1.2824814  -0.27802613 -0.3977802  \n-0.08534186 0.6385388   -0.86845094 \n\n(1,1,2,.,.) =\n-0.24652982 0.69465446  0.1713606   \n0.07106233  -0.88137305 1.0625362   \n-0.553569   1.1822331   -2.2488093  \n\n(1,2,1,.,.) =\n0.552869    0.4108489   1.7802315   \n0.018191056 0.72422534  -0.6423254  \n-0.4077748  0.024120487 -0.42820823 \n\n(1,2,2,.,.) =\n-1.3711191  -0.37988988 -2.1587164  \n-0.85155743 -1.5785019  -0.77727056 \n0.42253423  0.79593533  0.15303874  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x2x2x3x3]\n\nscala\n println(output)\n(1,1,1,.,.) =\n-0.29154167 -0.027156994    -0.6949123  -0.22638178 \n0.091479614 -0.106284864    -0.23198327 -0.5334093  \n0.092822656 -0.13807209 -0.07207352 -0.023272723    \n-0.19217497 -0.18892932 -0.089907974    -0.059967346    \n\n(1,1,2,.,.) =\n0.08078699  -0.0242998  0.27271587  0.48551774  \n-0.30726838 0.5497404   -0.7220843  0.48132813  \n0.007951438 -0.39301366 0.56711966  -0.39552623 \n-0.016941413    -0.5530351  0.21254264  -0.22647215 \n\n(1,1,3,.,.) =\n-0.38189644 -0.5241636  -0.49781954 -0.59505236 \n-0.23887709 -0.99911994 -0.773817   -0.63575095 \n-0.1193203  0.016682416 -0.41216886 -0.5211964  \n-0.06341652 -0.32541442 0.43984014  -0.16862796 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x3x4x4]\n\nscala\n println(gradOut)\n(1,1,1,.,.) =\n0.2 0.2 0.2 0.2 \n0.2 0.2 0.2 0.2 \n0.2 0.2 0.2 0.2 \n0.2 0.2 0.2 0.2 \n\n(1,1,2,.,.) =\n0.2 0.2 0.2 0.2 \n0.2 0.2 0.2 0.2 \n0.2 0.2 0.2 0.2 \n0.2 0.2 0.2 0.2 \n\n(1,1,3,.,.) =\n0.2 0.2 0.2 0.2 \n0.2 0.2 0.2 0.2 \n0.2 0.2 0.2 0.2 \n0.2 0.2 0.2 0.2 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x1x3x4x4]\nscala\n println(gradIn)\n(1,1,1,.,.) =\n-0.089189366    -0.089189366    -0.089189366    \n-0.089189366    -0.089189366    -0.089189366    \n-0.089189366    -0.089189366    -0.089189366    \n\n(1,1,2,.,.) =\n-0.089189366    -0.089189366    -0.089189366    \n-0.089189366    -0.089189366    -0.089189366    \n-0.089189366    -0.089189366    -0.089189366    \n\n(1,2,1,.,.) =\n0.06755526  0.06755526  0.06755526  \n0.06755526  0.06755526  0.06755526  \n0.06755526  0.06755526  0.06755526  \n\n(1,2,2,.,.) =\n0.06755526  0.06755526  0.06755526  \n0.06755526  0.06755526  0.06755526  \n0.06755526  0.06755526  0.06755526  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x3x3]\n\n\n\n\n\nTable input Example\n\n\nscala\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.T\n\nval m = VolumetricFullConvolution(1, 2, 2, 2, 2)\n\nval input1 = Tensor(1, 3, 3, 3).randn()\nval input2 = Tensor(3, 3, 3).fill(2.0f)\nval input = T(input1, input2)\nval output = m.forward(input)\nval gradOut = Tensor(2, 4, 4, 4).fill(0.1f)\nval gradIn = m.backward(input, gradOut)\n\nscala\n println(input)\n{\n  2: (1,.,.) =\n  2.0   2.0 2.0\n  2.0   2.0 2.0\n  2.0   2.0 2.0\n\n  (2,.,.) =\n  2.0   2.0 2.0\n  2.0   2.0 2.0\n  2.0   2.0 2.0\n\n  (3,.,.) =\n  2.0   2.0 2.0\n  2.0   2.0 2.0\n  2.0   2.0 2.0\n\n  [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3x3]\n  1: (1,1,.,.) =\n  0.23809154    1.2167819   0.3664989\n  0.8797001 1.5262067   0.15420714\n  0.38004395    -0.24190372 -1.1151218\n\n  (1,2,.,.) =\n  -1.895742 1.8554556   0.62502027\n  -0.6004498    0.056441266 -0.66499823\n  0.7039313 -0.08569297 -0.08191566\n\n  (1,3,.,.) =\n  -1.9555066    -0.20133287 -0.22135374\n  0.8918014 -1.2684877  0.14211883\n  2.5802526 1.1118578   -1.3165624\n\n  [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3x3]\n}\n\nscala\n println(output)\n(1,1,.,.) =\n-0.2578445  -0.48271507 -0.28246504 -0.20139077\n-0.43916196 -0.72301924 -0.2915339  -0.20471849\n-0.41347015 -0.36456454 0.021684423 -0.20852578\n-0.255981   -0.17165771 -0.04553239 -0.19543594\n\n(1,2,.,.) =\n0.18660262  -0.8204256  -0.08807768 -0.1023551\n0.026309028 -0.49442527 0.3699256   -0.12729678\n-0.34651133 0.08542377  0.24221262  -0.47949657\n-0.29622912 -0.15598825 -0.23278731 -0.32802662\n\n(1,3,.,.) =\n0.6303606   -1.0451282  0.21740273  -0.03673452\n-0.039471984    -0.2264648  0.15774214  -0.30815765\n-1.0726243  -0.13914594 0.08537227  -0.30611742\n-0.55404246 -0.29725668 -0.037192106    -0.20331946\n\n(1,4,.,.) =\n0.19113302  -0.68506914 -0.21211714 -0.26207167\n-0.40826926 0.068062216 -0.5962198  -0.18985644\n-0.7111124  0.3466564   0.2185097   -0.5388211\n-0.16902745 0.10249108  -0.09487718 -0.35127735\n\n(2,1,.,.) =\n-0.2744591  -0.21165672 -0.17422867 -0.25680506\n-0.24608877 -0.1242196  -0.02206999 -0.23146236\n-0.27057967 -0.17076656 -0.18083718 -0.35417527\n-0.28634468 -0.24118122 -0.30961025 -0.41247135\n\n(2,2,.,.) =\n-0.41682464 -0.5772195  -0.159199   -0.2294753\n-0.41187716 -0.41886678 0.4104582   -0.1382559\n-0.08818802 0.459113    0.48080307  -0.3373265\n-0.18515268 -0.14088067 -0.67644227 -0.67253566\n\n(2,3,.,.) =\n-0.009801388    -0.83997947 -0.39409852 -0.29002026\n-0.6333371  -0.66267097 0.52607954  -0.10082486\n-0.46748784 -0.08717018 -0.54928875 -0.59819674\n-0.103552   0.22147804  -0.20562811 -0.46321797\n\n(2,4,.,.) =\n0.090245515 -0.28537494 -0.24673338 -0.289634\n-0.98199505 -0.7408645  -0.4654177  -0.35744694\n-0.5410351  -0.48618284 -0.40212065 -0.26319134\n0.4081596   0.8880725   -0.26220837 -0.73146355\n\n  [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x4x4]\n\nscala\n println(gradOut)\n(1,1,.,.) =\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n\n(1,2,.,.) =\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n\n(1,3,.,.) =\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n\n(1,4,.,.) =\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n\n(2,1,.,.) =\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n\n(2,2,.,.) =\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n\n(2,3,.,.) =\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n\n(2,4,.,.) =\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n\n  [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x4x4x4]\n\nscala\n println(gradIn)\n{\n  2: (1,.,.) =\n  0.0   0.0 0.0\n  0.0   0.0 0.0\n  0.0   0.0 0.0\n\n  (2,.,.) =\n  0.0   0.0 0.0\n  0.0   0.0 0.0\n  0.0   0.0 0.0\n\n  (3,.,.) =\n  0.0   0.0 0.0\n  0.0   0.0 0.0\n  0.0   0.0 0.0\n\n  [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3x3]\n  1: (1,1,.,.) =\n  0.048819613   0.048819613 0.048819613\n  0.048819613   0.048819613 0.048819613\n  0.048819613   0.048819613 0.048819613\n\n  (1,2,.,.) =\n  0.048819613   0.048819613 0.048819613\n  0.048819613   0.048819613 0.048819613\n  0.048819613   0.048819613 0.048819613\n\n  (1,3,.,.) =\n  0.048819613   0.048819613 0.048819613\n  0.048819613   0.048819613 0.048819613\n  0.048819613   0.048819613 0.048819613\n\n  [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x3x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nm = VolumetricFullConvolution(2, 1, 2, 2, 2)\n\nprint \n--------- tensor input---------\n\ntensor_input = np.random.rand(1, 2, 2, 3, 3)\nprint \ninput is :\n,tensor_input\nout = m.forward(tensor_input)\nprint \noutput m is :\n,out\n\nprint \n----------- table input --------\n\nadj_input=np.empty([3, 3, 3])\nadj_input.fill(2.0)\ntable_input = [tensor_input,adj_input]\nprint \ninput is :\n,table_input\nout = m.forward(table_input)\nprint \noutput m is :\n,out\n\n\n\n\ncreating: createVolumetricFullConvolution\n--------- tensor input---------\ninput is : [[[[[ 0.41632522  0.62726142  0.11133406]\n    [ 0.61013369  0.76320391  0.27937597]\n    [ 0.3596402   0.85087329  0.18706284]]\n\n   [[ 0.19224562  0.79333622  0.02064112]\n    [ 0.34019388  0.36193739  0.0189533 ]\n    [ 0.01245767  0.59638721  0.97882726]]]\n\n\n  [[[ 0.03641869  0.92804035  0.08934243]\n    [ 0.96598196  0.54331079  0.9157464 ]\n    [ 0.31659511  0.48128023  0.13775686]]\n\n   [[ 0.44624135  0.02830871  0.95668413]\n    [ 0.32971474  0.46466264  0.58239329]\n    [ 0.94129846  0.27284845  0.59931096]]]]]\noutput m is : [[[[[ 0.24059629  0.11875484 -0.07601731  0.18490529]\n    [ 0.17978033 -0.05925606 -0.06877603 -0.00254188]\n    [ 0.33574528  0.10908454 -0.01606898  0.22380096]\n    [ 0.24050319  0.17277193  0.10569186  0.20417407]]\n\n   [[ 0.26733595  0.26336247 -0.16927747  0.04417276]\n    [ 0.39058518 -0.08025722 -0.11981271  0.08441451]\n    [ 0.21994853 -0.1127445  -0.01282334 -0.25795668]\n    [ 0.34960991  0.17045188  0.0885388   0.08292522]]\n\n   [[ 0.29700345  0.22094724  0.27189076  0.07538646]\n    [ 0.27829763  0.01766421  0.32052374 -0.09809484]\n    [ 0.28885722  0.08438809  0.24915564 -0.08578731]\n    [ 0.25339472 -0.09679155  0.09070791  0.21198538]]]]]\n----------- table input --------\ninput is : [array([[[[[ 0.41632522,  0.62726142,  0.11133406],\n          [ 0.61013369,  0.76320391,  0.27937597],\n          [ 0.3596402 ,  0.85087329,  0.18706284]],\n\n         [[ 0.19224562,  0.79333622,  0.02064112],\n          [ 0.34019388,  0.36193739,  0.0189533 ],\n          [ 0.01245767,  0.59638721,  0.97882726]]],\n\n\n        [[[ 0.03641869,  0.92804035,  0.08934243],\n          [ 0.96598196,  0.54331079,  0.9157464 ],\n          [ 0.31659511,  0.48128023,  0.13775686]],\n\n         [[ 0.44624135,  0.02830871,  0.95668413],\n          [ 0.32971474,  0.46466264,  0.58239329],\n          [ 0.94129846,  0.27284845,  0.59931096]]]]]), array([[[ 2.,  2.,  2.],\n        [ 2.,  2.,  2.],\n        [ 2.,  2.,  2.]],\n\n       [[ 2.,  2.,  2.],\n        [ 2.,  2.,  2.],\n        [ 2.,  2.,  2.]],\n\n       [[ 2.,  2.,  2.],\n        [ 2.,  2.,  2.],\n        [ 2.,  2.,  2.]]])]\noutput m is : [[[[[ 0.24059629  0.11875484 -0.07601731  0.18490529]\n    [ 0.17978033 -0.05925606 -0.06877603 -0.00254188]\n    [ 0.33574528  0.10908454 -0.01606898  0.22380096]\n    [ 0.24050319  0.17277193  0.10569186  0.20417407]]\n\n   [[ 0.26733595  0.26336247 -0.16927747  0.04417276]\n    [ 0.39058518 -0.08025722 -0.11981271  0.08441451]\n    [ 0.21994853 -0.1127445  -0.01282334 -0.25795668]\n    [ 0.34960991  0.17045188  0.0885388   0.08292522]]\n\n   [[ 0.29700345  0.22094724  0.27189076  0.07538646]\n    [ 0.27829763  0.01766421  0.32052374 -0.09809484]\n    [ 0.28885722  0.08438809  0.24915564 -0.08578731]\n    [ 0.25339472 -0.09679155  0.09070791  0.21198538]]]]]\n\n\n\n\n\n\nLocallyConnected1D\n\n\nScala:\n\n\nval module = LocallyConnected1D(\n  nInputFrame,inputFrameSize, outputFrameSize, kernelW, strideW = 1, propagateBack = true,\n  wRegularizer = null, bRegularizer = null, initWeight = null, initBias = null,\n  initGradWeight = null, initGradBias = null)\n\n\n\n\nPython:\n\n\nmodule = LocallyConnected1D(\n  n_input_frame, input_frame_size, output_frame_size, kernel_w, stride_w=1, propagate_back=True,\n  w_regularizer=None, b_regularizer=None, init_weight=None, init_bias=None,\n  init_grad_weight=None, init_grad_bias=None)\n\n\n\n\nApplies a 1D convolution over an input sequence composed of nInputFrame frames with unshared weights.\n The input tensor in \nforward(input)\n is expected to be a 3D tensor\n (\nnBatchFrame\n x \nnInputFrame\n x \ninputFrameSize\n) or a 2D tensor\n (\nnInputFrame\n x \ninputFrameSize\n).\n Output of \nforward(input)\n is expected to be a 3D tensor\n (\nnBatchFrame\n x \nnOutputFrame\n x \noutputFrameSize\n) or a 2D tensor\n (\nnOutputFrame\n x \noutputFrameSize\n).\n\n\n\n\nnInputFrame\n Length of the input frame expected in sequences given into \nforward()\n.\n\n\ninputFrameSize\n The input frame size expected in sequences given into \nforward()\n.\n\n\noutputFrameSize\n The output frame size the convolution layer will produce.\n\n\nkernelW\n The kernel width of the convolution\n\n\nstrideW\n The step of the convolution in the width dimension.\n\n\npropagateBack\n Whether propagate gradient back, default is true.\n\n\nwRegularizer\n instance of \nRegularizer\n\n                 (eg. L1 or L2 regularization), applied to the input weights matrices.\n\n\nbRegularizer\n instance of \nRegularizer\n\n                 applied to the bias.\n\n\ninitWeight\n Initial weight\n\n\ninitBias\n Initial bias\n\n\ninitGradWeight\n Initial gradient weight\n\n\ninitGradBias\n Initial gradient bias\n\n\nT\n The numeric type in the criterion, usually which are \nFloat\n or \nDouble\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nval seed = 100\nRNG.setSeed(seed)\nval nInputFrame = 10\nval inputFrameSize = 5\nval outputFrameSize = 3\nval kW = 5\nval dW = 2\nval layer = LocallyConnected1D(nInputFrame, inputFrameSize, outputFrameSize, kW, dW)\n\nRandom.setSeed(seed)\nval input = Tensor(10, 5).apply1(e =\n Random.nextFloat())\nval gradOutput = Tensor(3, 3).apply1(e =\n Random.nextFloat())\n\nval output = layer.updateOutput(input)\n\n println(output)\n(1,.,.) =\n-0.2896616  0.018883035 -0.45641226 \n-0.41183263 -0.33292565 0.27988705  \n0.076636955 -0.39710814 0.59631383  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nval gradInput = layer.updateGradInput(input, gradOutput)\n\n println(gradInput)\n(1,.,.) =\n0.018415622  -0.10201519  -0.15641063   -0.08271551   -0.060939234  \n0.13609992   0.14934899   0.06083451    -0.13943195   -0.11092151   \n-0.08760113  0.06923811   -0.07376863   0.06743649    0.042455398   \n0.064692274  0.15720972   0.13673763    0.03617531    0.12507091    \n-0.078272685 -0.25193688  0.10712688    -0.11330205   -0.19239372   \n-0.10032463  -0.06266674  0.1048636     0.26058376    -0.40386787   \n-0.10379471  0.07291742   -0.28790376   0.06023993    0.057165086   \n0.15167418   0.07384029   -0.052450493  -0.07709345   -0.016432922  \n-0.1044948   0.060714033  0.08341185    -0.082587965  0.052750245   \n0.0          0.0          0.0           0.0           0.0   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 10x5]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import LocallyConnected1D\nimport numpy as np\nnInputFrame = 10\ninputFrameSize = 5\noutputFrameSize = 3\nkW = 5\ndW = 2\nlayer = LocallyConnected1D(nInputFrame, inputFrameSize, outputFrameSize, kW, dW)\n\ninput = np.random.rand(10, 5)\ngradOutput = np.random.rand(3, 3)\n\noutput = layer.forward(input)\n\n print(output)\n[[ 0.37944531 -0.25905907 -0.02284177]\n [-0.06727666 -0.48430425 -0.12338555]\n [ 0.5237388  -0.72521925 -0.21979821]]\n\ngradInput = layer.backward(input, gradOutput)\n\n print(gradInput)\n[[-0.22256926 -0.11267932  0.05445758 -0.06569604  0.00799843]\n [ 0.08402308  0.00340014  0.04202492 -0.05055574  0.11835655]\n [ 0.00352848 -0.02568576 -0.08056175  0.06994451  0.09152003]\n [ 0.04089724 -0.19517297  0.19212601 -0.21531224  0.03563112]\n [-0.28906721  0.07873128 -0.01326483 -0.18504807  0.02452871]\n [-0.09979478 -0.1009931  -0.25594842  0.14314197 -0.30875987]\n [-0.00814501 -0.02431242 -0.1140819  -0.14522757 -0.09230929]\n [-0.11231296  0.0053857   0.00582423  0.18309449  0.13369997]\n [-0.01302226 -0.13035376  0.02006471  0.09794775 -0.08067283]\n [ 0.          0.          0.          0.          0.        ]]\n\n\n\n\n\n\n\nLocallyConnected2D\n\n\nScala:\n\n\nval module = LocallyConnected2D(\n   nInputPlane, inputWidth, inputHeight, nOutputPlane, kernelW, kernelH, \n   strideW = 1, strideH = 1, padW = 0, padH = 0, propagateBack = true, \n   wRegularizer = null, bRegularizer = null, initWeight = null, initBias = null,\n   initGradWeight = null, initGradBias = null, withBias = true, format = DataFormat.NCHW)\n\n\n\n\nPython:\n\n\nmodule = LocallyConnected2D(\n    n_input_plane, input_width, input_height, n_output_plane,\n    kernel_w, kernel_h, stride_w=1, stride_h=1, pad_w=0, pad_h=0,\n    propagate_back=True, wRegularizer=None, bRegularizer=None,\n    init_weight=None, init_bias=None, init_grad_weight=None,\n    init_grad_bias=None, with_bias=True, data_format=\nNCHW\n)\n\n\n\n\nThe LocallyConnected2D layer works similarly to the \nSpatialConvolution\n layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.\n\n\n\n\nnInputPlane\n The number of expected input planes in the image.\n\n\ninputWidth\n The input width.\n\n\ninputHeight\n The input height.\n\n\nnOutputPlane\n The number of output planes the convolution layer will produce.\n\n\nkernelW\n The kernel width of the convolution.\n\n\nkernelH\n The kernel height of the convolution.\n\n\nstrideW\n The step of the convolution in the width dimension.\n\n\nstrideH\n The step of the convolution in the height dimension.\n\n\npadW\n The additional zeros added per width to the input planes.\n\n\npadH\n The additional zeros added per height to the input planes.\n\n\npropagateBack\n Whether to propagate gradient back.\n\n\nwRegularizer\n Weight regularizer.\n\n\nbRegularizer\n Bias regularizer.\n\n\ninitWeight\n Initial weight.\n\n\ninitBias\n Initial bias.\n\n\ninitGradWeight\n Initial gradient weight.\n\n\ninitGradBias\n Initial gradient bias.\n\n\nwithBias\n Whether to include bias.\n\n\nformat\n Data format of the input. Either \"NHWC\" or \"NCHW\".\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.abstractnn.DataFormat\nimport com.intel.analytics.bigdl.nn.LocallyConnected2D\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval layer = LocallyConnected2D(2, 6, 3, 3, 1, 2, format=DataFormat.NHWC)\nval input = Tensor(1, 3, 6, 2).rand()\nval output = layer.forward(input)\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.580334    0.59774524\n0.35452667  0.9134508\n0.56355035  0.10698065\n0.95197415  0.10339011\n0.6571263   0.35572186\n0.31106102  0.97996104\n\n(1,2,.,.) =\n0.87887615  0.8108329\n0.7184107   0.487163\n0.85714895  0.30265027\n0.4407469   0.94804007\n0.5460197   0.01421738\n0.74672765  0.23766468\n\n(1,3,.,.) =\n0.10655104  0.008004449\n0.142883    0.7885532\n0.12025218  0.9536053\n0.85908693  0.088657066\n0.42529714  0.64380044\n0.8999299   0.6074533\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x6x2]\n\n\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.7493179     0.27513236    -0.2982489\n-0.41126582   0.21310717    0.36723173\n-0.039210618  0.13379198    -0.28216434\n0.19143593    -0.61731964   -0.018212453\n0.24316064    -1.1187351    0.74201244\n0.060099036   -0.5223875    -0.95892024\n\n(1,2,.,.) =\n-0.4977209   0.19270697    -0.00647337\n-0.18642347  -0.057786018  0.33848432\n0.044415057  -0.12975587   -0.054034393\n0.46163      0.06908426    -0.17127737\n-0.07933617  0.190754      0.6044696\n-0.723027    0.14250416    0.51286244\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x6x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.layer import LocallyConnected2D\n\nlayer = LocallyConnected2D(2, 6, 3, 3, 1, 2, data_format=\nNHWC\n)\ninput = np.random.rand(1, 3, 6, 2)\noutput = layer.forward(input)\n\nprint(input)\n[[[[  6.13867469e-01,   5.15609721e-01],\n   [  5.14951616e-01,   4.93308310e-01],\n   [  7.34218405e-01,   6.06311945e-01],\n   [  9.38263668e-01,   3.26766196e-01],\n   [  4.24955447e-02,   3.30625440e-01],\n   [  3.55858423e-01,   6.10869469e-01]],\n\n  [[  3.75525334e-02,   4.93555936e-02],\n   [  4.44188497e-01,   3.51001813e-02],\n   [  8.11139320e-01,   4.87916727e-01],\n   [  4.00786464e-01,   1.65522882e-01],\n   [  5.98298525e-01,   9.54343135e-01],\n   [  2.25942857e-01,   5.76090257e-02]],\n\n  [[  1.34708024e-01,   4.81133433e-01],\n   [  7.63198918e-01,   2.96906096e-01],\n   [  6.01935030e-01,   2.39748841e-01],\n   [  5.32036004e-01,   1.86107334e-01],\n   [  9.38617798e-01,   6.83511632e-04],\n   [  2.34639435e-01,   8.04904706e-01]]]]\n\nprint(output)\n[[[[-0.01100884,  0.59226239, -0.15626255],\n   [ 0.29099607,  0.16722232, -0.39429453],\n   [ 0.22557285,  0.30368266,  0.53235221],\n   [ 0.05602939, -0.07677993, -0.32399753],\n   [ 0.47589377, -0.15926963,  0.1135996 ],\n   [ 0.25957716,  0.17047183,  0.21640816]],\n\n  [[-0.15497619,  0.29392233, -0.12167639],\n   [ 0.60150111, -0.001901  ,  0.294438  ],\n   [-0.05004713,  0.22379839,  0.53971994],\n   [ 0.23204027,  0.17921877,  0.29594338],\n   [ 0.91105354,  0.881271  , -0.69958985],\n   [ 0.45518994, -0.645486  ,  0.37325871]]]]\n\n\n\n\n\n\nUpSampling1D\n\n\nScala:\n\n\nval module = UpSampling1D(length: Int)\n\n\n\n\nPython:\n\n\nm = UpSampling1D(length)\n\n\n\n\nUpSampling layer for 1D inputs. Repeats each temporal step length times along the time axis. \n\n\nIf input's size is (batch, steps, features), then the output's size will be (batch, steps * length, features). \n\n\nScala example:\n \n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.T\n\nval module = UpSampling1D(2)\nval input = Tensor(2, 3, 3).range(1, 18)\nmodule.forward(input)\n\n\n\n\nThe output should be \n\n\nres: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.0 2.0 3.0\n1.0 2.0 3.0\n4.0 5.0 6.0\n4.0 5.0 6.0\n7.0 8.0 9.0\n7.0 8.0 9.0\n\n(2,.,.) =\n10.0    11.0    12.0\n10.0    11.0    12.0\n13.0    14.0    15.0\n13.0    14.0    15.0\n16.0    17.0    18.0\n16.0    17.0    18.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x6x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\ninput = np.random.rand(1,2,2,2,2)\nprint \ninput is :\n,input\n\nm = UpSampling3D([2,2,2])\nout = m.forward(input)\nprint \noutput m is :\n,out\n\n\n\n\nGives the output,\n\n\ninput is : \n[[[[[ 0.80314148  0.79158609]\n    [ 0.3988551   0.91726511]]\n   [[ 0.86814757  0.90733343]\n    [ 0.34470172  0.03056507]]]\n\n  [[[ 0.62367481  0.20093996]\n    [ 0.57614891  0.75442351]]\n   [[ 0.52572424  0.04730832]\n    [ 0.74973562  0.2245238 ]]]]]\ncreating: createUpSampling3D\noutput m is : \n[[[[[ 0.80314147  0.80314147  0.7915861   0.7915861 ]\n    [ 0.80314147  0.80314147  0.7915861   0.7915861 ]\n    [ 0.39885509  0.39885509  0.91726512  0.91726512]\n    [ 0.39885509  0.39885509  0.91726512  0.91726512]]\n\n   [[ 0.80314147  0.80314147  0.7915861   0.7915861 ]\n    [ 0.80314147  0.80314147  0.7915861   0.7915861 ]\n    [ 0.39885509  0.39885509  0.91726512  0.91726512]\n    [ 0.39885509  0.39885509  0.91726512  0.91726512]]\n\n   [[ 0.86814755  0.86814755  0.90733343  0.90733343]\n    [ 0.86814755  0.86814755  0.90733343  0.90733343]\n    [ 0.34470171  0.34470171  0.03056507  0.03056507]\n    [ 0.34470171  0.34470171  0.03056507  0.03056507]]\n\n   [[ 0.86814755  0.86814755  0.90733343  0.90733343]\n    [ 0.86814755  0.86814755  0.90733343  0.90733343]\n    [ 0.34470171  0.34470171  0.03056507  0.03056507]\n    [ 0.34470171  0.34470171  0.03056507  0.03056507]]]\n\n\n  [[[ 0.62367481  0.62367481  0.20093997  0.20093997]\n    [ 0.62367481  0.62367481  0.20093997  0.20093997]\n    [ 0.57614893  0.57614893  0.7544235   0.7544235 ]\n    [ 0.57614893  0.57614893  0.7544235   0.7544235 ]]\n\n   [[ 0.62367481  0.62367481  0.20093997  0.20093997]\n    [ 0.62367481  0.62367481  0.20093997  0.20093997]\n    [ 0.57614893  0.57614893  0.7544235   0.7544235 ]\n    [ 0.57614893  0.57614893  0.7544235   0.7544235 ]]\n\n   [[ 0.52572423  0.52572423  0.04730832  0.04730832]\n    [ 0.52572423  0.52572423  0.04730832  0.04730832]\n    [ 0.74973559  0.74973559  0.2245238   0.2245238 ]\n    [ 0.74973559  0.74973559  0.2245238   0.2245238 ]]\n\n   [[ 0.52572423  0.52572423  0.04730832  0.04730832]\n    [ 0.52572423  0.52572423  0.04730832  0.04730832]\n    [ 0.74973559  0.74973559  0.2245238   0.2245238 ]\n    [ 0.74973559  0.74973559  0.2245238   0.2245238 ]]]]]\n\n\n\n\n\n\nUpSampling2D\n\n\nScala:\n\n\nval module = UpSampling2D(size: Array[Int], format: DataFormat = DataFormat.NCHW)\n\n\n\n\nPython:\n\n\nm = UpSampling2D(size, data_format)\n\n\n\n\nUpSampling layer for 2D inputs. \nRepeats the heights and widths of the data by size[0] and size[1] respectively. \n\n\nIf input's dataformat is NCHW, then the size of output will be (N, C, H * size[0], W * size[1]). \n\n\nDetailed parameter explanation for the constructor. \n * \nsize\n tuple of 2 integers. The upsampling factors for heights and widths.\n * \ndata_format\n a string value (or DataFormat Object in Scala) of \"NHWC\" or \"NCHW\" to specify the input data format of this layer. In \"NHWC\" format\n                        data is stored in the order of [batch_size, height, width, channels], in \"NCHW\" format data is stored\n                        in the order of [batch_size, channels, height, width].\n\n\nScala example:\n \n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.T\n\nval module = UpSampling2D(Array(2, 3))\nval input = Tensor(2, 2, 3, 3).range(1, 36)\nmodule.forward(input)\n\n\n\n\nThe output should be \n\n\nres: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n1.0 1.0 1.0 2.0 2.0 2.0 3.0 3.0 3.0\n1.0 1.0 1.0 2.0 2.0 2.0 3.0 3.0 3.0\n4.0 4.0 4.0 5.0 5.0 5.0 6.0 6.0 6.0\n4.0 4.0 4.0 5.0 5.0 5.0 6.0 6.0 6.0\n7.0 7.0 7.0 8.0 8.0 8.0 9.0 9.0 9.0\n7.0 7.0 7.0 8.0 8.0 8.0 9.0 9.0 9.0\n\n(1,2,.,.) =\n10.0    10.0    10.0    11.0    11.0    11.0    12.0    12.0    12.0\n10.0    10.0    10.0    11.0    11.0    11.0    12.0    12.0    12.0\n13.0    13.0    13.0    14.0    14.0    14.0    15.0    15.0    15.0\n13.0    13.0    13.0    14.0    14.0    14.0    15.0    15.0    15.0\n16.0    16.0    16.0    17.0    17.0    17.0    18.0    18.0    18.0\n16.0    16.0    16.0    17.0    17.0    17.0    18.0    18.0    18.0\n\n(2,1,.,.) =\n19.0    19.0    19.0    20.0    20.0    20.0    21.0    21.0    21.0\n19.0    19.0    19.0    20.0    20.0    20.0    21.0    21.0    21.0\n22.0    22.0    22.0    23.0    23.0    23.0    24.0    24.0    24.0\n22.0    22.0    22.0    23.0    23.0    23.0    24.0    24.0    24.0\n25.0    25.0    25.0    26.0    26.0    26.0    27.0    27....\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = UpSampling2D([2, 3])\ninput = np.arange(1, 37).reshape(2, 2, 3, 3)\nmodule.forward(input)\n\n\n\n\nThe output is \n\n\narray([[[[  1.,   1.,   1.,   2.,   2.,   2.,   3.,   3.,   3.],\n         [  1.,   1.,   1.,   2.,   2.,   2.,   3.,   3.,   3.],\n         [  4.,   4.,   4.,   5.,   5.,   5.,   6.,   6.,   6.],\n         [  4.,   4.,   4.,   5.,   5.,   5.,   6.,   6.,   6.],\n         [  7.,   7.,   7.,   8.,   8.,   8.,   9.,   9.,   9.],\n         [  7.,   7.,   7.,   8.,   8.,   8.,   9.,   9.,   9.]],\n\n        [[ 10.,  10.,  10.,  11.,  11.,  11.,  12.,  12.,  12.],\n         [ 10.,  10.,  10.,  11.,  11.,  11.,  12.,  12.,  12.],\n         [ 13.,  13.,  13.,  14.,  14.,  14.,  15.,  15.,  15.],\n         [ 13.,  13.,  13.,  14.,  14.,  14.,  15.,  15.,  15.],\n         [ 16.,  16.,  16.,  17.,  17.,  17.,  18.,  18.,  18.],\n         [ 16.,  16.,  16.,  17.,  17.,  17.,  18.,  18.,  18.]]],\n\n\n       [[[ 19.,  19.,  19.,  20.,  20.,  20.,  21.,  21.,  21.],\n         [ 19.,  19.,  19.,  20.,  20.,  20.,  21.,  21.,  21.],\n         [ 22.,  22.,  22.,  23.,  23.,  23.,  24.,  24.,  24.],\n         [ 22.,  22.,  22.,  23.,  23.,  23.,  24.,  24.,  24.],\n         [ 25.,  25.,  25.,  26.,  26.,  26.,  27.,  27.,  27.],\n         [ 25.,  25.,  25.,  26.,  26.,  26.,  27.,  27.,  27.]],\n\n        [[ 28.,  28.,  28.,  29.,  29.,  29.,  30.,  30.,  30.],\n         [ 28.,  28.,  28.,  29.,  29.,  29.,  30.,  30.,  30.],\n         [ 31.,  31.,  31.,  32.,  32.,  32.,  33.,  33.,  33.],\n         [ 31.,  31.,  31.,  32.,  32.,  32.,  33.,  33.,  33.],\n         [ 34.,  34.,  34.,  35.,  35.,  35.,  36.,  36.,  36.],\n         [ 34.,  34.,  34.,  35.,  35.,  35.,  36.,  36.,  36.]]]], dtype=float32)\n\n\n\n\n\n\nUpSampling3D\n\n\nScala:\n\n\nval module = UpSampling3D(size: Array[Int])\n\n\n\n\nPython:\n\n\nm = UpSampling3D(size)\n\n\n\n\nUpSampling3D is a module that upsamples for 3D inputs.\nIt repeats the 1st, 2nd and 3rd dimensions of the data by size[0], size[1] and size[2] respectively.\nThe input data is assumed to be of the form \nminibatch x channels x depth x height x width\n.\n\n\nScala example:\n\n\n\nscala\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval module = UpSampling3D(Array(2, 2, 2))\nval input = Tensor(1, 2, 2, 2, 2).randn()\nval output = module.forward(input)\n\n\n input\n(1,1,1,.,.) =\n0.8626614   -0.25849837\n0.89711547  0.41256216\n\n(1,1,2,.,.) =\n0.031144595 0.28527617\n0.36917794  -0.9892453\n\n(1,2,1,.,.) =\n-1.7768023  -0.39210165\n1.9640301   -2.2383325\n\n(1,2,2,.,.) =\n0.41984457  -1.1820035\n0.23327439  -0.17730176\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x2x2]\n\n\n output\n(1,1,1,.,.) =\n0.8626614   0.8626614   -0.25849837 -0.25849837\n0.8626614   0.8626614   -0.25849837 -0.25849837\n0.89711547  0.89711547  0.41256216  0.41256216\n0.89711547  0.89711547  0.41256216  0.41256216\n\n(1,1,2,.,.) =\n0.8626614   0.8626614   -0.25849837 -0.25849837\n0.8626614   0.8626614   -0.25849837 -0.25849837\n0.89711547  0.89711547  0.41256216  0.41256216\n0.89711547  0.89711547  0.41256216  0.41256216\n\n(1,1,3,.,.) =\n0.031144595 0.031144595 0.28527617  0.28527617\n0.031144595 0.031144595 0.28527617  0.28527617\n0.36917794  0.36917794  -0.9892453  -0.9892453\n0.36917794  0.36917794  -0.9892453  -0.9892453\n\n(1,1,4,.,.) =\n0.031144595 0.031144595 0.28527617  0.28527617\n0.031144595 0.031144595 0.28527617  0.28527617\n0.36917794  0.36917794  -0.9892453  -0.9892453\n0.36917794  0.36917794  -0.9892453  -0.9892453\n\n(1,2,1,.,.) =\n-1.7768023  -1.7768023  -0.39210165 -0.39210165\n-1.7768023  -1.7768023  -0.39210165 -0.39210165\n1.9640301   1.9640301   -2.2383325  -2.2383325\n1.9640301   1.9640301   -2.2383325  -2.2383325\n\n(1,2,2,.,.) =\n-1.7768023  -1.7768023  -0.39210165 -0.39210165\n-1.7768023  -1.7768023  -0.39210165 -0.39210165\n1.9640301   1.9640301   -2.2383325  -2.2383325\n1.9640301   1.9640301   -2.2383325  -2.2383325\n\n(1,2,3,.,.) =\n0.41984457  0.41984457  -1.1820035  -1.1820035\n0.41984457  0.41984457  -1.1820035  -1.1820035\n0.23327439  0.23327439  -0.17730176 -0.17730176\n0.23327439  0.23327439  -0.17730176 -0.17730176\n\n(1,2,4,.,.) =\n0.41984457  0.41984457  -1.1820035  -1.1820035\n0.41984457  0.41984457  -1.1820035  -1.1820035\n0.23327439  0.23327439  -0.17730176 -0.17730176\n0.23327439  0.23327439  -0.17730176 -0.17730176\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4x4]\n\n\n\n\n\n\n\nResizeBilinear\n\n\nScala:\n\n\nval module = ResizeBilinear(outputHeight, outputWidth,\n                      alignCorners=false, dataFormat = DataFormat.NCHW)\n\n\n\n\nPython:\n\n\nm = ResizeBilinear(outputHeight, outputWidth,\n               alignCorners=False, dataFormat=\nNCHW\n)\n\n\n\n\nResize the input image with bilinear interpolation. The input image must be a float tensor with\nNHWC or NCHW layout.\n\n\nScala example:\n\n\n\nscala\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = ResizeBilinear(4, 4)\nval input = Tensor(1, 1, 2, 2).range(1, 4)\nval output = module.forward(input)\n\n\n output\n(1,1,.,.) =\n1.0 1.5 2.0 2.0 \n2.0 2.5 3.0 3.0 \n3.0 3.5 4.0 4.0 \n3.0 3.5 4.0 4.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x1x4x4]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = ResizeBilinear(4, 4)\ninput = np.arange(1, 5).reshape(1, 1, 2, 2)\noutput = module.forward(input)\nprint output\n\n\n\n\nThe output is \n\n\n[[[[ 1.   1.5  2.   2. ]\n   [ 2.   2.5  3.   3. ]\n   [ 3.   3.5  4.   4. ]\n   [ 3.   3.5  4.   4. ]]]]", 
            "title": "Convolution Layers"
        }, 
        {
            "location": "/APIGuide/Layers/Convolution-Layers/#spatialconvolution", 
            "text": "Scala:  val m = SpatialConvolution(nInputPlane,nOutputPlane,kernelW,kernelH,strideW=1,strideH=1,padW=0,padH=0,nGroup=1,propagateBack=true,wRegularizer=null,bRegularizer=null,initWeight=null, initBias=null, initGradWeight=null, initGradBias=null, withBias=true, dataFormat=DataFormat.NCHW)  Python:  m = SpatialConvolution(n_input_plane,n_output_plane,kernel_w,kernel_h,stride_w=1,stride_h=1,pad_w=0,pad_h=0,n_group=1,propagate_back=True,wRegularizer=None,bRegularizer=None,init_weight=None,init_bias=None,init_grad_weight=None,init_grad_bias=None, with_bias=True, data_format= NCHW )  SpatialConvolution is a module that applies a 2D convolution over an input image.  The input tensor in  forward(input)  is expected to be\neither a 4D tensor ( batch x nInputPlane x height x width ) or a 3D tensor ( nInputPlane x height x width ). The convolution is performed on the last two dimensions.\noutput of  forward(input)  is also expected to be a 4D tensor ( batch x outputPlane x height x width )\nor a 3D tensor ( outputPlane x height x width )..  As for padding, when padW and padH are both -1, we use a padding algorithm similar to the \"SAME\" padding of tensorflow. That is   outHeight = Math.ceil(inHeight.toFloat/strideH.toFloat)\n outWidth = Math.ceil(inWidth.toFloat/strideW.toFloat)\n\n padAlongHeight = Math.max(0, (outHeight - 1) * strideH + kernelH - inHeight)\n padAlongWidth = Math.max(0, (outWidth - 1) * strideW + kernelW - inWidth)\n\n padTop = padAlongHeight / 2\n padLeft = padAlongWidth / 2  Detailed parameter explanation for the constructor.   nInputPlane  The number of expected input planes in the image given into forward()  nOutputPlane  The number of output planes the convolution layer will produce.  kernelW  The kernel width of the convolution  kernelH  The kernel height of the convolution  strideW  The step of the convolution in the width dimension.  strideH  The step of the convolution in the height dimension  padW   padding to be added to width to the input.  padH  padding to be added to height to the input.  nGroup  Kernel group number  propagateBack  whether to propagate gradient back  wRegularizer  regularizer on weight. an instance of [[Regularizer]] (e.g. L1 or L2)  bRegularizer  regularizer on bias. an instance of [[Regularizer]] (e.g. L1 or L2).  initWeight  weight initializer  initBias   bias initializer  initGradWeight  weight gradient initializer  initGradBias  bias gradient initializer  with_bias  the optional initial value for if need bias  data_format  a string value (or DataFormat Object in Scala) of \"NHWC\" or \"NCHW\" to specify the input data format of this layer. In \"NHWC\" format\n                        data is stored in the order of [batch_size, height, width, channels], in \"NCHW\" format data is stored\n                        in the order of [batch_size, channels, height, width].   Scala example:  \nscala \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval m = SpatialConvolution(2,1,2,2,1,1,0,0)\nm.setInitMethod(weightInitMethod = BilinearFiller, biasInitMethod = Zeros)\nval params = m.getParameters()\n\nscala  print(params)\n(1.0\n0.0\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 9],0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 9])\n\nscala \nval input = Tensor(1,2,3,3).randn()\nval output = m.forward(input)\nval gradOut = Tensor(1,1,2,2).fill(0.2f)\nval gradIn = m.backward(input,gradOut)\n\nscala  print(input)\n(1,1,.,.) =\n-0.37011376     0.13565119      -0.73574775\n-0.19486316     -0.4430604      -0.62543416\n0.7017611       -0.6441595      -1.2953792\n\n(1,2,.,.) =\n-0.9903588      0.5669722       0.2630131\n0.03392942      -0.6984676      -0.12389368\n0.78704715      0.5411976       -1.3877676\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x2x3x3]\n\nscala  print(output)\n(1,1,.,.) =\n-1.3604726      0.70262337\n-0.16093373     -1.141528\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x2]\n\nscala  print(gradOut)\n(1,1,.,.) =\n0.2     0.2\n0.2     0.2\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x1x2x2]\n\nscala  print(gradIn)\n(1,1,.,.) =\n0.2     0.2     0.0\n0.2     0.2     0.0\n0.0     0.0     0.0\n\n(1,2,.,.) =\n0.2     0.2     0.0\n0.2     0.2     0.0\n0.0     0.0     0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x3x3]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\ninput = np.random.rand(1,3,3,3)\nprint  input is : ,input\n\nm = SpatialConvolution(3,1,2,2,1,1,0,0)\nout = m.forward(input)\nprint  output m is : ,out\n\ngrad_out = np.random.rand(1,1,2,2)\nprint  grad out of m is : ,grad_out\ngrad_in = m.backward(input,grad_out)\nprint  grad input of m is : ,grad_in  Gives the output,  input is : [[[[ 0.75276617  0.44212513  0.90275949]\n   [ 0.78205279  0.77864714  0.83647254]\n   [ 0.76220944  0.22106036  0.68762202]]\n\n  [[ 0.37346971  0.31532213  0.33276243]\n   [ 0.69872884  0.07262236  0.66372462]\n   [ 0.47803013  0.80194459  0.53313873]]\n\n  [[ 0.56196833  0.20599878  0.47575818]\n   [ 0.35454298  0.96910557  0.36234704]\n   [ 0.64017738  0.95762579  0.50073035]]]]\ncreating: createSpatialConvolution\noutput m is : [[[[-1.08398974 -0.67615652]\n   [-0.77027249 -0.82885492]]]]\ngrad out of m is : [[[[ 0.38295452  0.77048361]\n   [ 0.11671955  0.76357513]]]]\ngrad input of m is : [[[[-0.02344826 -0.06515953 -0.03618064]\n   [-0.06770924 -0.22586647 -0.14004168]\n   [-0.01845866 -0.13653883 -0.10325129]]\n\n  [[-0.09294108 -0.14361492  0.08727306]\n   [-0.09885897 -0.21209857  0.29151234]\n   [-0.02149716 -0.10957514  0.20318349]]\n\n  [[-0.05926216 -0.04542646  0.14849319]\n   [-0.09506465 -0.34244278 -0.03763583]\n   [-0.02346931 -0.1815301  -0.18314059]]]]", 
            "title": "SpatialConvolution"
        }, 
        {
            "location": "/APIGuide/Layers/Convolution-Layers/#volumetricconvolution", 
            "text": "Scala:  val module = VolumetricConvolution(nInputPlane, nOutputPlane, kT, kW, kH,\n  dT=1, dW=1, dH=1, padT=0, padW=0, padH=0, withBias=true, wRegularizer=null, bRegularizer=null)  Python:  module = VolumetricConvolution(n_input_plane, n_output_plane, k_t, k_w, k_h,\n  d_t=1, d_w=1, d_h=1, pad_t=0, pad_w=0, pad_h=0, with_bias=true, wRegularizer=null, bRegularizer=null)  Applies a 3D convolution over an input image composed of several input planes. The input tensor\nin forward(input) is expected to be a 5D tensor ( batch x nInputPlane x depth(time) x height x width ) or\na 4D tensor ( nInputPlane x depth x height x width ).\nOutput of forward(input) is also expected to be a 5D tensor ( batch x depth(time) x outputPlane x height x width ) or\na 4D tensor ( outputPlane x depth x height x width ).\nAs for padding, when padW,padH, padT are all -1, we use a padding algorithm similar to the \"SAME\" padding of tensorflow.   nInputPlane  The number of expected input planes in the image given into forward()  nOutputPlane  The number of output planes the convolution layer will produce.  kT  The kernel size of the convolution in time  kW  The kernel width of the convolution  kH  The kernel height of the convolution  dT  The step of the convolution in the time dimension. Default is 1  dW  The step of the convolution in the width dimension. Default is 1  dH  The step of the convolution in the height dimension. Default is 1  padT  Additional zeros added to the input plane data on both sides of time axis.\n         Default is 0.  (kT-1)/2  is often used here.  padW  The additional zeros added per width to the input planes.  padH  The additional zeros added per height to the input planes.  withBias  whether with bias.  wRegularizer  instance of [[Regularizer]]\n                   (eg. L1 or L2 regularization), applied to the input weights matrices.  bRegularizer  instance of [[Regularizer]]\n                   applied to the bias.   Scala example:  val layer = VolumetricConvolution(2, 3, 2, 2, 2, dT=1, dW=1, dH=1,\n  padT=0, padW=0, padH=0, withBias=true)\nval input = Tensor(2, 2, 2, 2).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.54846555      0.5549177\n0.43748873      0.6596535\n\n(1,2,.,.) =\n0.87915933      0.5955469\n0.67464 0.40921077\n\n(2,1,.,.) =\n0.24127467      0.49356017\n0.6707502       0.5421975\n\n(2,2,.,.) =\n0.007834963     0.08188637\n0.51387626      0.7376101\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x2x2]\n\nlayer.forward(input)\nres16: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.6680023\n\n(2,1,.,.) =\n0.41926455\n\n(3,1,.,.) =\n-0.029196609\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x1x1x1]  Python example:  layer = VolumetricConvolution(2, 3, 2, 2, 2, d_t=1, d_w=1, d_h=1,\n          pad_t=0, pad_w=0, pad_h=0, with_bias=True, init_method= default ,\n          bigdl_type= float )\ninput = np.random.rand(2,2,2,2)\n array([[[[ 0.47639062,  0.76800312],\n         [ 0.28834351,  0.21883535]],\n\n        [[ 0.86097919,  0.89812597],\n         [ 0.43632181,  0.58004824]]],\n\n\n       [[[ 0.65784027,  0.34700039],\n         [ 0.64511955,  0.1660241 ]],\n\n        [[ 0.36060054,  0.71265665],\n         [ 0.51755249,  0.6508298 ]]]])\n\nlayer.forward(input)\narray([[[[ 0.54268712]]],\n\n\n       [[[ 0.17670505]]],\n\n\n       [[[ 0.40953237]]]], dtype=float32)", 
            "title": "VolumetricConvolution"
        }, 
        {
            "location": "/APIGuide/Layers/Convolution-Layers/#spatialdilatedconvolution", 
            "text": "Scala:  val layer = SpatialDilatedConvolution(\n  inputPlanes,\n  outputPlanes,\n  kernelW,\n  kernelH,\n  strideW,\n  strideH,\n  paddingW,\n  paddingH,\n  dilationW,\n  dilationH\n)  Python:  layer = SpatialDilatedConvolution(\n  inputPlanes,\n  outputPlanes,\n  kernelW,\n  kernelH,\n  strideW,\n  strideH,\n  paddingW,\n  paddingH,\n  dilationW,\n  dilationH\n)  Apply a 2D dilated convolution over an input image.  The input tensor in  forward(input)  is expected to be\neither a 4D tensor ( batch x nInputPlane x height x width ) or a 3D tensor ( nInputPlane x height x width ).\noutput of  forward(input)  is also expected to be a 4D tensor ( batch x outputPlane x height x width )\nor a 3D tensor ( outputPlane x height x width ).  For a normal SpatialConvolution, the kernel will multiply with input\nimage element-by-element contiguous. In dilated convolution, it\u2019s possible\nto have filters that have spaces between each cell. For example, filter w and\nimage x, when dilatiionW and dilationH both = 1, this is normal 2D convolution  w(0, 0) * x(0, 0), w(0, 1) * x(0, 1)\nw(1, 0) * x(1, 0), w(1, 1) * x(1, 1)  when dilationW and dilationH both = 2  w(0, 0) * x(0, 0), w(0, 1) * x(0, 2)\nw(1, 0) * x(2, 0), w(1, 1) * x(2, 2)  when dilationW and dilationH both = 3  w(0, 0) * x(0, 0), w(0, 1) * x(0, 3)\nw(1, 0) * x(3, 0), w(1, 1) * x(3, 3)  If input is a 3D tensor nInputPlane x height x width,\n *  owidth  = floor(width + 2 * padW - dilationW * (kW-1) - 1) / dW + 1 \n *  oheight = floor(height + 2 * padH - dilationH * (kH-1) - 1) / dH + 1  Reference Paper:   Yu F, Koltun V. Multi-scale context aggregation by dilated convolutions[J].\narXiv preprint arXiv:1511.07122, 2015.   Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = SpatialDilatedConvolution(1, 1, 2, 2, 1, 1, 0, 0, 2, 2)\nval input = Tensor(T(T(\n  T(1.0f, 2.0f, 3.0f, 4.0f),\n  T(5.0f, 6.0f, 7.0f, 8.0f),\n  T(9.0f, 1.0f, 2.0f, 3.0f),\n  T(4.0f, 5.0f, 6.0f, 7.0f)\n)))\nval filter = Tensor(T(T(T(\n  T(1.0f, 1.0f),\n  T(1.0f, 1.0f)\n))))\nlayer.weight.copy(filter)\nlayer.bias.zero()\nlayer.forward(input)\nlayer.backward(input, Tensor(T(T(\n  T(0.1f, 0.2f),\n  T(0.3f, 0.4f)\n))))  Gives the output,  (1,.,.) =\n15.0    10.0\n22.0    26.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2]\n\n(1,.,.) =\n0.1     0.2     0.1     0.2\n0.3     0.4     0.3     0.4\n0.1     0.2     0.1     0.2\n0.3     0.4     0.3     0.4\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x4x4]  Python example:  from bigdl.nn.layer import SpatialDilatedConvolution\nimport numpy as np\n\nlayer = SpatialDilatedConvolution(1, 1, 2, 2, 1, 1, 0, 0, 2, 2)\ninput = np.array([[\n  [1.0, 2.0, 3.0, 4.0],\n  [5.0, 6.0, 7.0, 8.0],\n  [9.0, 1.0, 2.0, 3.0],\n  [4.0, 5.0, 6.0, 7.0]\n]])\nfilter = np.array([[[\n  [1.0, 1.0],\n  [1.0, 1.0]\n]]])\nbias = np.array([0.0])\nlayer.set_weights([filter, bias])\nlayer.forward(input)\nlayer.backward(input, np.array([[[0.1, 0.2], [0.3, 0.4]]]))  Gives the output,  array([[[ 15.,  10.],\n        [ 22.,  26.]]], dtype=float32)\n\narray([[[ 0.1       ,  0.2       ,  0.1       ,  0.2       ],\n        [ 0.30000001,  0.40000001,  0.30000001,  0.40000001],\n        [ 0.1       ,  0.2       ,  0.1       ,  0.2       ],\n        [ 0.30000001,  0.40000001,  0.30000001,  0.40000001]]], dtype=float32)", 
            "title": "SpatialDilatedConvolution"
        }, 
        {
            "location": "/APIGuide/Layers/Convolution-Layers/#spatialshareconvolution", 
            "text": "Scala:  val layer = SpatialShareConvolution(nInputPlane, nOutputPlane, kW, kH, dW, dH,\n      padW, padH)  Python:  layer = SpatialShareConvolution(nInputPlane, nOutputPlane, kW, kH, dW, dH, padW, padH)  Applies a 2D convolution over an input image composed of several input planes.\n The input tensor in  forward(input)  is expected to be\n either a 4D tensor ( batch x nInputPlane x height x width ) or a 3D tensor ( nInputPlane x height x width ).\n output of  forward(input)  is also expected to be a 4D tensor ( batch x outputPlane x height x width )\n or a 3D tensor ( outputPlane x height x width ).  This layer has been optimized to save memory. If using this layer to construct multiple convolution\n layers, please add sharing script for the fInput and fGradInput. Please refer to the ResNet example.  Scala example:  \n    import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n    import com.intel.analytics.bigdl.nn._\n    import com.intel.analytics.bigdl.tensor._\n\n    val nInputPlane = 1\n    val nOutputPlane = 1\n    val kW = 2\n    val kH = 2\n    val dW = 1\n    val dH = 1\n    val padW = 0\n    val padH = 0\n    val layer = SpatialShareConvolution(nInputPlane, nOutputPlane, kW, kH, dW, dH,\n      padW, padH)\n\n    val inputData = Array(\n      1.0, 2, 3, 1,\n      4, 5, 6, 1,\n      7, 8, 9, 1,\n      1.0, 2, 3, 1,\n      4, 5, 6, 1,\n      7, 8, 9, 1,\n      1.0, 2, 3, 1,\n      4, 5, 6, 1,\n      7, 8, 9, 1\n    )\n\n    val kernelData = Array(\n      2.0, 3,\n      4, 5\n    )\n\n    val biasData = Array(0.0)\n\n    layer.weight.copy(Tensor(Storage(kernelData), 1,\n      Array(nOutputPlane, nInputPlane, kH, kW)))\n    layer.bias.copy(Tensor(Storage(biasData), 1, Array(nOutputPlane)))\n\n    val input = Tensor(Storage(inputData), 1, Array(3, 1, 3, 4))\n    val output = layer.updateOutput(input)\n\n      output\nres2: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n49.0    63.0    38.0\n91.0    105.0   56.0\n\n(2,1,.,.) =\n49.0    63.0    38.0\n91.0    105.0   56.0\n\n(3,1,.,.) =\n49.0    63.0    38.0\n91.0    105.0   56.0  Python example:  nInputPlane = 1\nnOutputPlane = 1\nkW = 2\nkH = 2\ndW = 1\ndH = 1\npadW = 0\npadH = 0\nlayer = SpatialShareConvolution(nInputPlane, nOutputPlane, kW, kH, dW, dH, padW, padH)\n\ninput = np.array([\n      1.0, 2, 3, 1,\n      4, 5, 6, 1,\n      7, 8, 9, 1,\n      1.0, 2, 3, 1,\n      4, 5, 6, 1,\n      7, 8, 9, 1,\n      1.0, 2, 3, 1,\n      4, 5, 6, 1,\n      7, 8, 9, 1]\n    ).astype( float32 ).reshape(3, 1, 3, 4)\nlayer.forward(input)  print (output)\narray([[[[-3.55372381, -4.0352459 , -2.65861344],\n         [-4.99829054, -5.4798131 , -3.29477644]]],\n\n\n       [[[-3.55372381, -4.0352459 , -2.65861344],\n         [-4.99829054, -5.4798131 , -3.29477644]]],\n\n\n       [[[-3.55372381, -4.0352459 , -2.65861344],\n         [-4.99829054, -5.4798131 , -3.29477644]]]], dtype=float32)", 
            "title": "SpatialShareConvolution"
        }, 
        {
            "location": "/APIGuide/Layers/Convolution-Layers/#spatialfullconvolution", 
            "text": "Scala:  val m  = SpatialFullConvolution(nInputPlane, nOutputPlane, kW, kH, dW=1, dH=1, padW=0, padH=0, adjW=0, adjH=0,nGroup=1, noBias=false,wRegularizer=null,bRegularizer=null)  Python:  m = SpatialFullConvolution(n_input_plane,n_output_plane,kw,kh,dw=1,dh=1,pad_w=0,pad_h=0,adj_w=0,adj_h=0,n_group=1,no_bias=False,init_method='default',wRegularizer=None,bRegularizer=None)  SpatialFullConvolution is a module that applies a 2D full convolution over an input image.   The input tensor in  forward(input)  is expected to be\neither a 4D tensor ( batch x nInputPlane x height x width ) or a 3D tensor ( nInputPlane x height x width ).\noutput of  forward(input)  is also expected to be a 4D tensor ( batch x outputPlane x height x width )\nor a 3D tensor ( outputPlane x height x width ).\nThe convolution is performed on the last two dimensions.  adjW  and  adjH  are used to adjust the size of the output image. The size of output tensor of  forward  will be :    output width  = (width  - 1) * dW - 2*padW + kW + adjW\n  output height = (height - 1) * dH - 2*padH + kH + adjH  Note, scala API also accepts a table input with two tensors:  T(convInput, sizeTensor)  where  convInput  is the standard input tensor, and the size of  sizeTensor  is used to set the size of the output (will ignore the  adjW  and  adjH  values used to construct the module). Use  SpatialFullConvolution[Table, T](...)  instead of  SpatialFullConvolution[Tensor,T](...) ) for table input.  This module can also be used without a bias by setting parameter  noBias = true  while constructing the module.  Other frameworks may call this operation \"In-network Upsampling\", \"Fractionally-strided convolution\", \"Backwards Convolution,\" \"Deconvolution\", or \"Upconvolution.\"  Reference: Long J, Shelhamer E, Darrell T. Fully convolutional networks for semantic segmentation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015: 3431-3440.  Detailed explanation of arguments in constructor.    nInputPlane  The number of expected input planes in the image given into forward()  nOutputPlane  The number of output planes the convolution layer will produce.  kW  The kernel width of the convolution.  kH  The kernel height of the convolution.  dW  The step of the convolution in the width dimension. Default is 1.  dH  The step of the convolution in the height dimension. Default is 1.  padW  The additional zeros added per width to the input planes. Default is 0.  padH  The additional zeros added per height to the input planes. Default is 0.  adjW  Extra width to add to the output image. Default is 0.  adjH  Extra height to add to the output image. Default is 0.  nGroup  Kernel group number.  noBias  If bias is needed.  wRegularizer  instance of [[Regularizer]]\n                   (eg. L1 or L2 regularization), applied to the input weights matrices.  bRegularizer  instance of [[Regularizer]]\n                   applied to the bias.   Scala example:  Tensor Input example:   \nscala \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval m = SpatialFullConvolution(1, 2, 2, 2, 1, 1,0, 0, 0, 0, 1, false)\n\nval input = Tensor(1,1,3,3).randn()\nval output = m.forward(input)\nval gradOut = Tensor(1,2,4,4).fill(0.1f)\nval gradIn = m.backward(input,gradOut)\n\nscala  print(input)\n(1,1,.,.) =\n0.18219171      1.3252861       -1.3991559\n0.82611334      1.0313315       0.6075537\n-0.7336061      0.3156875       -0.70616096\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x1x3x3]\n\nscala  print(output)\n(1,1,.,.) =\n-0.49278542     -0.5823938      -0.8304068      -0.077556044\n-0.5028842      -0.7281958      -1.1927067      -0.34262076\n-0.41680115     -0.41400516     -0.7599415      -0.42024887\n-0.5286566      -0.30015367     -0.5997892      -0.32439864\n\n(1,2,.,.) =\n-0.13131973     -0.5770084      1.1069719       -0.6003375\n-0.40302444     -0.07293816     -0.2654545      0.39749345\n0.37311426      -0.49090374     0.3088816       -0.41700447\n-0.12861171     0.09394867      -0.17229918     0.05556257\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4]\n\nscala  print(gradOut)\n(1,1,.,.) =\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n\n(1,2,.,.) =\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x2x4x4]\n\nscala  print(gradIn)\n(1,1,.,.) =\n-0.05955213     -0.05955213     -0.05955213\n-0.05955213     -0.05955213     -0.05955213\n-0.05955213     -0.05955213     -0.05955213\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x3x3]  Table input Example  \nscala \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.{T, Table}\n\nval m = SpatialFullConvolution(1, 2, 2, 2, 1, 1,0, 0, 0, 0, 1, false)\n\nval input1 = Tensor(1, 3, 3).randn()\nval input2 = Tensor(3, 3).fill(2.0f)\nval input = T(input1, input2)\nval output = m.forward(input)\nval gradOut = Tensor(2,4,4).fill(0.1f)\nval gradIn = m.backward(input,gradOut)\n\nscala  print(input)\n {\n        2: 2.0  2.0     2.0\n           2.0  2.0     2.0\n           2.0  2.0     2.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n        1: (1,.,.) =\n           1.276177     0.62761325      0.2715257\n           -0.030832397 0.5046206       0.6835176\n           -0.5832693   0.17266633      0.7461992\n\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]\n }\n\nscala  print(output)\n(1,.,.) =\n-0.18339296     0.04208675      -0.17708774     -0.30901802\n-0.1484881      0.23592418      0.115615785     -0.11288056\n-0.47266048     -0.41772115     0.07501307      0.041751802\n-0.4851033      -0.5427048      -0.18293871     -0.12682784\n\n(2,.,.) =\n0.6391188       0.845774        0.41208875      0.13754106\n-0.45785713     0.31221163      0.6006259       0.36563575\n-0.24076991     -0.31931365     0.31651747      0.4836449\n0.24247466      -0.16731171     -0.20887817     0.19513035\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x4]\n\nscala  print(gradOut)\n(1,.,.) =\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n\n(2,.,.) =\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n0.1     0.1     0.1     0.1\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x4x4]\n\nscala  print(gradIn)\n {\n        2: 0.0  0.0     0.0\n           0.0  0.0     0.0\n           0.0  0.0     0.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n        1: (1,.,.) =\n           0.16678208   0.16678208      0.16678208\n           0.16678208   0.16678208      0.16678208\n           0.16678208   0.16678208      0.16678208\n\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x3]\n }  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nm = SpatialFullConvolution(1, 2, 2, 2, 1, 1,0, 0, 0, 0, 1, False)\n\nprint  --------- tensor input--------- \ntensor_input = np.random.rand(1,3,3)\nprint  input is : ,tensor_input\nout = m.forward(tensor_input)\nprint  output m is : ,out\n\nprint  ----------- table input -------- \nadj_input=np.empty([3,3])\nadj_input.fill(2.0)\ntable_input = [tensor_input,adj_input]\nprint  input is : ,table_input\nout = m.forward(table_input)\nprint  output m is : ,out  Gives the output,  creating: createSpatialFullConvolution\n--------- tensor input---------\ninput is : [[[  9.03998497e-01   4.43054896e-01   6.19571211e-01]\n  [  4.24573060e-01   3.29886286e-04   5.48427154e-02]\n  [  8.99004782e-01   3.25514441e-01   6.85294650e-01]]]\noutput m is : [[[-0.04712385  0.21949144  0.0843184   0.14336972]\n  [-0.28748769  0.39192575  0.00372696  0.27235305]\n  [-0.16292028  0.41943201  0.03476509  0.18813471]\n  [-0.28051955  0.29929382 -0.0689255   0.28749463]]\n\n [[-0.21336153 -0.35994443 -0.29239666 -0.38612381]\n  [-0.33000433 -0.41727966 -0.36827195 -0.34524575]\n  [-0.2410759  -0.38439807 -0.27613443 -0.39401439]\n  [-0.38188276 -0.36746511 -0.37627563 -0.34141305]]]\n----------- table input --------\ninput is : [array([[[  9.03998497e-01,   4.43054896e-01,   6.19571211e-01],\n        [  4.24573060e-01,   3.29886286e-04,   5.48427154e-02],\n        [  8.99004782e-01,   3.25514441e-01,   6.85294650e-01]]]), array([[ 2.,  2.,  2.],\n       [ 2.,  2.,  2.],\n       [ 2.,  2.,  2.]])]\noutput m is : [[[-0.04712385  0.21949144  0.0843184   0.14336972]\n  [-0.28748769  0.39192575  0.00372696  0.27235305]\n  [-0.16292028  0.41943201  0.03476509  0.18813471]\n  [-0.28051955  0.29929382 -0.0689255   0.28749463]]\n\n [[-0.21336153 -0.35994443 -0.29239666 -0.38612381]\n  [-0.33000433 -0.41727966 -0.36827195 -0.34524575]\n  [-0.2410759  -0.38439807 -0.27613443 -0.39401439]\n  [-0.38188276 -0.36746511 -0.37627563 -0.34141305]]]", 
            "title": "SpatialFullConvolution"
        }, 
        {
            "location": "/APIGuide/Layers/Convolution-Layers/#spatialseparableconvolution", 
            "text": "Scala:  val m  = SpatialSeparableConvolution(nInputChannel, nOutputChannel, depthMultiplier, kW, kH, sW = 1, sH = 1, pW = 0, pH = 0, hasBias = True, dataFormat = DataFormat.NCHW, wRegularizer = null, bRegularizer = null, pRegularizer = null, initDepthWeight = null, initPointWeight = null, initBias = null)  Python:  m = SpatialSeparableConvolution(n_input_channel, n_output_channel, depth_multiplier, kernel_w, kernel_h, stride_w=1, stride_h=1, pad_w=0, pad_h=0, with_bias=True, data_format= NCHW , w_regularizer=None, b_regularizer=None, p_regularizer=None)  Separable convolutions consist in first performing a depthwise spatial convolution (which acts\non each input channel separately) followed by a pointwise convolution which mixes together the\nresulting output channels. The  depthMultiplier argument controls how many output channels are\nenerated per input channel in the depthwise step.   nInputChannel  The number of expected input planes in the image given into forward()  nOutputChannel  The number of output planes the convolution layer will produce.  depthMultiplier  how many internal channels are generated per input channel  kW  The kernel width of the convolution.  kH  The kernel height of the convolution.  sW  The step of the convolution in the width dimension.  sH  The step of the convolution in the height dimension.  pW  The additional zeros added per width to the input planes. Default is 0.  pH  The additional zeros added per height to the input planes. Default is 0.  hasBias  do we use a bias on the output, default is true  dataFormat  image data format, which can be NHWC or NCHW, default value is NCHW  wRegularizer  kernel parameter regularizer  bRegularizer  bias regularizer  pRegularizer  point wise kernel parameter regularizer  initDepthWeight  kernel parameter init tensor  initPointWeight  point wise kernel parameter init tensor  initBias  bias init tensor   Scala example:  \nscala \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.nn.abstractnn.DataFormat\n\nval m = SpatialSeparableConvolution[Float](1, 2, 1, 2, 2, dataFormat = DataFormat.NCHW)\nval input = Tensor(1, 1, 3, 3).randn()\nval output = m.forward(input)\nval gradOut = Tensor(1, 2, 2, 2).fill(0.1f)\nval gradIn = m.backward(input,gradOut)\n\nscala  print(input)\n(1,1,.,.) =\n-0.6636712      -1.3765892      -1.51044\n0.4502934       -0.38438025     -0.4279503\n-1.5327895      -0.33594692     1.5972415\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x1x3x3]\n\nscala  print(output)\n(1,1,.,.) =\n-0.2903078      -0.5241474\n-0.17961408     -0.11239494\n\n(1,2,.,.) =\n-1.3147768      -2.3738143\n-0.81345534     -0.5090261\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x2]\n\nscala  print(gradOut)\n(1,1,.,.) =\n0.1     0.1\n0.1     0.1\n\n(1,2,.,.) =\n0.1     0.1\n0.1     0.1\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x2x2x2]\n\nscala  print(gradIn)\n(1,1,.,.) =\n0.088415675     0.17780215      0.08938648\n0.15242647      0.26159728      0.109170794\n0.06401079      0.08379511      0.019784318\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x3x3]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nm = SpatialSeparableConvolution(1, 2, 1, 2, 2)\ntensor_input = np.random.rand(1, 1, 3, 3)\nprint  input is : ,tensor_input\nout = m.forward(tensor_input)\nprint  output m is : ,out  Gives the output,  creating: createSpatialFullConvolution\ninput is : [[[[ 0.77269038  0.82476003  0.58228669]\n   [ 0.35123569  0.25496535  0.16736527]\n   [ 0.62138293  0.83156875  0.77565037]]]]\noutput m is : [[[[ 0.91489887  0.81591743]\n   [ 0.84698057  0.76615578]]\n\n  [[ 1.05583775  0.94160837]\n   [ 0.97745675  0.88418102]]]]", 
            "title": "SpatialSeparableConvolution"
        }, 
        {
            "location": "/APIGuide/Layers/Convolution-Layers/#spatialconvolutionmap", 
            "text": "Scala:  val layer = SpatialConvolutionMap(\n  connTable,\n  kW,\n  kH,\n  dW = 1,\n  dH = 1,\n  padW = 0,\n  padH = 0,\n  wRegularizer = null,\n  bRegularizer = null)  Python:  layer = SpatialConvolutionMap(\n  conn_table,\n  kw,\n  kh,\n  dw=1,\n  dh=1,\n  pad_w=0,\n  pad_h=0,\n  wRegularizer=None,\n  bRegularizer=None)  This class is a generalization of SpatialConvolution.\nIt uses a generic connection table between input and output features.\nThe SpatialConvolution is equivalent to using a full connection table. \nA Connection Table is the mapping of input/output feature map, stored in a 2D Tensor. The first column is the input feature maps. The second column is output feature maps.  Full Connection table:  val conn = SpatialConvolutionMap.full(nin: Int, nout: In)  One to One connection table:  val conn = SpatialConvolutionMap.oneToOne(nfeat: Int)  Random Connection table:  val conn = SpatialConvolutionMap.random(nin: Int, nout: Int, nto: Int)  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval conn = SpatialConvolutionMap.oneToOne(3)  conn  is  conn: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0 1.0\n2.0 2.0\n3.0 3.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]  val module = SpatialConvolutionMap(SpatialConvolutionMap.oneToOne(3), 2, 2)\n\npritnln(module.forward(Tensor.range(1, 48, 1).resize(3, 4, 4)))  Gives the output,  com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n4.5230045   5.8323975   7.1417904\n9.760576    11.069969   12.379362\n14.998148   16.30754    17.616934\n\n(2,.,.) =\n-5.6122046  -5.9227824  -6.233361\n-6.8545156  -7.165093   -7.4756703\n-8.096827   -8.407404   -8.71798\n\n(3,.,.) =\n13.534529   13.908197   14.281864\n15.029203   15.402873   15.77654\n16.523876   16.897545   17.271214\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3x3]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = SpatialConvolutionMap(np.array([(1, 1), (2, 2), (3, 3)]), 2, 2)\n\nprint(module.forward(np.arange(1, 49, 1).reshape(3, 4, 4)))  Gives the output,  [array([[[-1.24280548, -1.70889318, -2.17498088],\n        [-3.10715604, -3.57324386, -4.03933144],\n        [-4.97150755, -5.43759441, -5.90368223]],\n\n       [[-5.22062826, -5.54696751, -5.87330723],\n        [-6.52598572, -6.85232496, -7.17866373],\n        [-7.8313427 , -8.15768337, -8.48402214]],\n\n       [[ 0.5065825 ,  0.55170798,  0.59683061],\n        [ 0.68707776,  0.73219943,  0.77732348],\n        [ 0.86757064,  0.91269422,  0.95781779]]], dtype=float32)]", 
            "title": "SpatialConvolutionMap"
        }, 
        {
            "location": "/APIGuide/Layers/Convolution-Layers/#temporalconvolution", 
            "text": "Scala:  val module = TemporalConvolution(\n  inputFrameSize, outputFrameSize, kernelW, strideW = 1, propagateBack = true,\n  wRegularizer = null, bRegularizer = null, initWeight = null, initBias = null,\n  initGradWeight = null, initGradBias = null\n  )  Python:  module = TemporalConvolution(\n  input_frame_size, output_frame_size, kernel_w, stride_w = 1, propagate_back = True,\n  w_regularizer = None, b_regularizer = None, init_weight = None, init_bias = None,\n  init_grad_weight = None, init_grad_bias = None\n  )  Applies a 1D convolution over an input sequence composed of nInputFrame frames.\n The input tensor in  forward(input)  is expected to be a 3D tensor\n ( nBatchFrame  x  nInputFrame  x  inputFrameSize ) or a 2D tensor\n ( nInputFrame  x  inputFrameSize ).\n Output of  forward(input)  is expected to be a 3D tensor\n ( nBatchFrame  x  nOutputFrame  x  outputFrameSize ) or a 2D tensor\n ( nOutputFrame  x  outputFrameSize ).   inputFrameSize  The input frame size expected in sequences given into  forward() .  outputFrameSize  The output frame size the convolution layer will produce.  kernelW  The kernel width of the convolution  strideW  The step of the convolution in the width dimension.  propagateBack  Whether propagate gradient back, default is true.  wRegularizer  instance of  Regularizer \n                     (eg. L1 or L2 regularization), applied to the input weights matrices.  bRegularizer  instance of  Regularizer \n                     applied to the bias.  initWeight  Initial weight  initBias  Initial bias  initGradWeight  Initial gradient weight  initGradBias  Initial gradient bias  T  The numeric type in the criterion, usually which are  Float  or  Double   Scala example:  import com.intel.analytics.bigdl.numeric.NumericFloat\nval seed = 100\nRNG.setSeed(seed)\nval inputFrameSize = 5\nval outputFrameSize = 3\nval kW = 5\nval dW = 2\nval layer = TemporalConvolution(inputFrameSize, outputFrameSize, kW, dW)\n\nRandom.setSeed(seed)\nval input = Tensor(10, 5).apply1(e =  Random.nextFloat())\nval gradOutput = Tensor(3, 3).apply1(e =  Random.nextFloat())\n\nval output = layer.updateOutput(input)  println(output)\n2017-07-21 06:18:00 INFO  ThreadPool$:79 - Set mkl threads to 1 on thread 1\n-0.34987333 -0.0063185245   -0.45821175 \n-0.20838472 0.15102878  -0.5656665  \n-0.13935827 -0.099345684    -0.76407385 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nval gradInput = layer.updateGradInput(input, gradOutput)  println(gradInput)\n0.018415622 -0.10201519 -0.15641063 -0.08271551 -0.060939234    \n0.13609992  0.14934899  0.06083451  -0.13943195 -0.11092151 \n-0.14552939 -0.024670592    -0.29887137 -0.14555064 -0.05840567 \n0.09920926  0.2705848   0.016875947 -0.27233958 -0.069991685    \n-0.0024300043   -0.15160085 -0.20593905 -0.2894306  -0.057458147    \n0.06390554  0.07710219  0.105445914 -0.26714328 -0.18871497 \n0.13901645  -0.10651534 0.006758575 -0.08754986 -0.13747974 \n-0.026543075    -0.044046614    0.13146847  -0.01198944 -0.030542556    \n0.18396454  -0.055985756    -0.03506116 -0.02156017 -0.09211717 \n0.0 0.0 0.0 0.0 0.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 10x5]  Python example:  from bigdl.nn.layer import TemporalConvolution\nimport numpy as np\ninputFrameSize = 5\noutputFrameSize = 3\nkW = 5\ndW = 2\nlayer = TemporalConvolution(inputFrameSize, outputFrameSize, kW, dW)\n\ninput = np.random.rand(10, 5)\ngradOutput = np.random.rand(3, 3)\n\noutput = layer.forward(input)  print(output)\n[[ 0.43262666  0.52964264 -0.09026626]\n [ 0.46828389  0.3391096   0.04789509]\n [ 0.37985104  0.13899082 -0.05767119]]\n\ngradInput = layer.backward(input, gradOutput)  print(gradInput)\n[[-0.08801709  0.03619258  0.06944641 -0.01570761  0.00682773]\n [-0.02754797  0.07474414 -0.08249797  0.04756897  0.0096445 ]\n [-0.14383194  0.05168077  0.27049363  0.10419817  0.05263135]\n [ 0.12452157 -0.02296585  0.14436334  0.02482709 -0.12260982]\n [ 0.04890725 -0.19043611  0.2909058  -0.10708418  0.07759682]\n [ 0.05745121  0.10499261  0.02989995  0.13047372  0.09119483]\n [-0.09693538 -0.12962547  0.22133902 -0.09149387  0.29208034]\n [ 0.2622599  -0.12875232  0.21714815  0.11484481 -0.00040091]\n [ 0.07558989  0.00072951  0.12860702 -0.27085134  0.10740379]\n [ 0.          0.          0.          0.          0.        ]]", 
            "title": "TemporalConvolution"
        }, 
        {
            "location": "/APIGuide/Layers/Convolution-Layers/#temporalmaxpooling", 
            "text": "scala:  val m = TemporalMaxPooling(k_w, d_w = k_w)  m = TemporalMaxPooling(k_w, d_w = k_w)  Applies 1D max-pooling operation in  k_w  regions by step size  d_w  steps.\nInput sequence composed of nInputFrame frames.\nThe input tensor in forward(input) is expected to be a 2D tensor\n(nInputFrame x inputFrameSize) or a 3D tensor (nBatchFrame x nInputFrame x inputFrameSize).  If the input sequence is a 2D tensor of dimension nInputFrame x inputFrameSize,\nthe output sequence will be nOutputFrame x inputFrameSize where  nOutputFrame = (nInputFrame - k_w) / d_w + 1   k_w: kernel width  d_w: step size in width   scala \nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval module = TemporalMaxPooling(4)\nval input = Tensor(1, 8, 5).rand()\nval output = module.forward(input)\nval gradOutput = Tensor(1, 2, 5).rand()\nval gradInput = module.backward(input, gradOutput)\n\nscala \nprintln(output)\n(1,.,.) =\n0.6248109817970544  0.7783127573784441  0.8484677821397781  0.6721713887527585  0.9674506767187268  \n0.9587726043537259  0.8359494411852211  0.6541860734578222  0.7671433456707746  0.8246882800012827  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x5]\n\nscala \nprintln(gradInput)\n(1,.,.) =\n0.0 0.0 0.0 0.0 0.012729122070595622    \n0.0 0.1717955127824098  0.00636984477750957 0.0 0.0 \n0.0 0.0 0.0 0.24560829368419945 0.0 \n0.8350501179229468  0.0 0.0 0.0 0.0 \n0.0 0.9017464134376496  0.662078354973346   0.4239895506761968  0.0 \n0.09446275723166764 0.0 0.0 0.0 0.974747731583193   \n0.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x8x5]  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = TemporalMaxPooling(4)\ninput = np.random.rand(1, 8, 5)\noutput = module.forward(input)\ngrad_output = np.random.rand(1, 2, 5)\ngrad_input = module.backward(input, gradOutput)\n\nprint  output is : ,output\nprint  gradient input m is : ,grad_input  creating: createTemporalMaxPooling\noutput is : [[[0.6248109817970544   0.7783127573784441  0.8484677821397781  0.6721713887527585  0.9674506767187268] \n[0.9587726043537259 0.8359494411852211  0.6541860734578222  0.7671433456707746  0.8246882800012827]]]   \ngradient input m is : [[[0.0    0.0 0.0 0.0 0.012729122070595622]   \n[0.0    0.1717955127824098  0.00636984477750957 0.0 0.0]    \n[0.0    0.0 0.0 0.24560829368419945 0.0 ]\n[0.8350501179229468 0.0 0.0 0.0 0.0 ]\n[0.0    0.9017464134376496  0.662078354973346   0.4239895506761968  0.0]    \n[0.09446275723166764    0.0 0.0 0.0 0.974747731583193]  \n[0.0    0.0 0.0 0.0 0.0]    \n[0.0    0.0 0.0 0.0 0.0]]]  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x8x5]", 
            "title": "TemporalMaxPooling"
        }, 
        {
            "location": "/APIGuide/Layers/Convolution-Layers/#volumetricfullconvolution", 
            "text": "Scala:  val m  = VolumetricFullConvolution(\n  nInputPlane, nOutputPlane,\n  kT, kW, kH,\n  dT, dW = 1, dH = 1,\n  padT = 0, padW = 0, padH = 0,\n  adjT = 0, adjW = 0, adjH = 0,\n  nGroup=1, noBias=false,wRegularizer=null,bRegularizer=null)  Python:  m = VolumetricFullConvolution(\n    n_input_plane, n_output_plane,\n    kt, kw, kh, \n    dt=1, dw=1,dh=1,\n    pad_t=0, pad_w=0, pad_h=0, \n    adj_t=0, adj_w=0,adj_h=0,\n    n_group=1,no_bias=False,init_method='default',wRegularizer=None,bRegularizer=None)  VolumetricFullConvolution  Apply a 3D full convolution over an 3D input image, a sequence of images, or a video etc.\nThe input tensor is expected to be a 4D or 5D(with batch) tensor. Note that instead\nof setting adjT, adjW and adjH,  VolumetricConvolution  also accepts a table input\nwith two tensors: T(convInput, sizeTensor) where convInput is the standard input tensor,\nand the size of sizeTensor is used to set the size of the output (will ignore the adjT, adjW and\nadjH values used to construct the module). This module can be used without a bias by setting\nparameter noBias = true while constructing the module.  Applies a 3D convolution over an input image composed of several input planes. The input tensor\nin forward(input) is expected to be a 5D tensor ( batch x nInputPlane x depth(time) x height x width ) or\na 4D tensor ( nInputPlane x depth x height x width ).\nOutput of forward(input) is also expected to be a 5D tensor ( batch x depth(time) x outputPlane x height x width ) or\na 4D tensor ( outputPlane x depth x height x width ).  odepth  = (depth  - 1) * dT - 2*padT + kT + adjT\nowidth  = (width  - 1) * dW - 2*padW + kW + adjW\noheight = (height - 1) * dH - 2*padH + kH + adjH  Other frameworks call this operation \"In-network Upsampling\", \"Fractionally-strided convolution\",\n\"Backwards Convolution,\" \"Deconvolution\", or \"Upconvolution.\"  Reference Paper: Long J, Shelhamer E, Darrell T. Fully convolutional networks for semantic\nsegmentation[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition.\n2015: 3431-3440.   nInputPlane The number of expected input planes in the image given into forward()  nOutputPlane The number of output planes the convolution layer will produce.  kT The kernel depth of the convolution.  kW The kernel width of the convolution.  kH The kernel height of the convolution.  dT The step of the convolution in the depth dimension. Default is 1.  dW The step of the convolution in the width dimension. Default is 1.  dH The step of the convolution in the height dimension. Default is 1.  padT The additional zeros added per depth to the input planes. Default is 0.  padW The additional zeros added per width to the input planes. Default is 0.  padH The additional zeros added per height to the input planes. Default is 0.  adjT Extra depth to add to the output image. Default is 0.  adjW Extra width to add to the output image. Default is 0.  adjH Extra height to add to the output image. Default is 0.  nGroup Kernel group number.  noBias If bias is needed.  wRegularizer: instance of  Regularizer  (eg. L1 or L2 regularization), applied to the input weights matrices.  bRegularizer: instance of  Regularizer \n                   applied to the bias.   Scala example:  Tensor Input example:   scala \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval m = VolumetricFullConvolution(2, 1, 2, 2, 2)\n\nval input = Tensor(1, 2, 2, 3, 3).randn()\nval output = m.forward(input)\nval gradOut = Tensor(1, 1, 3, 4, 4).fill(0.2f)\nval gradIn = m.backward(input, gradOut)\n\nscala  println(input)\n(1,1,1,.,.) =\n0.3903321   -0.90453357 1.735308    \n-1.2824814  -0.27802613 -0.3977802  \n-0.08534186 0.6385388   -0.86845094 \n\n(1,1,2,.,.) =\n-0.24652982 0.69465446  0.1713606   \n0.07106233  -0.88137305 1.0625362   \n-0.553569   1.1822331   -2.2488093  \n\n(1,2,1,.,.) =\n0.552869    0.4108489   1.7802315   \n0.018191056 0.72422534  -0.6423254  \n-0.4077748  0.024120487 -0.42820823 \n\n(1,2,2,.,.) =\n-1.3711191  -0.37988988 -2.1587164  \n-0.85155743 -1.5785019  -0.77727056 \n0.42253423  0.79593533  0.15303874  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x2x2x3x3]\n\nscala  println(output)\n(1,1,1,.,.) =\n-0.29154167 -0.027156994    -0.6949123  -0.22638178 \n0.091479614 -0.106284864    -0.23198327 -0.5334093  \n0.092822656 -0.13807209 -0.07207352 -0.023272723    \n-0.19217497 -0.18892932 -0.089907974    -0.059967346    \n\n(1,1,2,.,.) =\n0.08078699  -0.0242998  0.27271587  0.48551774  \n-0.30726838 0.5497404   -0.7220843  0.48132813  \n0.007951438 -0.39301366 0.56711966  -0.39552623 \n-0.016941413    -0.5530351  0.21254264  -0.22647215 \n\n(1,1,3,.,.) =\n-0.38189644 -0.5241636  -0.49781954 -0.59505236 \n-0.23887709 -0.99911994 -0.773817   -0.63575095 \n-0.1193203  0.016682416 -0.41216886 -0.5211964  \n-0.06341652 -0.32541442 0.43984014  -0.16862796 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x3x4x4]\n\nscala  println(gradOut)\n(1,1,1,.,.) =\n0.2 0.2 0.2 0.2 \n0.2 0.2 0.2 0.2 \n0.2 0.2 0.2 0.2 \n0.2 0.2 0.2 0.2 \n\n(1,1,2,.,.) =\n0.2 0.2 0.2 0.2 \n0.2 0.2 0.2 0.2 \n0.2 0.2 0.2 0.2 \n0.2 0.2 0.2 0.2 \n\n(1,1,3,.,.) =\n0.2 0.2 0.2 0.2 \n0.2 0.2 0.2 0.2 \n0.2 0.2 0.2 0.2 \n0.2 0.2 0.2 0.2 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x1x3x4x4]\nscala  println(gradIn)\n(1,1,1,.,.) =\n-0.089189366    -0.089189366    -0.089189366    \n-0.089189366    -0.089189366    -0.089189366    \n-0.089189366    -0.089189366    -0.089189366    \n\n(1,1,2,.,.) =\n-0.089189366    -0.089189366    -0.089189366    \n-0.089189366    -0.089189366    -0.089189366    \n-0.089189366    -0.089189366    -0.089189366    \n\n(1,2,1,.,.) =\n0.06755526  0.06755526  0.06755526  \n0.06755526  0.06755526  0.06755526  \n0.06755526  0.06755526  0.06755526  \n\n(1,2,2,.,.) =\n0.06755526  0.06755526  0.06755526  \n0.06755526  0.06755526  0.06755526  \n0.06755526  0.06755526  0.06755526  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x3x3]  Table input Example  scala \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.T\n\nval m = VolumetricFullConvolution(1, 2, 2, 2, 2)\n\nval input1 = Tensor(1, 3, 3, 3).randn()\nval input2 = Tensor(3, 3, 3).fill(2.0f)\nval input = T(input1, input2)\nval output = m.forward(input)\nval gradOut = Tensor(2, 4, 4, 4).fill(0.1f)\nval gradIn = m.backward(input, gradOut)\n\nscala  println(input)\n{\n  2: (1,.,.) =\n  2.0   2.0 2.0\n  2.0   2.0 2.0\n  2.0   2.0 2.0\n\n  (2,.,.) =\n  2.0   2.0 2.0\n  2.0   2.0 2.0\n  2.0   2.0 2.0\n\n  (3,.,.) =\n  2.0   2.0 2.0\n  2.0   2.0 2.0\n  2.0   2.0 2.0\n\n  [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3x3]\n  1: (1,1,.,.) =\n  0.23809154    1.2167819   0.3664989\n  0.8797001 1.5262067   0.15420714\n  0.38004395    -0.24190372 -1.1151218\n\n  (1,2,.,.) =\n  -1.895742 1.8554556   0.62502027\n  -0.6004498    0.056441266 -0.66499823\n  0.7039313 -0.08569297 -0.08191566\n\n  (1,3,.,.) =\n  -1.9555066    -0.20133287 -0.22135374\n  0.8918014 -1.2684877  0.14211883\n  2.5802526 1.1118578   -1.3165624\n\n  [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3x3]\n}\n\nscala  println(output)\n(1,1,.,.) =\n-0.2578445  -0.48271507 -0.28246504 -0.20139077\n-0.43916196 -0.72301924 -0.2915339  -0.20471849\n-0.41347015 -0.36456454 0.021684423 -0.20852578\n-0.255981   -0.17165771 -0.04553239 -0.19543594\n\n(1,2,.,.) =\n0.18660262  -0.8204256  -0.08807768 -0.1023551\n0.026309028 -0.49442527 0.3699256   -0.12729678\n-0.34651133 0.08542377  0.24221262  -0.47949657\n-0.29622912 -0.15598825 -0.23278731 -0.32802662\n\n(1,3,.,.) =\n0.6303606   -1.0451282  0.21740273  -0.03673452\n-0.039471984    -0.2264648  0.15774214  -0.30815765\n-1.0726243  -0.13914594 0.08537227  -0.30611742\n-0.55404246 -0.29725668 -0.037192106    -0.20331946\n\n(1,4,.,.) =\n0.19113302  -0.68506914 -0.21211714 -0.26207167\n-0.40826926 0.068062216 -0.5962198  -0.18985644\n-0.7111124  0.3466564   0.2185097   -0.5388211\n-0.16902745 0.10249108  -0.09487718 -0.35127735\n\n(2,1,.,.) =\n-0.2744591  -0.21165672 -0.17422867 -0.25680506\n-0.24608877 -0.1242196  -0.02206999 -0.23146236\n-0.27057967 -0.17076656 -0.18083718 -0.35417527\n-0.28634468 -0.24118122 -0.30961025 -0.41247135\n\n(2,2,.,.) =\n-0.41682464 -0.5772195  -0.159199   -0.2294753\n-0.41187716 -0.41886678 0.4104582   -0.1382559\n-0.08818802 0.459113    0.48080307  -0.3373265\n-0.18515268 -0.14088067 -0.67644227 -0.67253566\n\n(2,3,.,.) =\n-0.009801388    -0.83997947 -0.39409852 -0.29002026\n-0.6333371  -0.66267097 0.52607954  -0.10082486\n-0.46748784 -0.08717018 -0.54928875 -0.59819674\n-0.103552   0.22147804  -0.20562811 -0.46321797\n\n(2,4,.,.) =\n0.090245515 -0.28537494 -0.24673338 -0.289634\n-0.98199505 -0.7408645  -0.4654177  -0.35744694\n-0.5410351  -0.48618284 -0.40212065 -0.26319134\n0.4081596   0.8880725   -0.26220837 -0.73146355\n\n  [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x4x4]\n\nscala  println(gradOut)\n(1,1,.,.) =\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n\n(1,2,.,.) =\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n\n(1,3,.,.) =\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n\n(1,4,.,.) =\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n\n(2,1,.,.) =\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n\n(2,2,.,.) =\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n\n(2,3,.,.) =\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n\n(2,4,.,.) =\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n0.1 0.1 0.1 0.1\n\n  [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x4x4x4]\n\nscala  println(gradIn)\n{\n  2: (1,.,.) =\n  0.0   0.0 0.0\n  0.0   0.0 0.0\n  0.0   0.0 0.0\n\n  (2,.,.) =\n  0.0   0.0 0.0\n  0.0   0.0 0.0\n  0.0   0.0 0.0\n\n  (3,.,.) =\n  0.0   0.0 0.0\n  0.0   0.0 0.0\n  0.0   0.0 0.0\n\n  [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3x3]\n  1: (1,1,.,.) =\n  0.048819613   0.048819613 0.048819613\n  0.048819613   0.048819613 0.048819613\n  0.048819613   0.048819613 0.048819613\n\n  (1,2,.,.) =\n  0.048819613   0.048819613 0.048819613\n  0.048819613   0.048819613 0.048819613\n  0.048819613   0.048819613 0.048819613\n\n  (1,3,.,.) =\n  0.048819613   0.048819613 0.048819613\n  0.048819613   0.048819613 0.048819613\n  0.048819613   0.048819613 0.048819613\n\n  [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x3x3]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nm = VolumetricFullConvolution(2, 1, 2, 2, 2)\n\nprint  --------- tensor input--------- \ntensor_input = np.random.rand(1, 2, 2, 3, 3)\nprint  input is : ,tensor_input\nout = m.forward(tensor_input)\nprint  output m is : ,out\n\nprint  ----------- table input -------- \nadj_input=np.empty([3, 3, 3])\nadj_input.fill(2.0)\ntable_input = [tensor_input,adj_input]\nprint  input is : ,table_input\nout = m.forward(table_input)\nprint  output m is : ,out  creating: createVolumetricFullConvolution\n--------- tensor input---------\ninput is : [[[[[ 0.41632522  0.62726142  0.11133406]\n    [ 0.61013369  0.76320391  0.27937597]\n    [ 0.3596402   0.85087329  0.18706284]]\n\n   [[ 0.19224562  0.79333622  0.02064112]\n    [ 0.34019388  0.36193739  0.0189533 ]\n    [ 0.01245767  0.59638721  0.97882726]]]\n\n\n  [[[ 0.03641869  0.92804035  0.08934243]\n    [ 0.96598196  0.54331079  0.9157464 ]\n    [ 0.31659511  0.48128023  0.13775686]]\n\n   [[ 0.44624135  0.02830871  0.95668413]\n    [ 0.32971474  0.46466264  0.58239329]\n    [ 0.94129846  0.27284845  0.59931096]]]]]\noutput m is : [[[[[ 0.24059629  0.11875484 -0.07601731  0.18490529]\n    [ 0.17978033 -0.05925606 -0.06877603 -0.00254188]\n    [ 0.33574528  0.10908454 -0.01606898  0.22380096]\n    [ 0.24050319  0.17277193  0.10569186  0.20417407]]\n\n   [[ 0.26733595  0.26336247 -0.16927747  0.04417276]\n    [ 0.39058518 -0.08025722 -0.11981271  0.08441451]\n    [ 0.21994853 -0.1127445  -0.01282334 -0.25795668]\n    [ 0.34960991  0.17045188  0.0885388   0.08292522]]\n\n   [[ 0.29700345  0.22094724  0.27189076  0.07538646]\n    [ 0.27829763  0.01766421  0.32052374 -0.09809484]\n    [ 0.28885722  0.08438809  0.24915564 -0.08578731]\n    [ 0.25339472 -0.09679155  0.09070791  0.21198538]]]]]\n----------- table input --------\ninput is : [array([[[[[ 0.41632522,  0.62726142,  0.11133406],\n          [ 0.61013369,  0.76320391,  0.27937597],\n          [ 0.3596402 ,  0.85087329,  0.18706284]],\n\n         [[ 0.19224562,  0.79333622,  0.02064112],\n          [ 0.34019388,  0.36193739,  0.0189533 ],\n          [ 0.01245767,  0.59638721,  0.97882726]]],\n\n\n        [[[ 0.03641869,  0.92804035,  0.08934243],\n          [ 0.96598196,  0.54331079,  0.9157464 ],\n          [ 0.31659511,  0.48128023,  0.13775686]],\n\n         [[ 0.44624135,  0.02830871,  0.95668413],\n          [ 0.32971474,  0.46466264,  0.58239329],\n          [ 0.94129846,  0.27284845,  0.59931096]]]]]), array([[[ 2.,  2.,  2.],\n        [ 2.,  2.,  2.],\n        [ 2.,  2.,  2.]],\n\n       [[ 2.,  2.,  2.],\n        [ 2.,  2.,  2.],\n        [ 2.,  2.,  2.]],\n\n       [[ 2.,  2.,  2.],\n        [ 2.,  2.,  2.],\n        [ 2.,  2.,  2.]]])]\noutput m is : [[[[[ 0.24059629  0.11875484 -0.07601731  0.18490529]\n    [ 0.17978033 -0.05925606 -0.06877603 -0.00254188]\n    [ 0.33574528  0.10908454 -0.01606898  0.22380096]\n    [ 0.24050319  0.17277193  0.10569186  0.20417407]]\n\n   [[ 0.26733595  0.26336247 -0.16927747  0.04417276]\n    [ 0.39058518 -0.08025722 -0.11981271  0.08441451]\n    [ 0.21994853 -0.1127445  -0.01282334 -0.25795668]\n    [ 0.34960991  0.17045188  0.0885388   0.08292522]]\n\n   [[ 0.29700345  0.22094724  0.27189076  0.07538646]\n    [ 0.27829763  0.01766421  0.32052374 -0.09809484]\n    [ 0.28885722  0.08438809  0.24915564 -0.08578731]\n    [ 0.25339472 -0.09679155  0.09070791  0.21198538]]]]]", 
            "title": "VolumetricFullConvolution"
        }, 
        {
            "location": "/APIGuide/Layers/Convolution-Layers/#locallyconnected1d", 
            "text": "Scala:  val module = LocallyConnected1D(\n  nInputFrame,inputFrameSize, outputFrameSize, kernelW, strideW = 1, propagateBack = true,\n  wRegularizer = null, bRegularizer = null, initWeight = null, initBias = null,\n  initGradWeight = null, initGradBias = null)  Python:  module = LocallyConnected1D(\n  n_input_frame, input_frame_size, output_frame_size, kernel_w, stride_w=1, propagate_back=True,\n  w_regularizer=None, b_regularizer=None, init_weight=None, init_bias=None,\n  init_grad_weight=None, init_grad_bias=None)  Applies a 1D convolution over an input sequence composed of nInputFrame frames with unshared weights.\n The input tensor in  forward(input)  is expected to be a 3D tensor\n ( nBatchFrame  x  nInputFrame  x  inputFrameSize ) or a 2D tensor\n ( nInputFrame  x  inputFrameSize ).\n Output of  forward(input)  is expected to be a 3D tensor\n ( nBatchFrame  x  nOutputFrame  x  outputFrameSize ) or a 2D tensor\n ( nOutputFrame  x  outputFrameSize ).   nInputFrame  Length of the input frame expected in sequences given into  forward() .  inputFrameSize  The input frame size expected in sequences given into  forward() .  outputFrameSize  The output frame size the convolution layer will produce.  kernelW  The kernel width of the convolution  strideW  The step of the convolution in the width dimension.  propagateBack  Whether propagate gradient back, default is true.  wRegularizer  instance of  Regularizer \n                 (eg. L1 or L2 regularization), applied to the input weights matrices.  bRegularizer  instance of  Regularizer \n                 applied to the bias.  initWeight  Initial weight  initBias  Initial bias  initGradWeight  Initial gradient weight  initGradBias  Initial gradient bias  T  The numeric type in the criterion, usually which are  Float  or  Double   Scala example:  import com.intel.analytics.bigdl.numeric.NumericFloat\nval seed = 100\nRNG.setSeed(seed)\nval nInputFrame = 10\nval inputFrameSize = 5\nval outputFrameSize = 3\nval kW = 5\nval dW = 2\nval layer = LocallyConnected1D(nInputFrame, inputFrameSize, outputFrameSize, kW, dW)\n\nRandom.setSeed(seed)\nval input = Tensor(10, 5).apply1(e =  Random.nextFloat())\nval gradOutput = Tensor(3, 3).apply1(e =  Random.nextFloat())\n\nval output = layer.updateOutput(input)  println(output)\n(1,.,.) =\n-0.2896616  0.018883035 -0.45641226 \n-0.41183263 -0.33292565 0.27988705  \n0.076636955 -0.39710814 0.59631383  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nval gradInput = layer.updateGradInput(input, gradOutput)  println(gradInput)\n(1,.,.) =\n0.018415622  -0.10201519  -0.15641063   -0.08271551   -0.060939234  \n0.13609992   0.14934899   0.06083451    -0.13943195   -0.11092151   \n-0.08760113  0.06923811   -0.07376863   0.06743649    0.042455398   \n0.064692274  0.15720972   0.13673763    0.03617531    0.12507091    \n-0.078272685 -0.25193688  0.10712688    -0.11330205   -0.19239372   \n-0.10032463  -0.06266674  0.1048636     0.26058376    -0.40386787   \n-0.10379471  0.07291742   -0.28790376   0.06023993    0.057165086   \n0.15167418   0.07384029   -0.052450493  -0.07709345   -0.016432922  \n-0.1044948   0.060714033  0.08341185    -0.082587965  0.052750245   \n0.0          0.0          0.0           0.0           0.0   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 10x5]  Python example:  from bigdl.nn.layer import LocallyConnected1D\nimport numpy as np\nnInputFrame = 10\ninputFrameSize = 5\noutputFrameSize = 3\nkW = 5\ndW = 2\nlayer = LocallyConnected1D(nInputFrame, inputFrameSize, outputFrameSize, kW, dW)\n\ninput = np.random.rand(10, 5)\ngradOutput = np.random.rand(3, 3)\n\noutput = layer.forward(input)  print(output)\n[[ 0.37944531 -0.25905907 -0.02284177]\n [-0.06727666 -0.48430425 -0.12338555]\n [ 0.5237388  -0.72521925 -0.21979821]]\n\ngradInput = layer.backward(input, gradOutput)  print(gradInput)\n[[-0.22256926 -0.11267932  0.05445758 -0.06569604  0.00799843]\n [ 0.08402308  0.00340014  0.04202492 -0.05055574  0.11835655]\n [ 0.00352848 -0.02568576 -0.08056175  0.06994451  0.09152003]\n [ 0.04089724 -0.19517297  0.19212601 -0.21531224  0.03563112]\n [-0.28906721  0.07873128 -0.01326483 -0.18504807  0.02452871]\n [-0.09979478 -0.1009931  -0.25594842  0.14314197 -0.30875987]\n [-0.00814501 -0.02431242 -0.1140819  -0.14522757 -0.09230929]\n [-0.11231296  0.0053857   0.00582423  0.18309449  0.13369997]\n [-0.01302226 -0.13035376  0.02006471  0.09794775 -0.08067283]\n [ 0.          0.          0.          0.          0.        ]]", 
            "title": "LocallyConnected1D"
        }, 
        {
            "location": "/APIGuide/Layers/Convolution-Layers/#locallyconnected2d", 
            "text": "Scala:  val module = LocallyConnected2D(\n   nInputPlane, inputWidth, inputHeight, nOutputPlane, kernelW, kernelH, \n   strideW = 1, strideH = 1, padW = 0, padH = 0, propagateBack = true, \n   wRegularizer = null, bRegularizer = null, initWeight = null, initBias = null,\n   initGradWeight = null, initGradBias = null, withBias = true, format = DataFormat.NCHW)  Python:  module = LocallyConnected2D(\n    n_input_plane, input_width, input_height, n_output_plane,\n    kernel_w, kernel_h, stride_w=1, stride_h=1, pad_w=0, pad_h=0,\n    propagate_back=True, wRegularizer=None, bRegularizer=None,\n    init_weight=None, init_bias=None, init_grad_weight=None,\n    init_grad_bias=None, with_bias=True, data_format= NCHW )  The LocallyConnected2D layer works similarly to the  SpatialConvolution  layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.   nInputPlane  The number of expected input planes in the image.  inputWidth  The input width.  inputHeight  The input height.  nOutputPlane  The number of output planes the convolution layer will produce.  kernelW  The kernel width of the convolution.  kernelH  The kernel height of the convolution.  strideW  The step of the convolution in the width dimension.  strideH  The step of the convolution in the height dimension.  padW  The additional zeros added per width to the input planes.  padH  The additional zeros added per height to the input planes.  propagateBack  Whether to propagate gradient back.  wRegularizer  Weight regularizer.  bRegularizer  Bias regularizer.  initWeight  Initial weight.  initBias  Initial bias.  initGradWeight  Initial gradient weight.  initGradBias  Initial gradient bias.  withBias  Whether to include bias.  format  Data format of the input. Either \"NHWC\" or \"NCHW\".   Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.abstractnn.DataFormat\nimport com.intel.analytics.bigdl.nn.LocallyConnected2D\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval layer = LocallyConnected2D(2, 6, 3, 3, 1, 2, format=DataFormat.NHWC)\nval input = Tensor(1, 3, 6, 2).rand()\nval output = layer.forward(input)\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.580334    0.59774524\n0.35452667  0.9134508\n0.56355035  0.10698065\n0.95197415  0.10339011\n0.6571263   0.35572186\n0.31106102  0.97996104\n\n(1,2,.,.) =\n0.87887615  0.8108329\n0.7184107   0.487163\n0.85714895  0.30265027\n0.4407469   0.94804007\n0.5460197   0.01421738\n0.74672765  0.23766468\n\n(1,3,.,.) =\n0.10655104  0.008004449\n0.142883    0.7885532\n0.12025218  0.9536053\n0.85908693  0.088657066\n0.42529714  0.64380044\n0.8999299   0.6074533\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x6x2]\n\n\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.7493179     0.27513236    -0.2982489\n-0.41126582   0.21310717    0.36723173\n-0.039210618  0.13379198    -0.28216434\n0.19143593    -0.61731964   -0.018212453\n0.24316064    -1.1187351    0.74201244\n0.060099036   -0.5223875    -0.95892024\n\n(1,2,.,.) =\n-0.4977209   0.19270697    -0.00647337\n-0.18642347  -0.057786018  0.33848432\n0.044415057  -0.12975587   -0.054034393\n0.46163      0.06908426    -0.17127737\n-0.07933617  0.190754      0.6044696\n-0.723027    0.14250416    0.51286244\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x6x3]  Python example:  import numpy as np\nfrom bigdl.nn.layer import LocallyConnected2D\n\nlayer = LocallyConnected2D(2, 6, 3, 3, 1, 2, data_format= NHWC )\ninput = np.random.rand(1, 3, 6, 2)\noutput = layer.forward(input)\n\nprint(input)\n[[[[  6.13867469e-01,   5.15609721e-01],\n   [  5.14951616e-01,   4.93308310e-01],\n   [  7.34218405e-01,   6.06311945e-01],\n   [  9.38263668e-01,   3.26766196e-01],\n   [  4.24955447e-02,   3.30625440e-01],\n   [  3.55858423e-01,   6.10869469e-01]],\n\n  [[  3.75525334e-02,   4.93555936e-02],\n   [  4.44188497e-01,   3.51001813e-02],\n   [  8.11139320e-01,   4.87916727e-01],\n   [  4.00786464e-01,   1.65522882e-01],\n   [  5.98298525e-01,   9.54343135e-01],\n   [  2.25942857e-01,   5.76090257e-02]],\n\n  [[  1.34708024e-01,   4.81133433e-01],\n   [  7.63198918e-01,   2.96906096e-01],\n   [  6.01935030e-01,   2.39748841e-01],\n   [  5.32036004e-01,   1.86107334e-01],\n   [  9.38617798e-01,   6.83511632e-04],\n   [  2.34639435e-01,   8.04904706e-01]]]]\n\nprint(output)\n[[[[-0.01100884,  0.59226239, -0.15626255],\n   [ 0.29099607,  0.16722232, -0.39429453],\n   [ 0.22557285,  0.30368266,  0.53235221],\n   [ 0.05602939, -0.07677993, -0.32399753],\n   [ 0.47589377, -0.15926963,  0.1135996 ],\n   [ 0.25957716,  0.17047183,  0.21640816]],\n\n  [[-0.15497619,  0.29392233, -0.12167639],\n   [ 0.60150111, -0.001901  ,  0.294438  ],\n   [-0.05004713,  0.22379839,  0.53971994],\n   [ 0.23204027,  0.17921877,  0.29594338],\n   [ 0.91105354,  0.881271  , -0.69958985],\n   [ 0.45518994, -0.645486  ,  0.37325871]]]]", 
            "title": "LocallyConnected2D"
        }, 
        {
            "location": "/APIGuide/Layers/Convolution-Layers/#upsampling1d", 
            "text": "Scala:  val module = UpSampling1D(length: Int)  Python:  m = UpSampling1D(length)  UpSampling layer for 1D inputs. Repeats each temporal step length times along the time axis.   If input's size is (batch, steps, features), then the output's size will be (batch, steps * length, features).   Scala example:    import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.T\n\nval module = UpSampling1D(2)\nval input = Tensor(2, 3, 3).range(1, 18)\nmodule.forward(input)  The output should be   res: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.0 2.0 3.0\n1.0 2.0 3.0\n4.0 5.0 6.0\n4.0 5.0 6.0\n7.0 8.0 9.0\n7.0 8.0 9.0\n\n(2,.,.) =\n10.0    11.0    12.0\n10.0    11.0    12.0\n13.0    14.0    15.0\n13.0    14.0    15.0\n16.0    17.0    18.0\n16.0    17.0    18.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x6x3]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\ninput = np.random.rand(1,2,2,2,2)\nprint  input is : ,input\n\nm = UpSampling3D([2,2,2])\nout = m.forward(input)\nprint  output m is : ,out  Gives the output,  input is : \n[[[[[ 0.80314148  0.79158609]\n    [ 0.3988551   0.91726511]]\n   [[ 0.86814757  0.90733343]\n    [ 0.34470172  0.03056507]]]\n\n  [[[ 0.62367481  0.20093996]\n    [ 0.57614891  0.75442351]]\n   [[ 0.52572424  0.04730832]\n    [ 0.74973562  0.2245238 ]]]]]\ncreating: createUpSampling3D\noutput m is : \n[[[[[ 0.80314147  0.80314147  0.7915861   0.7915861 ]\n    [ 0.80314147  0.80314147  0.7915861   0.7915861 ]\n    [ 0.39885509  0.39885509  0.91726512  0.91726512]\n    [ 0.39885509  0.39885509  0.91726512  0.91726512]]\n\n   [[ 0.80314147  0.80314147  0.7915861   0.7915861 ]\n    [ 0.80314147  0.80314147  0.7915861   0.7915861 ]\n    [ 0.39885509  0.39885509  0.91726512  0.91726512]\n    [ 0.39885509  0.39885509  0.91726512  0.91726512]]\n\n   [[ 0.86814755  0.86814755  0.90733343  0.90733343]\n    [ 0.86814755  0.86814755  0.90733343  0.90733343]\n    [ 0.34470171  0.34470171  0.03056507  0.03056507]\n    [ 0.34470171  0.34470171  0.03056507  0.03056507]]\n\n   [[ 0.86814755  0.86814755  0.90733343  0.90733343]\n    [ 0.86814755  0.86814755  0.90733343  0.90733343]\n    [ 0.34470171  0.34470171  0.03056507  0.03056507]\n    [ 0.34470171  0.34470171  0.03056507  0.03056507]]]\n\n\n  [[[ 0.62367481  0.62367481  0.20093997  0.20093997]\n    [ 0.62367481  0.62367481  0.20093997  0.20093997]\n    [ 0.57614893  0.57614893  0.7544235   0.7544235 ]\n    [ 0.57614893  0.57614893  0.7544235   0.7544235 ]]\n\n   [[ 0.62367481  0.62367481  0.20093997  0.20093997]\n    [ 0.62367481  0.62367481  0.20093997  0.20093997]\n    [ 0.57614893  0.57614893  0.7544235   0.7544235 ]\n    [ 0.57614893  0.57614893  0.7544235   0.7544235 ]]\n\n   [[ 0.52572423  0.52572423  0.04730832  0.04730832]\n    [ 0.52572423  0.52572423  0.04730832  0.04730832]\n    [ 0.74973559  0.74973559  0.2245238   0.2245238 ]\n    [ 0.74973559  0.74973559  0.2245238   0.2245238 ]]\n\n   [[ 0.52572423  0.52572423  0.04730832  0.04730832]\n    [ 0.52572423  0.52572423  0.04730832  0.04730832]\n    [ 0.74973559  0.74973559  0.2245238   0.2245238 ]\n    [ 0.74973559  0.74973559  0.2245238   0.2245238 ]]]]]", 
            "title": "UpSampling1D"
        }, 
        {
            "location": "/APIGuide/Layers/Convolution-Layers/#upsampling2d", 
            "text": "Scala:  val module = UpSampling2D(size: Array[Int], format: DataFormat = DataFormat.NCHW)  Python:  m = UpSampling2D(size, data_format)  UpSampling layer for 2D inputs. \nRepeats the heights and widths of the data by size[0] and size[1] respectively.   If input's dataformat is NCHW, then the size of output will be (N, C, H * size[0], W * size[1]).   Detailed parameter explanation for the constructor. \n *  size  tuple of 2 integers. The upsampling factors for heights and widths.\n *  data_format  a string value (or DataFormat Object in Scala) of \"NHWC\" or \"NCHW\" to specify the input data format of this layer. In \"NHWC\" format\n                        data is stored in the order of [batch_size, height, width, channels], in \"NCHW\" format data is stored\n                        in the order of [batch_size, channels, height, width].  Scala example:    import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.T\n\nval module = UpSampling2D(Array(2, 3))\nval input = Tensor(2, 2, 3, 3).range(1, 36)\nmodule.forward(input)  The output should be   res: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n1.0 1.0 1.0 2.0 2.0 2.0 3.0 3.0 3.0\n1.0 1.0 1.0 2.0 2.0 2.0 3.0 3.0 3.0\n4.0 4.0 4.0 5.0 5.0 5.0 6.0 6.0 6.0\n4.0 4.0 4.0 5.0 5.0 5.0 6.0 6.0 6.0\n7.0 7.0 7.0 8.0 8.0 8.0 9.0 9.0 9.0\n7.0 7.0 7.0 8.0 8.0 8.0 9.0 9.0 9.0\n\n(1,2,.,.) =\n10.0    10.0    10.0    11.0    11.0    11.0    12.0    12.0    12.0\n10.0    10.0    10.0    11.0    11.0    11.0    12.0    12.0    12.0\n13.0    13.0    13.0    14.0    14.0    14.0    15.0    15.0    15.0\n13.0    13.0    13.0    14.0    14.0    14.0    15.0    15.0    15.0\n16.0    16.0    16.0    17.0    17.0    17.0    18.0    18.0    18.0\n16.0    16.0    16.0    17.0    17.0    17.0    18.0    18.0    18.0\n\n(2,1,.,.) =\n19.0    19.0    19.0    20.0    20.0    20.0    21.0    21.0    21.0\n19.0    19.0    19.0    20.0    20.0    20.0    21.0    21.0    21.0\n22.0    22.0    22.0    23.0    23.0    23.0    24.0    24.0    24.0\n22.0    22.0    22.0    23.0    23.0    23.0    24.0    24.0    24.0\n25.0    25.0    25.0    26.0    26.0    26.0    27.0    27....  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = UpSampling2D([2, 3])\ninput = np.arange(1, 37).reshape(2, 2, 3, 3)\nmodule.forward(input)  The output is   array([[[[  1.,   1.,   1.,   2.,   2.,   2.,   3.,   3.,   3.],\n         [  1.,   1.,   1.,   2.,   2.,   2.,   3.,   3.,   3.],\n         [  4.,   4.,   4.,   5.,   5.,   5.,   6.,   6.,   6.],\n         [  4.,   4.,   4.,   5.,   5.,   5.,   6.,   6.,   6.],\n         [  7.,   7.,   7.,   8.,   8.,   8.,   9.,   9.,   9.],\n         [  7.,   7.,   7.,   8.,   8.,   8.,   9.,   9.,   9.]],\n\n        [[ 10.,  10.,  10.,  11.,  11.,  11.,  12.,  12.,  12.],\n         [ 10.,  10.,  10.,  11.,  11.,  11.,  12.,  12.,  12.],\n         [ 13.,  13.,  13.,  14.,  14.,  14.,  15.,  15.,  15.],\n         [ 13.,  13.,  13.,  14.,  14.,  14.,  15.,  15.,  15.],\n         [ 16.,  16.,  16.,  17.,  17.,  17.,  18.,  18.,  18.],\n         [ 16.,  16.,  16.,  17.,  17.,  17.,  18.,  18.,  18.]]],\n\n\n       [[[ 19.,  19.,  19.,  20.,  20.,  20.,  21.,  21.,  21.],\n         [ 19.,  19.,  19.,  20.,  20.,  20.,  21.,  21.,  21.],\n         [ 22.,  22.,  22.,  23.,  23.,  23.,  24.,  24.,  24.],\n         [ 22.,  22.,  22.,  23.,  23.,  23.,  24.,  24.,  24.],\n         [ 25.,  25.,  25.,  26.,  26.,  26.,  27.,  27.,  27.],\n         [ 25.,  25.,  25.,  26.,  26.,  26.,  27.,  27.,  27.]],\n\n        [[ 28.,  28.,  28.,  29.,  29.,  29.,  30.,  30.,  30.],\n         [ 28.,  28.,  28.,  29.,  29.,  29.,  30.,  30.,  30.],\n         [ 31.,  31.,  31.,  32.,  32.,  32.,  33.,  33.,  33.],\n         [ 31.,  31.,  31.,  32.,  32.,  32.,  33.,  33.,  33.],\n         [ 34.,  34.,  34.,  35.,  35.,  35.,  36.,  36.,  36.],\n         [ 34.,  34.,  34.,  35.,  35.,  35.,  36.,  36.,  36.]]]], dtype=float32)", 
            "title": "UpSampling2D"
        }, 
        {
            "location": "/APIGuide/Layers/Convolution-Layers/#upsampling3d", 
            "text": "Scala:  val module = UpSampling3D(size: Array[Int])  Python:  m = UpSampling3D(size)  UpSampling3D is a module that upsamples for 3D inputs.\nIt repeats the 1st, 2nd and 3rd dimensions of the data by size[0], size[1] and size[2] respectively.\nThe input data is assumed to be of the form  minibatch x channels x depth x height x width .  Scala example:  \nscala \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval module = UpSampling3D(Array(2, 2, 2))\nval input = Tensor(1, 2, 2, 2, 2).randn()\nval output = module.forward(input)  input\n(1,1,1,.,.) =\n0.8626614   -0.25849837\n0.89711547  0.41256216\n\n(1,1,2,.,.) =\n0.031144595 0.28527617\n0.36917794  -0.9892453\n\n(1,2,1,.,.) =\n-1.7768023  -0.39210165\n1.9640301   -2.2383325\n\n(1,2,2,.,.) =\n0.41984457  -1.1820035\n0.23327439  -0.17730176\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x2x2]  output\n(1,1,1,.,.) =\n0.8626614   0.8626614   -0.25849837 -0.25849837\n0.8626614   0.8626614   -0.25849837 -0.25849837\n0.89711547  0.89711547  0.41256216  0.41256216\n0.89711547  0.89711547  0.41256216  0.41256216\n\n(1,1,2,.,.) =\n0.8626614   0.8626614   -0.25849837 -0.25849837\n0.8626614   0.8626614   -0.25849837 -0.25849837\n0.89711547  0.89711547  0.41256216  0.41256216\n0.89711547  0.89711547  0.41256216  0.41256216\n\n(1,1,3,.,.) =\n0.031144595 0.031144595 0.28527617  0.28527617\n0.031144595 0.031144595 0.28527617  0.28527617\n0.36917794  0.36917794  -0.9892453  -0.9892453\n0.36917794  0.36917794  -0.9892453  -0.9892453\n\n(1,1,4,.,.) =\n0.031144595 0.031144595 0.28527617  0.28527617\n0.031144595 0.031144595 0.28527617  0.28527617\n0.36917794  0.36917794  -0.9892453  -0.9892453\n0.36917794  0.36917794  -0.9892453  -0.9892453\n\n(1,2,1,.,.) =\n-1.7768023  -1.7768023  -0.39210165 -0.39210165\n-1.7768023  -1.7768023  -0.39210165 -0.39210165\n1.9640301   1.9640301   -2.2383325  -2.2383325\n1.9640301   1.9640301   -2.2383325  -2.2383325\n\n(1,2,2,.,.) =\n-1.7768023  -1.7768023  -0.39210165 -0.39210165\n-1.7768023  -1.7768023  -0.39210165 -0.39210165\n1.9640301   1.9640301   -2.2383325  -2.2383325\n1.9640301   1.9640301   -2.2383325  -2.2383325\n\n(1,2,3,.,.) =\n0.41984457  0.41984457  -1.1820035  -1.1820035\n0.41984457  0.41984457  -1.1820035  -1.1820035\n0.23327439  0.23327439  -0.17730176 -0.17730176\n0.23327439  0.23327439  -0.17730176 -0.17730176\n\n(1,2,4,.,.) =\n0.41984457  0.41984457  -1.1820035  -1.1820035\n0.41984457  0.41984457  -1.1820035  -1.1820035\n0.23327439  0.23327439  -0.17730176 -0.17730176\n0.23327439  0.23327439  -0.17730176 -0.17730176\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4x4]", 
            "title": "UpSampling3D"
        }, 
        {
            "location": "/APIGuide/Layers/Convolution-Layers/#resizebilinear", 
            "text": "Scala:  val module = ResizeBilinear(outputHeight, outputWidth,\n                      alignCorners=false, dataFormat = DataFormat.NCHW)  Python:  m = ResizeBilinear(outputHeight, outputWidth,\n               alignCorners=False, dataFormat= NCHW )  Resize the input image with bilinear interpolation. The input image must be a float tensor with\nNHWC or NCHW layout.  Scala example:  \nscala \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = ResizeBilinear(4, 4)\nval input = Tensor(1, 1, 2, 2).range(1, 4)\nval output = module.forward(input)  output\n(1,1,.,.) =\n1.0 1.5 2.0 2.0 \n2.0 2.5 3.0 3.0 \n3.0 3.5 4.0 4.0 \n3.0 3.5 4.0 4.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x1x4x4]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = ResizeBilinear(4, 4)\ninput = np.arange(1, 5).reshape(1, 1, 2, 2)\noutput = module.forward(input)\nprint output  The output is   [[[[ 1.   1.5  2.   2. ]\n   [ 2.   2.5  3.   3. ]\n   [ 3.   3.5  4.   4. ]\n   [ 3.   3.5  4.   4. ]]]]", 
            "title": "ResizeBilinear"
        }, 
        {
            "location": "/APIGuide/Layers/Pooling-Layers/", 
            "text": "SpatialMaxPooling\n\n\nScala:\n\n\nval mp = SpatialMaxPooling(2, 2, dW=2, dH=2, padW=0, padH=0, format=DataFormat.NCHW)\n\n\n\n\nPython:\n\n\nmp = SpatialMaxPooling(2, 2, dw=2, dh=2, pad_w=0, pad_h=0, to_ceil=false, format=\nNCHW\n)\n\n\n\n\nApplies 2D max-pooling operation in kWxkH regions by step size dWxdH steps.\nThe number of output features is equal to the number of input planes.\nIf the input image is a 3D tensor nInputPlane x height x width,\nthe output image size will be nOutputPlane x oheight x owidth where\n\n\n\n\nowidth  = op((width  + 2*padW - kW) / dW + 1)\n\n\noheight = op((height + 2*padH - kH) / dH + 1)\n\n\n\n\nop is a rounding operator. By default, it is floor.\nIt can be changed by calling ceil() or floor() methods.\n\n\nAs for padding, when padW and padH are both -1, we use a padding algorithm similar to the \"SAME\" padding of tensorflow. That is\n\n\n outHeight = Math.ceil(inHeight.toFloat/strideH.toFloat)\n outWidth = Math.ceil(inWidth.toFloat/strideW.toFloat)\n\n padAlongHeight = Math.max(0, (outHeight - 1) * strideH + kernelH - inHeight)\n padAlongWidth = Math.max(0, (outWidth - 1) * strideW + kernelW - inWidth)\n\n padTop = padAlongHeight / 2\n padLeft = padAlongWidth / 2\n\n\n\n\nThe format parameter is a string value (or DataFormat Object in Scala) of \"NHWC\" or \"NCHW\" to specify the input data format of this layer. In \"NHWC\" format\ndata is stored in the order of [batch_size, height, width, channels], in \"NCHW\" format data is stored\nin the order of [batch_size, channels, height, width].\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.SpatialMaxPooling\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval mp = SpatialMaxPooling(2, 2, 2, 2)\nval input = Tensor(1, 3, 3)\n\ninput(Array(1, 1, 1)) = 0.5336726f\ninput(Array(1, 1, 2)) = 0.7963769f\ninput(Array(1, 1, 3)) = 0.5674766f\ninput(Array(1, 2, 1)) = 0.1803996f\ninput(Array(1, 2, 2)) = 0.2460861f\ninput(Array(1, 2, 3)) = 0.2295625f\ninput(Array(1, 3, 1)) = 0.3073633f\ninput(Array(1, 3, 2)) = 0.5973460f\ninput(Array(1, 3, 3)) = 0.4298954f\n\nval gradOutput = Tensor(1, 1, 1)\ngradOutput(Array(1, 1, 1)) = 0.023921491578221f\n\nval output = mp.forward(input)\nval gradInput = mp.backward(input, gradOutput)\n\nprintln(output)\nprintln(gradInput)\n\n\n\n\nThe output is,\n\n\n(1,.,.) =\n0.7963769\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1]\n\n\n\n\nThe gradInput is,\n\n\n(1,.,.) =\n0.0     0.023921492     0.0\n0.0     0.0     0.0\n0.0     0.0     0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nmp = SpatialMaxPooling(2, 2, 2, 2)\n\n\ninput = np.array([0.5336726, 0.7963769, 0.5674766, 0.1803996, 0.2460861, 0.2295625, 0.3073633, 0.5973460, 0.4298954]).astype(\nfloat32\n)\ninput = input.reshape(1, 3, 3)\n\noutput = mp.forward(input)\nprint output\n\ngradOutput = np.array([0.023921491578221]).astype(\nfloat32\n)\ngradOutput = gradOutput.reshape(1, 1, 1)\n\ngradInput = mp.backward(input, gradOutput)\nprint gradInput\n\n\n\n\nThe output is,\n\n\n[array([[[ 0.79637688]]], dtype=float32)]\n\n\n\n\nThe gradInput is,\n\n\n[array([[[ 0.        ,  0.02392149,  0.        ],\n        [ 0.        ,  0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        ]]], dtype=float32)]\n\n\n\n\nSpatialAveragePooling\n\n\nScala:\n\n\nval m = SpatialAveragePooling(kW, kH, dW=1, dH=1, padW=0, padH=0, globalPooling=false, ceilMode=false, countIncludePad=true, divide=true, format=DataFormat.NCHW)\n\n\n\n\nPython:\n\n\nm = SpatialAveragePooling(kw, kh, dw=1, dh=1, pad_w=0, pad_h=0, global_pooling=False, ceil_mode=False, count_include_pad=True, divide=True, format=\nNCHW\n)\n\n\n\n\nSpatialAveragePooling is a module that applies 2D average-pooling operation in \nkW\nx\nkH\n regions by step size \ndW\nx\ndH\n.\n\n\nThe number of output features is equal to the number of input planes.\n\n\nAs for padding, when padW and padH are both -1, we use a padding algorithm similar to the \"SAME\" padding of tensorflow. That is\n\n\n outHeight = Math.ceil(inHeight.toFloat/strideH.toFloat)\n outWidth = Math.ceil(inWidth.toFloat/strideW.toFloat)\n\n padAlongHeight = Math.max(0, (outHeight - 1) * strideH + kernelH - inHeight)\n padAlongWidth = Math.max(0, (outWidth - 1) * strideW + kernelW - inWidth)\n\n padTop = padAlongHeight / 2\n padLeft = padAlongWidth / 2\n\n\n\n\nThe format parameter is a string value (or DataFormat Object in Scala) of \"NHWC\" or \"NCHW\" to specify the input data format of this layer. In \"NHWC\" format\ndata is stored in the order of [batch_size, height, width, channels], in \"NCHW\" format data is stored\nin the order of [batch_size, channels, height, width].\n\n\nScala example:\n\n\nscala\n \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval input = Tensor(1, 3, 3).randn()\nval m = SpatialAveragePooling(3, 2, 2, 1)\nval output = m.forward(input)\nval gradOut = Tensor(1, 2, 1).randn()\nval gradIn = m.backward(input,gradOut)\n\nscala\n print(input)\n(1,.,.) =\n0.9916249       1.0299556       0.5608558\n-0.1664829      1.5031902       0.48598626\n0.37362042      -0.0966136      -1.4257964\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]\n\nscala\n print(output)\n(1,.,.) =\n0.7341883\n0.1123173\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x1]\n\nscala\n print(gradOut)\n(1,.,.) =\n-0.42837557\n-1.5104272\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x2x1]\n\nscala\n print(gradIn)\n(1,.,.) =\n-0.071395926    -0.071395926    -0.071395926\n-0.3231338      -0.3231338      -0.3231338\n-0.25173786     -0.25173786     -0.25173786\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x3]\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\ninput = np.random.randn(1,3,3)\nprint \ninput is :\n,input\n\nm = SpatialAveragePooling(3,2,2,1)\nout = m.forward(input)\nprint \noutput of m is :\n,out\n\ngrad_out = np.random.rand(1,3,1)\ngrad_in = m.backward(input,grad_out)\nprint \ngrad input of m is :\n,grad_in\n\n\n\n\nproduces output:\n\n\ninput is : [[[ 1.50602425 -0.92869054 -1.9393117 ]\n  [ 0.31447547  0.63450578 -0.92485516]\n  [-2.07858315 -0.05688643  0.73648798]]]\ncreating: createSpatialAveragePooling\noutput of m is : [array([[[-0.22297533],\n        [-0.22914261]]], dtype=float32)]\ngrad input of m is : [array([[[ 0.06282618,  0.06282618,  0.06282618],\n        [ 0.09333335,  0.09333335,  0.09333335],\n        [ 0.03050717,  0.03050717,  0.03050717]]], dtype=float32)]\n\n\n\n\n\nVolumetricMaxPooling\n\n\nScala:\n\n\nval layer = VolumetricMaxPooling(\n  kernelT, kernelW, kernelH,\n  strideT, strideW, strideH,\n  paddingT, paddingW, paddingH\n)\n\n\n\n\nPython:\n\n\nlayer = VolumetricMaxPooling(\n  kernelT, kernelW, kernelH,\n  strideT, strideW, strideH,\n  paddingT, paddingW, paddingH\n)\n\n\n\n\nApplies 3D max-pooling operation in kT x kW x kH regions by step size dT x dW x dH.\nThe number of output features is equal to the number of input planes / dT.\nThe input can optionally be padded with zeros. Padding should be smaller than\nhalf of kernel size. That is, padT \n kT/2, padW \n kW/2 and padH \n kH/2\n\n\nThe input layout should be [batch, plane, time, height, width] or [plane, time, height, width]\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = VolumetricMaxPooling(\n  2, 2, 2,\n  1, 1, 1,\n  0, 0, 0\n)\n\nval input = Tensor(T(T(\n  T(\n    T(1.0f, 2.0f, 3.0f),\n    T(4.0f, 5.0f, 6.0f),\n    T(7.0f, 8.0f, 9.0f)\n  ),\n  T(\n    T(4.0f, 5.0f, 6.0f),\n    T(1.0f, 3.0f, 9.0f),\n    T(2.0f, 3.0f, 7.0f)\n  )\n)))\nlayer.forward(input)\nlayer.backward(input, Tensor(T(T(T(\n  T(0.1f, 0.2f),\n  T(0.3f, 0.4f)\n)))))\n\n\n\n\nIts output should be\n\n\n(1,1,.,.) =\n5.0     9.0\n8.0     9.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x2]\n\n(1,1,.,.) =\n0.0     0.0     0.0\n0.0     0.1     0.0\n0.0     0.3     0.4\n\n(1,2,.,.) =\n0.0     0.0     0.0\n0.0     0.0     0.2\n0.0     0.0     0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x3x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import VolumetricMaxPooling\nimport numpy as np\n\nlayer = VolumetricMaxPooling(\n  2, 2, 2,\n  1, 1, 1,\n  0, 0, 0\n)\n\ninput = np.array([[\n  [\n    [1.0, 2.0, 3.0],\n    [4.0, 5.0, 6.0],\n    [7.0, 8.0, 9.0]\n  ],\n  [\n    [4.0, 5.0, 6.0],\n    [1.0, 3.0, 9.0],\n    [2.0, 3.0, 7.0]\n  ]\n]])\nlayer.forward(input)\nlayer.backward(input, np.array([[[\n  [0.1, 0.2],\n  [0.3, 0.4]\n]]]))\n\n\n\n\nIts output should be\n\n\narray([[[[ 5.,  9.],\n         [ 8.,  9.]]]], dtype=float32)\n\narray([[[[ 0.        ,  0.        ,  0.        ],\n         [ 0.        ,  0.1       ,  0.        ],\n         [ 0.        ,  0.30000001,  0.40000001]],\n\n        [[ 0.        ,  0.        ,  0.        ],\n         [ 0.        ,  0.        ,  0.2       ],\n         [ 0.        ,  0.        ,  0.        ]]]], dtype=float32)\n\n\n\n\nVolumetricAveragePooling\n\n\nScala:\n\n\nval layer = VolumetricMaxPooling(\n  kT, kW, kH, dT, dW, dH,\n  padT=0, padW=0, padH=0,\n  countIncludePad=true, ceilMode=false\n)\n\n\n\n\nPython:\n\n\nlayer = VolumetricMaxPooling(\n  k_t, k_w, k_h, d_t, d_w, d_h\n  pad_t=0, pad_w=0, pad_h=0,\n  count_include_pad=True, ceil_mode=False\n)\n\n\n\n\nApplies 3D average-pooling operation in kernel kT x kW x kH regions by step size dT x dW x dH.\nThe number of output features is equal to the number of input planes / dT.\nThe input can optionally be padded with zeros. Padding should be smaller than\nhalf of kernel size. That is, padT \n kT/2, padW \n kW/2 and padH \n kH/2\n\n\nThe input layout should be [batch, plane, time, height, width] or [plane, time, height, width]\n\n\nBy default, countIncludePad=true, which means to include padding when dividing the number of elements in pooling region.\nOne can use ceilMode to control whether the output size is to be ceiled or floored.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = VolumetricAveragePooling(\n  2, 2, 2,\n  1, 1, 1,\n  0, 0, 0\n)\n\nval input = Tensor(T(T(\n  T(\n    T(1.0f, 2.0f, 3.0f),\n    T(4.0f, 5.0f, 6.0f),\n    T(7.0f, 8.0f, 9.0f)\n  ),\n  T(\n    T(4.0f, 5.0f, 6.0f),\n    T(1.0f, 3.0f, 9.0f),\n    T(2.0f, 3.0f, 7.0f)\n  )\n)))\nlayer.forward(input)\nlayer.backward(input, Tensor(T(T(T(\n  T(0.1f, 0.2f),\n  T(0.3f, 0.4f)\n)))))\n\n\n\n\nIts output should be\n\n\n(1,1,.,.) =\n3.125   4.875\n4.125   6.25\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x2]\n\n(1,1,.,.) =\n0.0125  0.0375  0.025\n0.05    0.125   0.075\n0.0375  0.087500006 0.05\n\n(1,2,.,.) =\n0.0125  0.0375  0.025\n0.05    0.125   0.075\n0.0375  0.087500006 0.05\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x3x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import VolumetricAveragePooling\nimport numpy as np\n\nlayer = VolumetricAveragePooling(\n  2, 2, 2,\n  1, 1, 1,\n  0, 0, 0\n)\n\ninput = np.array([[\n  [\n    [1.0, 2.0, 3.0],\n    [4.0, 5.0, 6.0],\n    [7.0, 8.0, 9.0]\n  ],\n  [\n    [4.0, 5.0, 6.0],\n    [1.0, 3.0, 9.0],\n    [2.0, 3.0, 7.0]\n  ]\n]])\nlayer.forward(input)\nlayer.backward(input, np.array([[[\n  [0.1, 0.2],\n  [0.3, 0.4]\n]]]))\n\n\n\n\nIts output should be\n\n\narray([[[[ 3.125  4.875]\n         [ 4.125  6.25 ]]]], dtype=float32)\n\narray([[[[ 0.0125      0.0375      0.025     ]\n         [ 0.05        0.125       0.075     ]\n         [ 0.0375      0.08750001  0.05      ]]\n\n        [[ 0.0125      0.0375      0.025     ]\n         [ 0.05        0.125       0.075     ]\n         [ 0.0375      0.08750001  0.05      ]]]], dtype=float32)\n\n\n\n\nRoiPooling\n\n\nScala:\n\n\nval m =  RoiPooling(pooled_w, pooled_h, spatial_scale)\n\n\n\n\nPython:\n\n\nm = RoiPooling(pooled_w, pooled_h, spatial_scale)\n\n\n\n\nRoiPooling is a module that performs Region of Interest pooling. \n\n\nIt uses max pooling to convert the features inside any valid region of interest into a small feature map with a fixed spatial extent of pooledH \u00d7 pooledW (e.g., 7 \u00d7 7).\n\n\nAn RoI is a rectangular window into a conv feature map. Each RoI is defined by a four-tuple (x1, y1, x2, y2) that specifies its top-left corner (x1, y1) and its bottom-right corner (x2, y2).\n\n\nRoI max pooling works by dividing the h \u00d7 w RoI window into an pooledH \u00d7 pooledW grid of sub-windows of approximate size h/H \u00d7 w/W and then max-pooling the values in each sub-window into the corresponding output grid cell. Pooling is applied independently to each feature map channel\n\n\nforward\n accepts a table containing 2 tensors as input, the first tensor is the input image, the second tensor is the ROI regions. The dimension of the second tensor should be (*,5) (5 are  \nbatch_num, x1, y1, x2, y2\n).  \n\n\nScala example:\n\n\nscala\n \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval input_data = Tensor(2,2,6,8).randn()\nval rois = Array(0, 0, 0, 7, 5, 1, 6, 2, 7, 5, 1, 3, 1, 6, 4, 0, 3, 3, 3, 3)\nval input_rois = Tensor(Storage(rois.map(x =\n x.toFloat))).resize(4, 5)\nval input = T(input_data,input_rois)\nval m = RoiPooling(3, 2, 1)\nval output = m.forward(input)\n\nscala\n print(input)\n {\n        2: 0.0  0.0     0.0     7.0     5.0\n           1.0  6.0     2.0     7.0     5.0\n           1.0  3.0     1.0     6.0     4.0\n           0.0  3.0     3.0     3.0     3.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 4x5]\n        1: (1,1,.,.) =\n           0.48066297   1.0994664       0.32474303      2.3391871       -0.79605865     0.836963950.36107457      1.2622415\n           0.657079     0.12720469      0.39894578      -0.41185552     -0.53111094     -0.36016005       -0.9726423      -2.5785272\n           0.3091435    -0.03613516     0.2375721       -1.1920663      -0.6757661      1.10612681.5409279        -0.17411499\n           0.23274016   -0.7149633      0.5473105       -0.40570387     -1.7966263      0.2071798-1.1530842       -0.010083453\n           -1.5769979   0.17043112      -0.28578365     -0.90779626     0.61457515      -0.1553582-0.3912479      -0.15326484\n           -0.24283029  1.3215472       1.3795123       -0.36933053     0.7077386       -0.56398267       0.6159163       0.5802894\n\n           (1,2,.,.) =\n           -1.1817129   -0.20470592     -1.3201113      0.36523122      -0.18260211     1.30210171.214403 1.1019816\n           0.7186407    0.78731173      1.5452348       0.0396181       0.5927014       1.17697431.0501136        -0.58295316\n           -0.96753055  0.6427254       -1.1396345      0.8701054       -0.22860864     -1.18719451.3372624       0.8616691\n           0.796831     -0.16609778     0.2950535       0.4595303       0.192339        0.6086106-0.76351887      -0.65964174\n           -0.12746814  -0.036058053    0.8858275       0.9677718       -1.1074747      -1.36859390.8783633       -0.11723315\n           -0.6947403   -0.23226547     -1.8510057      -1.3695518      -0.22317407     -0.36249024       -0.24097045     1.5691053\n\n           (2,1,.,.) =\n           0.84056973   1.144949        -1.0660682      0.4416162       -0.94440234     -0.24461010.91145027      -0.88650835\n           -0.81542057  0.14578317      -0.6531974      0.60776395      -0.32058007     -1.80771481.7660322       1.0680646\n           1.1328241    0.43677545      -0.9402618      -1.3002211      0.26012567      1.69481340.37849447       0.39286092\n           1.9443163    0.5415504       1.0793099       1.3312546       0.48346 1.2019655       0.3718734 0.21091922\n           0.5499047    1.6418253       0.8064177       0.37626198      0.8736181       -0.40816033       -0.5806787      1.286581\n           -0.5904657   -0.21188398     -0.040509004    1.2989452       1.6827602       1.3229258-0.68433124      0.87974\n\n           (2,2,.,.) =\n           -0.09759476  -0.32767114     0.16223079      2.3114302       -0.48496276     1.19290720.8572289        0.43429425\n           -1.0245247   0.19002944      1.5659521       -1.3689835      -1.4437296      -0.38216656       0.6333655       -0.57124794\n           -0.31111157  1.5184602       -1.3835855      -0.9295573      2.244521        -1.11849820.5451996       -0.4441631\n           -1.534093    -0.5599659      1.1980947       -1.0140935      1.3288999       0.19487387-0.1261734      -1.2222558\n           -0.070535585 0.9047848       -0.6719811      -1.6532638      -0.5290511      -0.18300447       0.69385433      0.018756092\n           0.24767837   0.620484        -0.5346291      1.0685066       -0.36903372     -0.26955062       1.1042496       0.5944603\n\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x6x8]\n }\n\nscala\n print(output)\n(1,1,.,.) =\n1.0994664       2.3391871       1.5409279\n1.3795123       1.3795123       0.6159163\n\n(1,2,.,.) =\n1.5452348       1.5452348       1.3372624\n0.8858275       0.9677718       1.5691053\n\n(2,1,.,.) =\n0.37849447      0.39286092      0.39286092\n-0.5806787      1.286581        1.286581\n\n(2,2,.,.) =\n0.5451996       0.5451996       -0.4441631\n1.1042496       1.1042496       0.5944603\n\n(3,1,.,.) =\n0.60776395      1.6948134       1.7660322\n1.3312546       1.2019655       1.2019655\n\n(3,2,.,.) =\n2.244521        2.244521        0.6333655\n1.3288999       1.3288999       0.69385433\n\n(4,1,.,.) =\n-0.40570387     -0.40570387     -0.40570387\n-0.40570387     -0.40570387     -0.40570387\n\n(4,2,.,.) =\n0.4595303       0.4595303       0.4595303\n0.4595303       0.4595303       0.4595303\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4x2x2x3]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\ninput_data = np.random.randn(2,2,6,8)\ninput_rois = np.array([0, 0, 0, 7, 5, 1, 6, 2, 7, 5, 1, 3, 1, 6, 4, 0, 3, 3, 3, 3],dtype='float64').reshape(4,5)\nprint \ninput is :\n,[input_data, input_rois]\n\nm = RoiPooling(3,2,1.0)\nout = m.forward([input_data,input_rois])\nprint \noutput of m is :\n,out\n\n\n\n\nproduces output:\n\n\ninput is : [array([[[[ 0.08500103,  0.33421796,  0.29084699,  1.60344635, -0.24289341,\n          -0.4793888 ,  0.09452426,  0.16842477],\n         [-1.18575497, -0.53337542,  0.11661001,  0.9647904 , -0.25187936,\n           0.36516823, -0.16647209, -0.08095158],\n         [ 1.1982232 , -0.33549174,  0.11721347, -0.29319686, -0.01290122,\n           0.12344296,  0.30074829, -2.34951463],\n         [-0.60470899, -0.84657051,  0.1269276 , -0.06152321, -1.68838416,\n          -0.69808296, -2.06112892, -1.44790449],\n         [ 1.03944288,  0.13871728,  0.91478479,  0.47517105,  1.24638374,\n           0.98666841,  0.49403488,  1.26101127],\n         [-1.03949343, -0.39291108,  1.39107512,  1.73779253,  0.91656129,\n           0.103381  ,  0.956243  ,  0.44743548]],\n\n        [[ 0.79028054,  0.64244228, -0.37997334, -0.09130215, -2.3903429 ,\n           0.71919208, -0.14079786,  0.98304272],\n         [ 1.14678457,  1.58825227,  0.17137367, -0.62121819, -0.36103113,\n          -0.04452576, -0.0886136 , -1.32884721],\n         [ 0.06728957, -0.29701304, -0.52754207, -1.5785875 ,  1.47354834,\n          -0.28545156,  0.49874194,  0.10277613],\n         [-0.10117571, -1.34902427, -1.40789327,  0.09853599,  0.60420022,\n           0.54869115, -0.49067696,  0.26696793],\n         [ 1.11780279, -0.77929016,  1.13772094,  0.14374057,  0.33199688,\n          -0.54057374, -0.45718861,  1.1577623 ],\n         [-1.4005645 ,  1.15870496,  0.39292003,  0.88379515,  0.06440974,\n           0.65013063,  0.03759244,  0.18730126]]],\n\n\n       [[[-2.28272906,  0.06056305,  0.73632597,  0.10063274, -1.27497525,\n          -0.95597581, -0.22745785,  0.40146498],\n         [-1.37783475,  1.66000653, -1.80071745, -0.11805539, -0.27160583,\n           0.30691418,  2.62243232, -1.95274516],\n         [ 1.61364148,  1.91470546, -1.51984424,  2.13598224, -0.23156685,\n          -0.74203698,  0.65316888,  0.08018846],\n         [-1.8912854 , -0.50106158,  0.94937966, -0.10930541,  0.82136627,\n          -1.33209063,  1.43371302, -1.36370916],\n         [-0.52737928, -0.0681305 , -0.63472587,  0.41979229, -0.57093624,\n          -0.15968764, -1.005951  , -2.06873572],\n         [-2.34089346,  1.02593977,  0.90183415,  0.09504819,  0.53185448,\n           1.11305345,  1.290016  , -1.76216646]],\n\n        [[-0.10885459, -0.57089742, -0.55340708, -1.94445884,  1.30130049,\n           0.6333372 , -1.03100083,  0.0111167 ],\n         [ 0.59678149, -0.67601521, -1.25288718, -0.10922251,  3.06808996,\n          -1.46701513, -0.42140765,  1.12485412],\n         [ 1.21301567, -1.43304957, -0.56047239,  0.20716087,  1.40737646,\n          -0.08386437, -0.21916043,  0.85692906],\n         [ 1.59992399, -1.37044315, -0.71884386,  2.61830979, -0.74305496,\n          -0.32021174,  1.43275058, -0.3891857 ],\n         [-0.41355145,  0.22589689,  0.33154415,  0.86146815, -1.66326091,\n           0.37581697, -3.2250516 , -0.48807863],\n         [-2.52968957,  0.95801598, -1.20118154,  0.01141421, -0.11871498,\n           0.04555184,  1.3950473 ,  0.37887998]]]]), array([[ 0.,  0.,  0.,  7.,  5.],\n       [ 1.,  6.,  2.,  7.,  5.],\n       [ 1.,  3.,  1.,  6.,  4.],\n       [ 0.,  3.,  3.,  3.,  3.]])]\ncreating: createRoiPooling\noutput of m is : [[[[ 1.19822323  1.60344636  0.36516821]\n   [ 1.39107513  1.73779249  1.26101124]]\n\n  [[ 1.58825231  1.47354829  0.98304272]\n   [ 1.158705    1.13772094  1.15776229]]]\n\n\n [[[ 1.43371308  1.43371308  0.08018846]\n   [ 1.29001606  1.29001606 -1.7621665 ]]\n\n  [[ 1.43275058  1.43275058  0.85692906]\n   [ 1.39504731  1.39504731  0.37887999]]]\n\n\n [[[ 2.13598228  0.30691418  2.62243223]\n   [ 0.82136625  0.82136625  1.43371308]]\n\n  [[ 3.06808996  3.06808996 -0.08386437]\n   [ 2.61830974  0.37581697  1.43275058]]]\n\n\n [[[-0.06152321 -0.06152321 -0.06152321]\n   [-0.06152321 -0.06152321 -0.06152321]]\n\n  [[ 0.09853599  0.09853599  0.09853599]\n   [ 0.09853599  0.09853599  0.09853599]]]]", 
            "title": "Pooling Layers"
        }, 
        {
            "location": "/APIGuide/Layers/Pooling-Layers/#spatialmaxpooling", 
            "text": "Scala:  val mp = SpatialMaxPooling(2, 2, dW=2, dH=2, padW=0, padH=0, format=DataFormat.NCHW)  Python:  mp = SpatialMaxPooling(2, 2, dw=2, dh=2, pad_w=0, pad_h=0, to_ceil=false, format= NCHW )  Applies 2D max-pooling operation in kWxkH regions by step size dWxdH steps.\nThe number of output features is equal to the number of input planes.\nIf the input image is a 3D tensor nInputPlane x height x width,\nthe output image size will be nOutputPlane x oheight x owidth where   owidth  = op((width  + 2*padW - kW) / dW + 1)  oheight = op((height + 2*padH - kH) / dH + 1)   op is a rounding operator. By default, it is floor.\nIt can be changed by calling ceil() or floor() methods.  As for padding, when padW and padH are both -1, we use a padding algorithm similar to the \"SAME\" padding of tensorflow. That is   outHeight = Math.ceil(inHeight.toFloat/strideH.toFloat)\n outWidth = Math.ceil(inWidth.toFloat/strideW.toFloat)\n\n padAlongHeight = Math.max(0, (outHeight - 1) * strideH + kernelH - inHeight)\n padAlongWidth = Math.max(0, (outWidth - 1) * strideW + kernelW - inWidth)\n\n padTop = padAlongHeight / 2\n padLeft = padAlongWidth / 2  The format parameter is a string value (or DataFormat Object in Scala) of \"NHWC\" or \"NCHW\" to specify the input data format of this layer. In \"NHWC\" format\ndata is stored in the order of [batch_size, height, width, channels], in \"NCHW\" format data is stored\nin the order of [batch_size, channels, height, width].  Scala example:  import com.intel.analytics.bigdl.nn.SpatialMaxPooling\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval mp = SpatialMaxPooling(2, 2, 2, 2)\nval input = Tensor(1, 3, 3)\n\ninput(Array(1, 1, 1)) = 0.5336726f\ninput(Array(1, 1, 2)) = 0.7963769f\ninput(Array(1, 1, 3)) = 0.5674766f\ninput(Array(1, 2, 1)) = 0.1803996f\ninput(Array(1, 2, 2)) = 0.2460861f\ninput(Array(1, 2, 3)) = 0.2295625f\ninput(Array(1, 3, 1)) = 0.3073633f\ninput(Array(1, 3, 2)) = 0.5973460f\ninput(Array(1, 3, 3)) = 0.4298954f\n\nval gradOutput = Tensor(1, 1, 1)\ngradOutput(Array(1, 1, 1)) = 0.023921491578221f\n\nval output = mp.forward(input)\nval gradInput = mp.backward(input, gradOutput)\n\nprintln(output)\nprintln(gradInput)  The output is,  (1,.,.) =\n0.7963769\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1]  The gradInput is,  (1,.,.) =\n0.0     0.023921492     0.0\n0.0     0.0     0.0\n0.0     0.0     0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x3]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nmp = SpatialMaxPooling(2, 2, 2, 2)\n\n\ninput = np.array([0.5336726, 0.7963769, 0.5674766, 0.1803996, 0.2460861, 0.2295625, 0.3073633, 0.5973460, 0.4298954]).astype( float32 )\ninput = input.reshape(1, 3, 3)\n\noutput = mp.forward(input)\nprint output\n\ngradOutput = np.array([0.023921491578221]).astype( float32 )\ngradOutput = gradOutput.reshape(1, 1, 1)\n\ngradInput = mp.backward(input, gradOutput)\nprint gradInput  The output is,  [array([[[ 0.79637688]]], dtype=float32)]  The gradInput is,  [array([[[ 0.        ,  0.02392149,  0.        ],\n        [ 0.        ,  0.        ,  0.        ],\n        [ 0.        ,  0.        ,  0.        ]]], dtype=float32)]", 
            "title": "SpatialMaxPooling"
        }, 
        {
            "location": "/APIGuide/Layers/Pooling-Layers/#spatialaveragepooling", 
            "text": "Scala:  val m = SpatialAveragePooling(kW, kH, dW=1, dH=1, padW=0, padH=0, globalPooling=false, ceilMode=false, countIncludePad=true, divide=true, format=DataFormat.NCHW)  Python:  m = SpatialAveragePooling(kw, kh, dw=1, dh=1, pad_w=0, pad_h=0, global_pooling=False, ceil_mode=False, count_include_pad=True, divide=True, format= NCHW )  SpatialAveragePooling is a module that applies 2D average-pooling operation in  kW x kH  regions by step size  dW x dH .  The number of output features is equal to the number of input planes.  As for padding, when padW and padH are both -1, we use a padding algorithm similar to the \"SAME\" padding of tensorflow. That is   outHeight = Math.ceil(inHeight.toFloat/strideH.toFloat)\n outWidth = Math.ceil(inWidth.toFloat/strideW.toFloat)\n\n padAlongHeight = Math.max(0, (outHeight - 1) * strideH + kernelH - inHeight)\n padAlongWidth = Math.max(0, (outWidth - 1) * strideW + kernelW - inWidth)\n\n padTop = padAlongHeight / 2\n padLeft = padAlongWidth / 2  The format parameter is a string value (or DataFormat Object in Scala) of \"NHWC\" or \"NCHW\" to specify the input data format of this layer. In \"NHWC\" format\ndata is stored in the order of [batch_size, height, width, channels], in \"NCHW\" format data is stored\nin the order of [batch_size, channels, height, width].  Scala example:  scala  \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval input = Tensor(1, 3, 3).randn()\nval m = SpatialAveragePooling(3, 2, 2, 1)\nval output = m.forward(input)\nval gradOut = Tensor(1, 2, 1).randn()\nval gradIn = m.backward(input,gradOut)\n\nscala  print(input)\n(1,.,.) =\n0.9916249       1.0299556       0.5608558\n-0.1664829      1.5031902       0.48598626\n0.37362042      -0.0966136      -1.4257964\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x3x3]\n\nscala  print(output)\n(1,.,.) =\n0.7341883\n0.1123173\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x1]\n\nscala  print(gradOut)\n(1,.,.) =\n-0.42837557\n-1.5104272\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x2x1]\n\nscala  print(gradIn)\n(1,.,.) =\n-0.071395926    -0.071395926    -0.071395926\n-0.3231338      -0.3231338      -0.3231338\n-0.25173786     -0.25173786     -0.25173786\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x3]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\ninput = np.random.randn(1,3,3)\nprint  input is : ,input\n\nm = SpatialAveragePooling(3,2,2,1)\nout = m.forward(input)\nprint  output of m is : ,out\n\ngrad_out = np.random.rand(1,3,1)\ngrad_in = m.backward(input,grad_out)\nprint  grad input of m is : ,grad_in  produces output:  input is : [[[ 1.50602425 -0.92869054 -1.9393117 ]\n  [ 0.31447547  0.63450578 -0.92485516]\n  [-2.07858315 -0.05688643  0.73648798]]]\ncreating: createSpatialAveragePooling\noutput of m is : [array([[[-0.22297533],\n        [-0.22914261]]], dtype=float32)]\ngrad input of m is : [array([[[ 0.06282618,  0.06282618,  0.06282618],\n        [ 0.09333335,  0.09333335,  0.09333335],\n        [ 0.03050717,  0.03050717,  0.03050717]]], dtype=float32)]", 
            "title": "SpatialAveragePooling"
        }, 
        {
            "location": "/APIGuide/Layers/Pooling-Layers/#volumetricmaxpooling", 
            "text": "Scala:  val layer = VolumetricMaxPooling(\n  kernelT, kernelW, kernelH,\n  strideT, strideW, strideH,\n  paddingT, paddingW, paddingH\n)  Python:  layer = VolumetricMaxPooling(\n  kernelT, kernelW, kernelH,\n  strideT, strideW, strideH,\n  paddingT, paddingW, paddingH\n)  Applies 3D max-pooling operation in kT x kW x kH regions by step size dT x dW x dH.\nThe number of output features is equal to the number of input planes / dT.\nThe input can optionally be padded with zeros. Padding should be smaller than\nhalf of kernel size. That is, padT   kT/2, padW   kW/2 and padH   kH/2  The input layout should be [batch, plane, time, height, width] or [plane, time, height, width]  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = VolumetricMaxPooling(\n  2, 2, 2,\n  1, 1, 1,\n  0, 0, 0\n)\n\nval input = Tensor(T(T(\n  T(\n    T(1.0f, 2.0f, 3.0f),\n    T(4.0f, 5.0f, 6.0f),\n    T(7.0f, 8.0f, 9.0f)\n  ),\n  T(\n    T(4.0f, 5.0f, 6.0f),\n    T(1.0f, 3.0f, 9.0f),\n    T(2.0f, 3.0f, 7.0f)\n  )\n)))\nlayer.forward(input)\nlayer.backward(input, Tensor(T(T(T(\n  T(0.1f, 0.2f),\n  T(0.3f, 0.4f)\n)))))  Its output should be  (1,1,.,.) =\n5.0     9.0\n8.0     9.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x2]\n\n(1,1,.,.) =\n0.0     0.0     0.0\n0.0     0.1     0.0\n0.0     0.3     0.4\n\n(1,2,.,.) =\n0.0     0.0     0.0\n0.0     0.0     0.2\n0.0     0.0     0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x3x3]  Python example:  from bigdl.nn.layer import VolumetricMaxPooling\nimport numpy as np\n\nlayer = VolumetricMaxPooling(\n  2, 2, 2,\n  1, 1, 1,\n  0, 0, 0\n)\n\ninput = np.array([[\n  [\n    [1.0, 2.0, 3.0],\n    [4.0, 5.0, 6.0],\n    [7.0, 8.0, 9.0]\n  ],\n  [\n    [4.0, 5.0, 6.0],\n    [1.0, 3.0, 9.0],\n    [2.0, 3.0, 7.0]\n  ]\n]])\nlayer.forward(input)\nlayer.backward(input, np.array([[[\n  [0.1, 0.2],\n  [0.3, 0.4]\n]]]))  Its output should be  array([[[[ 5.,  9.],\n         [ 8.,  9.]]]], dtype=float32)\n\narray([[[[ 0.        ,  0.        ,  0.        ],\n         [ 0.        ,  0.1       ,  0.        ],\n         [ 0.        ,  0.30000001,  0.40000001]],\n\n        [[ 0.        ,  0.        ,  0.        ],\n         [ 0.        ,  0.        ,  0.2       ],\n         [ 0.        ,  0.        ,  0.        ]]]], dtype=float32)", 
            "title": "VolumetricMaxPooling"
        }, 
        {
            "location": "/APIGuide/Layers/Pooling-Layers/#volumetricaveragepooling", 
            "text": "Scala:  val layer = VolumetricMaxPooling(\n  kT, kW, kH, dT, dW, dH,\n  padT=0, padW=0, padH=0,\n  countIncludePad=true, ceilMode=false\n)  Python:  layer = VolumetricMaxPooling(\n  k_t, k_w, k_h, d_t, d_w, d_h\n  pad_t=0, pad_w=0, pad_h=0,\n  count_include_pad=True, ceil_mode=False\n)  Applies 3D average-pooling operation in kernel kT x kW x kH regions by step size dT x dW x dH.\nThe number of output features is equal to the number of input planes / dT.\nThe input can optionally be padded with zeros. Padding should be smaller than\nhalf of kernel size. That is, padT   kT/2, padW   kW/2 and padH   kH/2  The input layout should be [batch, plane, time, height, width] or [plane, time, height, width]  By default, countIncludePad=true, which means to include padding when dividing the number of elements in pooling region.\nOne can use ceilMode to control whether the output size is to be ceiled or floored.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = VolumetricAveragePooling(\n  2, 2, 2,\n  1, 1, 1,\n  0, 0, 0\n)\n\nval input = Tensor(T(T(\n  T(\n    T(1.0f, 2.0f, 3.0f),\n    T(4.0f, 5.0f, 6.0f),\n    T(7.0f, 8.0f, 9.0f)\n  ),\n  T(\n    T(4.0f, 5.0f, 6.0f),\n    T(1.0f, 3.0f, 9.0f),\n    T(2.0f, 3.0f, 7.0f)\n  )\n)))\nlayer.forward(input)\nlayer.backward(input, Tensor(T(T(T(\n  T(0.1f, 0.2f),\n  T(0.3f, 0.4f)\n)))))  Its output should be  (1,1,.,.) =\n3.125   4.875\n4.125   6.25\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x2]\n\n(1,1,.,.) =\n0.0125  0.0375  0.025\n0.05    0.125   0.075\n0.0375  0.087500006 0.05\n\n(1,2,.,.) =\n0.0125  0.0375  0.025\n0.05    0.125   0.075\n0.0375  0.087500006 0.05\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x3x3]  Python example:  from bigdl.nn.layer import VolumetricAveragePooling\nimport numpy as np\n\nlayer = VolumetricAveragePooling(\n  2, 2, 2,\n  1, 1, 1,\n  0, 0, 0\n)\n\ninput = np.array([[\n  [\n    [1.0, 2.0, 3.0],\n    [4.0, 5.0, 6.0],\n    [7.0, 8.0, 9.0]\n  ],\n  [\n    [4.0, 5.0, 6.0],\n    [1.0, 3.0, 9.0],\n    [2.0, 3.0, 7.0]\n  ]\n]])\nlayer.forward(input)\nlayer.backward(input, np.array([[[\n  [0.1, 0.2],\n  [0.3, 0.4]\n]]]))  Its output should be  array([[[[ 3.125  4.875]\n         [ 4.125  6.25 ]]]], dtype=float32)\n\narray([[[[ 0.0125      0.0375      0.025     ]\n         [ 0.05        0.125       0.075     ]\n         [ 0.0375      0.08750001  0.05      ]]\n\n        [[ 0.0125      0.0375      0.025     ]\n         [ 0.05        0.125       0.075     ]\n         [ 0.0375      0.08750001  0.05      ]]]], dtype=float32)", 
            "title": "VolumetricAveragePooling"
        }, 
        {
            "location": "/APIGuide/Layers/Pooling-Layers/#roipooling", 
            "text": "Scala:  val m =  RoiPooling(pooled_w, pooled_h, spatial_scale)  Python:  m = RoiPooling(pooled_w, pooled_h, spatial_scale)  RoiPooling is a module that performs Region of Interest pooling.   It uses max pooling to convert the features inside any valid region of interest into a small feature map with a fixed spatial extent of pooledH \u00d7 pooledW (e.g., 7 \u00d7 7).  An RoI is a rectangular window into a conv feature map. Each RoI is defined by a four-tuple (x1, y1, x2, y2) that specifies its top-left corner (x1, y1) and its bottom-right corner (x2, y2).  RoI max pooling works by dividing the h \u00d7 w RoI window into an pooledH \u00d7 pooledW grid of sub-windows of approximate size h/H \u00d7 w/W and then max-pooling the values in each sub-window into the corresponding output grid cell. Pooling is applied independently to each feature map channel  forward  accepts a table containing 2 tensors as input, the first tensor is the input image, the second tensor is the ROI regions. The dimension of the second tensor should be (*,5) (5 are   batch_num, x1, y1, x2, y2 ).    Scala example:  scala  \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval input_data = Tensor(2,2,6,8).randn()\nval rois = Array(0, 0, 0, 7, 5, 1, 6, 2, 7, 5, 1, 3, 1, 6, 4, 0, 3, 3, 3, 3)\nval input_rois = Tensor(Storage(rois.map(x =  x.toFloat))).resize(4, 5)\nval input = T(input_data,input_rois)\nval m = RoiPooling(3, 2, 1)\nval output = m.forward(input)\n\nscala  print(input)\n {\n        2: 0.0  0.0     0.0     7.0     5.0\n           1.0  6.0     2.0     7.0     5.0\n           1.0  3.0     1.0     6.0     4.0\n           0.0  3.0     3.0     3.0     3.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 4x5]\n        1: (1,1,.,.) =\n           0.48066297   1.0994664       0.32474303      2.3391871       -0.79605865     0.836963950.36107457      1.2622415\n           0.657079     0.12720469      0.39894578      -0.41185552     -0.53111094     -0.36016005       -0.9726423      -2.5785272\n           0.3091435    -0.03613516     0.2375721       -1.1920663      -0.6757661      1.10612681.5409279        -0.17411499\n           0.23274016   -0.7149633      0.5473105       -0.40570387     -1.7966263      0.2071798-1.1530842       -0.010083453\n           -1.5769979   0.17043112      -0.28578365     -0.90779626     0.61457515      -0.1553582-0.3912479      -0.15326484\n           -0.24283029  1.3215472       1.3795123       -0.36933053     0.7077386       -0.56398267       0.6159163       0.5802894\n\n           (1,2,.,.) =\n           -1.1817129   -0.20470592     -1.3201113      0.36523122      -0.18260211     1.30210171.214403 1.1019816\n           0.7186407    0.78731173      1.5452348       0.0396181       0.5927014       1.17697431.0501136        -0.58295316\n           -0.96753055  0.6427254       -1.1396345      0.8701054       -0.22860864     -1.18719451.3372624       0.8616691\n           0.796831     -0.16609778     0.2950535       0.4595303       0.192339        0.6086106-0.76351887      -0.65964174\n           -0.12746814  -0.036058053    0.8858275       0.9677718       -1.1074747      -1.36859390.8783633       -0.11723315\n           -0.6947403   -0.23226547     -1.8510057      -1.3695518      -0.22317407     -0.36249024       -0.24097045     1.5691053\n\n           (2,1,.,.) =\n           0.84056973   1.144949        -1.0660682      0.4416162       -0.94440234     -0.24461010.91145027      -0.88650835\n           -0.81542057  0.14578317      -0.6531974      0.60776395      -0.32058007     -1.80771481.7660322       1.0680646\n           1.1328241    0.43677545      -0.9402618      -1.3002211      0.26012567      1.69481340.37849447       0.39286092\n           1.9443163    0.5415504       1.0793099       1.3312546       0.48346 1.2019655       0.3718734 0.21091922\n           0.5499047    1.6418253       0.8064177       0.37626198      0.8736181       -0.40816033       -0.5806787      1.286581\n           -0.5904657   -0.21188398     -0.040509004    1.2989452       1.6827602       1.3229258-0.68433124      0.87974\n\n           (2,2,.,.) =\n           -0.09759476  -0.32767114     0.16223079      2.3114302       -0.48496276     1.19290720.8572289        0.43429425\n           -1.0245247   0.19002944      1.5659521       -1.3689835      -1.4437296      -0.38216656       0.6333655       -0.57124794\n           -0.31111157  1.5184602       -1.3835855      -0.9295573      2.244521        -1.11849820.5451996       -0.4441631\n           -1.534093    -0.5599659      1.1980947       -1.0140935      1.3288999       0.19487387-0.1261734      -1.2222558\n           -0.070535585 0.9047848       -0.6719811      -1.6532638      -0.5290511      -0.18300447       0.69385433      0.018756092\n           0.24767837   0.620484        -0.5346291      1.0685066       -0.36903372     -0.26955062       1.1042496       0.5944603\n\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x6x8]\n }\n\nscala  print(output)\n(1,1,.,.) =\n1.0994664       2.3391871       1.5409279\n1.3795123       1.3795123       0.6159163\n\n(1,2,.,.) =\n1.5452348       1.5452348       1.3372624\n0.8858275       0.9677718       1.5691053\n\n(2,1,.,.) =\n0.37849447      0.39286092      0.39286092\n-0.5806787      1.286581        1.286581\n\n(2,2,.,.) =\n0.5451996       0.5451996       -0.4441631\n1.1042496       1.1042496       0.5944603\n\n(3,1,.,.) =\n0.60776395      1.6948134       1.7660322\n1.3312546       1.2019655       1.2019655\n\n(3,2,.,.) =\n2.244521        2.244521        0.6333655\n1.3288999       1.3288999       0.69385433\n\n(4,1,.,.) =\n-0.40570387     -0.40570387     -0.40570387\n-0.40570387     -0.40570387     -0.40570387\n\n(4,2,.,.) =\n0.4595303       0.4595303       0.4595303\n0.4595303       0.4595303       0.4595303\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4x2x2x3]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\ninput_data = np.random.randn(2,2,6,8)\ninput_rois = np.array([0, 0, 0, 7, 5, 1, 6, 2, 7, 5, 1, 3, 1, 6, 4, 0, 3, 3, 3, 3],dtype='float64').reshape(4,5)\nprint  input is : ,[input_data, input_rois]\n\nm = RoiPooling(3,2,1.0)\nout = m.forward([input_data,input_rois])\nprint  output of m is : ,out  produces output:  input is : [array([[[[ 0.08500103,  0.33421796,  0.29084699,  1.60344635, -0.24289341,\n          -0.4793888 ,  0.09452426,  0.16842477],\n         [-1.18575497, -0.53337542,  0.11661001,  0.9647904 , -0.25187936,\n           0.36516823, -0.16647209, -0.08095158],\n         [ 1.1982232 , -0.33549174,  0.11721347, -0.29319686, -0.01290122,\n           0.12344296,  0.30074829, -2.34951463],\n         [-0.60470899, -0.84657051,  0.1269276 , -0.06152321, -1.68838416,\n          -0.69808296, -2.06112892, -1.44790449],\n         [ 1.03944288,  0.13871728,  0.91478479,  0.47517105,  1.24638374,\n           0.98666841,  0.49403488,  1.26101127],\n         [-1.03949343, -0.39291108,  1.39107512,  1.73779253,  0.91656129,\n           0.103381  ,  0.956243  ,  0.44743548]],\n\n        [[ 0.79028054,  0.64244228, -0.37997334, -0.09130215, -2.3903429 ,\n           0.71919208, -0.14079786,  0.98304272],\n         [ 1.14678457,  1.58825227,  0.17137367, -0.62121819, -0.36103113,\n          -0.04452576, -0.0886136 , -1.32884721],\n         [ 0.06728957, -0.29701304, -0.52754207, -1.5785875 ,  1.47354834,\n          -0.28545156,  0.49874194,  0.10277613],\n         [-0.10117571, -1.34902427, -1.40789327,  0.09853599,  0.60420022,\n           0.54869115, -0.49067696,  0.26696793],\n         [ 1.11780279, -0.77929016,  1.13772094,  0.14374057,  0.33199688,\n          -0.54057374, -0.45718861,  1.1577623 ],\n         [-1.4005645 ,  1.15870496,  0.39292003,  0.88379515,  0.06440974,\n           0.65013063,  0.03759244,  0.18730126]]],\n\n\n       [[[-2.28272906,  0.06056305,  0.73632597,  0.10063274, -1.27497525,\n          -0.95597581, -0.22745785,  0.40146498],\n         [-1.37783475,  1.66000653, -1.80071745, -0.11805539, -0.27160583,\n           0.30691418,  2.62243232, -1.95274516],\n         [ 1.61364148,  1.91470546, -1.51984424,  2.13598224, -0.23156685,\n          -0.74203698,  0.65316888,  0.08018846],\n         [-1.8912854 , -0.50106158,  0.94937966, -0.10930541,  0.82136627,\n          -1.33209063,  1.43371302, -1.36370916],\n         [-0.52737928, -0.0681305 , -0.63472587,  0.41979229, -0.57093624,\n          -0.15968764, -1.005951  , -2.06873572],\n         [-2.34089346,  1.02593977,  0.90183415,  0.09504819,  0.53185448,\n           1.11305345,  1.290016  , -1.76216646]],\n\n        [[-0.10885459, -0.57089742, -0.55340708, -1.94445884,  1.30130049,\n           0.6333372 , -1.03100083,  0.0111167 ],\n         [ 0.59678149, -0.67601521, -1.25288718, -0.10922251,  3.06808996,\n          -1.46701513, -0.42140765,  1.12485412],\n         [ 1.21301567, -1.43304957, -0.56047239,  0.20716087,  1.40737646,\n          -0.08386437, -0.21916043,  0.85692906],\n         [ 1.59992399, -1.37044315, -0.71884386,  2.61830979, -0.74305496,\n          -0.32021174,  1.43275058, -0.3891857 ],\n         [-0.41355145,  0.22589689,  0.33154415,  0.86146815, -1.66326091,\n           0.37581697, -3.2250516 , -0.48807863],\n         [-2.52968957,  0.95801598, -1.20118154,  0.01141421, -0.11871498,\n           0.04555184,  1.3950473 ,  0.37887998]]]]), array([[ 0.,  0.,  0.,  7.,  5.],\n       [ 1.,  6.,  2.,  7.,  5.],\n       [ 1.,  3.,  1.,  6.,  4.],\n       [ 0.,  3.,  3.,  3.,  3.]])]\ncreating: createRoiPooling\noutput of m is : [[[[ 1.19822323  1.60344636  0.36516821]\n   [ 1.39107513  1.73779249  1.26101124]]\n\n  [[ 1.58825231  1.47354829  0.98304272]\n   [ 1.158705    1.13772094  1.15776229]]]\n\n\n [[[ 1.43371308  1.43371308  0.08018846]\n   [ 1.29001606  1.29001606 -1.7621665 ]]\n\n  [[ 1.43275058  1.43275058  0.85692906]\n   [ 1.39504731  1.39504731  0.37887999]]]\n\n\n [[[ 2.13598228  0.30691418  2.62243223]\n   [ 0.82136625  0.82136625  1.43371308]]\n\n  [[ 3.06808996  3.06808996 -0.08386437]\n   [ 2.61830974  0.37581697  1.43275058]]]\n\n\n [[[-0.06152321 -0.06152321 -0.06152321]\n   [-0.06152321 -0.06152321 -0.06152321]]\n\n  [[ 0.09853599  0.09853599  0.09853599]\n   [ 0.09853599  0.09853599  0.09853599]]]]", 
            "title": "RoiPooling"
        }, 
        {
            "location": "/APIGuide/Layers/Activations/", 
            "text": "SoftSign\n\n\nScala:\n\n\nval softSign = SoftSign()\n\n\n\n\nPython:\n\n\nsoftSign = SoftSign()\n\n\n\n\nSoftSign applies SoftSign function to the input tensor\n\n\nSoftSign function: \nf_i(x) = x_i / (1+|x_i|)\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval softSign = SoftSign()\nval input = Tensor(3, 3).rand()\n\n\n print(input)\n0.6733504   0.7566517   0.43793806  \n0.09683273  0.05829774  0.4567967   \n0.20021072  0.11158377  0.31668025\n\n\n print(softSign.forward(input))\n0.40239656  0.4307352   0.30455974  \n0.08828395  0.05508633  0.31356242  \n0.16681297  0.10038269  0.24051417  \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nsoftSign=SoftSign()\n\n softSign.forward(np.array([[1, 2, 4],[-1, -2, -4]]))\n[array([[ 0.5       ,  0.66666669,  0.80000001],\n       [-0.5       , -0.66666669, -0.80000001]], dtype=float32)]\n\n\n\n\n\n\n\nReLU6\n\n\nScala:\n\n\nval module = ReLU6(inplace = false)\n\n\n\n\nPython:\n\n\nmodule = ReLU6(inplace=False)\n\n\n\n\nSame as ReLU except that the rectifying function f(x) saturates at x = 6 \nReLU6 is defined as:\n\nf(x) = min(max(0, x), 6)\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = ReLU6()\n\nprintln(module.forward(Tensor.range(-2, 8, 1)))\n\n\n\n\nGives the output,\n\n\ncom.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.0\n0.0\n0.0\n1.0\n2.0\n3.0\n4.0\n5.0\n6.0\n6.0\n6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 11]\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = ReLU6()\n\nprint(module.forward(np.arange(-2, 9, 1)))\n\n\n\n\nGives the output,\n\n\n[array([ 0.,  0.,  0.,  1.,  2.,  3.,  4.,  5.,  6.,  6.,  6.], dtype=float32)]\n\n\n\n\n\n\nTanhShrink\n\n\nScala:\n\n\nval tanhShrink = TanhShrink()\n\n\n\n\nPython:\n\n\ntanhShrink = TanhShrink()\n\n\n\n\nTanhShrink applies element-wise Tanh and Shrink function to the input\n\n\nTanhShrink function : \nf(x) = scala.math.tanh(x) - 1\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval tanhShrink = TanhShrink()\nval input = Tensor(3, 3).rand()\n\n\n print(input)\n0.7056571   0.25239098  0.75746965  \n0.89736927  0.31193605  0.23842576  \n0.69492024  0.7512544   0.8386124   \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n\n\n print(tanhShrink.forward(input))\n0.09771085  0.0052260756    0.11788553  \n0.18235475  0.009738684 0.004417494 \n0.09378672  0.1153577   0.153539    \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\ntanhShrink = TanhShrink()\n\n\n  tanhShrink.forward(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]))\n[array([[ 0.23840582,  1.03597236,  2.00494528],\n       [ 3.00067067,  4.0000906 ,  5.0000124 ],\n       [ 6.00000191,  7.        ,  8.        ]], dtype=float32)]\n\n\n\n\n\n\n\nSoftMax\n\n\nScala:\n\n\nval layer = SoftMax()\n\n\n\n\nPython:\n\n\nlayer = SoftMax()\n\n\n\n\nApplies the SoftMax function to an n-dimensional input Tensor, rescaling them so that the\nelements of the n-dimensional output Tensor lie in the range (0, 1) and sum to 1.\nSoftmax is defined as:\nf_i(x) = exp(x_i - shift) / sum_j exp(x_j - shift)\n\nwhere \nshift = max_i(x_i)\n.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = SoftMax()\nval input = Tensor(3)\ninput.apply1(_ =\n 1.0f * 10)\nval gradOutput = Tensor(T(\n1.0f,\n0.0f,\n0.0f\n))\nval output = layer.forward(input)\nval gradient = layer.backward(input, gradOutput)\n-\n print(output)\n0.33333334\n0.33333334\n0.33333334\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n-\n print(gradient)\n0.22222221\n-0.11111112\n-0.11111112\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nlayer = SoftMax()\ninput = np.ones(3)*10\ngrad_output = np.array([1.0, 0.0, 0.0])\noutput = layer.forward(input)\ngradient = layer.backward(input, grad_output)\n-\n print output\n[ 0.33333334  0.33333334  0.33333334]\n-\n print gradient\n[ 0.22222221 -0.11111112 -0.11111112]\n\n\n\n\n\n\nPReLU\n\n\nScala:\n\n\nval module = PReLU(nOutputPlane = 0)\n\n\n\n\nPython:\n\n\nmodule = PReLU(nOutputPlane=0)\n\n\n\n\nApplies parametric ReLU, which parameter varies the slope of the negative part.\n\n\nPReLU: f(x) = max(0, x) + a * min(0, x)\n\n\n\n\nnOutputPlane's default value is 0, that means using PReLU in shared version and has\nonly one parameters. nOutputPlane is the input map number(Default is 0).\n\n\nNotice: Please don't use weight decay on this.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = PReLU(2)\nval input = Tensor(2, 2, 3).randn()\nval output = module.forward(input)\n\n\n input\n(1,.,.) =\n-0.17810068 -0.69607687 0.25582042\n-1.2140307  -1.5410945  1.0209005\n\n(2,.,.) =\n0.2826971   0.6370953   0.21471702\n-0.16203058 -0.5643519  0.816576\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x3]\n\n\n output\n(1,.,.) =\n-0.04452517 -0.17401922 0.25582042\n-0.3035077  -0.38527364 1.0209005\n\n(2,.,.) =\n0.2826971   0.6370953   0.21471702\n-0.040507644    -0.14108798 0.816576\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = PReLU(2)\ninput = np.random.randn(2, 2, 3)\noutput = module.forward(input)\n\n\n input\n[[[ 2.50596953 -0.06593339 -1.90273409]\n  [ 0.2464341   0.45941315 -0.41977094]]\n\n [[-0.8584367   2.19389229  0.93136755]\n  [-0.39209027  0.16507514 -0.35850447]]]\n\n\n output\n[array([[[ 2.50596952, -0.01648335, -0.47568351],\n         [ 0.24643411,  0.45941314, -0.10494273]],\n\n        [[-0.21460918,  2.19389224,  0.93136758],\n         [-0.09802257,  0.16507514, -0.08962612]]], dtype=float32)]\n\n\n\n\n\n\nReLU\n\n\nScala:\n\n\nval relu = ReLU(ip = false)\n\n\n\n\nPython:\n\n\nrelu = ReLU(ip)\n\n\n\n\nReLU applies the element-wise rectified linear unit (ReLU) function to the input\n\n\nip\n illustrate if the ReLU function is done on the origin input\n\n\nReLU function : f(x) = max(0, x)\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval relu = ReLU(false)\n\nval input = Tensor(3, 3).rand()\n\n print(input)\n0.13486342  0.8986828   0.2648762   \n0.56467545  0.7727274   0.65959305  \n0.01554346  0.9552375   0.2434533   \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n\n\n print(relu.forward(input))\n0.13486342  0.8986828   0.2648762   \n0.56467545  0.7727274   0.65959305  \n0.01554346  0.9552375   0.2434533   \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nrelu = ReLU(False)\n\n relu.forward(np.array([[-1, -2, -3], [0, 0, 0], [1, 2, 3]]))\n[array([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],\n       [ 1.,  2.,  3.]], dtype=float32)]\n\n\n\n\n\n\n\nSoftMin\n\n\nScala:\n\n\nval sm = SoftMin()\n\n\n\n\nPython:\n\n\nsm = SoftMin()\n\n\n\n\nApplies the SoftMin function to an n-dimensional input Tensor, rescaling them so that the\nelements of the n-dimensional output Tensor lie in the range (0,1) and sum to 1.\nSoftmin is defined as: \nf_i(x) = exp(-x_i - shift) / sum_j exp(-x_j - shift)\n\nwhere \nshift = max_i(-x_i)\n.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.SoftMin\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval sm = SoftMin()\nval input = Tensor(3, 3).range(1, 3 * 3)\n\nval output = sm.forward(input)\n\nval gradOutput = Tensor(3, 3).range(1, 3 * 3).apply1(x =\n (x / 10.0).toFloat)\nval gradInput = sm.backward(input, gradOutput)\n\n\n\n\n\nGives the output,\n\n\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.66524094      0.24472848      0.09003057\n0.66524094      0.24472848      0.09003057\n0.66524094      0.24472848      0.09003057\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\nGives the gradInput,\n\n\ngradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.02825874      -0.014077038    -0.014181711\n0.028258756     -0.01407703     -0.01418171\n0.028258756     -0.014077038    -0.014181707\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nsm = SoftMin()\n\ninput = np.arange(1, 10, 1).astype(\nfloat32\n)\ninput = input.reshape(3, 3)\n\noutput = sm.forward(input)\nprint output\n\ngradOutput = np.arange(1, 10, 1).astype(\nfloat32\n)\ngradOutput = np.vectorize(lambda t: t / 10)(gradOutput)\ngradOutput = gradOutput.reshape(3, 3)\n\ngradInput = sm.backward(input, gradOutput)\nprint gradInput\n\n\n\n\n\n\n\nELU\n\n\nScala:\n\n\nval m = ELU(alpha = 1.0, inplace = false)\n\n\n\n\nPython:\n\n\nm = ELU(alpha=1.0, inplace=False)\n\n\n\n\nApplies exponential linear unit (\nELU\n), which parameter a varies the convergence value of the exponential function below zero:\n\n\nELU\n is defined as:\n\n\nf(x) = max(0, x) + min(0, alpha * (exp(x) - 1))\n\n\n\n\nThe output dimension is always equal to input dimension.\n\n\nFor reference see \nFast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)\n.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval xs = Tensor(4).randn()\nprintln(xs)\nprintln(ELU(4).forward(xs))\n\n\n\n\n1.0217569\n-0.17189966\n1.4164596\n0.69361746\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\n\n1.0217569\n-0.63174534\n1.4164596\n0.69361746\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\n\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.layer import *\n\nxs = np.linspace(-3, 3, num=200)\ngo = np.ones(200)\n\ndef f(a):\n    return ELU(a).forward(xs)[0]\ndef df(a):\n    m = ELU(a)\n    m.forward(xs)\n    return m.backward(xs, go)[0]\n\nplt.plot(xs, f(0.1), '-', label='fw ELU, alpha = 0.1')\nplt.plot(xs, f(1.0), '-', label='fw ELU, alpha = 0.1')\nplt.plot(xs, df(0.1), '-', label='dw ELU, alpha = 0.1')\nplt.plot(xs, df(1.0), '-', label='dw ELU, alpha = 0.1')\n\nplt.legend(loc='best', shadow=True, fancybox=True)\nplt.show()\n\n\n\n\n\n\n\nSoftShrink\n\n\nScala:\n\n\nval layer = SoftShrink(lambda = 0.5)\n\n\n\n\nPython:\n\n\nlayer = SoftShrink(the_lambda=0.5)\n\n\n\n\nApply the soft shrinkage function element-wise to the input Tensor\n\n\nSoftShrinkage operator:\n\n\n       \u23a7 x - lambda, if x \n  lambda\nf(x) = \u23a8 x + lambda, if x \n -lambda\n       \u23a9 0, otherwise\n\n\n\n\nParameters:\n* \nlambda\n a factor, default is 0.5\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.SoftShrink\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval activation = SoftShrink()\nval input = Tensor(T(\n  T(-1f, 2f, 3f),\n  T(-2f, 3f, 4f),\n  T(-3f, 4f, 5f)\n))\n\nval gradOutput = Tensor(T(\n  T(3f, 4f, 5f),\n  T(2f, 3f, 4f),\n  T(1f, 2f, 3f)\n))\n\nval output = activation.forward(input)\nval grad = activation.backward(input, gradOutput)\n\nprintln(output)\n-0.5    1.5 2.5\n-1.5    2.5 3.5\n-2.5    3.5 4.5\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nprintln(grad)\n3.0 4.0 5.0\n2.0 3.0 4.0\n1.0 2.0 3.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\nScala example:\n\n\nactivation = SoftShrink()\ninput = np.array([\n  [-1.0, 2.0, 3.0],\n  [-2.0, 3.0, 4.0],\n  [-3.0, 4.0, 5.0]\n])\n\ngradOutput = np.array([\n  [3.0, 4.0, 5.0],\n  [2.0, 3.0, 4.0],\n  [1.0, 2.0, 5.0]\n])\n\noutput = activation.forward(input)\ngrad = activation.backward(input, gradOutput)\n\nprint output\n[[-0.5  1.5  2.5]\n [-1.5  2.5  3.5]\n [-2.5  3.5  4.5]]\n\nprint grad\n[[ 3.  4.  5.]\n [ 2.  3.  4.]\n [ 1.  2.  5.]]\n\n\n\n\n\n\nSigmoid\n\n\nScala:\n\n\nval module = Sigmoid()\n\n\n\n\nPython:\n\n\nmodule = Sigmoid()\n\n\n\n\nApplies the Sigmoid function element-wise to the input Tensor,\nthus outputting a Tensor of the same dimension.\n\n\nSigmoid is defined as: \nf(x) = 1 / (1 + exp(-x))\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = new Sigmoid()\nval input = Tensor(2, 3)\nvar i = 0\ninput.apply1(_ =\n {i += 1; i})\n\n print(layer.forward(input))\n0.7310586   0.880797    0.95257413  \n0.98201376  0.9933072   0.9975274   \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\n\nlayer = Sigmoid()\ninput = np.array([[1, 2, 3], [4, 5, 6]])\n\nlayer.forward(input)\narray([[ 0.7310586 ,  0.88079703,  0.95257413],\n       [ 0.98201376,  0.99330717,  0.99752742]], dtype=float32)\n\n\n\n\n\n\nTanh\n\n\nScala:\n\n\nval activation = Tanh()\n\n\n\n\nPython:\n\n\nactivation = Tanh()\n\n\n\n\nApplies the Tanh function element-wise to the input Tensor,\nthus outputting a Tensor of the same dimension.\nTanh is defined as\n\n\nf(x) = (exp(x)-exp(-x))/(exp(x)+exp(-x)).\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.Tanh\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval activation = Tanh()\nval input = Tensor(T(\n  T(1f, 2f, 3f),\n  T(2f, 3f, 4f),\n  T(3f, 4f, 5f)\n))\n\nval gradOutput = Tensor(T(\n  T(3f, 4f, 5f),\n  T(2f, 3f, 4f),\n  T(1f, 2f, 3f)\n))\n\nval output = activation.forward(input)\nval grad = activation.backward(input, gradOutput)\n\nprintln(output)\n0.7615942   0.9640276   0.9950548\n0.9640276   0.9950548   0.9993293\n0.9950548   0.9993293   0.9999092\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nprintln(grad)\n1.259923    0.28260326  0.049329996\n0.14130163  0.029597998 0.0053634644\n0.009865999 0.0026817322    5.4466724E-4\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\nPython example:\n\n\nactivation = Tanh()\ninput = np.array([\n  [1.0, 2.0, 3.0],\n  [2.0, 3.0, 4.0],\n  [3.0, 4.0, 5.0]\n])\n\ngradOutput = np.array([\n  [3.0, 4.0, 5.0],\n  [2.0, 3.0, 4.0],\n  [1.0, 2.0, 5.0]\n])\n\noutput = activation.forward(input)\ngrad = activation.backward(input, gradOutput)\n\nprint output\n[[ 0.76159418  0.96402758  0.99505478]\n [ 0.96402758  0.99505478  0.99932933]\n [ 0.99505478  0.99932933  0.99990922]]\n\nprint grad\n[[  1.25992298e+00   2.82603264e-01   4.93299961e-02]\n [  1.41301632e-01   2.95979977e-02   5.36346436e-03]\n [  9.86599922e-03   2.68173218e-03   9.07778740e-04]]\n\n\n\n\n\n\nSoftPlus\n\n\nScala:\n\n\nval model = SoftPlus(beta = 1.0)\n\n\n\n\nPython:\n\n\nmodel = SoftPlus(beta = 1.0)\n\n\n\n\nApply the SoftPlus function to an n-dimensional input tensor.\nSoftPlus function: \n\n\nf_i(x) = 1/beta * log(1 + exp(beta * x_i))\n\n\n\n\n\n\nparam beta Controls sharpness of transfer function\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = SoftPlus()\nval input = Tensor(2, 3, 4).rand()\nval output = model.forward(input)\n\nscala\n println(input)\n(1,.,.) =\n0.9812126   0.7044107   0.0657767   0.9173636   \n0.20853543  0.76482195  0.60774535  0.47837523  \n0.62954164  0.56440496  0.28893307  0.40742245  \n\n(2,.,.) =\n0.18701692  0.7700966   0.98496467  0.8958407   \n0.037015386 0.34626052  0.36459026  0.8460807   \n0.051016055 0.6742781   0.14469075  0.07565566  \n\nscala\n println(output)\n(1,.,.) =\n1.2995617   1.1061354   0.7265762   1.2535294   \n0.80284095  1.1469617   1.0424956   0.9606715   \n1.0566612   1.0146512   0.8480129   0.91746557  \n\n(2,.,.) =\n0.7910212   1.1505641   1.3022922   1.2381986   \n0.71182615  0.88119024  0.8919668   1.203121    \n0.7189805   1.0860726   0.7681072   0.7316903   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodel = SoftPlus()\ninput = np.random.randn(2, 3, 4)\noutput = model.forward(input)\n\n\n print(input)\n[[[ 0.82634972 -0.09853824  0.97570235  1.84464617]\n  [ 0.38466503  0.08963732  1.29438774  1.25204527]\n  [-0.01910449 -0.19560752 -0.81769143 -1.06365733]]\n\n [[-0.56284365 -0.28473239 -0.58206869 -1.97350909]\n  [-0.28303919 -0.59735361  0.73282102  0.0176838 ]\n  [ 0.63439133  1.84904987 -1.24073643  2.13275833]]]\n\n print(output)\n[[[ 1.18935537  0.6450913   1.2955569   1.99141073]\n  [ 0.90386271  0.73896986  1.53660071  1.50351918]\n  [ 0.68364054  0.60011864  0.36564925  0.29653603]]\n\n [[ 0.45081255  0.56088102  0.44387865  0.1301229 ]\n  [ 0.56160825  0.43842646  1.12523568  0.70202816]\n  [ 1.0598278   1.99521446  0.2539995   2.24475574]]]\n\n\n\n\n\n\nL1Penalty\n\n\nScala:\n\n\nval l1Penalty = L1Penalty(l1weight, sizeAverage = false, provideOutput = true)\n\n\n\n\nPython:\n\n\nl1Penalty = L1Penalty( l1weight, size_average=False, provide_output=True)\n\n\n\n\nL1Penalty adds an L1 penalty to an input \nFor forward, the output is the same as input and a L1 loss of the latent state will be calculated each time\nFor backward, gradInput = gradOutput + gradLoss\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval l1Penalty = L1Penalty(1, true, true)\nval input = Tensor(3, 3).rand()\n\n\n print(input)\n0.0370419   0.03080979  0.22083037  \n0.1547358   0.018475588 0.8102709   \n0.86393493  0.7081842   0.13717912  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n\n\n\n print(l1Penalty.forward(input))\n0.0370419   0.03080979  0.22083037  \n0.1547358   0.018475588 0.8102709   \n0.86393493  0.7081842   0.13717912  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]   \n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nl1Penalty = L1Penalty(1, True, True)\n\n\n l1Penalty.forward(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]))\n[array([[ 1.,  2.,  3.],\n       [ 4.,  5.,  6.],\n       [ 7.,  8.,  9.]], dtype=float32)]\n\n\n\n\n\n\n\nNegativeEntropyPenalty\n\n\nScala:\n\n\nval penalty = NegativeEntropyPenalty(beta = 0.01)\n\n\n\n\nPython:\n\n\npenalty = NegativeEntropyPenalty(beta = 0.01)\n\n\n\n\nPenalize the input multinomial distribution if it has low entropy.\nThe input to this layer should be a batch of vector each representing a\nmultinomial distribution. The input is typically the output of a softmax layer.\n\n\nFor forward, the output is the same as input and a NegativeEntropy loss of the latent state will be calculated each time\nFor backward, gradInput = gradOutput + gradLoss\n\n\nThis can be used in reinforcement learning to discourage the policy from\ncollapsing to a single action for a given state, which improves exploration.\nSee the A3C paper for more detail (https://arxiv.org/pdf/1602.01783.pdf).\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval penalty = NegativeEntropyPenalty(0.01)\nval input = Tensor(3, 3).rand()\n\n\n print(input)\n0.0370419   0.03080979  0.22083037  \n0.1547358   0.018475588 0.8102709   \n0.86393493  0.7081842   0.13717912  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n\n\n\n print(l1Penalty.forward(input))\n0.0370419   0.03080979  0.22083037  \n0.1547358   0.018475588 0.8102709   \n0.86393493  0.7081842   0.13717912  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]   \n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\npenalty = NegativeEntropyPenalty(0.01)\n\n\n l1Penalty.forward(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]))\n[array([[ 1.,  2.,  3.],\n       [ 4.,  5.,  6.],\n       [ 7.,  8.,  9.]], dtype=float32)]\n\n\n\n\n\n\n\nHardShrink\n\n\nScala:\n\n\nval m = HardShrink(lambda = 0.5)\n\n\n\n\nPython:\n\n\nm = HardShrink(the_lambda=0.5)\n\n\n\n\nApplies the hard shrinkage function element-wise to the input Tensor. lambda is set to 0.5 by default.\n\n\nHardShrinkage operator is defined as:\n\n\n       \u23a7 x, if x \n  lambda\nf(x) = \u23a8 x, if x \n -lambda\n       \u23a9 0, otherwise\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nimport com.intel.analytics.bigdl.utils._\n\ndef randomn(): Float = RandomGenerator.RNG.uniform(-10, 10)\nval input = Tensor(3, 4)\ninput.apply1(x =\n randomn().toFloat)\n\nval layer = new HardShrink(8)\nprintln(\ninput:\n)\nprintln(input)\nprintln(\noutput:\n)\nprintln(layer.forward(input))\n\n\n\n\ninput:\n8.53746839798987    -2.25314284209162   2.838596091605723   0.7181660132482648  \n0.8278933027759194  8.986027473583817   -3.6885232804343104 -2.4018199276179075 \n-9.51015486381948   2.6402589259669185  5.438693333417177   -6.577442386187613  \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4]\noutput:\n8.53746839798987    0.0 0.0 0.0 \n0.0 8.986027473583817   0.0 0.0 \n-9.51015486381948   0.0 0.0 0.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.layer import *\n\ninput = np.linspace(-5, 5, num=10)\nlayer = HardShrink(the_lambda=3.0)\nprint(\ninput:\n)\nprint(input)\nprint(\noutput: \n)\nprint(layer.forward(input))\n\n\n\n\ncreating: createHardShrink\ninput:\n[-5.         -3.88888889 -2.77777778 -1.66666667 -0.55555556  0.55555556\n  1.66666667  2.77777778  3.88888889  5.        ]\noutput: \n[-5.         -3.88888884  0.          0.          0.          0.          0.\n  0.          3.88888884  5.        ]\n\n\n\n\n\n\n\nRReLU\n\n\nScala:\n\n\nval layer = RReLU(lower, upper, inPlace)\n\n\n\n\nPython:\n\n\nlayer = RReLU(lower, upper, inPlace)\n\n\n\n\nApplies the randomized leaky rectified linear unit (RReLU) element-wise to the input Tensor,\nthus outputting a Tensor of the same dimension. Informally the RReLU is also known as 'insanity' layer.\n\n\nRReLU is defined as: \nf(x) = max(0,x) + a * min(0, x) where a ~ U(l, u)\n.\n\n\nIn training mode negative inputs are multiplied by a factor drawn from a uniform random\ndistribution U(l, u). In evaluation mode a RReLU behaves like a LeakyReLU with a constant mean\nfactor \na = (l + u) / 2\n.\n\n\nBy default, \nl = 1/8\n and \nu = 1/3\n. If \nl == u\n a RReLU effectively becomes a LeakyReLU.\n\n\nRegardless of operating in in-place mode a RReLU will internally allocate an input-sized noise tensor to store random factors for negative inputs.\n\n\nThe backward() operation assumes that forward() has been called before.\n\n\nFor reference see \nEmpirical Evaluation of Rectified Activations in Convolutional Network\n.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = RReLU()\nlayer.forward(Tensor(T(1.0f, 2.0f, -1.0f, -2.0f)))\nlayer.backward(Tensor(T(1.0f, 2.0f, -1.0f, -2.0f)),Tensor(T(0.1f, 0.2f, -0.1f, -0.2f)))\n\n\n\n\nThere's random factor. Gives the output,\n\n\n1.0\n2.0\n-0.24342789\n-0.43175703\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\n\n0.1\n0.2\n-0.024342788\n-0.043175705\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import RReLU\nimport numpy as np\n\nlayer = RReLU()\nlayer.forward(np.array([1.0, 2.0, -1.0, -2.0]))\nlayer.backward(np.array([1.0, 2.0, -1.0, -2.0]),\n  np.array([0.1, 0.2, -0.1, -0.2]))\n\n\n\n\nThere's random factor. Gives the ouput like\n\n\narray([ 1.,  2., -0.15329693, -0.40423378], dtype=float32)\n\narray([ 0.1, 0.2, -0.01532969, -0.04042338], dtype=float32)\n\n\n\n\n\n\nHardTanh\n\n\nScala:\n\n\nval activation = HardTanh(\n    minValue = -1,\n    maxValue = 1,\n    inplace = false)\n\n\n\n\nPython:\n\n\nactivation = HardTanh(\n    min_value=-1.0,\n    max_value=1.0,\n    inplace=False)\n\n\n\n\nApplies non-linear function HardTanh to each element of input, HardTanh is defined:\n\n\n           \u23a7  maxValue, if x \n maxValue\n    f(x) = \u23a8  minValue, if x \n minValue\n           \u23a9  x, otherwise\n\n\n\n\nParameters:\n\n \nminValue\n minValue in f(x), default is -1.\n\n \nmaxValue\n maxValue in f(x), default is 1.\n* \ninplace\n  weather inplace update output from input. default is false.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.HardTanh\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval activation = HardTanh()\nval input = Tensor(T(\n  T(-1f, 2f, 3f),\n  T(-2f, 3f, 4f),\n  T(-3f, 4f, 5f)\n))\n\nval gradOutput = Tensor(T(\n  T(3f, 4f, 5f),\n  T(2f, 3f, 4f),\n  T(1f, 2f, 3f)\n))\n\nval output = activation.forward(input)\nval grad = activation.backward(input, gradOutput)\n\nprintln(output)\n-1.0    1.0 1.0\n-1.0    1.0 1.0\n-1.0    1.0 1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nprintln(grad)\n0.0 0.0 0.0\n0.0 0.0 0.0\n0.0 0.0 0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\nPython example:\n\n\nactivation = HardTanh()\ninput = np.array([\n  [-1.0, 2.0, 3.0],\n  [-2.0, 3.0, 4.0],\n  [-3.0, 4.0, 5.0]\n])\n\ngradOutput = np.array([\n  [3.0, 4.0, 5.0],\n  [2.0, 3.0, 4.0],\n  [1.0, 2.0, 5.0]\n])\n\noutput = activation.forward(input)\ngrad = activation.backward(input, gradOutput)\n\nprint output\n[[-1.  1.  1.]\n [-1.  1.  1.]\n [-1.  1.  1.]]\n\nprint grad\n[[ 0.  0.  0.]\n [ 0.  0.  0.]\n [ 0.  0.  0.]]\n\n\n\n\n\n\nLeakyReLU\n\n\nScala:\n\n\nlayer = LeakyReLU(negval=0.01,inplace=false)\n\n\n\n\nPython:\n\n\nlayer = LeakyReLU(negval=0.01,inplace=False,bigdl_type=\nfloat\n)\n\n\n\n\nIt is a transfer module that applies LeakyReLU, which parameter\nnegval sets the slope of the negative part:\n LeakyReLU is defined as:\n  \nf(x) = max(0, x) + negval * min(0, x)\n\n\n\n\nnegval\n sets the slope of the negative partl, default is 0.01\n\n\ninplace\n if it is true, doing the operation in-place without\n                using extra state memory, default is false\n\n\n\n\nScala example:\n\n\nval layer = LeakyReLU(negval=0.01,inplace=false)\nval input = Tensor(3, 2).rand(-1, 1)\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.6923256      -0.14086828\n0.029539397     0.477964\n0.5202874       0.10458552\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\nlayer.forward(input)\nres7: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.006923256    -0.0014086828\n0.029539397     0.477964\n0.5202874       0.10458552\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x2]\n\n\n\n\nPython example:\n\n\nlayer = LeakyReLU(negval=0.01,inplace=False,bigdl_type=\nfloat\n)\ninput = np.random.rand(3, 2)\narray([[ 0.19502378,  0.40498206],\n       [ 0.97056004,  0.35643192],\n       [ 0.25075111,  0.18904582]])\n\nlayer.forward(input)\narray([[ 0.19502378,  0.40498206],\n       [ 0.97056001,  0.35643193],\n       [ 0.25075111,  0.18904583]], dtype=float32)\n\n\n\n\n\n\nLogSigmoid\n\n\nScala:\n\n\nval activation = LogSigmoid()\n\n\n\n\nPython:\n\n\nactivation = LogSigmoid()\n\n\n\n\nThis class is a activation layer corresponding to the non-linear function sigmoid function:\n\n\nf(x) = Log(1 / (1 + e ^ (-x)))\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.LogSigmoid\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval activation = LogSigmoid()\nval input = Tensor(T(\n  T(1f, 2f, 3f),\n  T(2f, 3f, 4f),\n  T(3f, 4f, 5f)\n))\n\nval gradOutput = Tensor(T(\n  T(3f, 4f, 5f),\n  T(2f, 3f, 4f),\n  T(1f, 2f, 3f)\n))\n\nval output = activation.forward(input)\nval grad = activation.backward(input, gradOutput)\n\nprintln(output)\n-0.3132617  -0.12692802 -0.04858735\n-0.12692802 -0.04858735 -0.01814993\n-0.04858735 -0.01814993 -0.0067153485\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nprintln(grad)\n0.8068244   0.47681168  0.23712938\n0.23840584  0.14227761  0.07194484\n0.047425874 0.03597242  0.020078553\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\nPython example:\n\n\nactivation = LogSigmoid()\ninput = np.array([\n  [1.0, 2.0, 3.0],\n  [2.0, 3.0, 4.0],\n  [3.0, 4.0, 5.0]\n])\n\ngradOutput = np.array([\n  [3.0, 4.0, 5.0],\n  [2.0, 3.0, 4.0],\n  [1.0, 2.0, 5.0]\n])\n\noutput = activation.forward(input)\ngrad = activation.backward(input, gradOutput)\n\nprint output\n[[-0.31326169 -0.12692802 -0.04858735]\n [-0.12692802 -0.04858735 -0.01814993]\n [-0.04858735 -0.01814993 -0.00671535]]\n\nprint grad\n[[ 0.80682439  0.47681168  0.23712938]\n [ 0.23840584  0.14227761  0.07194484]\n [ 0.04742587  0.03597242  0.03346425]]\n\n\n\n\n\n\nLogSoftMax\n\n\nScala:\n\n\nval model = LogSoftMax()\n\n\n\n\nPython:\n\n\nmodel = LogSoftMax()\n\n\n\n\nThe LogSoftMax module applies a LogSoftMax transformation to the input data\nwhich is defined as:\n\n\nf_i(x) = log(1 / a exp(x_i))\nwhere a = sum_j[exp(x_j)]\n\n\n\n\nThe input given in \nforward(input)\n must be either\na vector (1D tensor) or matrix (2D tensor).\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = LogSoftMax()\nval input = Tensor(2, 5).rand()\nval output = model.forward(input)\n\nscala\n print(input)\n0.4434036   0.64535594  0.7516194   0.11752353  0.5216674   \n0.57294756  0.744955    0.62644184  0.0052207764    0.900162    \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x5]\n\nscala\n print(output)\n-1.6841899  -1.4822376  -1.3759742  -2.01007    -1.605926   \n-1.6479948  -1.4759872  -1.5945004  -2.2157214  -1.3207803  \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5]\n\n\n\n\nPython example:\n\n\nmodel = LogSoftMax()\ninput = np.random.randn(4, 10)\noutput = model.forward(input)\n\n\n print(input)\n[[ 0.10805365  0.11392282  1.31891713 -0.62910637 -0.80532589  0.57976863\n  -0.44454368  0.26292944  0.8338328   0.32305099]\n [-0.16443839  0.12010763  0.62978233 -1.57224143 -2.16133614 -0.60932395\n  -0.22722708  0.23268273  0.00313597  0.34585582]\n [ 0.55913444 -0.7560615   0.12170887  1.40628806  0.97614582  1.20417145\n  -1.60619173 -0.54483025  1.12227399 -0.79976189]\n [-0.05540945  0.86954458  0.34586427  2.52004267  0.6998163  -1.61315173\n  -0.76276874  0.38332142  0.66351792 -0.30111399]]\n\n\n print(output)\n[[-2.55674744 -2.55087829 -1.34588397 -3.2939074  -3.47012711 -2.08503246\n  -3.10934472 -2.40187168 -1.83096838 -2.34175014]\n [-2.38306785 -2.09852171 -1.58884704 -3.79087067 -4.37996578 -2.82795334\n  -2.44585633 -1.98594666 -2.21549344 -1.87277353]\n [-2.31549931 -3.63069534 -2.75292492 -1.46834576 -1.89848804 -1.67046237\n  -4.48082542 -3.41946411 -1.75235975 -3.67439556]\n [-3.23354769 -2.30859375 -2.83227396 -0.6580956  -2.47832203 -4.79128981\n  -3.940907   -2.79481697 -2.5146203  -3.47925234]]\n\n\n\n\n\n\nThreshold\n\n\nScala:\n\n\nval module = Threshold(threshold, value, ip)\n\n\n\n\nPython:\n\n\nmodule = Threshold(threshold, value, ip)\n\n\n\n\nThresholds each element of the input Tensor.\nThreshold is defined as:\n\n\n     \u23a7 x        if x \n= threshold\n y = \u23a8 \n     \u23a9 value    if x \n  threshold\n\n\n\n\n\n\nthreshold: The value to threshold at\n\n\nvalue: The value to replace with\n\n\nip: can optionally do the operation in-place\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = Threshold(1, 0.8)\nval input = Tensor(2, 2, 2).randn()\nval output = module.forward(input)\n\n\n input\n(1,.,.) =\n2.0502799   -0.37522468\n-1.2704345  -0.22533786\n\n(2,.,.) =\n1.1959263   1.6670992\n-0.24333914 1.4424673\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2]\n\n\n output\n(1,.,.) =\n(1,.,.) =\n2.0502799   0.8\n0.8 0.8\n\n(2,.,.) =\n1.1959263   1.6670992\n0.8 1.4424673\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Threshold(1.0, 0.8)\ninput = np.random.randn(2, 2, 2)\noutput = module.forward(input)\n\n\n input\n[[[-0.43226865 -1.09160093]\n  [-0.20280088  0.68196767]]\n\n [[ 2.32017942  1.00003307]\n  [-0.46618767  0.57057167]]]\n\n\n output\n[array([[[ 0.80000001,  0.80000001],\n        [ 0.80000001,  0.80000001]],\n\n       [[ 2.32017946,  1.00003302],\n        [ 0.80000001,  0.80000001]]], dtype=float32)]\n\n\n\n\nHardSigmoid\n\n\nScala:\n\n\nval module = HardSigmoid()\n\n\n\n\nPython:\n\n\nmodule = HardSigmoid()\n\n\n\n\nActivate each element as below\n\n\n           \u23a7  0, if x \n -2.5\n    f(x) = \u23a8  1, if x \n 2.5\n           \u23a9  0.2 * x + 0.5, otherwise\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = HardSigmoid()\nval input = Tensor(2, 2).randn()\nval output = module.forward(input)\n\n\n input\n-1.7260494  -0.17521624 \n-1.6705151  0.013930867 \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n\n\n output\n0.15479012  0.46495676  \n0.16589698  0.50278616  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = HardSigmoid()\ninput = np.random.randn(2, 2)\noutput = module.forward(input)\n\n\n input\narray([[-1.45094354, -1.78217815],\n       [ 0.84914007,  0.7104982 ]])\n\n\n output\narray([[ 0.20981129,  0.14356437],\n       [ 0.669828  ,  0.64209962]], dtype=float32)\n\n\n\n\n\nSReLU\n\n\nS-shaped Rectified Linear Unit based on paper \nDeep Learning with S-shaped Rectified Linear Activation Units\n.\n\n\n     \u23a7 t^r + a^r(x - t^r) if x \n= t^r\n y = \u23a8 x                  if t^r \n x \n t^l\n     \u23a9 t^l + a^l(x - t^l) if x \n= t^l\n\n\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval input = Tensor[Float](2, 3, 4).rand()\nval gradOutput = Tensor[Float](2, 3, 4).rand()\nval srelu = SReLU[Float]([3, 4])\nval output = srelu.forward(input)\nval gradInput = srelu.backward(input, gradOutput)\n\nprintln(input)\nprintln(gradInput)\n\n\n\n\nThe input is,\n\n\n(1,.,.) =\n0.4835907       0.53359604      0.37766683      0.32341897\n0.96768993      0.78638965      0.6921552       0.49003857\n0.10896994      0.22801183      0.9023593       0.43514457\n\n(2,.,.) =\n0.6720485       0.5893981       0.45753896      0.28696498\n0.16126601      0.75192916      0.79481035      0.24795102\n0.7665252       0.775531        0.74594253      0.23907393\n\n\n\n\nThe output is,\n\n\nsrelu: com.intel.analytics.bigdl.nn.SReLU[Float] = SReLU[71e3de13]\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =                   \n0.4835907       0.53359604      0.37766683      0.32341897\n0.96768993      0.78638965      0.6921552       0.49003857\n0.10896994      0.22801183      0.9023593       0.43514457\n\n(2,.,.) =                                                                    \n0.6720485       0.5893981       0.45753896      0.28696498\n0.16126601      0.75192916      0.79481035      0.24795102\n0.7665252       0.775531        0.74594253      0.23907393\n\n\n\n\nThe python code is,\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = SReLU([3, 4])\ninput = np.random.randn(2, 3, 4)\noutput = module.forward(input)\ngradOutput = np.random.randn(2, 3, 4)\ngradInput = module.backward(input, gradOutput)\nprint output\nprint gradInput", 
            "title": "Activations"
        }, 
        {
            "location": "/APIGuide/Layers/Activations/#softsign", 
            "text": "Scala:  val softSign = SoftSign()  Python:  softSign = SoftSign()  SoftSign applies SoftSign function to the input tensor  SoftSign function:  f_i(x) = x_i / (1+|x_i|)  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval softSign = SoftSign()\nval input = Tensor(3, 3).rand()  print(input)\n0.6733504   0.7566517   0.43793806  \n0.09683273  0.05829774  0.4567967   \n0.20021072  0.11158377  0.31668025  print(softSign.forward(input))\n0.40239656  0.4307352   0.30455974  \n0.08828395  0.05508633  0.31356242  \n0.16681297  0.10038269  0.24051417  \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  from bigdl.nn.layer import *\nsoftSign=SoftSign()  softSign.forward(np.array([[1, 2, 4],[-1, -2, -4]]))\n[array([[ 0.5       ,  0.66666669,  0.80000001],\n       [-0.5       , -0.66666669, -0.80000001]], dtype=float32)]", 
            "title": "SoftSign"
        }, 
        {
            "location": "/APIGuide/Layers/Activations/#relu6", 
            "text": "Scala:  val module = ReLU6(inplace = false)  Python:  module = ReLU6(inplace=False)  Same as ReLU except that the rectifying function f(x) saturates at x = 6 \nReLU6 is defined as: f(x) = min(max(0, x), 6)  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = ReLU6()\n\nprintln(module.forward(Tensor.range(-2, 8, 1)))  Gives the output,  com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.0\n0.0\n0.0\n1.0\n2.0\n3.0\n4.0\n5.0\n6.0\n6.0\n6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 11]   Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = ReLU6()\n\nprint(module.forward(np.arange(-2, 9, 1)))  Gives the output,  [array([ 0.,  0.,  0.,  1.,  2.,  3.,  4.,  5.,  6.,  6.,  6.], dtype=float32)]", 
            "title": "ReLU6"
        }, 
        {
            "location": "/APIGuide/Layers/Activations/#tanhshrink", 
            "text": "Scala:  val tanhShrink = TanhShrink()  Python:  tanhShrink = TanhShrink()  TanhShrink applies element-wise Tanh and Shrink function to the input  TanhShrink function :  f(x) = scala.math.tanh(x) - 1  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval tanhShrink = TanhShrink()\nval input = Tensor(3, 3).rand()  print(input)\n0.7056571   0.25239098  0.75746965  \n0.89736927  0.31193605  0.23842576  \n0.69492024  0.7512544   0.8386124   \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]  print(tanhShrink.forward(input))\n0.09771085  0.0052260756    0.11788553  \n0.18235475  0.009738684 0.004417494 \n0.09378672  0.1153577   0.153539    \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  from bigdl.nn.layer import *\ntanhShrink = TanhShrink()   tanhShrink.forward(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]))\n[array([[ 0.23840582,  1.03597236,  2.00494528],\n       [ 3.00067067,  4.0000906 ,  5.0000124 ],\n       [ 6.00000191,  7.        ,  8.        ]], dtype=float32)]", 
            "title": "TanhShrink"
        }, 
        {
            "location": "/APIGuide/Layers/Activations/#softmax", 
            "text": "Scala:  val layer = SoftMax()  Python:  layer = SoftMax()  Applies the SoftMax function to an n-dimensional input Tensor, rescaling them so that the\nelements of the n-dimensional output Tensor lie in the range (0, 1) and sum to 1.\nSoftmax is defined as: f_i(x) = exp(x_i - shift) / sum_j exp(x_j - shift) \nwhere  shift = max_i(x_i) .  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = SoftMax()\nval input = Tensor(3)\ninput.apply1(_ =  1.0f * 10)\nval gradOutput = Tensor(T(\n1.0f,\n0.0f,\n0.0f\n))\nval output = layer.forward(input)\nval gradient = layer.backward(input, gradOutput)\n-  print(output)\n0.33333334\n0.33333334\n0.33333334\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n-  print(gradient)\n0.22222221\n-0.11111112\n-0.11111112\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nlayer = SoftMax()\ninput = np.ones(3)*10\ngrad_output = np.array([1.0, 0.0, 0.0])\noutput = layer.forward(input)\ngradient = layer.backward(input, grad_output)\n-  print output\n[ 0.33333334  0.33333334  0.33333334]\n-  print gradient\n[ 0.22222221 -0.11111112 -0.11111112]", 
            "title": "SoftMax"
        }, 
        {
            "location": "/APIGuide/Layers/Activations/#prelu", 
            "text": "Scala:  val module = PReLU(nOutputPlane = 0)  Python:  module = PReLU(nOutputPlane=0)  Applies parametric ReLU, which parameter varies the slope of the negative part.  PReLU: f(x) = max(0, x) + a * min(0, x)  nOutputPlane's default value is 0, that means using PReLU in shared version and has\nonly one parameters. nOutputPlane is the input map number(Default is 0).  Notice: Please don't use weight decay on this.  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = PReLU(2)\nval input = Tensor(2, 2, 3).randn()\nval output = module.forward(input)  input\n(1,.,.) =\n-0.17810068 -0.69607687 0.25582042\n-1.2140307  -1.5410945  1.0209005\n\n(2,.,.) =\n0.2826971   0.6370953   0.21471702\n-0.16203058 -0.5643519  0.816576\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x3]  output\n(1,.,.) =\n-0.04452517 -0.17401922 0.25582042\n-0.3035077  -0.38527364 1.0209005\n\n(2,.,.) =\n0.2826971   0.6370953   0.21471702\n-0.040507644    -0.14108798 0.816576\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = PReLU(2)\ninput = np.random.randn(2, 2, 3)\noutput = module.forward(input)  input\n[[[ 2.50596953 -0.06593339 -1.90273409]\n  [ 0.2464341   0.45941315 -0.41977094]]\n\n [[-0.8584367   2.19389229  0.93136755]\n  [-0.39209027  0.16507514 -0.35850447]]]  output\n[array([[[ 2.50596952, -0.01648335, -0.47568351],\n         [ 0.24643411,  0.45941314, -0.10494273]],\n\n        [[-0.21460918,  2.19389224,  0.93136758],\n         [-0.09802257,  0.16507514, -0.08962612]]], dtype=float32)]", 
            "title": "PReLU"
        }, 
        {
            "location": "/APIGuide/Layers/Activations/#relu", 
            "text": "Scala:  val relu = ReLU(ip = false)  Python:  relu = ReLU(ip)  ReLU applies the element-wise rectified linear unit (ReLU) function to the input  ip  illustrate if the ReLU function is done on the origin input  ReLU function : f(x) = max(0, x)  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval relu = ReLU(false)\n\nval input = Tensor(3, 3).rand()  print(input)\n0.13486342  0.8986828   0.2648762   \n0.56467545  0.7727274   0.65959305  \n0.01554346  0.9552375   0.2434533   \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]  print(relu.forward(input))\n0.13486342  0.8986828   0.2648762   \n0.56467545  0.7727274   0.65959305  \n0.01554346  0.9552375   0.2434533   \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  from bigdl.nn.layer import *\nrelu = ReLU(False)  relu.forward(np.array([[-1, -2, -3], [0, 0, 0], [1, 2, 3]]))\n[array([[ 0.,  0.,  0.],\n       [ 0.,  0.,  0.],\n       [ 1.,  2.,  3.]], dtype=float32)]", 
            "title": "ReLU"
        }, 
        {
            "location": "/APIGuide/Layers/Activations/#softmin", 
            "text": "Scala:  val sm = SoftMin()  Python:  sm = SoftMin()  Applies the SoftMin function to an n-dimensional input Tensor, rescaling them so that the\nelements of the n-dimensional output Tensor lie in the range (0,1) and sum to 1.\nSoftmin is defined as:  f_i(x) = exp(-x_i - shift) / sum_j exp(-x_j - shift) \nwhere  shift = max_i(-x_i) .  Scala example:  import com.intel.analytics.bigdl.nn.SoftMin\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval sm = SoftMin()\nval input = Tensor(3, 3).range(1, 3 * 3)\n\nval output = sm.forward(input)\n\nval gradOutput = Tensor(3, 3).range(1, 3 * 3).apply1(x =  (x / 10.0).toFloat)\nval gradInput = sm.backward(input, gradOutput)  Gives the output,  output: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.66524094      0.24472848      0.09003057\n0.66524094      0.24472848      0.09003057\n0.66524094      0.24472848      0.09003057\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Gives the gradInput,  gradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.02825874      -0.014077038    -0.014181711\n0.028258756     -0.01407703     -0.01418171\n0.028258756     -0.014077038    -0.014181707\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nsm = SoftMin()\n\ninput = np.arange(1, 10, 1).astype( float32 )\ninput = input.reshape(3, 3)\n\noutput = sm.forward(input)\nprint output\n\ngradOutput = np.arange(1, 10, 1).astype( float32 )\ngradOutput = np.vectorize(lambda t: t / 10)(gradOutput)\ngradOutput = gradOutput.reshape(3, 3)\n\ngradInput = sm.backward(input, gradOutput)\nprint gradInput", 
            "title": "SoftMin"
        }, 
        {
            "location": "/APIGuide/Layers/Activations/#elu", 
            "text": "Scala:  val m = ELU(alpha = 1.0, inplace = false)  Python:  m = ELU(alpha=1.0, inplace=False)  Applies exponential linear unit ( ELU ), which parameter a varies the convergence value of the exponential function below zero:  ELU  is defined as:  f(x) = max(0, x) + min(0, alpha * (exp(x) - 1))  The output dimension is always equal to input dimension.  For reference see  Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs) .  Scala example:  import com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval xs = Tensor(4).randn()\nprintln(xs)\nprintln(ELU(4).forward(xs))  1.0217569\n-0.17189966\n1.4164596\n0.69361746\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\n\n1.0217569\n-0.63174534\n1.4164596\n0.69361746\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]  Python example:  import numpy as np\nfrom bigdl.nn.layer import *\n\nxs = np.linspace(-3, 3, num=200)\ngo = np.ones(200)\n\ndef f(a):\n    return ELU(a).forward(xs)[0]\ndef df(a):\n    m = ELU(a)\n    m.forward(xs)\n    return m.backward(xs, go)[0]\n\nplt.plot(xs, f(0.1), '-', label='fw ELU, alpha = 0.1')\nplt.plot(xs, f(1.0), '-', label='fw ELU, alpha = 0.1')\nplt.plot(xs, df(0.1), '-', label='dw ELU, alpha = 0.1')\nplt.plot(xs, df(1.0), '-', label='dw ELU, alpha = 0.1')\n\nplt.legend(loc='best', shadow=True, fancybox=True)\nplt.show()", 
            "title": "ELU"
        }, 
        {
            "location": "/APIGuide/Layers/Activations/#softshrink", 
            "text": "Scala:  val layer = SoftShrink(lambda = 0.5)  Python:  layer = SoftShrink(the_lambda=0.5)  Apply the soft shrinkage function element-wise to the input Tensor  SoftShrinkage operator:         \u23a7 x - lambda, if x    lambda\nf(x) = \u23a8 x + lambda, if x   -lambda\n       \u23a9 0, otherwise  Parameters:\n*  lambda  a factor, default is 0.5  Scala example:  import com.intel.analytics.bigdl.nn.SoftShrink\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval activation = SoftShrink()\nval input = Tensor(T(\n  T(-1f, 2f, 3f),\n  T(-2f, 3f, 4f),\n  T(-3f, 4f, 5f)\n))\n\nval gradOutput = Tensor(T(\n  T(3f, 4f, 5f),\n  T(2f, 3f, 4f),\n  T(1f, 2f, 3f)\n))\n\nval output = activation.forward(input)\nval grad = activation.backward(input, gradOutput)\n\nprintln(output)\n-0.5    1.5 2.5\n-1.5    2.5 3.5\n-2.5    3.5 4.5\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nprintln(grad)\n3.0 4.0 5.0\n2.0 3.0 4.0\n1.0 2.0 3.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Scala example:  activation = SoftShrink()\ninput = np.array([\n  [-1.0, 2.0, 3.0],\n  [-2.0, 3.0, 4.0],\n  [-3.0, 4.0, 5.0]\n])\n\ngradOutput = np.array([\n  [3.0, 4.0, 5.0],\n  [2.0, 3.0, 4.0],\n  [1.0, 2.0, 5.0]\n])\n\noutput = activation.forward(input)\ngrad = activation.backward(input, gradOutput)\n\nprint output\n[[-0.5  1.5  2.5]\n [-1.5  2.5  3.5]\n [-2.5  3.5  4.5]]\n\nprint grad\n[[ 3.  4.  5.]\n [ 2.  3.  4.]\n [ 1.  2.  5.]]", 
            "title": "SoftShrink"
        }, 
        {
            "location": "/APIGuide/Layers/Activations/#sigmoid", 
            "text": "Scala:  val module = Sigmoid()  Python:  module = Sigmoid()  Applies the Sigmoid function element-wise to the input Tensor,\nthus outputting a Tensor of the same dimension.  Sigmoid is defined as:  f(x) = 1 / (1 + exp(-x))  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = new Sigmoid()\nval input = Tensor(2, 3)\nvar i = 0\ninput.apply1(_ =  {i += 1; i})  print(layer.forward(input))\n0.7310586   0.880797    0.95257413  \n0.98201376  0.9933072   0.9975274   \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  from bigdl.nn.layer import *\n\nlayer = Sigmoid()\ninput = np.array([[1, 2, 3], [4, 5, 6]]) layer.forward(input)\narray([[ 0.7310586 ,  0.88079703,  0.95257413],\n       [ 0.98201376,  0.99330717,  0.99752742]], dtype=float32)", 
            "title": "Sigmoid"
        }, 
        {
            "location": "/APIGuide/Layers/Activations/#tanh", 
            "text": "Scala:  val activation = Tanh()  Python:  activation = Tanh()  Applies the Tanh function element-wise to the input Tensor,\nthus outputting a Tensor of the same dimension.\nTanh is defined as  f(x) = (exp(x)-exp(-x))/(exp(x)+exp(-x)).  Scala example:  import com.intel.analytics.bigdl.nn.Tanh\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval activation = Tanh()\nval input = Tensor(T(\n  T(1f, 2f, 3f),\n  T(2f, 3f, 4f),\n  T(3f, 4f, 5f)\n))\n\nval gradOutput = Tensor(T(\n  T(3f, 4f, 5f),\n  T(2f, 3f, 4f),\n  T(1f, 2f, 3f)\n))\n\nval output = activation.forward(input)\nval grad = activation.backward(input, gradOutput)\n\nprintln(output)\n0.7615942   0.9640276   0.9950548\n0.9640276   0.9950548   0.9993293\n0.9950548   0.9993293   0.9999092\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nprintln(grad)\n1.259923    0.28260326  0.049329996\n0.14130163  0.029597998 0.0053634644\n0.009865999 0.0026817322    5.4466724E-4\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  activation = Tanh()\ninput = np.array([\n  [1.0, 2.0, 3.0],\n  [2.0, 3.0, 4.0],\n  [3.0, 4.0, 5.0]\n])\n\ngradOutput = np.array([\n  [3.0, 4.0, 5.0],\n  [2.0, 3.0, 4.0],\n  [1.0, 2.0, 5.0]\n])\n\noutput = activation.forward(input)\ngrad = activation.backward(input, gradOutput)\n\nprint output\n[[ 0.76159418  0.96402758  0.99505478]\n [ 0.96402758  0.99505478  0.99932933]\n [ 0.99505478  0.99932933  0.99990922]]\n\nprint grad\n[[  1.25992298e+00   2.82603264e-01   4.93299961e-02]\n [  1.41301632e-01   2.95979977e-02   5.36346436e-03]\n [  9.86599922e-03   2.68173218e-03   9.07778740e-04]]", 
            "title": "Tanh"
        }, 
        {
            "location": "/APIGuide/Layers/Activations/#softplus", 
            "text": "Scala:  val model = SoftPlus(beta = 1.0)  Python:  model = SoftPlus(beta = 1.0)  Apply the SoftPlus function to an n-dimensional input tensor.\nSoftPlus function:   f_i(x) = 1/beta * log(1 + exp(beta * x_i))   param beta Controls sharpness of transfer function   Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = SoftPlus()\nval input = Tensor(2, 3, 4).rand()\nval output = model.forward(input)\n\nscala  println(input)\n(1,.,.) =\n0.9812126   0.7044107   0.0657767   0.9173636   \n0.20853543  0.76482195  0.60774535  0.47837523  \n0.62954164  0.56440496  0.28893307  0.40742245  \n\n(2,.,.) =\n0.18701692  0.7700966   0.98496467  0.8958407   \n0.037015386 0.34626052  0.36459026  0.8460807   \n0.051016055 0.6742781   0.14469075  0.07565566  \n\nscala  println(output)\n(1,.,.) =\n1.2995617   1.1061354   0.7265762   1.2535294   \n0.80284095  1.1469617   1.0424956   0.9606715   \n1.0566612   1.0146512   0.8480129   0.91746557  \n\n(2,.,.) =\n0.7910212   1.1505641   1.3022922   1.2381986   \n0.71182615  0.88119024  0.8919668   1.203121    \n0.7189805   1.0860726   0.7681072   0.7316903   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodel = SoftPlus()\ninput = np.random.randn(2, 3, 4)\noutput = model.forward(input)  print(input)\n[[[ 0.82634972 -0.09853824  0.97570235  1.84464617]\n  [ 0.38466503  0.08963732  1.29438774  1.25204527]\n  [-0.01910449 -0.19560752 -0.81769143 -1.06365733]]\n\n [[-0.56284365 -0.28473239 -0.58206869 -1.97350909]\n  [-0.28303919 -0.59735361  0.73282102  0.0176838 ]\n  [ 0.63439133  1.84904987 -1.24073643  2.13275833]]]  print(output)\n[[[ 1.18935537  0.6450913   1.2955569   1.99141073]\n  [ 0.90386271  0.73896986  1.53660071  1.50351918]\n  [ 0.68364054  0.60011864  0.36564925  0.29653603]]\n\n [[ 0.45081255  0.56088102  0.44387865  0.1301229 ]\n  [ 0.56160825  0.43842646  1.12523568  0.70202816]\n  [ 1.0598278   1.99521446  0.2539995   2.24475574]]]", 
            "title": "SoftPlus"
        }, 
        {
            "location": "/APIGuide/Layers/Activations/#l1penalty", 
            "text": "Scala:  val l1Penalty = L1Penalty(l1weight, sizeAverage = false, provideOutput = true)  Python:  l1Penalty = L1Penalty( l1weight, size_average=False, provide_output=True)  L1Penalty adds an L1 penalty to an input \nFor forward, the output is the same as input and a L1 loss of the latent state will be calculated each time\nFor backward, gradInput = gradOutput + gradLoss  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval l1Penalty = L1Penalty(1, true, true)\nval input = Tensor(3, 3).rand()  print(input)\n0.0370419   0.03080979  0.22083037  \n0.1547358   0.018475588 0.8102709   \n0.86393493  0.7081842   0.13717912  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]  print(l1Penalty.forward(input))\n0.0370419   0.03080979  0.22083037  \n0.1547358   0.018475588 0.8102709   \n0.86393493  0.7081842   0.13717912  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]     Python example:  from bigdl.nn.layer import *\nl1Penalty = L1Penalty(1, True, True)  l1Penalty.forward(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]))\n[array([[ 1.,  2.,  3.],\n       [ 4.,  5.,  6.],\n       [ 7.,  8.,  9.]], dtype=float32)]", 
            "title": "L1Penalty"
        }, 
        {
            "location": "/APIGuide/Layers/Activations/#negativeentropypenalty", 
            "text": "Scala:  val penalty = NegativeEntropyPenalty(beta = 0.01)  Python:  penalty = NegativeEntropyPenalty(beta = 0.01)  Penalize the input multinomial distribution if it has low entropy.\nThe input to this layer should be a batch of vector each representing a\nmultinomial distribution. The input is typically the output of a softmax layer.  For forward, the output is the same as input and a NegativeEntropy loss of the latent state will be calculated each time\nFor backward, gradInput = gradOutput + gradLoss  This can be used in reinforcement learning to discourage the policy from\ncollapsing to a single action for a given state, which improves exploration.\nSee the A3C paper for more detail (https://arxiv.org/pdf/1602.01783.pdf).  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval penalty = NegativeEntropyPenalty(0.01)\nval input = Tensor(3, 3).rand()  print(input)\n0.0370419   0.03080979  0.22083037  \n0.1547358   0.018475588 0.8102709   \n0.86393493  0.7081842   0.13717912  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]  print(l1Penalty.forward(input))\n0.0370419   0.03080979  0.22083037  \n0.1547358   0.018475588 0.8102709   \n0.86393493  0.7081842   0.13717912  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]     Python example:  from bigdl.nn.layer import *\npenalty = NegativeEntropyPenalty(0.01)  l1Penalty.forward(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]))\n[array([[ 1.,  2.,  3.],\n       [ 4.,  5.,  6.],\n       [ 7.,  8.,  9.]], dtype=float32)]", 
            "title": "NegativeEntropyPenalty"
        }, 
        {
            "location": "/APIGuide/Layers/Activations/#hardshrink", 
            "text": "Scala:  val m = HardShrink(lambda = 0.5)  Python:  m = HardShrink(the_lambda=0.5)  Applies the hard shrinkage function element-wise to the input Tensor. lambda is set to 0.5 by default.  HardShrinkage operator is defined as:         \u23a7 x, if x    lambda\nf(x) = \u23a8 x, if x   -lambda\n       \u23a9 0, otherwise  Scala example:  import com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nimport com.intel.analytics.bigdl.utils._\n\ndef randomn(): Float = RandomGenerator.RNG.uniform(-10, 10)\nval input = Tensor(3, 4)\ninput.apply1(x =  randomn().toFloat)\n\nval layer = new HardShrink(8)\nprintln( input: )\nprintln(input)\nprintln( output: )\nprintln(layer.forward(input))  input:\n8.53746839798987    -2.25314284209162   2.838596091605723   0.7181660132482648  \n0.8278933027759194  8.986027473583817   -3.6885232804343104 -2.4018199276179075 \n-9.51015486381948   2.6402589259669185  5.438693333417177   -6.577442386187613  \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4]\noutput:\n8.53746839798987    0.0 0.0 0.0 \n0.0 8.986027473583817   0.0 0.0 \n-9.51015486381948   0.0 0.0 0.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4]  Python example:  import numpy as np\nfrom bigdl.nn.layer import *\n\ninput = np.linspace(-5, 5, num=10)\nlayer = HardShrink(the_lambda=3.0)\nprint( input: )\nprint(input)\nprint( output:  )\nprint(layer.forward(input))  creating: createHardShrink\ninput:\n[-5.         -3.88888889 -2.77777778 -1.66666667 -0.55555556  0.55555556\n  1.66666667  2.77777778  3.88888889  5.        ]\noutput: \n[-5.         -3.88888884  0.          0.          0.          0.          0.\n  0.          3.88888884  5.        ]", 
            "title": "HardShrink"
        }, 
        {
            "location": "/APIGuide/Layers/Activations/#rrelu", 
            "text": "Scala:  val layer = RReLU(lower, upper, inPlace)  Python:  layer = RReLU(lower, upper, inPlace)  Applies the randomized leaky rectified linear unit (RReLU) element-wise to the input Tensor,\nthus outputting a Tensor of the same dimension. Informally the RReLU is also known as 'insanity' layer.  RReLU is defined as:  f(x) = max(0,x) + a * min(0, x) where a ~ U(l, u) .  In training mode negative inputs are multiplied by a factor drawn from a uniform random\ndistribution U(l, u). In evaluation mode a RReLU behaves like a LeakyReLU with a constant mean\nfactor  a = (l + u) / 2 .  By default,  l = 1/8  and  u = 1/3 . If  l == u  a RReLU effectively becomes a LeakyReLU.  Regardless of operating in in-place mode a RReLU will internally allocate an input-sized noise tensor to store random factors for negative inputs.  The backward() operation assumes that forward() has been called before.  For reference see  Empirical Evaluation of Rectified Activations in Convolutional Network .  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = RReLU()\nlayer.forward(Tensor(T(1.0f, 2.0f, -1.0f, -2.0f)))\nlayer.backward(Tensor(T(1.0f, 2.0f, -1.0f, -2.0f)),Tensor(T(0.1f, 0.2f, -0.1f, -0.2f)))  There's random factor. Gives the output,  1.0\n2.0\n-0.24342789\n-0.43175703\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\n\n0.1\n0.2\n-0.024342788\n-0.043175705\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]  Python example:  from bigdl.nn.layer import RReLU\nimport numpy as np\n\nlayer = RReLU()\nlayer.forward(np.array([1.0, 2.0, -1.0, -2.0]))\nlayer.backward(np.array([1.0, 2.0, -1.0, -2.0]),\n  np.array([0.1, 0.2, -0.1, -0.2]))  There's random factor. Gives the ouput like  array([ 1.,  2., -0.15329693, -0.40423378], dtype=float32)\n\narray([ 0.1, 0.2, -0.01532969, -0.04042338], dtype=float32)", 
            "title": "RReLU"
        }, 
        {
            "location": "/APIGuide/Layers/Activations/#hardtanh", 
            "text": "Scala:  val activation = HardTanh(\n    minValue = -1,\n    maxValue = 1,\n    inplace = false)  Python:  activation = HardTanh(\n    min_value=-1.0,\n    max_value=1.0,\n    inplace=False)  Applies non-linear function HardTanh to each element of input, HardTanh is defined:             \u23a7  maxValue, if x   maxValue\n    f(x) = \u23a8  minValue, if x   minValue\n           \u23a9  x, otherwise  Parameters:   minValue  minValue in f(x), default is -1.   maxValue  maxValue in f(x), default is 1.\n*  inplace   weather inplace update output from input. default is false.  Scala example:  import com.intel.analytics.bigdl.nn.HardTanh\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval activation = HardTanh()\nval input = Tensor(T(\n  T(-1f, 2f, 3f),\n  T(-2f, 3f, 4f),\n  T(-3f, 4f, 5f)\n))\n\nval gradOutput = Tensor(T(\n  T(3f, 4f, 5f),\n  T(2f, 3f, 4f),\n  T(1f, 2f, 3f)\n))\n\nval output = activation.forward(input)\nval grad = activation.backward(input, gradOutput)\n\nprintln(output)\n-1.0    1.0 1.0\n-1.0    1.0 1.0\n-1.0    1.0 1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nprintln(grad)\n0.0 0.0 0.0\n0.0 0.0 0.0\n0.0 0.0 0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  activation = HardTanh()\ninput = np.array([\n  [-1.0, 2.0, 3.0],\n  [-2.0, 3.0, 4.0],\n  [-3.0, 4.0, 5.0]\n])\n\ngradOutput = np.array([\n  [3.0, 4.0, 5.0],\n  [2.0, 3.0, 4.0],\n  [1.0, 2.0, 5.0]\n])\n\noutput = activation.forward(input)\ngrad = activation.backward(input, gradOutput)\n\nprint output\n[[-1.  1.  1.]\n [-1.  1.  1.]\n [-1.  1.  1.]]\n\nprint grad\n[[ 0.  0.  0.]\n [ 0.  0.  0.]\n [ 0.  0.  0.]]", 
            "title": "HardTanh"
        }, 
        {
            "location": "/APIGuide/Layers/Activations/#leakyrelu", 
            "text": "Scala:  layer = LeakyReLU(negval=0.01,inplace=false)  Python:  layer = LeakyReLU(negval=0.01,inplace=False,bigdl_type= float )  It is a transfer module that applies LeakyReLU, which parameter\nnegval sets the slope of the negative part:\n LeakyReLU is defined as:\n   f(x) = max(0, x) + negval * min(0, x)   negval  sets the slope of the negative partl, default is 0.01  inplace  if it is true, doing the operation in-place without\n                using extra state memory, default is false   Scala example:  val layer = LeakyReLU(negval=0.01,inplace=false)\nval input = Tensor(3, 2).rand(-1, 1)\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.6923256      -0.14086828\n0.029539397     0.477964\n0.5202874       0.10458552\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\nlayer.forward(input)\nres7: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.006923256    -0.0014086828\n0.029539397     0.477964\n0.5202874       0.10458552\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x2]  Python example:  layer = LeakyReLU(negval=0.01,inplace=False,bigdl_type= float )\ninput = np.random.rand(3, 2)\narray([[ 0.19502378,  0.40498206],\n       [ 0.97056004,  0.35643192],\n       [ 0.25075111,  0.18904582]])\n\nlayer.forward(input)\narray([[ 0.19502378,  0.40498206],\n       [ 0.97056001,  0.35643193],\n       [ 0.25075111,  0.18904583]], dtype=float32)", 
            "title": "LeakyReLU"
        }, 
        {
            "location": "/APIGuide/Layers/Activations/#logsigmoid", 
            "text": "Scala:  val activation = LogSigmoid()  Python:  activation = LogSigmoid()  This class is a activation layer corresponding to the non-linear function sigmoid function:  f(x) = Log(1 / (1 + e ^ (-x)))  Scala example:  import com.intel.analytics.bigdl.nn.LogSigmoid\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval activation = LogSigmoid()\nval input = Tensor(T(\n  T(1f, 2f, 3f),\n  T(2f, 3f, 4f),\n  T(3f, 4f, 5f)\n))\n\nval gradOutput = Tensor(T(\n  T(3f, 4f, 5f),\n  T(2f, 3f, 4f),\n  T(1f, 2f, 3f)\n))\n\nval output = activation.forward(input)\nval grad = activation.backward(input, gradOutput)\n\nprintln(output)\n-0.3132617  -0.12692802 -0.04858735\n-0.12692802 -0.04858735 -0.01814993\n-0.04858735 -0.01814993 -0.0067153485\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nprintln(grad)\n0.8068244   0.47681168  0.23712938\n0.23840584  0.14227761  0.07194484\n0.047425874 0.03597242  0.020078553\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  activation = LogSigmoid()\ninput = np.array([\n  [1.0, 2.0, 3.0],\n  [2.0, 3.0, 4.0],\n  [3.0, 4.0, 5.0]\n])\n\ngradOutput = np.array([\n  [3.0, 4.0, 5.0],\n  [2.0, 3.0, 4.0],\n  [1.0, 2.0, 5.0]\n])\n\noutput = activation.forward(input)\ngrad = activation.backward(input, gradOutput)\n\nprint output\n[[-0.31326169 -0.12692802 -0.04858735]\n [-0.12692802 -0.04858735 -0.01814993]\n [-0.04858735 -0.01814993 -0.00671535]]\n\nprint grad\n[[ 0.80682439  0.47681168  0.23712938]\n [ 0.23840584  0.14227761  0.07194484]\n [ 0.04742587  0.03597242  0.03346425]]", 
            "title": "LogSigmoid"
        }, 
        {
            "location": "/APIGuide/Layers/Activations/#logsoftmax", 
            "text": "Scala:  val model = LogSoftMax()  Python:  model = LogSoftMax()  The LogSoftMax module applies a LogSoftMax transformation to the input data\nwhich is defined as:  f_i(x) = log(1 / a exp(x_i))\nwhere a = sum_j[exp(x_j)]  The input given in  forward(input)  must be either\na vector (1D tensor) or matrix (2D tensor).  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = LogSoftMax()\nval input = Tensor(2, 5).rand()\nval output = model.forward(input)\n\nscala  print(input)\n0.4434036   0.64535594  0.7516194   0.11752353  0.5216674   \n0.57294756  0.744955    0.62644184  0.0052207764    0.900162    \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x5]\n\nscala  print(output)\n-1.6841899  -1.4822376  -1.3759742  -2.01007    -1.605926   \n-1.6479948  -1.4759872  -1.5945004  -2.2157214  -1.3207803  \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5]  Python example:  model = LogSoftMax()\ninput = np.random.randn(4, 10)\noutput = model.forward(input)  print(input)\n[[ 0.10805365  0.11392282  1.31891713 -0.62910637 -0.80532589  0.57976863\n  -0.44454368  0.26292944  0.8338328   0.32305099]\n [-0.16443839  0.12010763  0.62978233 -1.57224143 -2.16133614 -0.60932395\n  -0.22722708  0.23268273  0.00313597  0.34585582]\n [ 0.55913444 -0.7560615   0.12170887  1.40628806  0.97614582  1.20417145\n  -1.60619173 -0.54483025  1.12227399 -0.79976189]\n [-0.05540945  0.86954458  0.34586427  2.52004267  0.6998163  -1.61315173\n  -0.76276874  0.38332142  0.66351792 -0.30111399]]  print(output)\n[[-2.55674744 -2.55087829 -1.34588397 -3.2939074  -3.47012711 -2.08503246\n  -3.10934472 -2.40187168 -1.83096838 -2.34175014]\n [-2.38306785 -2.09852171 -1.58884704 -3.79087067 -4.37996578 -2.82795334\n  -2.44585633 -1.98594666 -2.21549344 -1.87277353]\n [-2.31549931 -3.63069534 -2.75292492 -1.46834576 -1.89848804 -1.67046237\n  -4.48082542 -3.41946411 -1.75235975 -3.67439556]\n [-3.23354769 -2.30859375 -2.83227396 -0.6580956  -2.47832203 -4.79128981\n  -3.940907   -2.79481697 -2.5146203  -3.47925234]]", 
            "title": "LogSoftMax"
        }, 
        {
            "location": "/APIGuide/Layers/Activations/#threshold", 
            "text": "Scala:  val module = Threshold(threshold, value, ip)  Python:  module = Threshold(threshold, value, ip)  Thresholds each element of the input Tensor.\nThreshold is defined as:       \u23a7 x        if x  = threshold\n y = \u23a8 \n     \u23a9 value    if x    threshold   threshold: The value to threshold at  value: The value to replace with  ip: can optionally do the operation in-place   Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = Threshold(1, 0.8)\nval input = Tensor(2, 2, 2).randn()\nval output = module.forward(input)  input\n(1,.,.) =\n2.0502799   -0.37522468\n-1.2704345  -0.22533786\n\n(2,.,.) =\n1.1959263   1.6670992\n-0.24333914 1.4424673\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2]  output\n(1,.,.) =\n(1,.,.) =\n2.0502799   0.8\n0.8 0.8\n\n(2,.,.) =\n1.1959263   1.6670992\n0.8 1.4424673\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Threshold(1.0, 0.8)\ninput = np.random.randn(2, 2, 2)\noutput = module.forward(input)  input\n[[[-0.43226865 -1.09160093]\n  [-0.20280088  0.68196767]]\n\n [[ 2.32017942  1.00003307]\n  [-0.46618767  0.57057167]]]  output\n[array([[[ 0.80000001,  0.80000001],\n        [ 0.80000001,  0.80000001]],\n\n       [[ 2.32017946,  1.00003302],\n        [ 0.80000001,  0.80000001]]], dtype=float32)]", 
            "title": "Threshold"
        }, 
        {
            "location": "/APIGuide/Layers/Activations/#hardsigmoid", 
            "text": "Scala:  val module = HardSigmoid()  Python:  module = HardSigmoid()  Activate each element as below             \u23a7  0, if x   -2.5\n    f(x) = \u23a8  1, if x   2.5\n           \u23a9  0.2 * x + 0.5, otherwise  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = HardSigmoid()\nval input = Tensor(2, 2).randn()\nval output = module.forward(input)  input\n-1.7260494  -0.17521624 \n-1.6705151  0.013930867 \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]  output\n0.15479012  0.46495676  \n0.16589698  0.50278616  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = HardSigmoid()\ninput = np.random.randn(2, 2)\noutput = module.forward(input)  input\narray([[-1.45094354, -1.78217815],\n       [ 0.84914007,  0.7104982 ]])  output\narray([[ 0.20981129,  0.14356437],\n       [ 0.669828  ,  0.64209962]], dtype=float32)", 
            "title": "HardSigmoid"
        }, 
        {
            "location": "/APIGuide/Layers/Activations/#srelu", 
            "text": "S-shaped Rectified Linear Unit based on paper  Deep Learning with S-shaped Rectified Linear Activation Units .       \u23a7 t^r + a^r(x - t^r) if x  = t^r\n y = \u23a8 x                  if t^r   x   t^l\n     \u23a9 t^l + a^l(x - t^l) if x  = t^l  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval input = Tensor[Float](2, 3, 4).rand()\nval gradOutput = Tensor[Float](2, 3, 4).rand()\nval srelu = SReLU[Float]([3, 4])\nval output = srelu.forward(input)\nval gradInput = srelu.backward(input, gradOutput)\n\nprintln(input)\nprintln(gradInput)  The input is,  (1,.,.) =\n0.4835907       0.53359604      0.37766683      0.32341897\n0.96768993      0.78638965      0.6921552       0.49003857\n0.10896994      0.22801183      0.9023593       0.43514457\n\n(2,.,.) =\n0.6720485       0.5893981       0.45753896      0.28696498\n0.16126601      0.75192916      0.79481035      0.24795102\n0.7665252       0.775531        0.74594253      0.23907393  The output is,  srelu: com.intel.analytics.bigdl.nn.SReLU[Float] = SReLU[71e3de13]\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =                   \n0.4835907       0.53359604      0.37766683      0.32341897\n0.96768993      0.78638965      0.6921552       0.49003857\n0.10896994      0.22801183      0.9023593       0.43514457\n\n(2,.,.) =                                                                    \n0.6720485       0.5893981       0.45753896      0.28696498\n0.16126601      0.75192916      0.79481035      0.24795102\n0.7665252       0.775531        0.74594253      0.23907393  The python code is,  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = SReLU([3, 4])\ninput = np.random.randn(2, 3, 4)\noutput = module.forward(input)\ngradOutput = np.random.randn(2, 3, 4)\ngradInput = module.backward(input, gradOutput)\nprint output\nprint gradInput", 
            "title": "SReLU"
        }, 
        {
            "location": "/APIGuide/Layers/Embedding-Layers/", 
            "text": "LookupTable\n\n\nScala:\n\n\nval layer = LookupTable(nIndex: Int, nOutput: Int, paddingValue: Double = 0,\n                                 maxNorm: Double = Double.MaxValue,\n                                 normType: Double = 2.0,\n                                 shouldScaleGradByFreq: Boolean = false,\n                                 wRegularizer: Regularizer[T] = null)\n\n\n\n\nPython:\n\n\nlayer = LookupTable(nIndex, nOutput, paddingValue, maxNorm, normType, shouldScaleGradByFreq)\n\n\n\n\nThis layer is a particular case of a convolution, where the width of the convolution would be 1.\nInput should be a 1D or 2D tensor filled with indices. Indices are corresponding to the position\nin weight. For each index element of input, it outputs the selected index part of weight.\nThis layer is often used in word embedding. In collaborative filtering, it can be used together with Select to create embeddings for users or items. \n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval layer = LookupTable(9, 4, 2, 0.1, 2.0, true)\nval input = Tensor(Storage(Array(5.0f, 2.0f, 6.0f, 9.0f, 4.0f)), 1, Array(5))\n\nval output = layer.forward(input)\nval gradInput = layer.backward(input, output)\n\n\n println(layer.weight)\nres6: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.2949163      -0.8240777      -0.9440595      -0.8326071\n-0.025108865    -0.025346711    0.09046136      -0.023320194\n-1.7525806      0.7305201       0.3349018       0.03952092\n-0.0048129847   0.023922665     0.005595926     -0.09681542\n-0.01619357     -0.030372608    0.07217587      -0.060049288\n0.014426847     -0.09052222     0.019132217     -0.035093457\n-0.7002858      1.1149521       0.9869375       1.2580993\n0.36649692      -0.6583153      0.90005803      0.12671651\n0.048913725     0.033388995     -0.07938445     0.01381052\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 9x4]\n\n\n println(input)\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n5.0\n2.0\n6.0\n9.0\n4.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n\n\n println(output)\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.01619357     -0.030372608    0.07217587      -0.060049288\n-0.025108865    -0.025346711    0.09046136      -0.023320194\n0.014426847     -0.09052222     0.019132217     -0.035093457\n0.048913725     0.033388995     -0.07938445     0.01381052\n-0.0048129847   0.023922665     0.005595926     -0.09681542\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5x4]\n\n\n println(gradInput)\ngradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.0\n0.0\n0.0\n0.0\n0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n\n\n\n\n\nPython example:\n\n\nlayer = LookupTable(9, 4, 2.0, 0.1, 2.0, True)\ninput = np.array([5.0, 2.0, 6.0, 9.0, 4.0]).astype(\nfloat32\n)\n\noutput = layer.forward(input)\ngradInput = layer.backward(input, output)\n\n\n output\n[array([[-0.00704637,  0.07495038,  0.06465427,  0.01235369],\n        [ 0.00350313,  0.02751033, -0.02163727,  0.0936095 ],\n        [ 0.02330465, -0.05696457,  0.0081728 ,  0.07839092],\n        [ 0.06580321, -0.0743262 , -0.00414508, -0.01133001],\n        [-0.00382435, -0.04677011,  0.02839171, -0.08361723]], dtype=float32)]\n\n\n gradInput\n[array([ 0.,  0.,  0.,  0.,  0.], dtype=float32)]\n\n\n\n\n\n\n\nLookupTableSparse\n\n\nScala:\n\n\nval layer = LookupTableSparse(nIndex: Int, nOutput: Int,\n    combiner: String = \nsum\n,\n    maxNorm: Double = -1,\n    wRegularizer: Regularizer[T] = null)\n\n\n\n\nPython:\n\n\nlayer = LookupTableSparse(nIndex, nOutput,\n    combiner,\n    maxNorm,\n    wRegularizer)\n\n\n\n\nLookupTable for multi-values. \nAlso called embedding_lookup_sparse in TensorFlow. \n\n\nThe input of LookupTableSparse should be a 2D SparseTensor or two 2D SparseTensors. If the input is a SparseTensor, the values are positive integer ids, values in each row of this SparseTensor will be turned into a dense vector. If the input is two SparseTensor, the first tensor should be the integer ids, just like the SparseTensor input. And the second tensor is the corresponding weights of the integer ids.\n\n\n@param nIndex Indices of input row\n@param nOutput the last dimension size of output\n@param combiner A string specifying the reduce type. Currently \"mean\", \"sum\", \"sqrtn\" is supported.\n@param maxNorm If provided, each embedding is normalized to have l2 norm equal to maxNorm before combining.\n@param wRegularizer: instance of \n[Regularizer]\n, applied to the input weights matrices.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.T\n\nval indices1 = Array(0, 0, 1, 2)\nval indices2 = Array(0, 1, 0, 3)\nval values = Array(2f, 4, 1, 2)\nval weightValues = Array(2f, 0.5f, 1, 3)\nval input = Tensor.sparse(Array(indices1, indices2), values, Array(3, 4))\nval weight = Tensor.sparse(Array(indices1, indices2), weightValues, Array(3, 4))\n\nval layer1 = LookupTableSparse(10, 4, \nmean\n)\nlayer1.weight.range(1, 40, 1) // set weight to 1 to 40\nval output = layer1.forward(T(input, weight))\n\n\n\n\nThe output is\n\n\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n6.6 7.6000004   8.6 9.6\n1.0 2.0 3.0 4.0\n5.0 6.0 7.0 8.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nindices = np.array([[0, 0, 1, 2], [0, 1, 0, 3]])\nvalues = np.array([2, 4, 1, 2])\nweightValues = np.array([2, 0.5, 1, 3])\ninput = JTensor.sparse(values, indices, np.array([3, 4]))\nweight = JTensor.sparse(weightValues, indices, np.array([3, 4]))\n\nlayer1 = LookupTableSparse(10, 4, \nmean\n)\nlayer1.set_weights(np.arange(1, 41, 1).reshape(10, 4)) # set weight to 1 to 40\noutput = layer1.forward([input, weight])\nprint(output)\n\n\n\n\nThe output is\n\n\narray([[ 6.5999999 ,  7.60000038,  8.60000038,  9.60000038],\n       [ 1.        ,  2.        ,  3.        ,  4.        ],\n       [ 5.        ,  6.        ,  7.        ,  8.        ]], dtype=float32)", 
            "title": "Embedding Layers"
        }, 
        {
            "location": "/APIGuide/Layers/Embedding-Layers/#lookuptable", 
            "text": "Scala:  val layer = LookupTable(nIndex: Int, nOutput: Int, paddingValue: Double = 0,\n                                 maxNorm: Double = Double.MaxValue,\n                                 normType: Double = 2.0,\n                                 shouldScaleGradByFreq: Boolean = false,\n                                 wRegularizer: Regularizer[T] = null)  Python:  layer = LookupTable(nIndex, nOutput, paddingValue, maxNorm, normType, shouldScaleGradByFreq)  This layer is a particular case of a convolution, where the width of the convolution would be 1.\nInput should be a 1D or 2D tensor filled with indices. Indices are corresponding to the position\nin weight. For each index element of input, it outputs the selected index part of weight.\nThis layer is often used in word embedding. In collaborative filtering, it can be used together with Select to create embeddings for users or items.   Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval layer = LookupTable(9, 4, 2, 0.1, 2.0, true)\nval input = Tensor(Storage(Array(5.0f, 2.0f, 6.0f, 9.0f, 4.0f)), 1, Array(5))\n\nval output = layer.forward(input)\nval gradInput = layer.backward(input, output)  println(layer.weight)\nres6: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.2949163      -0.8240777      -0.9440595      -0.8326071\n-0.025108865    -0.025346711    0.09046136      -0.023320194\n-1.7525806      0.7305201       0.3349018       0.03952092\n-0.0048129847   0.023922665     0.005595926     -0.09681542\n-0.01619357     -0.030372608    0.07217587      -0.060049288\n0.014426847     -0.09052222     0.019132217     -0.035093457\n-0.7002858      1.1149521       0.9869375       1.2580993\n0.36649692      -0.6583153      0.90005803      0.12671651\n0.048913725     0.033388995     -0.07938445     0.01381052\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 9x4]  println(input)\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n5.0\n2.0\n6.0\n9.0\n4.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5]  println(output)\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.01619357     -0.030372608    0.07217587      -0.060049288\n-0.025108865    -0.025346711    0.09046136      -0.023320194\n0.014426847     -0.09052222     0.019132217     -0.035093457\n0.048913725     0.033388995     -0.07938445     0.01381052\n-0.0048129847   0.023922665     0.005595926     -0.09681542\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5x4]  println(gradInput)\ngradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.0\n0.0\n0.0\n0.0\n0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5]  Python example:  layer = LookupTable(9, 4, 2.0, 0.1, 2.0, True)\ninput = np.array([5.0, 2.0, 6.0, 9.0, 4.0]).astype( float32 )\n\noutput = layer.forward(input)\ngradInput = layer.backward(input, output)  output\n[array([[-0.00704637,  0.07495038,  0.06465427,  0.01235369],\n        [ 0.00350313,  0.02751033, -0.02163727,  0.0936095 ],\n        [ 0.02330465, -0.05696457,  0.0081728 ,  0.07839092],\n        [ 0.06580321, -0.0743262 , -0.00414508, -0.01133001],\n        [-0.00382435, -0.04677011,  0.02839171, -0.08361723]], dtype=float32)]  gradInput\n[array([ 0.,  0.,  0.,  0.,  0.], dtype=float32)]", 
            "title": "LookupTable"
        }, 
        {
            "location": "/APIGuide/Layers/Embedding-Layers/#lookuptablesparse", 
            "text": "Scala:  val layer = LookupTableSparse(nIndex: Int, nOutput: Int,\n    combiner: String =  sum ,\n    maxNorm: Double = -1,\n    wRegularizer: Regularizer[T] = null)  Python:  layer = LookupTableSparse(nIndex, nOutput,\n    combiner,\n    maxNorm,\n    wRegularizer)  LookupTable for multi-values. \nAlso called embedding_lookup_sparse in TensorFlow.   The input of LookupTableSparse should be a 2D SparseTensor or two 2D SparseTensors. If the input is a SparseTensor, the values are positive integer ids, values in each row of this SparseTensor will be turned into a dense vector. If the input is two SparseTensor, the first tensor should be the integer ids, just like the SparseTensor input. And the second tensor is the corresponding weights of the integer ids.  @param nIndex Indices of input row\n@param nOutput the last dimension size of output\n@param combiner A string specifying the reduce type. Currently \"mean\", \"sum\", \"sqrtn\" is supported.\n@param maxNorm If provided, each embedding is normalized to have l2 norm equal to maxNorm before combining.\n@param wRegularizer: instance of  [Regularizer] , applied to the input weights matrices.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.T\n\nval indices1 = Array(0, 0, 1, 2)\nval indices2 = Array(0, 1, 0, 3)\nval values = Array(2f, 4, 1, 2)\nval weightValues = Array(2f, 0.5f, 1, 3)\nval input = Tensor.sparse(Array(indices1, indices2), values, Array(3, 4))\nval weight = Tensor.sparse(Array(indices1, indices2), weightValues, Array(3, 4))\n\nval layer1 = LookupTableSparse(10, 4,  mean )\nlayer1.weight.range(1, 40, 1) // set weight to 1 to 40\nval output = layer1.forward(T(input, weight))  The output is  output: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n6.6 7.6000004   8.6 9.6\n1.0 2.0 3.0 4.0\n5.0 6.0 7.0 8.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nindices = np.array([[0, 0, 1, 2], [0, 1, 0, 3]])\nvalues = np.array([2, 4, 1, 2])\nweightValues = np.array([2, 0.5, 1, 3])\ninput = JTensor.sparse(values, indices, np.array([3, 4]))\nweight = JTensor.sparse(weightValues, indices, np.array([3, 4]))\n\nlayer1 = LookupTableSparse(10, 4,  mean )\nlayer1.set_weights(np.arange(1, 41, 1).reshape(10, 4)) # set weight to 1 to 40\noutput = layer1.forward([input, weight])\nprint(output)  The output is  array([[ 6.5999999 ,  7.60000038,  8.60000038,  9.60000038],\n       [ 1.        ,  2.        ,  3.        ,  4.        ],\n       [ 5.        ,  6.        ,  7.        ,  8.        ]], dtype=float32)", 
            "title": "LookupTableSparse"
        }, 
        {
            "location": "/APIGuide/Layers/MergeSplit-Layers/", 
            "text": "Pack\n\n\nScala:\n\n\nval module = Pack(dim)\n\n\n\n\nPython:\n\n\nmodule = Pack(dim)\n\n\n\n\nPack is used to stack a list of n-dimensional tensors into one (n+1)-dimensional tensor.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = Pack(2)\nval input1 = Tensor(2, 2).randn()\nval input2 = Tensor(2, 2).randn()\nval input = T()\ninput(1) = input1\ninput(2) = input2\n\nval output = module.forward(input)\n\n\n input\n {\n    2: -0.8737048   -0.7337217\n       0.7268678    -0.53470045\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n    1: -1.3062215   -0.58756566\n       0.8921608    -1.8087773\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n }\n\n\n\n output\n(1,.,.) =\n-1.3062215  -0.58756566\n-0.8737048  -0.7337217\n\n(2,.,.) =\n0.8921608   -1.8087773\n0.7268678   -0.53470045\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Pack(2)\ninput1 = np.random.randn(2, 2)\ninput2 = np.random.randn(2, 2)\ninput = [input1, input2]\noutput = module.forward(input)\n\n\n input\n[array([[ 0.92741416, -3.29826586],\n       [-0.03147819, -0.10049306]]), array([[-0.27146461, -0.25729802],\n       [ 0.1316149 ,  1.27620145]])]\n\n\n output\narray([[[ 0.92741418, -3.29826593],\n        [-0.27146462, -0.25729802]],\n\n       [[-0.03147819, -0.10049306],\n        [ 0.13161489,  1.27620149]]], dtype=float32)\n\n\n\n\n\n\nMM\n\n\nScala:\n\n\nval m = MM(transA=false,transB=false)\n\n\n\n\nPython:\n\n\nm = MM(trans_a=False,trans_b=False)\n\n\n\n\nMM is a module that performs matrix multiplication on two mini-batch inputs, producing one mini-batch.\n\n\nScala example:\n\n\nscala\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.T\n\nval input = T(1 -\n Tensor(3, 3).randn(), 2 -\n Tensor(3, 3).randn())\nval m1 = MM()\nval output1 = m1.forward(input)\nval m2 = MM(true,true)\nval output2 = m2.forward(input)\n\nscala\n print(input)\n {\n        2: -0.62020904  -0.18690863     0.34132162\n           -0.5359324   -0.09937895     0.86147165\n           -2.6607985   -1.426654       2.3428898\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n        1: -1.3087689   0.048720464     0.69583243\n           -0.52055264  -1.5275089      -1.1569321\n           0.28093573   -0.29353273     -0.9505267\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n }\n\nscala\n print(output1)\n-1.0658705      -0.7529337      1.225519\n4.2198563       1.8996398       -4.204146\n2.512235        1.3327343       -2.38396\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nscala\n print(output2)\n1.0048954       0.99516183      4.8832207\n0.15509865      -0.12717877     1.3618765\n-0.5397563      -1.0767963      -2.4279075\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\ninput1=np.random.rand(3,3)\ninput2=np.random.rand(3,3)\ninput = [input1,input2]\nprint \ninput is :\n,input\nout = MM().forward(input)\nprint \noutput is :\n,out\n\n\n\n\nproduces output:\n\n\ninput is : [array([[ 0.13696046,  0.92653165,  0.73585328],\n       [ 0.28167852,  0.06431783,  0.15710073],\n       [ 0.21896166,  0.00780161,  0.25780671]]), array([[ 0.11232797,  0.17023931,  0.92430042],\n       [ 0.86629537,  0.07630215,  0.08584417],\n       [ 0.47087278,  0.22992833,  0.59257503]])]\ncreating: createMM\noutput is : [array([[ 1.16452789,  0.26320592,  0.64217824],\n       [ 0.16133308,  0.08898225,  0.35897085],\n       [ 0.15274818,  0.09714822,  0.3558259 ]], dtype=float32)]\n\n\n\n\nCMaxTable\n\n\nScala:\n\n\nval m = CMaxTable()\n\n\n\n\nPython:\n\n\nm = CMaxTable()\n\n\n\n\nCMaxTable is a module that takes a table of Tensors and outputs the max of all of them.\n\n\nScala example:\n\n\n\nscala\n \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.T\n\nval input1 = Tensor(3).randn()\nval input2 =  Tensor(3).randn()\nval input = T(input1, input2)\nval m = CMaxTable()\nval output = m.forward(input)\nval gradOut = Tensor(3).randn()\nval gradIn = m.backward(input,gradOut)\n\nscala\n print(input)\n {\n        2: -0.38613814\n           0.74074316\n           -1.753783\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n        1: -1.6037064\n           -2.3297918\n           -0.7160026\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n }\n\nscala\n print(output)\n-0.38613814\n0.74074316\n-0.7160026\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n\nscala\n print(gradOut)\n-1.4526331\n0.7070323\n0.29294914\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n\nscala\n print(gradIn)\n {\n        2: -1.4526331\n           0.7070323\n           0.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n        1: 0.0\n           0.0\n           0.29294914\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n }\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\ninput1 = np.random.rand(3)\ninput2 = np.random.rand(3)\nprint \ninput is :\n,input1,input2\n\nm = CMaxTable()\nout = m.forward([input1,input2])\nprint \noutput of m is :\n,out\n\ngrad_out = np.random.rand(3)\ngrad_in = m.backward([input1, input2],grad_out)\nprint \ngrad input of m is :\n,grad_in\n\n\n\n\nGives the output,\n\n\ninput is : [ 0.48649797  0.22131348  0.45667796] [ 0.73207053  0.74290136  0.03169769]\ncreating: createCMaxTable\noutput of m is : [array([ 0.73207051,  0.74290138,  0.45667794], dtype=float32)]\ngrad input of m is : [array([ 0.        ,  0.        ,  0.86938971], dtype=float32), array([ 0.04140199,  0.4787094 ,  0.        ], dtype=float32)]\n\n\n\n\n\n\nSplitTable\n\n\nScala:\n\n\nval layer = SplitTable(dim)\n\n\n\n\nPython:\n\n\nlayer = SplitTable(dim)\n\n\n\n\nSplitTable takes a Tensor as input and outputs several tables,\nsplitting the Tensor along the specified dimension \ndimension\n. Please note\nthe dimension starts from 1.\n\n\nThe input to this layer is expected to be a tensor, or a batch of tensors;\nwhen using mini-batch, a batch of sample tensors will be passed to the layer and\nthe user needs to specify the number of dimensions of each sample tensor in a\nbatch using \nnInputDims\n.\n\n\n    +----------+         +-----------+\n    | input[1] +---------\n {member1, |\n  +----------+-+         |           |\n  | input[2] +-----------\n  member2, |\n+----------+-+           |           |\n| input[3] +-------------\n  member3} |\n+----------+             +-----------+\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = SplitTable(2)\nlayer.forward(Tensor(T(\n  T(1.0f, 2.0f, 3.0f),\n  T(4.0f, 5.0f, 6.0f),\n  T(7.0f, 8.0f, 9.0f)\n)))\nlayer.backward(Tensor(T(\n  T(1.0f, 2.0f, 3.0f),\n  T(4.0f, 5.0f, 6.0f),\n  T(7.0f, 8.0f, 9.0f)\n)), T(\n  Tensor(T(0.1f, 0.2f, 0.3f)),\n  Tensor(T(0.4f, 0.5f, 0.6f)),\n  Tensor(T(0.7f, 0.8f, 0.9f))\n))\n\n\n\n\nGives the output,\n\n\n {\n        2: 2.0\n           5.0\n           8.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n        1: 1.0\n           4.0\n           7.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n        3: 3.0\n           6.0\n           9.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n }\n\n0.1     0.4     0.7\n0.2     0.5     0.8\n0.3     0.6     0.9\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import SplitTable\nimport numpy as np\n\nlayer = SplitTable(2)\nlayer.forward(np.array([\n  [1.0, 2.0, 3.0],\n  [4.0, 5.0, 6.0],\n  [7.0, 8.0, 9.0]\n]))\n\nlayer.backward(np.array([\n  [1.0, 2.0, 3.0],\n  [4.0, 5.0, 6.0],\n  [7.0, 8.0, 9.0]\n]), [\n  np.array([0.1, 0.2, 0.3]),\n  np.array([0.4, 0.5, 0.6]),\n  np.array([0.7, 0.8, 0.9])\n])\n\n\n\n\nGives the output,\n\n\n[\n  array([ 1.,  4.,  7.], dtype=float32),\n  array([ 2.,  5.,  8.], dtype=float32),\n  array([ 3.,  6.,  9.], dtype=float32)\n]\n\narray([[ 0.1       ,  0.40000001,  0.69999999],\n       [ 0.2       ,  0.5       ,  0.80000001],\n       [ 0.30000001,  0.60000002,  0.89999998]], dtype=float32)\n\n\n\n\n\n\nDotProduct\n\n\nScala:\n\n\nval m = DotProduct()\n\n\n\n\nPython:\n\n\nm = DotProduct()\n\n\n\n\nOutputs the dot product (similarity) between inputs\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.{T, Table}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval mlp = DotProduct()\nval x = Tensor(3).fill(1f)\nval y = Tensor(3).fill(2f)\nprintln(\ninput:\n)\nprintln(x)\nprintln(y)\nprintln(\noutput:\n)\nprintln(mlp.forward(T(x, y)))\n\n\n\n\ninput:\n1.0\n1.0\n1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n2.0\n2.0\n2.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\noutput:\n6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1]\n\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.layer import *\n\nmlp = DotProduct()\nx = np.array([1, 1, 1])\ny = np.array([2, 2, 2])\nprint(\ninput:\n)\nprint(x)\nprint(y)\nprint(\noutput:\n)\nprint(mlp.forward([x, y]))\n\n\n\n\n\ncreating: createDotProduct\ninput:\n[1 1 1]\n[2 2 2]\noutput:\n[ 6.]\n\n\n\n\n\n\nCSubTable\n\n\nScala:\n\n\nval model = CSubTable()\n\n\n\n\nPython:\n\n\nmodel = CSubTable()\n\n\n\n\nTakes a sequence with two Tensor and returns the component-wise subtraction between them.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\n\nval model = CSubTable()\nval input1 = Tensor(5).rand()\nval input2 = Tensor(5).rand()\nval input = T(input1, input2)\nval output = model.forward(input)\n\nscala\n print(input)\n {\n    2: 0.29122078\n       0.17347474\n       0.14127742\n       0.2249051\n       0.12171601\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n    1: 0.6202152\n       0.70417005\n       0.21334995\n       0.05191216\n       0.4209623\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n\nscala\n print(output)\n0.3289944\n0.5306953\n0.072072536\n-0.17299294\n0.2992463\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n\n\n\n\nPython example:\n\n\nmodel = CSubTable()\ninput1 = np.random.randn(5)\ninput2 = np.random.randn(5)\ninput = [input1, input2]\noutput = model.forward(input)\n\n\n\n\nGives the output,\n\n\narray([-1.15087152,  0.6169951 ,  2.41840839,  1.34374809,  1.39436531], dtype=float32)\n\n\n\n\n\n\nCDivTable\n\n\nScala:\n\n\nval module = CDivTable()\n\n\n\n\nPython:\n\n\nmodule = CDivTable()\n\n\n\n\nTakes a table with two Tensor and returns the component-wise division between them.\n\n\nScala example:\n\n\nval module = CDivTable()\nval input = T(1 -\n Tensor(2,3).rand(), 2 -\n Tensor(2,3).rand())\ninput: com.intel.analytics.bigdl.utils.Table =\n {\n        2: 0.802295     0.7113872       0.29395157\n           0.6562403    0.06519115      0.20099664\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n        1: 0.7435388    0.59126955      0.10225375\n           0.46819785   0.10572237      0.9861797\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n }\n\nmodule.forward(input)\nres6: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.9267648       0.8311501       0.34785917\n0.7134549       1.6217289       4.906449\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nmodule = CDivTable()\ninput = [np.array([[1, 2, 3],[4, 5, 6]]), np.array([[1, 4, 9],[6, 10, 3]])]\nmodule.forward(input)\n[array([\n[ 1.,                   0.5     ,    0.33333334],\n[ 0.66666669, 0.5       ,  2.        ]], dtype=float32)]\n\n\n\n\n\n\nJoinTable\n\n\nScala:\n\n\nval layer = JoinTable(dimension, nInputDims)\n\n\n\n\nPython:\n\n\nlayer = JoinTable(dimension, n_input_dims)\n\n\n\n\nIt is a table module which takes a table of Tensors as input and\noutputs a Tensor by joining them together along the dimension \ndimension\n.\n\n\nThe input to this layer is expected to be a tensor, or a batch of tensors;\nwhen using mini-batch, a batch of sample tensors will be passed to the layer and\nthe user need to specify the number of dimensions of each sample tensor in the\nbatch using \nnInputDims\n.\n\n\nParameters:\n\n \ndimension\n  to be join in this dimension\n\n \nnInputDims\n specify the number of dimensions that this module will receiveIf it is more than the dimension of input tensors, the first dimension would be considered as batch size\n\n\n+----------+             +-----------+\n| {input1, +-------------\n output[1] |\n|          |           +-----------+-+\n|  input2, +-----------\n output[2] |\n|          |         +-----------+-+\n|  input3} +---------\n output[3] |\n+----------+         +-----------+\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.JoinTable\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval layer = JoinTable(2, 2)\nval input1 = Tensor(T(\n  T(\n    T(1f, 2f, 3f),\n    T(2f, 3f, 4f),\n    T(3f, 4f, 5f))\n))\n\nval input2 = Tensor(T(\n  T(\n    T(3f, 4f, 5f),\n    T(2f, 3f, 4f),\n    T(1f, 2f, 3f))\n))\n\nval input = T(input1, input2)\n\nval gradOutput = Tensor(T(\n  T(\n    T(1f, 2f, 3f, 3f, 4f, 5f),\n    T(2f, 3f, 4f, 2f, 3f, 4f),\n    T(3f, 4f, 5f, 1f, 2f, 3f)\n)))\n\nval output = layer.forward(input)\nval grad = layer.backward(input, gradOutput)\n\nprintln(output)\n(1,.,.) =\n1.0 2.0 3.0 3.0 4.0 5.0\n2.0 3.0 4.0 2.0 3.0 4.0\n3.0 4.0 5.0 1.0 2.0 3.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x6]\n\nprintln(grad)\n {\n    2: (1,.,.) =\n       3.0  4.0 5.0\n       2.0  3.0 4.0\n       1.0  2.0 3.0\n\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x3]\n    1: (1,.,.) =\n       1.0  2.0 3.0\n       2.0  3.0 4.0\n       3.0  4.0 5.0\n\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x3]\n }\n\n\n\n\nPython example:\n\n\nlayer = JoinTable(2, 2)\ninput1 = np.array([\n [\n    [1.0, 2.0, 3.0],\n    [2.0, 3.0, 4.0],\n    [3.0, 4.0, 5.0]\n  ]\n])\n\ninput2 = np.array([\n  [\n    [3.0, 4.0, 5.0],\n    [2.0, 3.0, 4.0],\n    [1.0, 2.0, 3.0]\n  ]\n])\n\ninput = [input1, input2]\n\ngradOutput = np.array([\n  [\n    [1.0, 2.0, 3.0, 3.0, 4.0, 5.0],\n    [2.0, 3.0, 4.0, 2.0, 3.0, 4.0],\n    [3.0, 4.0, 5.0, 1.0, 2.0, 3.0]\n  ]\n])\n\noutput = layer.forward(input)\ngrad = layer.backward(input, gradOutput)\n\nprint output\n[[[ 1.  2.  3.  3.  4.  5.]\n  [ 2.  3.  4.  2.  3.  4.]\n  [ 3.  4.  5.  1.  2.  3.]]]\n\nprint grad\n[array([[[ 1.,  2.,  3.],\n        [ 2.,  3.,  4.],\n        [ 3.,  4.,  5.]]], dtype=float32), array([[[ 3.,  4.,  5.],\n        [ 2.,  3.,  4.],\n        [ 1.,  2.,  3.]]], dtype=float32)]\n\n\n\n\n\n\nSelectTable\n\n\nScala:\n\n\nval m = SelectTable(index: Int)\n\n\n\n\nPython:\n\n\nm = SelectTable(dimension)\n\n\n\n\nSelect one element from a table by a given index.\nIn Scala API, table is kind of like HashMap with one-base index as the key.\nIn python, table is a just a list.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.{T, Table}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval input = T(Tensor(2,3).randn(), Tensor(2,3).randn())\n\nprintln(\ninput: \n)\nprintln(input)\nprintln(\noutput:\n)\nprintln(SelectTable(1).forward(input)) // Select and output the first element of the input which shape is (2, 3)\nprintln(SelectTable(2).forward(input)) // Select and output the second element of the input which shape is (2, 3)\n\n\n\n\n\ninput: \n {\n    2: 2.005436370849835    0.09670211785545313 1.186779895312918   \n       2.238415300857082    0.241626512721254   0.15765709974113828 \n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    1: 0.5668905654052705   -1.3205159007397167 -0.5431464848526197 \n       -0.11582559521074104 0.7671830693813515  -0.39992781407893574    \n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n }\noutput:\n0.5668905654052705  -1.3205159007397167 -0.5431464848526197 \n-0.11582559521074104    0.7671830693813515  -0.39992781407893574    \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n2.005436370849835   0.09670211785545313 1.186779895312918   \n2.238415300857082   0.241626512721254   0.15765709974113828 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.layer import *\n\ninput = [np.random.random((2,3)), np.random.random((2, 1))]\nprint(\ninput:\n)\nprint(input)\nprint(\noutput:\n)\nprint(SelectTable(1).forward(input)) # Select and output the first element of the input which shape is (2, 3)\n\n\n\n\ninput:\n[array([[ 0.07185111,  0.26140439,  0.9437582 ],\n       [ 0.50278191,  0.83923974,  0.06396735]]), array([[ 0.84955122],\n       [ 0.16053703]])]\noutput:\ncreating: createSelectTable\n[[ 0.07185111  0.2614044   0.94375819]\n [ 0.50278193  0.83923972  0.06396735]]\n\n\n\n\n\n\n\nNarrowTable\n\n\nScala:\n\n\nval narrowTable = NarrowTable(offset, length = 1)\n\n\n\n\nPython:\n\n\nnarrowTable = NarrowTable(offset, length = 1)\n\n\n\n\nNarrowTable takes a table as input and returns a subtable starting from index \noffset\n having \nlength\n elements\n\n\nNegative \nlength\n means the last element is located at Abs|length| to the last element of input\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.T\nval narrowTable = NarrowTable(1, 1)\n\nval input = T()\ninput(1.0) = Tensor(2, 2).rand()\ninput(2.0) = Tensor(2, 2).rand()\ninput(3.0) = Tensor(2, 2).rand()\n\n print(input)\n {\n    2.0: 0.27686104 0.9040761   \n         0.75969505 0.8008061   \n         [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n    1.0: 0.94122535 0.46173728  \n         0.43302807 0.1670979   \n         [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n    3.0: 0.43944374 0.49336782  \n         0.7274511  0.67777634  \n         [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n }\n\n  print(narrowTable.forward(input))\n {\n    1: 0.94122535   0.46173728  \n       0.43302807   0.1670979   \n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n }\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nnarrowTable = NarrowTable(1, 1)\n\n narrowTable.forward([np.array([1, 2, 3]), np.array([4, 5, 6])])\n[array([ 1.,  2.,  3.], dtype=float32)]\n\n\n\n\n\n\n\nCAddTable\n\n\nScala:\n\n\nval module = CAddTable(inplace = false)\n\n\n\n\nPython:\n\n\nmodule = CAddTable(inplace=False)\n\n\n\n\nCAddTable merges the input tensors in the input table by element-wise adding. The input table is actually an array of tensor with same size.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval mlp = Sequential()\nmlp.add(ConcatTable().add(Identity()).add(Identity()))\nmlp.add(CAddTable())\n\nprintln(mlp.forward(Tensor.range(1, 3, 1)))\n\n\n\n\nGives the output,\n\n\ncom.intel.analytics.bigdl.nn.abstractnn.Activity =\n2.0\n4.0\n6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmlp = Sequential()\nmlp.add(ConcatTable().add(Identity()).add(Identity()))\nmlp.add(CAddTable())\n\nprint(mlp.forward(np.arange(1, 4, 1)))\n\n\n\n\nGives the output,\n\n\n[array([ 2.,  4.,  6.], dtype=float32)]\n\n\n\n\n\n\nCAveTable\n\n\nScala:\n\n\nval model = CAveTable(inplace=false)\n\n\n\n\nPython:\n\n\nmodel = CAveTable(inplace=False)\n\n\n\n\nCAveTable merges the input tensors in the input table by element-wise taking the average. The input table is actually an array of tensor with same size.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.T\n\nval model = CAveTable()\nval input1 = Tensor(5).rand()\nval input2 = Tensor(5).rand()\nval input = T(input1, input2)\nval output = model.forward(input)\n\n\n\n\nGives the output,\n\n\ninput1: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.6061657\n0.55972266\n0.972365\n0.5624792\n0.7495829\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n\ninput2: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.3897284\n0.82165825\n0.46275142\n0.95935726\n0.64157426\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.49794704\n0.69069046\n0.7175582\n0.76091826\n0.6955786\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodel = CAveTable()\ninput1 = np.random.rand(5)\ninput2 = np.random.rand(5)\ninput = [input1, input2]\noutput = model.forward(input)\n\nprint(input1)\nprint(input2)\nprint(output)\n\n\n\n\nGives the output,\n\n\n[array([ 0.26202468  0.15868397  0.27812652  0.45931689  0.32100054], dtype=float32)]\n[array([ 0.51839282  0.26194293  0.97608528  0.73281455  0.11527423], dtype=float32)]\n[array([ 0.39020872  0.21031344  0.62710589  0.5960657   0.21813738], dtype=float32)]\n\n\n\n\n\n\nCMulTable\n\n\nScala:\n\n\nval model = CMulTable()\n\n\n\n\nPython:\n\n\nmodel = CMulTable()\n\n\n\n\nTakes a sequence of Tensors and outputs the multiplication of all of them.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\n\nval model = CMulTable()\nval input1 = Tensor(5).rand()\nval input2 = Tensor(5).rand()\nval input = T(input1, input2)\nval output = model.forward(input)\n\nscala\n print(input)\n {\n    2: 0.13224044\n       0.5460452\n       0.33032498\n       0.6317603\n       0.6665052\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n    1: 0.28694472\n       0.45169437\n       0.36891535\n       0.9126049\n       0.41318864\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n }\n\nscala\n print(output)\n0.037945695\n0.24664554\n0.12186196\n0.57654756\n0.27539238\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n\n\n\n\nPython example:\n\n\nmodel = CMulTable()\ninput1 = np.random.randn(5)\ninput2 = np.random.randn(5)\ninput = [input1, input2]\noutput = model.forward(input)\n\n\n print(input)\n[array([ 0.28183274, -0.6477487 , -0.21279841,  0.22725124,  0.54748552]), array([-0.78673028, -1.08337196, -0.62710066,  0.37332587, -1.40708162])]\n\n\n print(output)\n[-0.22172636  0.70175284  0.13344601  0.08483877 -0.77035683]\n\n\n\n\n\n\nMV\n\n\nScala:\n\n\nval module = MV(trans = false)\n\n\n\n\nPython:\n\n\nmodule = MV(trans=False)\n\n\n\n\nIt is a module to perform matrix vector multiplication on two mini-batch inputs, producing a mini-batch.\n\n\ntrans\n means whether make matrix transpose before multiplication.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.T\n\nval module = MV()\n\nprintln(module.forward(T(Tensor.range(1, 12, 1).resize(2, 2, 3), Tensor.range(1, 6, 1).resize(2, 3))))\n\n\n\n\nGives the output,\n\n\ncom.intel.analytics.bigdl.tensor.Tensor[Float] =\n14.0    32.0\n122.0   167.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nmodule = MV()\n\nprint(module.forward([np.arange(1, 13, 1).reshape(2, 2, 3), np.arange(1, 7, 1).reshape(2, 3)]))\n\n\n\n\nGives the output,\n\n\n[array([ 0.31657887, -1.11062765, -1.16235781, -0.67723978,  0.74650359], dtype=float32)]\n\n\n\n\n\n\nFlattenTable\n\n\nScala:\n\n\nval module = FlattenTable()\n\n\n\n\nPython:\n\n\nmodule = FlattenTable()\n\n\n\n\nFlattenTable takes an arbitrarily deep table of Tensors (potentially nested) as input and a table of Tensors without any nested table will be produced\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = FlattenTable()\nval t1 = Tensor(3).randn()\nval t2 = Tensor(3).randn()\nval t3 = Tensor(3).randn()\nval input = T(t1, T(t2, T(t3)))\n\nval output = module.forward(input)\n\n\n input\n {\n    2:  {\n        2:  {\n            1: 0.5521984\n               -0.4160644\n               -0.698762\n               [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n            }\n        1: -1.7380241\n           0.60336906\n           -0.8751049\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n        }\n    1: 1.0529885\n       -0.792229\n       0.8395628\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n }\n\n\n\n output\n{\n    2: -1.7380241\n       0.60336906\n       -0.8751049\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n    1: 1.0529885\n       -0.792229\n       0.8395628\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n    3: 0.5521984\n       -0.4160644\n       -0.698762\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n }\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Sequential()\n# this will create a nested table\nnested = ConcatTable().add(Identity()).add(Identity())\nmodule.add(nested).add(FlattenTable())\nt1 = np.random.randn(3)\nt2 = np.random.randn(3)\ninput = [t1, t2]\noutput = module.forward(input)\n\n\n input\n[array([-2.21080689, -0.48928043, -0.26122161]), array([-0.8499716 ,  1.63694575, -0.31109292])]\n\n\n output\n[array([-2.21080685, -0.48928043, -0.26122162], dtype=float32),\n array([-0.84997159,  1.63694572, -0.31109291], dtype=float32),\n array([-2.21080685, -0.48928043, -0.26122162], dtype=float32),\n array([-0.84997159,  1.63694572, -0.31109291], dtype=float32)]\n\n\n\n\n\n\n\nCMinTable\n\n\nScala:\n\n\nval layer = CMinTable()\n\n\n\n\nPython:\n\n\nlayer = CMinTable()\n\n\n\n\nCMinTable takes a bunch of tensors as inputs. These tensors must have\nsame shape. This layer will merge them by doing an element-wise comparision\nand use the min value.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = CMinTable()\nlayer.forward(T(\n  Tensor(T(1.0f, 5.0f, 2.0f)),\n  Tensor(T(3.0f, 4.0f, -1.0f)),\n  Tensor(T(5.0f, 7.0f, -5.0f))\n))\nlayer.backward(T(\n  Tensor(T(1.0f, 5.0f, 2.0f)),\n  Tensor(T(3.0f, 4.0f, -1.0f)),\n  Tensor(T(5.0f, 7.0f, -5.0f))\n), Tensor(T(0.1f, 0.2f, 0.3f)))\n\n\n\n\nGives the output,\n\n\n1.0\n4.0\n-5.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n\n{\n  2: 0.0\n     0.2\n     0.0\n     [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n  1: 0.1\n     0.0\n     0.0\n     [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n  3: 0.0\n     0.0\n     0.3\n  [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n}\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import CMinTable\nimport numpy as np\n\nlayer = CMinTable()\nlayer.forward([\n  np.array([1.0, 5.0, 2.0]),\n  np.array([3.0, 4.0, -1.0]),\n  np.array([5.0, 7.0, -5.0])\n])\n\nlayer.backward([\n  np.array([1.0, 5.0, 2.0]),\n  np.array([3.0, 4.0, -1.0]),\n  np.array([5.0, 7.0, -5.0])\n], np.array([0.1, 0.2, 0.3]))\n\n\n\n\n\nGives the output,\n\n\narray([ 1.,  4., -5.], dtype=float32)\n\n[array([ 0.1, 0., 0.], dtype=float32),\narray([ 0., 0.2, 0.], dtype=float32),\narray([ 0., 0., 0.30000001], dtype=float32)]", 
            "title": "Merge/Split Layers"
        }, 
        {
            "location": "/APIGuide/Layers/MergeSplit-Layers/#pack", 
            "text": "Scala:  val module = Pack(dim)  Python:  module = Pack(dim)  Pack is used to stack a list of n-dimensional tensors into one (n+1)-dimensional tensor.  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = Pack(2)\nval input1 = Tensor(2, 2).randn()\nval input2 = Tensor(2, 2).randn()\nval input = T()\ninput(1) = input1\ninput(2) = input2\n\nval output = module.forward(input)  input\n {\n    2: -0.8737048   -0.7337217\n       0.7268678    -0.53470045\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n    1: -1.3062215   -0.58756566\n       0.8921608    -1.8087773\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n }  output\n(1,.,.) =\n-1.3062215  -0.58756566\n-0.8737048  -0.7337217\n\n(2,.,.) =\n0.8921608   -1.8087773\n0.7268678   -0.53470045\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Pack(2)\ninput1 = np.random.randn(2, 2)\ninput2 = np.random.randn(2, 2)\ninput = [input1, input2]\noutput = module.forward(input)  input\n[array([[ 0.92741416, -3.29826586],\n       [-0.03147819, -0.10049306]]), array([[-0.27146461, -0.25729802],\n       [ 0.1316149 ,  1.27620145]])]  output\narray([[[ 0.92741418, -3.29826593],\n        [-0.27146462, -0.25729802]],\n\n       [[-0.03147819, -0.10049306],\n        [ 0.13161489,  1.27620149]]], dtype=float32)", 
            "title": "Pack"
        }, 
        {
            "location": "/APIGuide/Layers/MergeSplit-Layers/#mm", 
            "text": "Scala:  val m = MM(transA=false,transB=false)  Python:  m = MM(trans_a=False,trans_b=False)  MM is a module that performs matrix multiplication on two mini-batch inputs, producing one mini-batch.  Scala example:  scala \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.T\n\nval input = T(1 -  Tensor(3, 3).randn(), 2 -  Tensor(3, 3).randn())\nval m1 = MM()\nval output1 = m1.forward(input)\nval m2 = MM(true,true)\nval output2 = m2.forward(input)\n\nscala  print(input)\n {\n        2: -0.62020904  -0.18690863     0.34132162\n           -0.5359324   -0.09937895     0.86147165\n           -2.6607985   -1.426654       2.3428898\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n        1: -1.3087689   0.048720464     0.69583243\n           -0.52055264  -1.5275089      -1.1569321\n           0.28093573   -0.29353273     -0.9505267\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n }\n\nscala  print(output1)\n-1.0658705      -0.7529337      1.225519\n4.2198563       1.8996398       -4.204146\n2.512235        1.3327343       -2.38396\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nscala  print(output2)\n1.0048954       0.99516183      4.8832207\n0.15509865      -0.12717877     1.3618765\n-0.5397563      -1.0767963      -2.4279075\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]   Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\ninput1=np.random.rand(3,3)\ninput2=np.random.rand(3,3)\ninput = [input1,input2]\nprint  input is : ,input\nout = MM().forward(input)\nprint  output is : ,out  produces output:  input is : [array([[ 0.13696046,  0.92653165,  0.73585328],\n       [ 0.28167852,  0.06431783,  0.15710073],\n       [ 0.21896166,  0.00780161,  0.25780671]]), array([[ 0.11232797,  0.17023931,  0.92430042],\n       [ 0.86629537,  0.07630215,  0.08584417],\n       [ 0.47087278,  0.22992833,  0.59257503]])]\ncreating: createMM\noutput is : [array([[ 1.16452789,  0.26320592,  0.64217824],\n       [ 0.16133308,  0.08898225,  0.35897085],\n       [ 0.15274818,  0.09714822,  0.3558259 ]], dtype=float32)]", 
            "title": "MM"
        }, 
        {
            "location": "/APIGuide/Layers/MergeSplit-Layers/#cmaxtable", 
            "text": "Scala:  val m = CMaxTable()  Python:  m = CMaxTable()  CMaxTable is a module that takes a table of Tensors and outputs the max of all of them.  Scala example:  \nscala  \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.T\n\nval input1 = Tensor(3).randn()\nval input2 =  Tensor(3).randn()\nval input = T(input1, input2)\nval m = CMaxTable()\nval output = m.forward(input)\nval gradOut = Tensor(3).randn()\nval gradIn = m.backward(input,gradOut)\n\nscala  print(input)\n {\n        2: -0.38613814\n           0.74074316\n           -1.753783\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n        1: -1.6037064\n           -2.3297918\n           -0.7160026\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n }\n\nscala  print(output)\n-0.38613814\n0.74074316\n-0.7160026\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n\nscala  print(gradOut)\n-1.4526331\n0.7070323\n0.29294914\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n\nscala  print(gradIn)\n {\n        2: -1.4526331\n           0.7070323\n           0.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n        1: 0.0\n           0.0\n           0.29294914\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n }  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\ninput1 = np.random.rand(3)\ninput2 = np.random.rand(3)\nprint  input is : ,input1,input2\n\nm = CMaxTable()\nout = m.forward([input1,input2])\nprint  output of m is : ,out\n\ngrad_out = np.random.rand(3)\ngrad_in = m.backward([input1, input2],grad_out)\nprint  grad input of m is : ,grad_in  Gives the output,  input is : [ 0.48649797  0.22131348  0.45667796] [ 0.73207053  0.74290136  0.03169769]\ncreating: createCMaxTable\noutput of m is : [array([ 0.73207051,  0.74290138,  0.45667794], dtype=float32)]\ngrad input of m is : [array([ 0.        ,  0.        ,  0.86938971], dtype=float32), array([ 0.04140199,  0.4787094 ,  0.        ], dtype=float32)]", 
            "title": "CMaxTable"
        }, 
        {
            "location": "/APIGuide/Layers/MergeSplit-Layers/#splittable", 
            "text": "Scala:  val layer = SplitTable(dim)  Python:  layer = SplitTable(dim)  SplitTable takes a Tensor as input and outputs several tables,\nsplitting the Tensor along the specified dimension  dimension . Please note\nthe dimension starts from 1.  The input to this layer is expected to be a tensor, or a batch of tensors;\nwhen using mini-batch, a batch of sample tensors will be passed to the layer and\nthe user needs to specify the number of dimensions of each sample tensor in a\nbatch using  nInputDims .      +----------+         +-----------+\n    | input[1] +---------  {member1, |\n  +----------+-+         |           |\n  | input[2] +-----------   member2, |\n+----------+-+           |           |\n| input[3] +-------------   member3} |\n+----------+             +-----------+  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = SplitTable(2)\nlayer.forward(Tensor(T(\n  T(1.0f, 2.0f, 3.0f),\n  T(4.0f, 5.0f, 6.0f),\n  T(7.0f, 8.0f, 9.0f)\n)))\nlayer.backward(Tensor(T(\n  T(1.0f, 2.0f, 3.0f),\n  T(4.0f, 5.0f, 6.0f),\n  T(7.0f, 8.0f, 9.0f)\n)), T(\n  Tensor(T(0.1f, 0.2f, 0.3f)),\n  Tensor(T(0.4f, 0.5f, 0.6f)),\n  Tensor(T(0.7f, 0.8f, 0.9f))\n))  Gives the output,   {\n        2: 2.0\n           5.0\n           8.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n        1: 1.0\n           4.0\n           7.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n        3: 3.0\n           6.0\n           9.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n }\n\n0.1     0.4     0.7\n0.2     0.5     0.8\n0.3     0.6     0.9\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  from bigdl.nn.layer import SplitTable\nimport numpy as np\n\nlayer = SplitTable(2)\nlayer.forward(np.array([\n  [1.0, 2.0, 3.0],\n  [4.0, 5.0, 6.0],\n  [7.0, 8.0, 9.0]\n]))\n\nlayer.backward(np.array([\n  [1.0, 2.0, 3.0],\n  [4.0, 5.0, 6.0],\n  [7.0, 8.0, 9.0]\n]), [\n  np.array([0.1, 0.2, 0.3]),\n  np.array([0.4, 0.5, 0.6]),\n  np.array([0.7, 0.8, 0.9])\n])  Gives the output,  [\n  array([ 1.,  4.,  7.], dtype=float32),\n  array([ 2.,  5.,  8.], dtype=float32),\n  array([ 3.,  6.,  9.], dtype=float32)\n]\n\narray([[ 0.1       ,  0.40000001,  0.69999999],\n       [ 0.2       ,  0.5       ,  0.80000001],\n       [ 0.30000001,  0.60000002,  0.89999998]], dtype=float32)", 
            "title": "SplitTable"
        }, 
        {
            "location": "/APIGuide/Layers/MergeSplit-Layers/#dotproduct", 
            "text": "Scala:  val m = DotProduct()  Python:  m = DotProduct()  Outputs the dot product (similarity) between inputs  Scala example:  import com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.{T, Table}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval mlp = DotProduct()\nval x = Tensor(3).fill(1f)\nval y = Tensor(3).fill(2f)\nprintln( input: )\nprintln(x)\nprintln(y)\nprintln( output: )\nprintln(mlp.forward(T(x, y)))  input:\n1.0\n1.0\n1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n2.0\n2.0\n2.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\noutput:\n6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1]  Python example:  import numpy as np\nfrom bigdl.nn.layer import *\n\nmlp = DotProduct()\nx = np.array([1, 1, 1])\ny = np.array([2, 2, 2])\nprint( input: )\nprint(x)\nprint(y)\nprint( output: )\nprint(mlp.forward([x, y]))  creating: createDotProduct\ninput:\n[1 1 1]\n[2 2 2]\noutput:\n[ 6.]", 
            "title": "DotProduct"
        }, 
        {
            "location": "/APIGuide/Layers/MergeSplit-Layers/#csubtable", 
            "text": "Scala:  val model = CSubTable()  Python:  model = CSubTable()  Takes a sequence with two Tensor and returns the component-wise subtraction between them.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\n\nval model = CSubTable()\nval input1 = Tensor(5).rand()\nval input2 = Tensor(5).rand()\nval input = T(input1, input2)\nval output = model.forward(input)\n\nscala  print(input)\n {\n    2: 0.29122078\n       0.17347474\n       0.14127742\n       0.2249051\n       0.12171601\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n    1: 0.6202152\n       0.70417005\n       0.21334995\n       0.05191216\n       0.4209623\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n\nscala  print(output)\n0.3289944\n0.5306953\n0.072072536\n-0.17299294\n0.2992463\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5]  Python example:  model = CSubTable()\ninput1 = np.random.randn(5)\ninput2 = np.random.randn(5)\ninput = [input1, input2]\noutput = model.forward(input)  Gives the output,  array([-1.15087152,  0.6169951 ,  2.41840839,  1.34374809,  1.39436531], dtype=float32)", 
            "title": "CSubTable"
        }, 
        {
            "location": "/APIGuide/Layers/MergeSplit-Layers/#cdivtable", 
            "text": "Scala:  val module = CDivTable()  Python:  module = CDivTable()  Takes a table with two Tensor and returns the component-wise division between them.  Scala example:  val module = CDivTable()\nval input = T(1 -  Tensor(2,3).rand(), 2 -  Tensor(2,3).rand())\ninput: com.intel.analytics.bigdl.utils.Table =\n {\n        2: 0.802295     0.7113872       0.29395157\n           0.6562403    0.06519115      0.20099664\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n        1: 0.7435388    0.59126955      0.10225375\n           0.46819785   0.10572237      0.9861797\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n }\n\nmodule.forward(input)\nres6: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.9267648       0.8311501       0.34785917\n0.7134549       1.6217289       4.906449\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  module = CDivTable()\ninput = [np.array([[1, 2, 3],[4, 5, 6]]), np.array([[1, 4, 9],[6, 10, 3]])]\nmodule.forward(input)\n[array([\n[ 1.,                   0.5     ,    0.33333334],\n[ 0.66666669, 0.5       ,  2.        ]], dtype=float32)]", 
            "title": "CDivTable"
        }, 
        {
            "location": "/APIGuide/Layers/MergeSplit-Layers/#jointable", 
            "text": "Scala:  val layer = JoinTable(dimension, nInputDims)  Python:  layer = JoinTable(dimension, n_input_dims)  It is a table module which takes a table of Tensors as input and\noutputs a Tensor by joining them together along the dimension  dimension .  The input to this layer is expected to be a tensor, or a batch of tensors;\nwhen using mini-batch, a batch of sample tensors will be passed to the layer and\nthe user need to specify the number of dimensions of each sample tensor in the\nbatch using  nInputDims .  Parameters:   dimension   to be join in this dimension   nInputDims  specify the number of dimensions that this module will receiveIf it is more than the dimension of input tensors, the first dimension would be considered as batch size  +----------+             +-----------+\n| {input1, +-------------  output[1] |\n|          |           +-----------+-+\n|  input2, +-----------  output[2] |\n|          |         +-----------+-+\n|  input3} +---------  output[3] |\n+----------+         +-----------+  Scala example:  import com.intel.analytics.bigdl.nn.JoinTable\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval layer = JoinTable(2, 2)\nval input1 = Tensor(T(\n  T(\n    T(1f, 2f, 3f),\n    T(2f, 3f, 4f),\n    T(3f, 4f, 5f))\n))\n\nval input2 = Tensor(T(\n  T(\n    T(3f, 4f, 5f),\n    T(2f, 3f, 4f),\n    T(1f, 2f, 3f))\n))\n\nval input = T(input1, input2)\n\nval gradOutput = Tensor(T(\n  T(\n    T(1f, 2f, 3f, 3f, 4f, 5f),\n    T(2f, 3f, 4f, 2f, 3f, 4f),\n    T(3f, 4f, 5f, 1f, 2f, 3f)\n)))\n\nval output = layer.forward(input)\nval grad = layer.backward(input, gradOutput)\n\nprintln(output)\n(1,.,.) =\n1.0 2.0 3.0 3.0 4.0 5.0\n2.0 3.0 4.0 2.0 3.0 4.0\n3.0 4.0 5.0 1.0 2.0 3.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x6]\n\nprintln(grad)\n {\n    2: (1,.,.) =\n       3.0  4.0 5.0\n       2.0  3.0 4.0\n       1.0  2.0 3.0\n\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x3]\n    1: (1,.,.) =\n       1.0  2.0 3.0\n       2.0  3.0 4.0\n       3.0  4.0 5.0\n\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x3]\n }  Python example:  layer = JoinTable(2, 2)\ninput1 = np.array([\n [\n    [1.0, 2.0, 3.0],\n    [2.0, 3.0, 4.0],\n    [3.0, 4.0, 5.0]\n  ]\n])\n\ninput2 = np.array([\n  [\n    [3.0, 4.0, 5.0],\n    [2.0, 3.0, 4.0],\n    [1.0, 2.0, 3.0]\n  ]\n])\n\ninput = [input1, input2]\n\ngradOutput = np.array([\n  [\n    [1.0, 2.0, 3.0, 3.0, 4.0, 5.0],\n    [2.0, 3.0, 4.0, 2.0, 3.0, 4.0],\n    [3.0, 4.0, 5.0, 1.0, 2.0, 3.0]\n  ]\n])\n\noutput = layer.forward(input)\ngrad = layer.backward(input, gradOutput)\n\nprint output\n[[[ 1.  2.  3.  3.  4.  5.]\n  [ 2.  3.  4.  2.  3.  4.]\n  [ 3.  4.  5.  1.  2.  3.]]]\n\nprint grad\n[array([[[ 1.,  2.,  3.],\n        [ 2.,  3.,  4.],\n        [ 3.,  4.,  5.]]], dtype=float32), array([[[ 3.,  4.,  5.],\n        [ 2.,  3.,  4.],\n        [ 1.,  2.,  3.]]], dtype=float32)]", 
            "title": "JoinTable"
        }, 
        {
            "location": "/APIGuide/Layers/MergeSplit-Layers/#selecttable", 
            "text": "Scala:  val m = SelectTable(index: Int)  Python:  m = SelectTable(dimension)  Select one element from a table by a given index.\nIn Scala API, table is kind of like HashMap with one-base index as the key.\nIn python, table is a just a list.  Scala example:  import com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.{T, Table}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval input = T(Tensor(2,3).randn(), Tensor(2,3).randn())\n\nprintln( input:  )\nprintln(input)\nprintln( output: )\nprintln(SelectTable(1).forward(input)) // Select and output the first element of the input which shape is (2, 3)\nprintln(SelectTable(2).forward(input)) // Select and output the second element of the input which shape is (2, 3)  input: \n {\n    2: 2.005436370849835    0.09670211785545313 1.186779895312918   \n       2.238415300857082    0.241626512721254   0.15765709974113828 \n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    1: 0.5668905654052705   -1.3205159007397167 -0.5431464848526197 \n       -0.11582559521074104 0.7671830693813515  -0.39992781407893574    \n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n }\noutput:\n0.5668905654052705  -1.3205159007397167 -0.5431464848526197 \n-0.11582559521074104    0.7671830693813515  -0.39992781407893574    \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n2.005436370849835   0.09670211785545313 1.186779895312918   \n2.238415300857082   0.241626512721254   0.15765709974113828 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom bigdl.nn.layer import *\n\ninput = [np.random.random((2,3)), np.random.random((2, 1))]\nprint( input: )\nprint(input)\nprint( output: )\nprint(SelectTable(1).forward(input)) # Select and output the first element of the input which shape is (2, 3)  input:\n[array([[ 0.07185111,  0.26140439,  0.9437582 ],\n       [ 0.50278191,  0.83923974,  0.06396735]]), array([[ 0.84955122],\n       [ 0.16053703]])]\noutput:\ncreating: createSelectTable\n[[ 0.07185111  0.2614044   0.94375819]\n [ 0.50278193  0.83923972  0.06396735]]", 
            "title": "SelectTable"
        }, 
        {
            "location": "/APIGuide/Layers/MergeSplit-Layers/#narrowtable", 
            "text": "Scala:  val narrowTable = NarrowTable(offset, length = 1)  Python:  narrowTable = NarrowTable(offset, length = 1)  NarrowTable takes a table as input and returns a subtable starting from index  offset  having  length  elements  Negative  length  means the last element is located at Abs|length| to the last element of input  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.T\nval narrowTable = NarrowTable(1, 1)\n\nval input = T()\ninput(1.0) = Tensor(2, 2).rand()\ninput(2.0) = Tensor(2, 2).rand()\ninput(3.0) = Tensor(2, 2).rand()  print(input)\n {\n    2.0: 0.27686104 0.9040761   \n         0.75969505 0.8008061   \n         [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n    1.0: 0.94122535 0.46173728  \n         0.43302807 0.1670979   \n         [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n    3.0: 0.43944374 0.49336782  \n         0.7274511  0.67777634  \n         [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n }   print(narrowTable.forward(input))\n {\n    1: 0.94122535   0.46173728  \n       0.43302807   0.1670979   \n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2]\n }  Python example:  from bigdl.nn.layer import *\nnarrowTable = NarrowTable(1, 1)  narrowTable.forward([np.array([1, 2, 3]), np.array([4, 5, 6])])\n[array([ 1.,  2.,  3.], dtype=float32)]", 
            "title": "NarrowTable"
        }, 
        {
            "location": "/APIGuide/Layers/MergeSplit-Layers/#caddtable", 
            "text": "Scala:  val module = CAddTable(inplace = false)  Python:  module = CAddTable(inplace=False)  CAddTable merges the input tensors in the input table by element-wise adding. The input table is actually an array of tensor with same size.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval mlp = Sequential()\nmlp.add(ConcatTable().add(Identity()).add(Identity()))\nmlp.add(CAddTable())\n\nprintln(mlp.forward(Tensor.range(1, 3, 1)))  Gives the output,  com.intel.analytics.bigdl.nn.abstractnn.Activity =\n2.0\n4.0\n6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmlp = Sequential()\nmlp.add(ConcatTable().add(Identity()).add(Identity()))\nmlp.add(CAddTable())\n\nprint(mlp.forward(np.arange(1, 4, 1)))  Gives the output,  [array([ 2.,  4.,  6.], dtype=float32)]", 
            "title": "CAddTable"
        }, 
        {
            "location": "/APIGuide/Layers/MergeSplit-Layers/#cavetable", 
            "text": "Scala:  val model = CAveTable(inplace=false)  Python:  model = CAveTable(inplace=False)  CAveTable merges the input tensors in the input table by element-wise taking the average. The input table is actually an array of tensor with same size.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.T\n\nval model = CAveTable()\nval input1 = Tensor(5).rand()\nval input2 = Tensor(5).rand()\nval input = T(input1, input2)\nval output = model.forward(input)  Gives the output,  input1: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.6061657\n0.55972266\n0.972365\n0.5624792\n0.7495829\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n\ninput2: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.3897284\n0.82165825\n0.46275142\n0.95935726\n0.64157426\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.49794704\n0.69069046\n0.7175582\n0.76091826\n0.6955786\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodel = CAveTable()\ninput1 = np.random.rand(5)\ninput2 = np.random.rand(5)\ninput = [input1, input2]\noutput = model.forward(input)\n\nprint(input1)\nprint(input2)\nprint(output)  Gives the output,  [array([ 0.26202468  0.15868397  0.27812652  0.45931689  0.32100054], dtype=float32)]\n[array([ 0.51839282  0.26194293  0.97608528  0.73281455  0.11527423], dtype=float32)]\n[array([ 0.39020872  0.21031344  0.62710589  0.5960657   0.21813738], dtype=float32)]", 
            "title": "CAveTable"
        }, 
        {
            "location": "/APIGuide/Layers/MergeSplit-Layers/#cmultable", 
            "text": "Scala:  val model = CMulTable()  Python:  model = CMulTable()  Takes a sequence of Tensors and outputs the multiplication of all of them.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\n\nval model = CMulTable()\nval input1 = Tensor(5).rand()\nval input2 = Tensor(5).rand()\nval input = T(input1, input2)\nval output = model.forward(input)\n\nscala  print(input)\n {\n    2: 0.13224044\n       0.5460452\n       0.33032498\n       0.6317603\n       0.6665052\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n    1: 0.28694472\n       0.45169437\n       0.36891535\n       0.9126049\n       0.41318864\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n }\n\nscala  print(output)\n0.037945695\n0.24664554\n0.12186196\n0.57654756\n0.27539238\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5]  Python example:  model = CMulTable()\ninput1 = np.random.randn(5)\ninput2 = np.random.randn(5)\ninput = [input1, input2]\noutput = model.forward(input)  print(input)\n[array([ 0.28183274, -0.6477487 , -0.21279841,  0.22725124,  0.54748552]), array([-0.78673028, -1.08337196, -0.62710066,  0.37332587, -1.40708162])]  print(output)\n[-0.22172636  0.70175284  0.13344601  0.08483877 -0.77035683]", 
            "title": "CMulTable"
        }, 
        {
            "location": "/APIGuide/Layers/MergeSplit-Layers/#mv", 
            "text": "Scala:  val module = MV(trans = false)  Python:  module = MV(trans=False)  It is a module to perform matrix vector multiplication on two mini-batch inputs, producing a mini-batch.  trans  means whether make matrix transpose before multiplication.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils.T\n\nval module = MV()\n\nprintln(module.forward(T(Tensor.range(1, 12, 1).resize(2, 2, 3), Tensor.range(1, 6, 1).resize(2, 3))))  Gives the output,  com.intel.analytics.bigdl.tensor.Tensor[Float] =\n14.0    32.0\n122.0   167.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  module = MV()\n\nprint(module.forward([np.arange(1, 13, 1).reshape(2, 2, 3), np.arange(1, 7, 1).reshape(2, 3)]))  Gives the output,  [array([ 0.31657887, -1.11062765, -1.16235781, -0.67723978,  0.74650359], dtype=float32)]", 
            "title": "MV"
        }, 
        {
            "location": "/APIGuide/Layers/MergeSplit-Layers/#flattentable", 
            "text": "Scala:  val module = FlattenTable()  Python:  module = FlattenTable()  FlattenTable takes an arbitrarily deep table of Tensors (potentially nested) as input and a table of Tensors without any nested table will be produced  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = FlattenTable()\nval t1 = Tensor(3).randn()\nval t2 = Tensor(3).randn()\nval t3 = Tensor(3).randn()\nval input = T(t1, T(t2, T(t3)))\n\nval output = module.forward(input)  input\n {\n    2:  {\n        2:  {\n            1: 0.5521984\n               -0.4160644\n               -0.698762\n               [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n            }\n        1: -1.7380241\n           0.60336906\n           -0.8751049\n           [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n        }\n    1: 1.0529885\n       -0.792229\n       0.8395628\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n }  output\n{\n    2: -1.7380241\n       0.60336906\n       -0.8751049\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n    1: 1.0529885\n       -0.792229\n       0.8395628\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n    3: 0.5521984\n       -0.4160644\n       -0.698762\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n }  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Sequential()\n# this will create a nested table\nnested = ConcatTable().add(Identity()).add(Identity())\nmodule.add(nested).add(FlattenTable())\nt1 = np.random.randn(3)\nt2 = np.random.randn(3)\ninput = [t1, t2]\noutput = module.forward(input)  input\n[array([-2.21080689, -0.48928043, -0.26122161]), array([-0.8499716 ,  1.63694575, -0.31109292])]  output\n[array([-2.21080685, -0.48928043, -0.26122162], dtype=float32),\n array([-0.84997159,  1.63694572, -0.31109291], dtype=float32),\n array([-2.21080685, -0.48928043, -0.26122162], dtype=float32),\n array([-0.84997159,  1.63694572, -0.31109291], dtype=float32)]", 
            "title": "FlattenTable"
        }, 
        {
            "location": "/APIGuide/Layers/MergeSplit-Layers/#cmintable", 
            "text": "Scala:  val layer = CMinTable()  Python:  layer = CMinTable()  CMinTable takes a bunch of tensors as inputs. These tensors must have\nsame shape. This layer will merge them by doing an element-wise comparision\nand use the min value.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = CMinTable()\nlayer.forward(T(\n  Tensor(T(1.0f, 5.0f, 2.0f)),\n  Tensor(T(3.0f, 4.0f, -1.0f)),\n  Tensor(T(5.0f, 7.0f, -5.0f))\n))\nlayer.backward(T(\n  Tensor(T(1.0f, 5.0f, 2.0f)),\n  Tensor(T(3.0f, 4.0f, -1.0f)),\n  Tensor(T(5.0f, 7.0f, -5.0f))\n), Tensor(T(0.1f, 0.2f, 0.3f)))  Gives the output,  1.0\n4.0\n-5.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n\n{\n  2: 0.0\n     0.2\n     0.0\n     [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n  1: 0.1\n     0.0\n     0.0\n     [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n  3: 0.0\n     0.0\n     0.3\n  [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n}  Python example:  from bigdl.nn.layer import CMinTable\nimport numpy as np\n\nlayer = CMinTable()\nlayer.forward([\n  np.array([1.0, 5.0, 2.0]),\n  np.array([3.0, 4.0, -1.0]),\n  np.array([5.0, 7.0, -5.0])\n])\n\nlayer.backward([\n  np.array([1.0, 5.0, 2.0]),\n  np.array([3.0, 4.0, -1.0]),\n  np.array([5.0, 7.0, -5.0])\n], np.array([0.1, 0.2, 0.3]))  Gives the output,  array([ 1.,  4., -5.], dtype=float32)\n\n[array([ 0.1, 0., 0.], dtype=float32),\narray([ 0., 0.2, 0.], dtype=float32),\narray([ 0., 0., 0.30000001], dtype=float32)]", 
            "title": "CMinTable"
        }, 
        {
            "location": "/APIGuide/Layers/Math-Layers/", 
            "text": "Scale\n\n\nScala:\n\n\nval m = Scale(Array(2, 1))\n\n\n\n\nPython:\n\n\nm = scale = Scale([2, 1])\n\n\n\n\nScale is the combination of cmul and cadd. \nScale(size).forward(input) == CAdd(size).forward(CMul(size).forward(input))\n\nComputes the elementwise product of input and weight, with the shape of the weight \"expand\" to\nmatch the shape of the input.Similarly, perform a expand cdd bias and perform an elementwise add.\n\noutput = input .* weight .+ bias (element wise)\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.{T, Table}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval input = Tensor(2, 3).fill(1f)\nprintln(\ninput:\n)\nprintln(input)\nval scale = Scale(Array(2, 1))\nval weight = Tensor(2, 1).fill(2f)\nval bias = Tensor(2, 1).fill(3f)\nscale.setWeightsBias(Array(weight, bias))\nprintln(\nWeight:\n)\nprintln(weight)\nprintln(\nbias:\n)\nprintln(bias)\nprintln(\noutput:\n)\nprint(scale.forward(input))\n\n\n\n\ninput:\n1.0 1.0 1.0 \n1.0 1.0 1.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\nWeight:\n2.0 \n2.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1]\nbias:\n3.0 \n3.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1]\noutput:\n5.0 5.0 5.0 \n5.0 5.0 5.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.layer import *\ninput = np.ones([2, 3])\nprint(\ninput:\n)\nprint(input)\nscale = Scale([2, 1])\nweight = np.full([2, 1], 2)\nbias = np.full([2, 1], 3)\nprint(\nweight: \n)\nprint(weight)\nprint(\nbias: \n)\nprint(bias)\nscale.set_weights([weight, bias])\nprint(\noutput: \n)\nprint(scale.forward(input))\n\n\n\n\n\ninput:\n[[ 1.  1.  1.]\n [ 1.  1.  1.]]\ncreating: createScale\nweight: \n[[2]\n [2]]\nbias: \n[[3]\n [3]]\noutput: \n[[ 5.  5.  5.]\n [ 5.  5.  5.]]\n\n\n\n\n\n\nMin\n\n\nScala:\n\n\nval min = Min(dim, numInputDims)\n\n\n\n\nPython:\n\n\nmin = Min(dim, num_input_dims)\n\n\n\n\nApplies a min operation over dimension \ndim\n.\n\n\nParameters:\n\n \ndim\n A integer. The dimension to min along.\n\n \nnumInputDims\n An optional integer indicating the number of input dimensions.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval min = Min(2)\nval input = Tensor(T(\n T(1.0f, 2.0f),\n T(3.0f, 4.0f))\n)\nval gradOutput = Tensor(T(\n 1.0f,\n 1.0f\n))\nval output = min.forward(input)\nval gradient = min.backward(input, gradOutput)\n-\n print(output)\n1.0\n3.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n\n-\n print(gradient)\n1.0     0.0     \n1.0     0.0     \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nmin = Min(2)\ninput = np.array([\n  [1.0, 2.0],\n  [3.0, 4.0]\n])\n\ngrad_output = np.array([1.0, 1.0])\noutput = min.forward(input)\ngradient = min.backward(input, grad_output)\n-\n print output\n[ 1.  3.]\n-\n print gradient\n[[ 1.  0.]\n [ 1.  0.]]\n\n\n\n\n\n\nAdd\n\n\nScala:\n\n\nval addLayer = Add(inputSize)\n\n\n\n\nPython:\n\n\nadd_layer = Add(input_size)\n\n\n\n\nA.K.A BiasAdd. This layer adds input tensor with a parameter tensor and output the result.\nIf the input is 1D, this layer just do a element-wise add. If the input has multiple dimensions,\nthis layer will treat the first dimension as batch dimension, resize the input tensor to a 2D \ntensor(batch-dimension x input_size) and do a broadcast add between the 2D tensor and the \nparameter.\n\n\nPlease note that the parameter will be trained in the back propagation.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval addLayer = Add(4)\naddLayer.bias.set(Tensor(T(1.0f, 2.0f, 3.0f, 4.0f)))\naddLayer.forward(Tensor(T(T(1.0f, 1.0f, 1.0f, 1.0f), T(3.0f, 3.0f, 3.0f, 3.0f))))\naddLayer.backward(Tensor(T(T(1.0f, 1.0f, 1.0f, 1.0f), T(3.0f, 3.0f, 3.0f, 3.0f))),\n    Tensor(T(T(0.1f, 0.1f, 0.1f, 0.1f), T(0.3f, 0.3f, 0.3f, 0.3f))))\n\n\n\n\nGives the output,\n\n\n2.0     3.0     4.0     5.0\n4.0     5.0     6.0     7.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]\n\n0.1     0.1     0.1     0.1\n0.3     0.3     0.3     0.3\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import Add\nimport numpy as np\n\nadd_layer = Add(4)\nadd_layer.set_weights([np.array([1.0, 2.0, 3.0, 4.0])])\nadd_layer.forward(np.array([[1.0, 1.0, 1.0, 1.0], [3.0, 3.0, 3.0, 3.0]]))\nadd_layer.backward(np.array([[1.0, 1.0, 1.0, 1.0], [3.0, 3.0, 3.0, 3.0]]),\n    np.array([[0.1, 0.1, 0.1, 0.1], [0.3, 0.3, 0.3, 0.3]]))\n\n\n\n\nGives the output,\n\n\narray([[ 2.,  3.,  4.,  5.],\n       [ 4.,  5.,  6.,  7.]], dtype=float32)\n\narray([[ 0.1       ,  0.1       ,  0.1       ,  0.1       ],\n       [ 0.30000001,  0.30000001,  0.30000001,  0.30000001]], dtype=float32)   \n\n\n\n\n\n\nBiLinear\n\n\nScala:\n\n\nval layer = BiLinear(\n  inputSize1,\n  inputSize2,\n  outputSize,\n  biasRes = true,\n  wRegularizer = null,\n  bRegularizer = null)\n\n\n\n\nPython:\n\n\nlayer = BiLinear(\n    input_size1,\n    input_size2,\n    output_size,\n    bias_res=True,\n    wRegularizer=None,\n    bRegularizer=None)\n\n\n\n\nA bilinear transformation with sparse inputs.\nThe input tensor given in forward(input) is a table containing both inputs x_1 and x_2,\nwhich are tensors of size N x inputDimension1 and N x inputDimension2, respectively.\n\n\nParameters:\n\n\n\n\ninputSize1\n   dimension of input x_1\n\n\ninputSize2\n   dimension of input x_2\n\n\noutputSize\n   output dimension\n\n\nbiasRes\n The layer can be trained without biases by setting bias = false. otherwise true\n\n\nwRegularizer\n instance of \nRegularizer\n\n             (eg. L1 or L2 regularization), applied to the input weights matrices.\n\n\nbRegularizer\n instance of \nRegularizer\n applied to the bias.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.Bilinear\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval layer = Bilinear(3, 2, 3)\nval input1 = Tensor(T(\n  T(-1f, 2f, 3f),\n  T(-2f, 3f, 4f),\n  T(-3f, 4f, 5f)\n))\nval input2 = Tensor(T(\n  T(-2f, 3f),\n  T(-1f, 2f),\n  T(-3f, 4f)\n))\nval input = T(input1, input2)\n\nval gradOutput = Tensor(T(\n  T(3f, 4f, 5f),\n  T(2f, 3f, 4f),\n  T(1f, 2f, 3f)\n))\n\nval output = layer.forward(input)\nval grad = layer.backward(input, gradOutput)\n\nprintln(output)\n-0.14168167 -8.697224   -10.097688\n-0.20962894 -7.114827   -8.568602\n0.16706467  -19.751905  -24.516418\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nprintln(grad)\n {\n    2: 13.411718    -18.695072\n       14.674414    -19.503393\n       13.9599  -17.271534\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x2]\n    1: -5.3747015   -17.803686  -17.558662\n       -2.413877    -8.373887   -8.346823\n       -2.239298    -11.249412  -14.537216\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n }\n\n\n\n\nPython example:\n\n\nlayer = Bilinear(3, 2, 3)\ninput_1 = np.array([\n  [-1.0, 2.0, 3.0],\n  [-2.0, 3.0, 4.0],\n  [-3.0, 4.0, 5.0]\n])\n\ninput_2 = np.array([\n  [-3.0, 4.0],\n  [-2.0, 3.0],\n  [-1.0, 2.0]\n])\n\ninput = [input_1, input_2]\n\ngradOutput = np.array([\n  [3.0, 4.0, 5.0],\n  [2.0, 3.0, 4.0],\n  [1.0, 2.0, 5.0]\n])\n\noutput = layer.forward(input)\ngrad = layer.backward(input, gradOutput)\n\nprint output\n[[-0.5  1.5  2.5]\n [-1.5  2.5  3.5]\n [-2.5  3.5  4.5]]\n[[ 3.  4.  5.]\n [ 2.  3.  4.]\n [ 1.  2.  5.]]\n\nprint grad\n[array([[ 11.86168194, -14.02727222,  -6.16624403],\n       [  6.72984409,  -7.96572971,  -2.89302039],\n       [  5.52902842,  -5.76724434,  -1.46646953]], dtype=float32), array([[ 13.22105694,  -4.6879468 ],\n       [ 14.39296341,  -6.71434498],\n       [ 20.93929482, -13.02455521]], dtype=float32)]\n\n\n\n\n\n\nClamp\n\n\nScala:\n\n\nval model = Clamp(min, max)\n\n\n\n\nPython:\n\n\nmodel = Clamp(min, max)\n\n\n\n\nA kind of hard tanh activition function with integer min and max\n\n \nmin\n min value\n\n \nmax\n max value\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Clamp(-10, 10)\nval input = Tensor(2, 2, 2).rand()\nval output = model.forward(input)\n\nscala\n print(input)\n(1,.,.) =\n0.95979714  0.27654588  \n0.35592428  0.49355772  \n\n(2,.,.) =\n0.2624511   0.78833413  \n0.967827    0.59160346  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x2]\n\nscala\n print(output)\n(1,.,.) =\n0.95979714  0.27654588  \n0.35592428  0.49355772  \n\n(2,.,.) =\n0.2624511   0.78833413  \n0.967827    0.59160346  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2]\n\n\n\n\n\nPython example:\n\n\nmodel = Clamp(-10, 10)\ninput = np.random.randn(2, 2, 2)\noutput = model.forward(input)\n\n\n print(input)\n[[[-0.66763755  1.15392566]\n  [-2.10846048  0.46931736]]\n\n [[ 1.74174638 -1.04323311]\n  [-1.91858729  0.12624046]]]\n\n\n print(output)\n[[[-0.66763753  1.15392566]\n  [-2.10846043  0.46931735]]\n\n [[ 1.74174643 -1.04323316]\n  [-1.91858733  0.12624046]]\n\n\n\n\n\n\nSquare\n\n\nScala:\n\n\nval module = Square()\n\n\n\n\nPython:\n\n\nmodule = Square()\n\n\n\n\nSquare apply an element-wise square operation.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = Square()\n\nprintln(module.forward(Tensor.range(1, 6, 1)))\n\n\n\n\nGives the output,\n\n\ncom.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0\n4.0\n9.0\n16.0\n25.0\n36.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 6]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Square()\nprint(module.forward(np.arange(1, 7, 1)))\n\n\n\n\nGives the output,\n\n\n[array([  1.,   4.,   9.,  16.,  25.,  36.], dtype=float32)]\n\n\n\n\n\n\nMean\n\n\nScala:\n\n\nval m = Mean(dimension=1, nInputDims=-1, squeeze=true)\n\n\n\n\nPython:\n\n\nm = Mean(dimension=1,n_input_dims=-1, squeeze=True)\n\n\n\n\nMean is a module that simply applies a mean operation over the given dimension - specified by \ndimension\n (starting from 1).\n\n\nThe input is expected to be either one tensor, or a batch of tensors (in mini-batch processing). If the input is a batch of tensors, you need to specify the number of dimensions of each tensor in the batch using \nnInputDims\n.  When input is one tensor, do not specify \nnInputDims\n or set it = -1, otherwise input will be interpreted as batch of tensors. \n\n\nScala example:\n\n\nscala\n \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval input = Tensor(2, 2, 2).randn()\nval m1 = Mean()\nval output1 = m1.forward(input)\nval m2 = Mean(2,1,true)\nval output2 = m2.forward(input)\n\nscala\n print(input)\n(1,.,.) =\n-0.52021635     -1.8250599\n-0.2321481      -2.5672712\n\n(2,.,.) =\n4.007425        -0.8705412\n1.6506456       -0.2470611\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x2]\n\nscala\n print(output1)\n1.7436042       -1.3478005\n0.7092488       -1.4071661\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\nscala\n print(output2)\n-0.37618223     -2.1961656\n2.8290353       -0.5588012\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\ninput = np.random.rand(2,2,2)\nprint \ninput is :\n,input\n\nm1 = Mean()\nout = m1.forward(input)\nprint \noutput m1 is :\n,out\n\nm2 = Mean(2,1,True)\nout = m2.forward(input)\nprint \noutput m2 is :\n,out\n\n\n\n\nGives the output,\n\n\ninput is : [[[ 0.01990713  0.37740696]\n  [ 0.67689963  0.67715705]]\n\n [[ 0.45685026  0.58995121]\n  [ 0.33405769  0.86351324]]]\ncreating: createMean\noutput m1 is : [array([[ 0.23837869,  0.48367909],\n       [ 0.50547862,  0.77033514]], dtype=float32)]\ncreating: createMean\noutput m2 is : [array([[ 0.34840336,  0.527282  ],\n       [ 0.39545399,  0.72673225]], dtype=float32)]\n\n\n\n\n\n\nPower\n\n\nScala:\n\n\nval module = Power(power, scale=1, shift=0)\n\n\n\n\nPython:\n\n\nmodule = Power(power, scale=1.0, shift=0.0)\n\n\n\n\nApply an element-wise power operation with scale and shift.\n\n\nf(x) = (shift + scale * x)^power^\n\n\n\n\npower\n the exponent.\n\n\nscale\n Default is 1.\n\n\nshift\n Default is 0.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.Storage\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval power = Power(2, 1, 1)\nval input = Tensor(Storage(Array(0.0, 1, 2, 3, 4, 5)), 1, Array(2, 3))\n\n print(power.forward(input))\n1.0     4.0      9.0    \n16.0        25.0     36.0   \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\n\npower = Power(2.0, 1.0, 1.0)\ninput = np.array([[0.0, 1, 2], [3, 4, 5]])\n\npower.forward(input)\narray([[  1.,   4.,   9.],\n       [ 16.,  25.,  36.]], dtype=float32)\n\n\n\n\n\nCMul\n\n\nScala:\n\n\nval module = CMul(size, wRegularizer = null)\n\n\n\n\nPython:\n\n\nmodule = CMul(size, wRegularizer=None)\n\n\n\n\nThis layer has a weight tensor with given size. The weight will be multiplied element wise to\nthe input tensor. If the element number of the weight tensor match the input tensor, a simply\nelement wise multiply will be done. Or the bias will be expanded to the same size of the input.\nThe expand means repeat on unmatched singleton dimension(if some unmatched dimension isn't\nsingleton dimension, it will report an error). If the input is a batch, a singleton dimension\nwill be add to the first dimension before the expand.\n\n\nsize\n the size of the bias, which is an array of bias shape\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = CMul(Array(2, 1))\nval input = Tensor(2, 3)\nvar i = 0\ninput.apply1(_ =\n {i += 1; i})\n\n print(layer.forward(input))\n-0.29362988     -0.58725977     -0.88088965\n1.9482219       2.4352775       2.9223328\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\n\nlayer = CMul([2,1])\ninput = np.array([[1, 2, 3], [4, 5, 6]])\n\nlayer.forward(input)\narray([[-0.17618844, -0.35237688, -0.52856529],\n       [ 0.85603124,  1.07003903,  1.28404689]], dtype=float32)\n\n\n\n\nAddConstant\n\n\nScala:\n\n\nval module = AddConstant(constant_scalar,inplace= false)\n\n\n\n\nPython:\n\n\nmodule = AddConstant(constant_scalar,inplace=False,bigdl_type=\nfloat\n)\n\n\n\n\nElement wise add a constant scalar to input tensor\n\n \nconstant_scalar\n constant value\n\n \ninplace\n Can optionally do its operation in-place without using extra state memory\n\n\nScala example:\n\n\nval module = AddConstant(3.0)\nval input = Tensor(2,3).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.40684703      0.077655114     0.42314094\n0.55392265      0.8650696       0.3621729\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nmodule.forward(input)\nres11: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n3.406847        3.077655        3.423141\n3.5539227       3.8650696       3.3621728\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\n\nPython example:\n\n\nmodule = AddConstant(3.0,inplace=False,bigdl_type=\nfloat\n)\ninput = np.array([[1, 2, 3],[4, 5, 6]])\nmodule.forward(input)\n[array([\n[ 4.,  5.,  6.],\n[ 7.,  8.,  9.]], dtype=float32)]\n\n\n\n\n\n\nAbs\n\n\nScala:\n\n\nval m = Abs()\n\n\n\n\nPython:\n\n\nm = Abs()\n\n\n\n\nAn element-wise abs operation.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval abs = new Abs\nval input = Tensor(2)\ninput(1) = 21f\ninput(2) = -29f\nprint(abs.forward(input))\n\n\n\n\noutput is:\u300021.0\u300029.0\n\n\nPython example:\n\n\nabs = Abs()\ninput = np.array([21, -29, 30])\nprint(abs.forward(input))\n\n\n\n\noutput is: [array([ 21.,  29.,  30.], dtype=float32)]\n\n\n\n\nLog\n\n\nScala:\n\n\nval log = Log()\n\n\n\n\nPython:\n\n\nlog = Log()\n\n\n\n\nThe Log module applies a log transformation to the input data\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval log = Log()\nval input = Tensor(T(1.0f, Math.E.toFloat))\nval gradOutput = Tensor(T(1.0f, 1.0f))\nval output = log.forward(input)\nval gradient = log.backward(input, gradOutput)\n-\n print(output)\n0.0\n1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n\n-\n print(gradient)\n1.0\n0.36787945\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nimport math\nlog = Log()\ninput = np.array([1.0, math.e])\ngrad_output = np.array([1.0, 1.0])\noutput = log.forward(input)\ngradient = log.backward(input, grad_output)\n\n-\n print output\n[ 0.  1.]\n\n-\n print gradient\n[ 1.          0.36787945]\n\n\n\n\n\n\nSum\n\n\nScala:\n\n\nval m = Sum(dimension=1,nInputDims=-1,sizeAverage=false,squeeze=true)\n\n\n\n\nPython:\n\n\nm = Sum(dimension=1,n_input_dims=-1,size_average=False,squeeze=True)\n\n\n\n\nSum is a module that simply applies a sum operation over the given dimension - specified by the argument \ndimension\n (starting from 1). \n\n\nThe input is expected to be either one tensor, or a batch of tensors (in mini-batch processing). If the input is a batch of tensors, you need to specify the number of dimensions of each tensor in the batch using \nnInputDims\n.  When input is one tensor, do not specify \nnInputDims\n or set it = -1, otherwise input will be interpreted as batch of tensors. \n\n\nScala example:\n\n\n\nscala\n \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval input = Tensor(2, 2, 2).randn()\nval m1 = Sum(2)\nval output1 = m1.forward(input)\nval m2 = Sum(2, 1, true)\nval output2 = m2.forward(input)\n\nscala\n print(input)\n(1,.,.) =\n-0.003314678    0.96401167\n0.79000163      0.78624517\n\n(2,.,.) =\n-0.29975495     0.24742787\n0.8709072       0.4381108\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x2]\n\nscala\n print(output1)\n0.78668696      1.7502568\n0.5711522       0.68553865\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\nscala\n print(output2)\n0.39334348      0.8751284\n0.2855761       0.34276932\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\ninput=np.random.rand(2,2,2)\nprint \ninput is :\n,input\nmodule = Sum(2)\nout = module.forward(input)\nprint \noutput 1 is :\n,out\nmodule = Sum(2,1,True)\nout = module.forward(input)\nprint \noutput 2 is :\n,out\n\n\n\n\nproduces output:\n\n\ninput is : [[[ 0.7194801   0.99120677]\n  [ 0.07446639  0.056318  ]]\n\n [[ 0.08639016  0.17173268]\n  [ 0.71686986  0.30503663]]]\ncreating: createSum\noutput 1 is : [array([[ 0.7939465 ,  1.04752481],\n       [ 0.80325997,  0.47676933]], dtype=float32)]\ncreating: createSum\noutput 2 is : [array([[ 0.39697325,  0.5237624 ],\n       [ 0.40162998,  0.23838466]], dtype=float32)]\n\n\n\n\n\n\nSqrt\n\n\nApply an element-wise sqrt operation.\n\n\nScala:\n\n\nval sqrt = new Sqrt\n\n\n\n\nPython:\n\n\nsqrt = Sqrt()\n\n\n\n\nApply an element-wise sqrt operation.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.Sqrt\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval input = Tensor(3, 5).range(1, 15, 1)\nval sqrt = new Sqrt\nval output = sqrt.forward(input)\nprintln(output)\n\nval gradOutput = Tensor(3, 5).range(2, 16, 1)\nval gradInput = sqrt.backward(input, gradOutput)\nprintln(gradOutput\n\n\n\n\nGives the output,\n\n\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0     1.4142135       1.7320508       2.0     2.236068\n2.4494898       2.6457512       2.828427        3.0     3.1622777\n3.3166249       3.4641016       3.6055512       3.7416575       3.8729835\n\n\n\n\nGives the gradInput\n\n\ngradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0     1.0606601       1.1547005       1.25    1.3416407\n1.428869        1.5118579       1.5909902       1.6666667       1.7392527\n1.8090681       1.8763883       1.9414507       2.0044594       2.065591\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nsqrt = Sqrt()\n\ninput = np.arange(1, 16, 1).astype(\nfloat32\n)\ninput = input.reshape(3, 5)\n\noutput = sqrt.forward(input)\nprint output\n\ngradOutput = np.arange(2, 17, 1).astype(\nfloat32\n)\ngradOutput = gradOutput.reshape(3, 5)\n\ngradInput = sqrt.backward(input, gradOutput)\nprint gradInput\n\n\n\n\nGives the output,\n\n\n[array([[ 1.        ,  1.41421354,  1.73205078,  2.        ,  2.23606801],\n       [ 2.44948983,  2.64575124,  2.82842708,  3.        ,  3.1622777 ],\n       [ 3.31662488,  3.46410155,  3.60555124,  3.7416575 ,  3.87298346]], dtype=float32)]\n\n\n\n\nGives the gradInput:\n\n\n[array([[ 1.        ,  1.06066012,  1.15470052,  1.25      ,  1.34164071],\n       [ 1.42886901,  1.51185787,  1.59099019,  1.66666675,  1.73925269],\n       [ 1.80906808,  1.87638831,  1.94145072,  2.00445938,  2.0655911 ]], dtype=float32)]\n\n\n\n\n\n\nExp\n\n\nScala:\n\n\nval exp = Exp()\n\n\n\n\nPython:\n\n\nexp = Exp()\n\n\n\n\nExp applies element-wise exp operation to input tensor\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval exp = Exp()\nval input = Tensor(3, 3).rand()\n\n print(input)\n0.0858663   0.28117087  0.85724664  \n0.62026995  0.29137492  0.07581586  \n0.22099794  0.45131826  0.78286386  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n\n print(exp.forward(input))\n1.0896606   1.32468     2.356663    \n1.85943     1.3382663   1.078764    \n1.2473209   1.5703809   2.1877286   \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nexp = Exp()\n\n exp.forward(np.array([[1, 2, 3],[1, 2, 3]]))\n[array([[  2.71828175,   7.38905621,  20.08553696],\n       [  2.71828175,   7.38905621,  20.08553696]], dtype=float32)]\n\n\n\n\n\n\n\nMax\n\n\nScala:\n\n\nval layer = Max(dim = 1, numInputDims = Int.MinValue)\n\n\n\n\nPython:\n\n\nlayer = Max(dim, num_input_dims=INTMIN)\n\n\n\n\nApplies a max operation over dimension \ndim\n.\n\n\nParameters:\n\n\n\n\n\n\ndim\n max along this dimension\n\n\n\n\n\n\nnumInputDims\n Optional. If in a batch model, set to the inputDims.\n\n\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.Max\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval layer = Max(1, 1)\nval input = Tensor(T(\n  T(-1f, 2f, 3f),\n  T(-2f, 3f, 4f),\n  T(-3f, 4f, 5f)\n))\n\nval gradOutput = Tensor(T(3f, 4f, 5f))\n\nval output = layer.forward(input)\nval grad = layer.backward(input, gradOutput)\n\nprintln(output)\n3.0\n4.0\n5.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n\nprintln(grad)\n0.0 0.0 3.0\n0.0 0.0 4.0\n0.0 0.0 5.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\nPython example:\n\n\nlayer = Max(1, 1)\ninput = np.array([\n  [-1.0, 2.0, 3.0],\n  [-2.0, 3.0, 4.0],\n  [-3.0, 4.0, 5.0]\n])\n\ngradOutput = np.array([3.0, 4.0, 5.0])\n\noutput = layer.forward(input)\ngrad = layer.backward(input, gradOutput)\n\nprint output\n[ 3.  4.  5.]\n\nprint grad\n[[ 0.  0.  3.]\n [ 0.  0.  4.]\n [ 0.  0.  5.]]\n\n\n\n\n\n\nCAdd\n\n\nScala:\n\n\nval module = CAdd(size,bRegularizer=null)\n\n\n\n\nPython:\n\n\nmodule = CAdd(size,bRegularizer=None,bigdl_type=\nfloat\n)\n\n\n\n\nThis layer has a bias tensor with given size. The bias will be added element wise to the input\ntensor. If the element number of the bias tensor match the input tensor, a simply element wise\nwill be done. Or the bias will be expanded to the same size of the input. The expand means\nrepeat on unmatched singleton dimension(if some unmatched dimension isn't singleton dimension,\nit will report an error). If the input is a batch, a singleton dimension will be add to the first\ndimension before the expand.\n\n\n\n\nsize\n the size of the bias \n\n\n\n\nScala example:\n\n\nval module = CAdd(Array(2, 1),bRegularizer=null)\nval input = Tensor(2, 3).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.52146345      0.86262375      0.74210143\n0.15882674      0.026310394     0.28394955\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nmodule.forward(input)\nres12: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.97027373      1.311434        1.1909117\n-0.047433108    -0.17994945     0.07768971\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nmodule = CAdd([2, 1],bRegularizer=None,bigdl_type=\nfloat\n)\ninput = np.random.rand(2, 3)\narray([[ 0.71239789,  0.65869477,  0.50425182],\n       [ 0.40333312,  0.64843273,  0.07286636]])\n\nmodule.forward(input)\narray([[ 0.89537328,  0.84167016,  0.68722725],\n       [ 0.1290929 ,  0.37419251, -0.20137388]], dtype=float32)\n\n\n\n\n\n\nCosine\n\n\nScala:\n\n\nval m = Cosine(inputSize, outputSize)\n\n\n\n\nPython:\n\n\nm = Cosine(input_size, output_size)\n\n\n\n\nCosine is a module used to  calculate the \ncosine similarity\n of the input to \noutputSize\n centers, i.e. this layer has the weights \nw_j\n, for \nj = 1,..,outputSize\n, where \nw_j\n are vectors of dimension \ninputSize\n.\n\n\nThe distance \ny_j\n between center \nj\n and input \nx\n is formulated as \ny_j = (x \u00b7 w_j) / ( || w_j || * || x || )\n.\n\n\nThe input given in \nforward(input)\n must be either a vector (1D tensor) or matrix (2D tensor). If the input is a\nvector, it must have the size of \ninputSize\n. If it is a matrix, then each row is assumed to be an input sample of given batch (the number of rows means the batch size and the number of columns should be equal to the \ninputSize\n).\n\n\nScala example:\n\n\nscala\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval m = Cosine(2, 3)\nval input = Tensor(3, 2).rand()\nval output = m.forward(input)\n\nscala\n print(input)\n0.48958543      0.38529378\n0.28814933      0.66979927\n0.3581584       0.67365724\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\nscala\n print(output)\n0.998335        0.9098057       -0.71862763\n0.8496431       0.99756527      -0.2993874\n0.8901594       0.9999207       -0.37689084\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\ninput=np.random.rand(2,3)\nprint \ninput is :\n,input\nmodule = Cosine(3,3)\nmodule.forward(input)\nprint \noutput is :\n,out\n\n\n\n\nGives the output,\n\n\ninput is : [[ 0.31156943  0.85577626  0.4274042 ]\n [ 0.79744055  0.66431136  0.05657437]]\ncreating: createCosine\noutput is : [array([[-0.73284394, -0.28076306, -0.51965958],\n       [-0.9563939 , -0.42036989, -0.08060561]], dtype=float32)]\n\n\n\n\n\n\n\n\nMul\n\n\nScala:\n\n\nval module = Mul()\n\n\n\n\nPython:\n\n\nmodule = Mul()\n\n\n\n\nMultiply a singla scalar factor to the incoming data\n\n\n                 +----Mul----+\n input -----+---\n input * weight -----+----\n output\n\n\n\n\nScala example:\n\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval mul = Mul()\n\n\n print(mul.forward(Tensor(1, 5).rand()))\n-0.03212923     -0.019040342    -9.136753E-4    -0.014459004    -0.04096878\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmul = Mul()\ninput = np.random.uniform(0, 1, (1, 5)).astype(\nfloat32\n)\n\n\n mul.forward(input)\n[array([[ 0.72429317,  0.7377845 ,  0.09136307,  0.40439236,  0.29011244]], dtype=float32)]\n\n\n\n\n\n\n\nMulConstant\n\n\nScala:\n\n\nval layer = MulConstant(scalar, inplace)\n\n\n\n\nPython:\n\n\nlayer = MulConstant(const, inplace)\n\n\n\n\nMultiplies input Tensor by a (non-learnable) scalar constant.\nThis module is sometimes useful for debugging purposes.\n\n\nParameters:\n\n \nconstant\nscalar constant\n\n \ninplace\n Can optionally do its operation in-place without using extra state memory. Default: false\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval input = Tensor(T(\n T(1.0f, 2.0f),\n T(3.0f, 4.0f))\n)\nval gradOutput = Tensor(T(\n T(1.0f, 1.0f),\n T(1.0f, 1.0f))\n)\nval scalar = 2.0\nval module = MulConstant(scalar)\nval output = module.forward(input)\nval gradient = module.backward(input, gradOutput)\n-\n print(output)\n2.0     4.0     \n6.0     8.0     \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n-\n print(gradient)\n2.0     2.0     \n2.0     2.0     \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\ninput = np.array([\n          [1.0, 2.0],\n          [3.0, 4.0]\n        ])\ngrad_output = np.array([\n           [1.0, 1.0],\n           [1.0, 1.0]\n         ])\nscalar = 2.0\nmodule = MulConstant(scalar)\noutput = module.forward(input)\ngradient = module.backward(input, grad_output)\n-\n print output\n[[ 2.  4.]\n [ 6.  8.]]\n-\n print gradient\n[[ 2.  2.]\n [ 2.  2.]]", 
            "title": "Math Layers"
        }, 
        {
            "location": "/APIGuide/Layers/Math-Layers/#scale", 
            "text": "Scala:  val m = Scale(Array(2, 1))  Python:  m = scale = Scale([2, 1])  Scale is the combination of cmul and cadd.  Scale(size).forward(input) == CAdd(size).forward(CMul(size).forward(input)) \nComputes the elementwise product of input and weight, with the shape of the weight \"expand\" to\nmatch the shape of the input.Similarly, perform a expand cdd bias and perform an elementwise add. output = input .* weight .+ bias (element wise)  Scala example:  import com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.{T, Table}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval input = Tensor(2, 3).fill(1f)\nprintln( input: )\nprintln(input)\nval scale = Scale(Array(2, 1))\nval weight = Tensor(2, 1).fill(2f)\nval bias = Tensor(2, 1).fill(3f)\nscale.setWeightsBias(Array(weight, bias))\nprintln( Weight: )\nprintln(weight)\nprintln( bias: )\nprintln(bias)\nprintln( output: )\nprint(scale.forward(input))  input:\n1.0 1.0 1.0 \n1.0 1.0 1.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\nWeight:\n2.0 \n2.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1]\nbias:\n3.0 \n3.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1]\noutput:\n5.0 5.0 5.0 \n5.0 5.0 5.0 \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom bigdl.nn.layer import *\ninput = np.ones([2, 3])\nprint( input: )\nprint(input)\nscale = Scale([2, 1])\nweight = np.full([2, 1], 2)\nbias = np.full([2, 1], 3)\nprint( weight:  )\nprint(weight)\nprint( bias:  )\nprint(bias)\nscale.set_weights([weight, bias])\nprint( output:  )\nprint(scale.forward(input))  input:\n[[ 1.  1.  1.]\n [ 1.  1.  1.]]\ncreating: createScale\nweight: \n[[2]\n [2]]\nbias: \n[[3]\n [3]]\noutput: \n[[ 5.  5.  5.]\n [ 5.  5.  5.]]", 
            "title": "Scale"
        }, 
        {
            "location": "/APIGuide/Layers/Math-Layers/#min", 
            "text": "Scala:  val min = Min(dim, numInputDims)  Python:  min = Min(dim, num_input_dims)  Applies a min operation over dimension  dim .  Parameters:   dim  A integer. The dimension to min along.   numInputDims  An optional integer indicating the number of input dimensions.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval min = Min(2)\nval input = Tensor(T(\n T(1.0f, 2.0f),\n T(3.0f, 4.0f))\n)\nval gradOutput = Tensor(T(\n 1.0f,\n 1.0f\n))\nval output = min.forward(input)\nval gradient = min.backward(input, gradOutput)\n-  print(output)\n1.0\n3.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n\n-  print(gradient)\n1.0     0.0     \n1.0     0.0     \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nmin = Min(2)\ninput = np.array([\n  [1.0, 2.0],\n  [3.0, 4.0]\n])\n\ngrad_output = np.array([1.0, 1.0])\noutput = min.forward(input)\ngradient = min.backward(input, grad_output)\n-  print output\n[ 1.  3.]\n-  print gradient\n[[ 1.  0.]\n [ 1.  0.]]", 
            "title": "Min"
        }, 
        {
            "location": "/APIGuide/Layers/Math-Layers/#add", 
            "text": "Scala:  val addLayer = Add(inputSize)  Python:  add_layer = Add(input_size)  A.K.A BiasAdd. This layer adds input tensor with a parameter tensor and output the result.\nIf the input is 1D, this layer just do a element-wise add. If the input has multiple dimensions,\nthis layer will treat the first dimension as batch dimension, resize the input tensor to a 2D \ntensor(batch-dimension x input_size) and do a broadcast add between the 2D tensor and the \nparameter.  Please note that the parameter will be trained in the back propagation.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval addLayer = Add(4)\naddLayer.bias.set(Tensor(T(1.0f, 2.0f, 3.0f, 4.0f)))\naddLayer.forward(Tensor(T(T(1.0f, 1.0f, 1.0f, 1.0f), T(3.0f, 3.0f, 3.0f, 3.0f))))\naddLayer.backward(Tensor(T(T(1.0f, 1.0f, 1.0f, 1.0f), T(3.0f, 3.0f, 3.0f, 3.0f))),\n    Tensor(T(T(0.1f, 0.1f, 0.1f, 0.1f), T(0.3f, 0.3f, 0.3f, 0.3f))))  Gives the output,  2.0     3.0     4.0     5.0\n4.0     5.0     6.0     7.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]\n\n0.1     0.1     0.1     0.1\n0.3     0.3     0.3     0.3\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]  Python example:  from bigdl.nn.layer import Add\nimport numpy as np\n\nadd_layer = Add(4)\nadd_layer.set_weights([np.array([1.0, 2.0, 3.0, 4.0])])\nadd_layer.forward(np.array([[1.0, 1.0, 1.0, 1.0], [3.0, 3.0, 3.0, 3.0]]))\nadd_layer.backward(np.array([[1.0, 1.0, 1.0, 1.0], [3.0, 3.0, 3.0, 3.0]]),\n    np.array([[0.1, 0.1, 0.1, 0.1], [0.3, 0.3, 0.3, 0.3]]))  Gives the output,  array([[ 2.,  3.,  4.,  5.],\n       [ 4.,  5.,  6.,  7.]], dtype=float32)\n\narray([[ 0.1       ,  0.1       ,  0.1       ,  0.1       ],\n       [ 0.30000001,  0.30000001,  0.30000001,  0.30000001]], dtype=float32)", 
            "title": "Add"
        }, 
        {
            "location": "/APIGuide/Layers/Math-Layers/#bilinear", 
            "text": "Scala:  val layer = BiLinear(\n  inputSize1,\n  inputSize2,\n  outputSize,\n  biasRes = true,\n  wRegularizer = null,\n  bRegularizer = null)  Python:  layer = BiLinear(\n    input_size1,\n    input_size2,\n    output_size,\n    bias_res=True,\n    wRegularizer=None,\n    bRegularizer=None)  A bilinear transformation with sparse inputs.\nThe input tensor given in forward(input) is a table containing both inputs x_1 and x_2,\nwhich are tensors of size N x inputDimension1 and N x inputDimension2, respectively.  Parameters:   inputSize1    dimension of input x_1  inputSize2    dimension of input x_2  outputSize    output dimension  biasRes  The layer can be trained without biases by setting bias = false. otherwise true  wRegularizer  instance of  Regularizer \n             (eg. L1 or L2 regularization), applied to the input weights matrices.  bRegularizer  instance of  Regularizer  applied to the bias.   Scala example:  import com.intel.analytics.bigdl.nn.Bilinear\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval layer = Bilinear(3, 2, 3)\nval input1 = Tensor(T(\n  T(-1f, 2f, 3f),\n  T(-2f, 3f, 4f),\n  T(-3f, 4f, 5f)\n))\nval input2 = Tensor(T(\n  T(-2f, 3f),\n  T(-1f, 2f),\n  T(-3f, 4f)\n))\nval input = T(input1, input2)\n\nval gradOutput = Tensor(T(\n  T(3f, 4f, 5f),\n  T(2f, 3f, 4f),\n  T(1f, 2f, 3f)\n))\n\nval output = layer.forward(input)\nval grad = layer.backward(input, gradOutput)\n\nprintln(output)\n-0.14168167 -8.697224   -10.097688\n-0.20962894 -7.114827   -8.568602\n0.16706467  -19.751905  -24.516418\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\nprintln(grad)\n {\n    2: 13.411718    -18.695072\n       14.674414    -19.503393\n       13.9599  -17.271534\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x2]\n    1: -5.3747015   -17.803686  -17.558662\n       -2.413877    -8.373887   -8.346823\n       -2.239298    -11.249412  -14.537216\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n }  Python example:  layer = Bilinear(3, 2, 3)\ninput_1 = np.array([\n  [-1.0, 2.0, 3.0],\n  [-2.0, 3.0, 4.0],\n  [-3.0, 4.0, 5.0]\n])\n\ninput_2 = np.array([\n  [-3.0, 4.0],\n  [-2.0, 3.0],\n  [-1.0, 2.0]\n])\n\ninput = [input_1, input_2]\n\ngradOutput = np.array([\n  [3.0, 4.0, 5.0],\n  [2.0, 3.0, 4.0],\n  [1.0, 2.0, 5.0]\n])\n\noutput = layer.forward(input)\ngrad = layer.backward(input, gradOutput)\n\nprint output\n[[-0.5  1.5  2.5]\n [-1.5  2.5  3.5]\n [-2.5  3.5  4.5]]\n[[ 3.  4.  5.]\n [ 2.  3.  4.]\n [ 1.  2.  5.]]\n\nprint grad\n[array([[ 11.86168194, -14.02727222,  -6.16624403],\n       [  6.72984409,  -7.96572971,  -2.89302039],\n       [  5.52902842,  -5.76724434,  -1.46646953]], dtype=float32), array([[ 13.22105694,  -4.6879468 ],\n       [ 14.39296341,  -6.71434498],\n       [ 20.93929482, -13.02455521]], dtype=float32)]", 
            "title": "BiLinear"
        }, 
        {
            "location": "/APIGuide/Layers/Math-Layers/#clamp", 
            "text": "Scala:  val model = Clamp(min, max)  Python:  model = Clamp(min, max)  A kind of hard tanh activition function with integer min and max   min  min value   max  max value  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Clamp(-10, 10)\nval input = Tensor(2, 2, 2).rand()\nval output = model.forward(input)\n\nscala  print(input)\n(1,.,.) =\n0.95979714  0.27654588  \n0.35592428  0.49355772  \n\n(2,.,.) =\n0.2624511   0.78833413  \n0.967827    0.59160346  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x2]\n\nscala  print(output)\n(1,.,.) =\n0.95979714  0.27654588  \n0.35592428  0.49355772  \n\n(2,.,.) =\n0.2624511   0.78833413  \n0.967827    0.59160346  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2]  Python example:  model = Clamp(-10, 10)\ninput = np.random.randn(2, 2, 2)\noutput = model.forward(input)  print(input)\n[[[-0.66763755  1.15392566]\n  [-2.10846048  0.46931736]]\n\n [[ 1.74174638 -1.04323311]\n  [-1.91858729  0.12624046]]]  print(output)\n[[[-0.66763753  1.15392566]\n  [-2.10846043  0.46931735]]\n\n [[ 1.74174643 -1.04323316]\n  [-1.91858733  0.12624046]]", 
            "title": "Clamp"
        }, 
        {
            "location": "/APIGuide/Layers/Math-Layers/#square", 
            "text": "Scala:  val module = Square()  Python:  module = Square()  Square apply an element-wise square operation.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = Square()\n\nprintln(module.forward(Tensor.range(1, 6, 1)))  Gives the output,  com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0\n4.0\n9.0\n16.0\n25.0\n36.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 6]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Square()\nprint(module.forward(np.arange(1, 7, 1)))  Gives the output,  [array([  1.,   4.,   9.,  16.,  25.,  36.], dtype=float32)]", 
            "title": "Square"
        }, 
        {
            "location": "/APIGuide/Layers/Math-Layers/#mean", 
            "text": "Scala:  val m = Mean(dimension=1, nInputDims=-1, squeeze=true)  Python:  m = Mean(dimension=1,n_input_dims=-1, squeeze=True)  Mean is a module that simply applies a mean operation over the given dimension - specified by  dimension  (starting from 1).  The input is expected to be either one tensor, or a batch of tensors (in mini-batch processing). If the input is a batch of tensors, you need to specify the number of dimensions of each tensor in the batch using  nInputDims .  When input is one tensor, do not specify  nInputDims  or set it = -1, otherwise input will be interpreted as batch of tensors.   Scala example:  scala  \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval input = Tensor(2, 2, 2).randn()\nval m1 = Mean()\nval output1 = m1.forward(input)\nval m2 = Mean(2,1,true)\nval output2 = m2.forward(input)\n\nscala  print(input)\n(1,.,.) =\n-0.52021635     -1.8250599\n-0.2321481      -2.5672712\n\n(2,.,.) =\n4.007425        -0.8705412\n1.6506456       -0.2470611\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x2]\n\nscala  print(output1)\n1.7436042       -1.3478005\n0.7092488       -1.4071661\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\nscala  print(output2)\n-0.37618223     -2.1961656\n2.8290353       -0.5588012\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\ninput = np.random.rand(2,2,2)\nprint  input is : ,input\n\nm1 = Mean()\nout = m1.forward(input)\nprint  output m1 is : ,out\n\nm2 = Mean(2,1,True)\nout = m2.forward(input)\nprint  output m2 is : ,out  Gives the output,  input is : [[[ 0.01990713  0.37740696]\n  [ 0.67689963  0.67715705]]\n\n [[ 0.45685026  0.58995121]\n  [ 0.33405769  0.86351324]]]\ncreating: createMean\noutput m1 is : [array([[ 0.23837869,  0.48367909],\n       [ 0.50547862,  0.77033514]], dtype=float32)]\ncreating: createMean\noutput m2 is : [array([[ 0.34840336,  0.527282  ],\n       [ 0.39545399,  0.72673225]], dtype=float32)]", 
            "title": "Mean"
        }, 
        {
            "location": "/APIGuide/Layers/Math-Layers/#power", 
            "text": "Scala:  val module = Power(power, scale=1, shift=0)  Python:  module = Power(power, scale=1.0, shift=0.0)  Apply an element-wise power operation with scale and shift.  f(x) = (shift + scale * x)^power^   power  the exponent.  scale  Default is 1.  shift  Default is 0.   Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.Storage\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval power = Power(2, 1, 1)\nval input = Tensor(Storage(Array(0.0, 1, 2, 3, 4, 5)), 1, Array(2, 3))  print(power.forward(input))\n1.0     4.0      9.0    \n16.0        25.0     36.0   \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  from bigdl.nn.layer import *\n\npower = Power(2.0, 1.0, 1.0)\ninput = np.array([[0.0, 1, 2], [3, 4, 5]]) power.forward(input)\narray([[  1.,   4.,   9.],\n       [ 16.,  25.,  36.]], dtype=float32)", 
            "title": "Power"
        }, 
        {
            "location": "/APIGuide/Layers/Math-Layers/#cmul", 
            "text": "Scala:  val module = CMul(size, wRegularizer = null)  Python:  module = CMul(size, wRegularizer=None)  This layer has a weight tensor with given size. The weight will be multiplied element wise to\nthe input tensor. If the element number of the weight tensor match the input tensor, a simply\nelement wise multiply will be done. Or the bias will be expanded to the same size of the input.\nThe expand means repeat on unmatched singleton dimension(if some unmatched dimension isn't\nsingleton dimension, it will report an error). If the input is a batch, a singleton dimension\nwill be add to the first dimension before the expand.  size  the size of the bias, which is an array of bias shape  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = CMul(Array(2, 1))\nval input = Tensor(2, 3)\nvar i = 0\ninput.apply1(_ =  {i += 1; i})  print(layer.forward(input))\n-0.29362988     -0.58725977     -0.88088965\n1.9482219       2.4352775       2.9223328\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  from bigdl.nn.layer import *\n\nlayer = CMul([2,1])\ninput = np.array([[1, 2, 3], [4, 5, 6]]) layer.forward(input)\narray([[-0.17618844, -0.35237688, -0.52856529],\n       [ 0.85603124,  1.07003903,  1.28404689]], dtype=float32)", 
            "title": "CMul"
        }, 
        {
            "location": "/APIGuide/Layers/Math-Layers/#addconstant", 
            "text": "Scala:  val module = AddConstant(constant_scalar,inplace= false)  Python:  module = AddConstant(constant_scalar,inplace=False,bigdl_type= float )  Element wise add a constant scalar to input tensor   constant_scalar  constant value   inplace  Can optionally do its operation in-place without using extra state memory  Scala example:  val module = AddConstant(3.0)\nval input = Tensor(2,3).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.40684703      0.077655114     0.42314094\n0.55392265      0.8650696       0.3621729\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nmodule.forward(input)\nres11: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n3.406847        3.077655        3.423141\n3.5539227       3.8650696       3.3621728\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  module = AddConstant(3.0,inplace=False,bigdl_type= float )\ninput = np.array([[1, 2, 3],[4, 5, 6]])\nmodule.forward(input)\n[array([\n[ 4.,  5.,  6.],\n[ 7.,  8.,  9.]], dtype=float32)]", 
            "title": "AddConstant"
        }, 
        {
            "location": "/APIGuide/Layers/Math-Layers/#abs", 
            "text": "Scala:  val m = Abs()  Python:  m = Abs()  An element-wise abs operation.  Scala example:  import com.intel.analytics.bigdl.utils._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval abs = new Abs\nval input = Tensor(2)\ninput(1) = 21f\ninput(2) = -29f\nprint(abs.forward(input))  output is:\u300021.0\u300029.0  Python example:  abs = Abs()\ninput = np.array([21, -29, 30])\nprint(abs.forward(input))  output is: [array([ 21.,  29.,  30.], dtype=float32)]", 
            "title": "Abs"
        }, 
        {
            "location": "/APIGuide/Layers/Math-Layers/#log", 
            "text": "Scala:  val log = Log()  Python:  log = Log()  The Log module applies a log transformation to the input data  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval log = Log()\nval input = Tensor(T(1.0f, Math.E.toFloat))\nval gradOutput = Tensor(T(1.0f, 1.0f))\nval output = log.forward(input)\nval gradient = log.backward(input, gradOutput)\n-  print(output)\n0.0\n1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n\n-  print(gradient)\n1.0\n0.36787945\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nimport math\nlog = Log()\ninput = np.array([1.0, math.e])\ngrad_output = np.array([1.0, 1.0])\noutput = log.forward(input)\ngradient = log.backward(input, grad_output)\n\n-  print output\n[ 0.  1.]\n\n-  print gradient\n[ 1.          0.36787945]", 
            "title": "Log"
        }, 
        {
            "location": "/APIGuide/Layers/Math-Layers/#sum", 
            "text": "Scala:  val m = Sum(dimension=1,nInputDims=-1,sizeAverage=false,squeeze=true)  Python:  m = Sum(dimension=1,n_input_dims=-1,size_average=False,squeeze=True)  Sum is a module that simply applies a sum operation over the given dimension - specified by the argument  dimension  (starting from 1).   The input is expected to be either one tensor, or a batch of tensors (in mini-batch processing). If the input is a batch of tensors, you need to specify the number of dimensions of each tensor in the batch using  nInputDims .  When input is one tensor, do not specify  nInputDims  or set it = -1, otherwise input will be interpreted as batch of tensors.   Scala example:  \nscala  \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval input = Tensor(2, 2, 2).randn()\nval m1 = Sum(2)\nval output1 = m1.forward(input)\nval m2 = Sum(2, 1, true)\nval output2 = m2.forward(input)\n\nscala  print(input)\n(1,.,.) =\n-0.003314678    0.96401167\n0.79000163      0.78624517\n\n(2,.,.) =\n-0.29975495     0.24742787\n0.8709072       0.4381108\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x2]\n\nscala  print(output1)\n0.78668696      1.7502568\n0.5711522       0.68553865\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\nscala  print(output2)\n0.39334348      0.8751284\n0.2855761       0.34276932\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\ninput=np.random.rand(2,2,2)\nprint  input is : ,input\nmodule = Sum(2)\nout = module.forward(input)\nprint  output 1 is : ,out\nmodule = Sum(2,1,True)\nout = module.forward(input)\nprint  output 2 is : ,out  produces output:  input is : [[[ 0.7194801   0.99120677]\n  [ 0.07446639  0.056318  ]]\n\n [[ 0.08639016  0.17173268]\n  [ 0.71686986  0.30503663]]]\ncreating: createSum\noutput 1 is : [array([[ 0.7939465 ,  1.04752481],\n       [ 0.80325997,  0.47676933]], dtype=float32)]\ncreating: createSum\noutput 2 is : [array([[ 0.39697325,  0.5237624 ],\n       [ 0.40162998,  0.23838466]], dtype=float32)]", 
            "title": "Sum"
        }, 
        {
            "location": "/APIGuide/Layers/Math-Layers/#sqrt", 
            "text": "Apply an element-wise sqrt operation.  Scala:  val sqrt = new Sqrt  Python:  sqrt = Sqrt()  Apply an element-wise sqrt operation.  Scala example:  import com.intel.analytics.bigdl.nn.Sqrt\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval input = Tensor(3, 5).range(1, 15, 1)\nval sqrt = new Sqrt\nval output = sqrt.forward(input)\nprintln(output)\n\nval gradOutput = Tensor(3, 5).range(2, 16, 1)\nval gradInput = sqrt.backward(input, gradOutput)\nprintln(gradOutput  Gives the output,  output: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0     1.4142135       1.7320508       2.0     2.236068\n2.4494898       2.6457512       2.828427        3.0     3.1622777\n3.3166249       3.4641016       3.6055512       3.7416575       3.8729835  Gives the gradInput  gradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0     1.0606601       1.1547005       1.25    1.3416407\n1.428869        1.5118579       1.5909902       1.6666667       1.7392527\n1.8090681       1.8763883       1.9414507       2.0044594       2.065591  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nsqrt = Sqrt()\n\ninput = np.arange(1, 16, 1).astype( float32 )\ninput = input.reshape(3, 5)\n\noutput = sqrt.forward(input)\nprint output\n\ngradOutput = np.arange(2, 17, 1).astype( float32 )\ngradOutput = gradOutput.reshape(3, 5)\n\ngradInput = sqrt.backward(input, gradOutput)\nprint gradInput  Gives the output,  [array([[ 1.        ,  1.41421354,  1.73205078,  2.        ,  2.23606801],\n       [ 2.44948983,  2.64575124,  2.82842708,  3.        ,  3.1622777 ],\n       [ 3.31662488,  3.46410155,  3.60555124,  3.7416575 ,  3.87298346]], dtype=float32)]  Gives the gradInput:  [array([[ 1.        ,  1.06066012,  1.15470052,  1.25      ,  1.34164071],\n       [ 1.42886901,  1.51185787,  1.59099019,  1.66666675,  1.73925269],\n       [ 1.80906808,  1.87638831,  1.94145072,  2.00445938,  2.0655911 ]], dtype=float32)]", 
            "title": "Sqrt"
        }, 
        {
            "location": "/APIGuide/Layers/Math-Layers/#exp", 
            "text": "Scala:  val exp = Exp()  Python:  exp = Exp()  Exp applies element-wise exp operation to input tensor  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval exp = Exp()\nval input = Tensor(3, 3).rand()  print(input)\n0.0858663   0.28117087  0.85724664  \n0.62026995  0.29137492  0.07581586  \n0.22099794  0.45131826  0.78286386  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]  print(exp.forward(input))\n1.0896606   1.32468     2.356663    \n1.85943     1.3382663   1.078764    \n1.2473209   1.5703809   2.1877286   \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  from bigdl.nn.layer import *\nexp = Exp()  exp.forward(np.array([[1, 2, 3],[1, 2, 3]]))\n[array([[  2.71828175,   7.38905621,  20.08553696],\n       [  2.71828175,   7.38905621,  20.08553696]], dtype=float32)]", 
            "title": "Exp"
        }, 
        {
            "location": "/APIGuide/Layers/Math-Layers/#max", 
            "text": "Scala:  val layer = Max(dim = 1, numInputDims = Int.MinValue)  Python:  layer = Max(dim, num_input_dims=INTMIN)  Applies a max operation over dimension  dim .  Parameters:    dim  max along this dimension    numInputDims  Optional. If in a batch model, set to the inputDims.    Scala example:  import com.intel.analytics.bigdl.nn.Max\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval layer = Max(1, 1)\nval input = Tensor(T(\n  T(-1f, 2f, 3f),\n  T(-2f, 3f, 4f),\n  T(-3f, 4f, 5f)\n))\n\nval gradOutput = Tensor(T(3f, 4f, 5f))\n\nval output = layer.forward(input)\nval grad = layer.backward(input, gradOutput)\n\nprintln(output)\n3.0\n4.0\n5.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n\nprintln(grad)\n0.0 0.0 3.0\n0.0 0.0 4.0\n0.0 0.0 5.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  layer = Max(1, 1)\ninput = np.array([\n  [-1.0, 2.0, 3.0],\n  [-2.0, 3.0, 4.0],\n  [-3.0, 4.0, 5.0]\n])\n\ngradOutput = np.array([3.0, 4.0, 5.0])\n\noutput = layer.forward(input)\ngrad = layer.backward(input, gradOutput)\n\nprint output\n[ 3.  4.  5.]\n\nprint grad\n[[ 0.  0.  3.]\n [ 0.  0.  4.]\n [ 0.  0.  5.]]", 
            "title": "Max"
        }, 
        {
            "location": "/APIGuide/Layers/Math-Layers/#cadd", 
            "text": "Scala:  val module = CAdd(size,bRegularizer=null)  Python:  module = CAdd(size,bRegularizer=None,bigdl_type= float )  This layer has a bias tensor with given size. The bias will be added element wise to the input\ntensor. If the element number of the bias tensor match the input tensor, a simply element wise\nwill be done. Or the bias will be expanded to the same size of the input. The expand means\nrepeat on unmatched singleton dimension(if some unmatched dimension isn't singleton dimension,\nit will report an error). If the input is a batch, a singleton dimension will be add to the first\ndimension before the expand.   size  the size of the bias    Scala example:  val module = CAdd(Array(2, 1),bRegularizer=null)\nval input = Tensor(2, 3).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.52146345      0.86262375      0.74210143\n0.15882674      0.026310394     0.28394955\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nmodule.forward(input)\nres12: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.97027373      1.311434        1.1909117\n-0.047433108    -0.17994945     0.07768971\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  module = CAdd([2, 1],bRegularizer=None,bigdl_type= float )\ninput = np.random.rand(2, 3)\narray([[ 0.71239789,  0.65869477,  0.50425182],\n       [ 0.40333312,  0.64843273,  0.07286636]])\n\nmodule.forward(input)\narray([[ 0.89537328,  0.84167016,  0.68722725],\n       [ 0.1290929 ,  0.37419251, -0.20137388]], dtype=float32)", 
            "title": "CAdd"
        }, 
        {
            "location": "/APIGuide/Layers/Math-Layers/#cosine", 
            "text": "Scala:  val m = Cosine(inputSize, outputSize)  Python:  m = Cosine(input_size, output_size)  Cosine is a module used to  calculate the  cosine similarity  of the input to  outputSize  centers, i.e. this layer has the weights  w_j , for  j = 1,..,outputSize , where  w_j  are vectors of dimension  inputSize .  The distance  y_j  between center  j  and input  x  is formulated as  y_j = (x \u00b7 w_j) / ( || w_j || * || x || ) .  The input given in  forward(input)  must be either a vector (1D tensor) or matrix (2D tensor). If the input is a\nvector, it must have the size of  inputSize . If it is a matrix, then each row is assumed to be an input sample of given batch (the number of rows means the batch size and the number of columns should be equal to the  inputSize ).  Scala example:  scala \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval m = Cosine(2, 3)\nval input = Tensor(3, 2).rand()\nval output = m.forward(input)\n\nscala  print(input)\n0.48958543      0.38529378\n0.28814933      0.66979927\n0.3581584       0.67365724\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\nscala  print(output)\n0.998335        0.9098057       -0.71862763\n0.8496431       0.99756527      -0.2993874\n0.8901594       0.9999207       -0.37689084\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\ninput=np.random.rand(2,3)\nprint  input is : ,input\nmodule = Cosine(3,3)\nmodule.forward(input)\nprint  output is : ,out  Gives the output,  input is : [[ 0.31156943  0.85577626  0.4274042 ]\n [ 0.79744055  0.66431136  0.05657437]]\ncreating: createCosine\noutput is : [array([[-0.73284394, -0.28076306, -0.51965958],\n       [-0.9563939 , -0.42036989, -0.08060561]], dtype=float32)]", 
            "title": "Cosine"
        }, 
        {
            "location": "/APIGuide/Layers/Math-Layers/#mul", 
            "text": "Scala:  val module = Mul()  Python:  module = Mul()  Multiply a singla scalar factor to the incoming data                   +----Mul----+\n input -----+---  input * weight -----+----  output  Scala example:  \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval mul = Mul()  print(mul.forward(Tensor(1, 5).rand()))\n-0.03212923     -0.019040342    -9.136753E-4    -0.014459004    -0.04096878\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmul = Mul()\ninput = np.random.uniform(0, 1, (1, 5)).astype( float32 )  mul.forward(input)\n[array([[ 0.72429317,  0.7377845 ,  0.09136307,  0.40439236,  0.29011244]], dtype=float32)]", 
            "title": "Mul"
        }, 
        {
            "location": "/APIGuide/Layers/Math-Layers/#mulconstant", 
            "text": "Scala:  val layer = MulConstant(scalar, inplace)  Python:  layer = MulConstant(const, inplace)  Multiplies input Tensor by a (non-learnable) scalar constant.\nThis module is sometimes useful for debugging purposes.  Parameters:   constant scalar constant   inplace  Can optionally do its operation in-place without using extra state memory. Default: false  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval input = Tensor(T(\n T(1.0f, 2.0f),\n T(3.0f, 4.0f))\n)\nval gradOutput = Tensor(T(\n T(1.0f, 1.0f),\n T(1.0f, 1.0f))\n)\nval scalar = 2.0\nval module = MulConstant(scalar)\nval output = module.forward(input)\nval gradient = module.backward(input, gradOutput)\n-  print(output)\n2.0     4.0     \n6.0     8.0     \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n-  print(gradient)\n2.0     2.0     \n2.0     2.0     \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\ninput = np.array([\n          [1.0, 2.0],\n          [3.0, 4.0]\n        ])\ngrad_output = np.array([\n           [1.0, 1.0],\n           [1.0, 1.0]\n         ])\nscalar = 2.0\nmodule = MulConstant(scalar)\noutput = module.forward(input)\ngradient = module.backward(input, grad_output)\n-  print output\n[[ 2.  4.]\n [ 6.  8.]]\n-  print gradient\n[[ 2.  2.]\n [ 2.  2.]]", 
            "title": "MulConstant"
        }, 
        {
            "location": "/APIGuide/Layers/Padding-Layers/", 
            "text": "SpatialZeroPadding\n\n\nScala:\n\n\nval spatialZeroPadding = SpatialZeroPadding(padLeft, padRight, padTop, padBottom)\n\n\n\n\nPython:\n\n\nspatialZeroPadding = SpatialZeroPadding(pad_left, pad_right, pad_top, pad_bottom)\n\n\n\n\nEach feature map of a given input is padded with specified number of zeros.\n\n\nIf padding values are negative, then input will be cropped.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval spatialZeroPadding = SpatialZeroPadding(1, 0, -1, 0)\nval input = Tensor(3, 3, 3).rand()\n\n print(input)\n(1,.,.) =\n0.9494078   0.31556255  0.8432871   \n0.0064580487    0.6487367   0.151881    \n0.8822722   0.3634125   0.7034494   \n\n(2,.,.) =\n0.32691675  0.07487922  0.08813124  \n0.4564806   0.37191486  0.05507739  \n0.10097649  0.6589037   0.8721945   \n\n(3,.,.) =\n0.068939745 0.040364727 0.4893642   \n0.39481318  0.17923461  0.15748173  \n0.87117475  0.9933199   0.6097995\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3x3]\n\n\n  print(spatialZeroPadding.forward(input))\n(1,.,.) =\n0.0 0.0064580487    0.6487367   0.151881    \n0.0 0.8822722   0.3634125   0.7034494   \n\n(2,.,.) =\n0.0 0.4564806   0.37191486  0.05507739  \n0.0 0.10097649  0.6589037   0.8721945   \n\n(3,.,.) =\n0.0 0.39481318  0.17923461  0.15748173  \n0.0 0.87117475  0.9933199   0.6097995   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x2x4]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nspatialZeroPadding = SpatialZeroPadding(1, 0, -1, 0)\n\n spatialZeroPadding.forward(np.array([[[1, 2],[3, 4]],[[1, 2],[3, 4]]]))\n[array([[[ 0.,  3.,  4.]],\n       [[ 0.,  3.,  4.]]], dtype=float32)]\n\n\n\n\n\nPadding\n\n\nScala:\n\n\nval module = Padding(dim,pad,nInputDim,value=0.0,nIndex=1)\n\n\n\n\nPython:\n\n\nmodule = Padding(dim,pad,n_input_dim,value=0.0,n_index=1,bigdl_type=\nfloat\n)\n\n\n\n\nThis module adds pad units of padding to dimension dim of the input. If pad is negative,\npadding is added to the left, otherwise, it is added to the right of the dimension.\nThe input to this layer is expected to be a tensor, or a batch of tensors;\nwhen using mini-batch, a batch of sample tensors will be passed to the layer and\nthe user need to specify the number of dimensions of each sample tensor in the\nbatch using nInputDims.\n\n\n\n\n@param dim the dimension to be applied padding operation\n\n\n@param pad num of the pad units\n\n\n@param nInputDim specify the number of dimensions that this module will receive\n                  If it is more than the dimension of input tensors, the first dimension\n                  would be considered as batch size\n\n\n@param value padding value, default is 0\n\n\n\n\nScala example:\n\n\nval module = Padding(1,-1,3,value=0.0,nIndex=1)\nval input = Tensor(3,2,1).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.673425\n0.9350421\n\n(2,.,.) =\n0.35407698\n0.52607465\n\n(3,.,.) =\n0.7226349\n0.70645845\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2x1]\n\nmodule.forward(input)\nres14: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.0\n0.0\n\n(2,.,.) =\n0.673425\n0.9350421\n\n(3,.,.) =\n0.35407698\n0.52607465\n\n(4,.,.) =\n0.7226349\n0.70645845\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4x2x1]\n\n\n\n\n\nPython example:\n\n\nmodule = Padding(1, -1, 3, value=0.0,n_index=1,bigdl_type=\nfloat\n)\ninput = np.random.rand(3, 2, 1)\narray([[[ 0.81505274],\n        [ 0.55769512]],\n\n       [[ 0.13193961],\n        [ 0.32610741]],\n\n       [[ 0.29855582],\n        [ 0.47394154]]])\n\nmodule.forward(input)\narray([[[ 0.        ],\n        [ 0.        ]],\n\n       [[ 0.81505275],\n        [ 0.55769515]],\n\n       [[ 0.1319396 ],\n        [ 0.32610741]],\n\n       [[ 0.29855582],\n        [ 0.47394153]]], dtype=float32)", 
            "title": "Padding Layers"
        }, 
        {
            "location": "/APIGuide/Layers/Padding-Layers/#spatialzeropadding", 
            "text": "Scala:  val spatialZeroPadding = SpatialZeroPadding(padLeft, padRight, padTop, padBottom)  Python:  spatialZeroPadding = SpatialZeroPadding(pad_left, pad_right, pad_top, pad_bottom)  Each feature map of a given input is padded with specified number of zeros.  If padding values are negative, then input will be cropped.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval spatialZeroPadding = SpatialZeroPadding(1, 0, -1, 0)\nval input = Tensor(3, 3, 3).rand()  print(input)\n(1,.,.) =\n0.9494078   0.31556255  0.8432871   \n0.0064580487    0.6487367   0.151881    \n0.8822722   0.3634125   0.7034494   \n\n(2,.,.) =\n0.32691675  0.07487922  0.08813124  \n0.4564806   0.37191486  0.05507739  \n0.10097649  0.6589037   0.8721945   \n\n(3,.,.) =\n0.068939745 0.040364727 0.4893642   \n0.39481318  0.17923461  0.15748173  \n0.87117475  0.9933199   0.6097995\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3x3]   print(spatialZeroPadding.forward(input))\n(1,.,.) =\n0.0 0.0064580487    0.6487367   0.151881    \n0.0 0.8822722   0.3634125   0.7034494   \n\n(2,.,.) =\n0.0 0.4564806   0.37191486  0.05507739  \n0.0 0.10097649  0.6589037   0.8721945   \n\n(3,.,.) =\n0.0 0.39481318  0.17923461  0.15748173  \n0.0 0.87117475  0.9933199   0.6097995   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x2x4]  Python example:  from bigdl.nn.layer import *\nspatialZeroPadding = SpatialZeroPadding(1, 0, -1, 0)  spatialZeroPadding.forward(np.array([[[1, 2],[3, 4]],[[1, 2],[3, 4]]]))\n[array([[[ 0.,  3.,  4.]],\n       [[ 0.,  3.,  4.]]], dtype=float32)]", 
            "title": "SpatialZeroPadding"
        }, 
        {
            "location": "/APIGuide/Layers/Padding-Layers/#padding", 
            "text": "Scala:  val module = Padding(dim,pad,nInputDim,value=0.0,nIndex=1)  Python:  module = Padding(dim,pad,n_input_dim,value=0.0,n_index=1,bigdl_type= float )  This module adds pad units of padding to dimension dim of the input. If pad is negative,\npadding is added to the left, otherwise, it is added to the right of the dimension.\nThe input to this layer is expected to be a tensor, or a batch of tensors;\nwhen using mini-batch, a batch of sample tensors will be passed to the layer and\nthe user need to specify the number of dimensions of each sample tensor in the\nbatch using nInputDims.   @param dim the dimension to be applied padding operation  @param pad num of the pad units  @param nInputDim specify the number of dimensions that this module will receive\n                  If it is more than the dimension of input tensors, the first dimension\n                  would be considered as batch size  @param value padding value, default is 0   Scala example:  val module = Padding(1,-1,3,value=0.0,nIndex=1)\nval input = Tensor(3,2,1).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.673425\n0.9350421\n\n(2,.,.) =\n0.35407698\n0.52607465\n\n(3,.,.) =\n0.7226349\n0.70645845\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2x1]\n\nmodule.forward(input)\nres14: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.0\n0.0\n\n(2,.,.) =\n0.673425\n0.9350421\n\n(3,.,.) =\n0.35407698\n0.52607465\n\n(4,.,.) =\n0.7226349\n0.70645845\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4x2x1]  Python example:  module = Padding(1, -1, 3, value=0.0,n_index=1,bigdl_type= float )\ninput = np.random.rand(3, 2, 1)\narray([[[ 0.81505274],\n        [ 0.55769512]],\n\n       [[ 0.13193961],\n        [ 0.32610741]],\n\n       [[ 0.29855582],\n        [ 0.47394154]]])\n\nmodule.forward(input)\narray([[[ 0.        ],\n        [ 0.        ]],\n\n       [[ 0.81505275],\n        [ 0.55769515]],\n\n       [[ 0.1319396 ],\n        [ 0.32610741]],\n\n       [[ 0.29855582],\n        [ 0.47394153]]], dtype=float32)", 
            "title": "Padding"
        }, 
        {
            "location": "/APIGuide/Layers/Normalization-Layers/", 
            "text": "BatchNormalization\n\n\nScala:\n\n\nval bn = BatchNormalization(nOutput, eps, momentum, affine)\n\n\n\n\nPython:\n\n\nbn = BatchNormalization(n_output, eps, momentum, affine)\n\n\n\n\nThis layer implements Batch Normalization as described in the paper:\n\nBatch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\n\nby Sergey Ioffe, Christian Szegedy\n\n\nThis implementation is useful for inputs NOT coming from convolution layers. For convolution layers, use nn.SpatialBatchNormalization.\n\n\nThe operation implemented is:\n\n\n              ( x - mean(x) )\n      y =  -------------------- * gamma + beta\n              standard-deviation(x)\n\n\n\n\nwhere gamma and beta are learnable parameters.The learning of gamma and beta is optional.\n\n\nParameters:\n\n\n\n\nnOutput\n feature map number\n\n\neps\n avoid divide zero. Default: 1e-5\n\n\nmomentum\n momentum for weight update. Default: 0.1\n\n\naffine\n affine operation on output or not. Default: true\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval bn = BatchNormalization(2)\nval input = Tensor(T(\n             T(1.0f, 2.0f),\n             T(3.0f, 6.0f))\n            )\nval gradOutput = Tensor(T(\n             T(1.0f, 2.0f),\n             T(3.0f, 6.0f))\n)\nval output = bn.forward(input)\nval gradient = bn.backward(input, gradOutput)\n-\n print(output) \n# There's random factor. An output could be\n-0.46433213     -0.2762179      \n0.46433213      0.2762179       \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n-\n print(gradient)\n# There's random factor. An output could be\n-4.649627E-6    -6.585548E-7    \n4.649627E-6     6.585548E-7     \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nbn = BatchNormalization(2)\ninput = np.array([\n  [1.0, 2.0],\n  [3.0, 6.0]\n])\ngrad_output = np.array([\n           [2.0, 3.0],\n           [4.0, 5.0]\n         ])\noutput = bn.forward(input)\ngradient = bn.backward(input, grad_output)\n-\n print output\n# There's random factor. An output could be\n[[-0.99583918 -0.13030811]\n [ 0.99583918  0.13030811]]\n-\n print gradient\n# There's random factor. An output could be\n[[ -9.97191637e-06  -1.55339364e-07]\n [  9.97191637e-06   1.55339364e-07]]\n\n\n\n\n\n\nSpatialBatchNormalization\n\n\nScala:\n\n\nval module = SpatialBatchNormalization(nOutput, eps=1e-5, momentum=0.1, affine=true,\n                                           initWeight=null, initBias=null, initGradWeight=null, initGradBias=null)\n\n\n\n\nPython:\n\n\nmodule = SpatialBatchNormalization(nOutput, eps=1e-5, momentum=0.1, affine=True)\n\n\n\n\n\nThis file implements Batch Normalization as described in the paper:\n\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\"\nby Sergey Ioffe, Christian Szegedy.\n\n\nThis implementation is useful for inputs coming from convolution layers.\nFor non-convolutional layers, see \nBatchNormalization\n\nThe operation implemented is:\n\n\n        ( x - mean(x) )\n  y = -------------------- * gamma + beta\n       standard-deviation(x)\n\n  where gamma and beta are learnable parameters.\n  The learning of gamma and beta is optional.\n\n\n\n\n\n\nnOutput\n output feature map number\n\n\neps\n avoid divide zero\n\n\nmomentum\n momentum for weight update\n\n\naffine\n affine operation on output or not\n\n\ninitWeight\n initial weight tensor\n\n\ninitBias\n  initial bias tensor\n\n\ninitGradWeight\n initial gradient weight \n\n\ninitGradBias\n initial gradient bias\n\n\ndata_format\n a string value (or DataFormat Object in Scala) of \"NHWC\" or \"NCHW\" to specify the input data format of this layer. In \"NHWC\" format\n                        data is stored in the order of [batch_size, height, width, channels], in \"NCHW\" format data is stored\n                        in the order of [batch_size, channels, height, width].\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = SpatialBatchNormalization(3, 1e-3)\nval input = Tensor(2, 3, 2, 2).randn()\n\n print(layer.forward(input))\n(1,1,.,.) =\n-0.21939678 -0.64394164 \n-0.03280549 0.13889995  \n\n(1,2,.,.) =\n0.48519397  0.40222475  \n-0.9339038  0.4131121   \n\n(1,3,.,.) =\n0.39790314  -0.040012743    \n-0.009540742    0.21598668  \n\n(2,1,.,.) =\n0.32008895  -0.23125978 \n0.4053611   0.26305377  \n\n(2,2,.,.) =\n-0.3810518  -0.34581286 \n0.14797378  0.21226381  \n\n(2,3,.,.) =\n0.2558251   -0.2211882  \n-0.59388477 -0.00508846 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x2x2]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\n\nlayer = SpatialBatchNormalization(3, 1e-3)\ninput = np.random.rand(2,3,2,2)\n\nlayer.forward(input)\narray([[[[  5.70826093e-03,   9.06338100e-05],\n         [ -3.49177676e-03,   1.10401707e-02]],\n\n        [[  1.80168569e-01,  -8.87815133e-02],\n         [  2.11335659e-01,   2.11817324e-01]],\n\n        [[ -1.02916014e+00,   4.02444333e-01],\n         [ -1.72453150e-01,   5.31806648e-01]]],\n\n\n       [[[ -3.46255396e-03,  -1.37512591e-02],\n         [  3.84721952e-03,   1.93112865e-05]],\n\n        [[  4.65962708e-01,  -5.29752195e-01],\n         [ -2.28064612e-01,  -2.22685724e-01]],\n\n        [[  8.49217057e-01,  -9.03094828e-01],\n         [  8.56826544e-01,  -5.35586655e-01]]]], dtype=float32)\n\n\n\n\n\n\nSpatialCrossMapLRN\n\n\nScala:\n\n\nval spatialCrossMapLRN = SpatialCrossMapLRN(size = 5, alpha  = 1.0, beta = 0.75, k = 1.0)\n\n\n\n\nPython:\n\n\nspatialCrossMapLRN = SpatialCrossMapLRN(size=5, alpha=1.0, beta=0.75, k=1.0)\n\n\n\n\nSpatialCrossMapLRN applies Spatial Local Response Normalization between different feature maps\n\n\n                             x_f\n  y_f =  -------------------------------------------------\n          (k+(alpha/size)* sum_{l=l1 to l2} (x_l^2^))^beta^\n\nwhere  l1 corresponds to `max(0,f-ceil(size/2))` and l2 to `min(F, f-ceil(size/2) + size)`, `F` is the number  of feature maps       \n\n\n\n\n\n\nsize\n  the number of channels to sum over\n\n\nalpha\n  the scaling parameter\n\n\nbeta\n   the exponent\n\n\nk\n a constant\n\n\ndata_format\n a string value (or DataFormat Object in Scala) of \"NHWC\" or \"NCHW\" to specify the input data format of this layer. In \"NHWC\" format\n                        data is stored in the order of [batch_size, height, width, channels], in \"NCHW\" format data is stored\n                        in the order of [batch_size, channels, height, width]\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval spatialCrossMapLRN = SpatialCrossMapLRN(5, 0.01, 0.75, 1.0)\n\nval input = Tensor(2, 2, 2, 2).rand()\n\n\n print(input)\n(1,1,.,.) =\n0.42596373  0.20075735  \n0.10307904  0.7486494   \n\n(1,2,.,.) =\n0.9887414   0.3554662   \n0.6291069   0.53952795  \n\n(2,1,.,.) =\n0.41220918  0.5463298   \n0.40766734  0.08064394  \n\n(2,2,.,.) =\n0.58255607  0.027811589 \n0.47811228  0.3082057   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x2x2]\n\n\n print(spatialCrossMapLRN.forward(input))\n(1,1,.,.) =\n0.42522463  0.20070718  \n0.10301625  0.74769455  \n\n(1,2,.,.) =\n0.98702586  0.35537735  \n0.6287237   0.5388398   \n\n(2,1,.,.) =\n0.41189456  0.5460847   \n0.4074261   0.08063166  \n\n(2,2,.,.) =\n0.5821114   0.02779911  \n0.47782937  0.3081588   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nspatialCrossMapLRN = SpatialCrossMapLRN(5, 0.01, 0.75, 1.0)\n\n spatialCrossMapLRN.forward(np.array([[[[1, 2],[3, 4]],[[5, 6],[7, 8]]],[[[9, 10],[11, 12]],[[13, 14],[15, 16]]]]))\n[array([[[[  0.96269381,   1.88782692],\n         [  2.76295042,   3.57862759]],\n\n        [[  4.81346893,   5.66348076],\n         [  6.44688463,   7.15725517]]],\n\n\n       [[[  6.6400919 ,   7.05574226],\n         [  7.41468   ,   7.72194815]],\n\n        [[  9.59124374,   9.87803936],\n         [ 10.11092758,  10.29593086]]]], dtype=float32)]\n\n\n\n\n\n\n\n\nSpatialWithinChannelLRN\n\n\nScala:\n\n\nval spatialWithinChannelLRN = SpatialWithinChannelLRN(size = 5, alpha  = 1.0, beta = 0.75)\n\n\n\n\nPython:\n\n\nspatialWithinChannelLRN = SpatialWithinChannelLRN(size=5, alpha=1.0, beta=0.75)\n\n\n\n\nSpatialWithinChannelLRN performs a kind of \u201clateral inhibition\u201d\nby normalizing over local input regions. the local regions extend spatially,\nin separate channels (i.e., they have shape 1 x size x size).\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval spatialWithinChannelLRN = SpatialWithinChannelLRN(5, 0.01, 0.75)\n\nval input = Tensor(2, 2, 2, 2).rand()\n\n\n print(input)\n(1,1,.,.) =\n0.8658837       0.1297312\n0.7559588       0.039047405\n\n(1,2,.,.) =\n0.79211944      0.84445393\n0.8854509       0.6596644\n\n(2,1,.,.) =\n0.96907943      0.7036902\n0.90358996      0.5719087\n\n(2,2,.,.) =\n0.52309155      0.8838519\n0.44981572      0.40950212\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x2x2]\n\n\n print(spatialWithinChannelLRN.forward(input))\n(1,1,.,.) =\n0.8655359       0.12967908      \n0.75565517      0.03903172      \n\n(1,2,.,.) =\n0.7915117       0.843806        \n0.8847715       0.6591583       \n\n(2,1,.,.) =\n0.9683307       0.70314646      \n0.9028918       0.5714668       \n\n(2,2,.,.) =\n0.52286804      0.8834743       \n0.44962353      0.40932715      \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nspatialWithinChannelLRN = SpatialWithinChannelLRN(5, 0.01, 0.75)\n\n spatialWithinChannelLRN.forward(np.array([[[[1, 2],[3, 4]],[[5, 6],[7, 8]]],[[[9, 10],[11, 12]],[[13, 14],[15, 16]]]]))\narray([[[[  0.99109352,   1.98218703],\n         [  2.97328043,   3.96437407]],\n\n        [[  4.75394297,   5.70473146],\n         [  6.65551996,   7.60630846]]],\n\n\n       [[[  7.95743227,   8.84159184],\n         [  9.72575092,  10.60991001]],\n\n        [[ 10.44729614,  11.2509346 ],\n         [ 12.05457211,  12.85821056]]]], dtype=float32)\n\n\n\n\n\n\n\n\nNormalize\n\n\nScala:\n\n\nval module = Normalize(p,eps=1e-10)\n\n\n\n\nPython:\n\n\nmodule = Normalize(p,eps=1e-10,bigdl_type=\nfloat\n)\n\n\n\n\nNormalizes the input Tensor to have unit L_p norm. The smoothing parameter eps prevents\ndivision by zero when the input contains all zero elements (default = 1e-10).\nThe input can be 1d, 2d or 4d. If the input is 4d, it should follow the format (n, c, h, w) where n is the batch number,\nc is the channel number, h is the height and w is the width\n\n\n\n\np\n L_p norm\n\n\neps\n smoothing parameter\n\n\n\n\nScala example:\n\n\nval module = Normalize(2.0,eps=1e-10)\nval input = Tensor(2,3).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.7075603       0.084298864     0.91339105\n0.22373432      0.8704987       0.6936567\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nmodule.forward(input)\nres8: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.6107763       0.072768        0.7884524\n0.19706465      0.76673317      0.61097115\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nmodule = Normalize(2.0,eps=1e-10,bigdl_type=\nfloat\n)\ninput = np.array([[1, 2, 3],[4, 5, 6]])\nmodule.forward(input)\n[array([\n[ 0.26726124,  0.53452247,  0.80178368],\n[ 0.45584232,  0.56980288,  0.68376344]], dtype=float32)]\n\n\n\n\nSpatialDivisiveNormalization\n\n\nScala:\n\n\nval layer = SpatialDivisiveNormalization()\n\n\n\n\nPython:\n\n\nlayer = SpatialDivisiveNormalization()\n\n\n\n\nApplies a spatial division operation on a series of 2D inputs using kernel for\ncomputing the weighted average in a neighborhood. The neighborhood is defined for\na local spatial region that is the size as kernel and across all features. For\nan input image, since there is only one feature, the region is only spatial. For\nan RGB image, the weighted average is taken over RGB channels and a spatial region.\n\n\nIf the kernel is 1D, then it will be used for constructing and separable 2D kernel.\nThe operations will be much more efficient in this case.\n\n\nThe kernel is generally chosen as a gaussian when it is believed that the correlation\nof two pixel locations decrease with increasing distance. On the feature dimension,\na uniform average is used since the weighting across features is not known.\n\n\nScala example:\n\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval layer = SpatialDivisiveNormalization()\nval input = Tensor(1, 5, 5).rand\nval gradOutput = Tensor(1, 5, 5).rand\n\nval output = layer.forward(input)\nval gradInput = layer.backward(input, gradOutput)\n\n\n println(input)\nres19: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.4022106       0.6872489       0.9712838       0.7769542       0.771034\n0.97930336      0.61022973      0.65092266      0.9507807       0.3158211\n0.12607759      0.320569        0.9267993       0.47579524      0.63989824\n0.713135        0.30836385      0.009723447     0.67723924      0.24405171\n0.51036286      0.115807846     0.123513035     0.28398398      0.271164\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x5]\n\n\n println(output)\nres20: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.37849638      0.6467289       0.91401714      0.73114514      0.725574\n0.9215639       0.57425076      0.6125444       0.89472294      0.29720038\n0.11864409      0.30166835      0.8721555       0.4477425       0.60217\n0.67108876      0.2901828       0.009150156     0.6373094       0.2296625\n0.480272        0.10897984      0.11623074      0.26724035      0.25517625\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x5]\n\n\n println(gradInput)\nres21: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.09343022     -0.25612304     0.25756648      -0.66132677     -0.44575396\n0.052990615     0.7899354       0.27205157      0.028260134     0.23150417\n-0.115425855    0.21133065      0.53093016      -0.36421964     -0.102551565\n0.7222408       0.46287358      0.0010696054    0.26336592      -0.050598443\n0.03733714      0.2775169       -0.21430963     0.3175013       0.6600435\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x5]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nlayer = SpatialDivisiveNormalization()\ninput = np.random.uniform(0, 1, (1, 5, 5)).astype(\nfloat32\n)\ngradOutput = np.random.uniform(0, 1, (1, 5, 5)).astype(\nfloat32\n)\n\noutput = layer.forward(input)\ngradInput = layer.backward(input, gradOutput)\n\n\n output\n[array([[[ 0.30657911,  0.75221181,  0.2318386 ,  0.84053135,  0.24818985],\n         [ 0.32852787,  0.43504578,  0.0219258 ,  0.47856906,  0.31112722],\n         [ 0.12381417,  0.61807972,  0.90043157,  0.57342309,  0.65450585],\n         [ 0.00401461,  0.33700454,  0.79859954,  0.64382601,  0.51768768],\n         [ 0.38087726,  0.8963666 ,  0.7982524 ,  0.78525543,  0.09658573]]], dtype=float32)]\n\n gradInput\n[array([[[ 0.08059166, -0.4616771 ,  0.11626807,  0.30253756,  0.7333734 ],\n         [ 0.2633073 , -0.01641282,  0.40653706,  0.07766753, -0.0237394 ],\n         [ 0.10733987,  0.23385212, -0.3291783 , -0.12808481,  0.4035565 ],\n         [ 0.56126803,  0.49945205, -0.40531909, -0.18559581,  0.27156472],\n         [ 0.28016835,  0.03791744, -0.17803842, -0.27817759,  0.42473239]]], dtype=float32)]\n\n\n\n\n\n\nSpatialSubtractiveNormalization\n\n\nScala:\n\n\nval spatialSubtractiveNormalization = SpatialSubtractiveNormalization(nInputPlane = 1, kernel = null)\n\n\n\n\nPython:\n\n\nspatialSubtractiveNormalization = SpatialSubtractiveNormalization(n_input_plane=1, kernel=None)\n\n\n\n\nSpatialSubtractiveNormalization applies a spatial subtraction operation on a series of 2D inputs using kernel for computing the weighted average in a neighborhood.The neighborhood is defined for a local spatial region that is the size as kernel and across all features. For an input image, since there is only one feature, the region is only spatial. For an RGB image, the weighted average is taken over RGB channels and a spatial region.\n\n\nIf the kernel is 1D, then it will be used for constructing and separable 2D kernel.\nThe operations will be much more efficient in this case.\n\n\nThe kernel is generally chosen as a gaussian when it is believed that the correlation\nof two pixel locations decrease with increasing distance. On the feature dimension,\na uniform average is used since the weighting across features is not known.\n\n\n\n\nnInputPlane\n  number of input plane, default is 1.\n\n\nkernel\n kernel tensor, default is a 9 x 9 tensor.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval kernel = Tensor(3, 3).rand()\n\n\n print(kernel)\n0.56141114  0.76815456  0.29409808  \n0.3599753   0.17142025  0.5243272   \n0.62450963  0.28084084  0.17154165  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n\n\nval spatialSubtractiveNormalization = SpatialSubtractiveNormalization(1, kernel)\n\nval input = Tensor(1, 1, 1, 5).rand()\n\n\n print(input)\n(1,1,.,.) =\n0.122356184 0.44442436  0.6394927   0.9349956   0.8226007   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x1x1x5]\n\n\n print(spatialSubtractiveNormalization.forward(input))\n(1,1,.,.) =\n-0.2427161  0.012936085 -0.08024883 0.15658027  -0.07613802 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1x5]\n\n\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nkernel=np.array([[1, 2, 3],[4, 5, 6],[7, 8, 9]])\nspatialSubtractiveNormalization = SpatialSubtractiveNormalization(1, kernel)\n\n  spatialSubtractiveNormalization.forward(np.array([[[[1, 2, 3, 4, 5]]]]))\n[array([[[[ 0.,  0.,  0.,  0.,  0.]]]], dtype=float32)]", 
            "title": "Normalization Layers"
        }, 
        {
            "location": "/APIGuide/Layers/Normalization-Layers/#batchnormalization", 
            "text": "Scala:  val bn = BatchNormalization(nOutput, eps, momentum, affine)  Python:  bn = BatchNormalization(n_output, eps, momentum, affine)  This layer implements Batch Normalization as described in the paper: Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift \nby Sergey Ioffe, Christian Szegedy  This implementation is useful for inputs NOT coming from convolution layers. For convolution layers, use nn.SpatialBatchNormalization.  The operation implemented is:                ( x - mean(x) )\n      y =  -------------------- * gamma + beta\n              standard-deviation(x)  where gamma and beta are learnable parameters.The learning of gamma and beta is optional.  Parameters:   nOutput  feature map number  eps  avoid divide zero. Default: 1e-5  momentum  momentum for weight update. Default: 0.1  affine  affine operation on output or not. Default: true   Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval bn = BatchNormalization(2)\nval input = Tensor(T(\n             T(1.0f, 2.0f),\n             T(3.0f, 6.0f))\n            )\nval gradOutput = Tensor(T(\n             T(1.0f, 2.0f),\n             T(3.0f, 6.0f))\n)\nval output = bn.forward(input)\nval gradient = bn.backward(input, gradOutput)\n-  print(output) \n# There's random factor. An output could be\n-0.46433213     -0.2762179      \n0.46433213      0.2762179       \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n-  print(gradient)\n# There's random factor. An output could be\n-4.649627E-6    -6.585548E-7    \n4.649627E-6     6.585548E-7     \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nbn = BatchNormalization(2)\ninput = np.array([\n  [1.0, 2.0],\n  [3.0, 6.0]\n])\ngrad_output = np.array([\n           [2.0, 3.0],\n           [4.0, 5.0]\n         ])\noutput = bn.forward(input)\ngradient = bn.backward(input, grad_output)\n-  print output\n# There's random factor. An output could be\n[[-0.99583918 -0.13030811]\n [ 0.99583918  0.13030811]]\n-  print gradient\n# There's random factor. An output could be\n[[ -9.97191637e-06  -1.55339364e-07]\n [  9.97191637e-06   1.55339364e-07]]", 
            "title": "BatchNormalization"
        }, 
        {
            "location": "/APIGuide/Layers/Normalization-Layers/#spatialbatchnormalization", 
            "text": "Scala:  val module = SpatialBatchNormalization(nOutput, eps=1e-5, momentum=0.1, affine=true,\n                                           initWeight=null, initBias=null, initGradWeight=null, initGradBias=null)  Python:  module = SpatialBatchNormalization(nOutput, eps=1e-5, momentum=0.1, affine=True)  This file implements Batch Normalization as described in the paper:\n\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\"\nby Sergey Ioffe, Christian Szegedy.  This implementation is useful for inputs coming from convolution layers.\nFor non-convolutional layers, see  BatchNormalization \nThe operation implemented is:          ( x - mean(x) )\n  y = -------------------- * gamma + beta\n       standard-deviation(x)\n\n  where gamma and beta are learnable parameters.\n  The learning of gamma and beta is optional.   nOutput  output feature map number  eps  avoid divide zero  momentum  momentum for weight update  affine  affine operation on output or not  initWeight  initial weight tensor  initBias   initial bias tensor  initGradWeight  initial gradient weight   initGradBias  initial gradient bias  data_format  a string value (or DataFormat Object in Scala) of \"NHWC\" or \"NCHW\" to specify the input data format of this layer. In \"NHWC\" format\n                        data is stored in the order of [batch_size, height, width, channels], in \"NCHW\" format data is stored\n                        in the order of [batch_size, channels, height, width].   Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = SpatialBatchNormalization(3, 1e-3)\nval input = Tensor(2, 3, 2, 2).randn()  print(layer.forward(input))\n(1,1,.,.) =\n-0.21939678 -0.64394164 \n-0.03280549 0.13889995  \n\n(1,2,.,.) =\n0.48519397  0.40222475  \n-0.9339038  0.4131121   \n\n(1,3,.,.) =\n0.39790314  -0.040012743    \n-0.009540742    0.21598668  \n\n(2,1,.,.) =\n0.32008895  -0.23125978 \n0.4053611   0.26305377  \n\n(2,2,.,.) =\n-0.3810518  -0.34581286 \n0.14797378  0.21226381  \n\n(2,3,.,.) =\n0.2558251   -0.2211882  \n-0.59388477 -0.00508846 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x2x2]  Python example:  from bigdl.nn.layer import *\n\nlayer = SpatialBatchNormalization(3, 1e-3)\ninput = np.random.rand(2,3,2,2) layer.forward(input)\narray([[[[  5.70826093e-03,   9.06338100e-05],\n         [ -3.49177676e-03,   1.10401707e-02]],\n\n        [[  1.80168569e-01,  -8.87815133e-02],\n         [  2.11335659e-01,   2.11817324e-01]],\n\n        [[ -1.02916014e+00,   4.02444333e-01],\n         [ -1.72453150e-01,   5.31806648e-01]]],\n\n\n       [[[ -3.46255396e-03,  -1.37512591e-02],\n         [  3.84721952e-03,   1.93112865e-05]],\n\n        [[  4.65962708e-01,  -5.29752195e-01],\n         [ -2.28064612e-01,  -2.22685724e-01]],\n\n        [[  8.49217057e-01,  -9.03094828e-01],\n         [  8.56826544e-01,  -5.35586655e-01]]]], dtype=float32)", 
            "title": "SpatialBatchNormalization"
        }, 
        {
            "location": "/APIGuide/Layers/Normalization-Layers/#spatialcrossmaplrn", 
            "text": "Scala:  val spatialCrossMapLRN = SpatialCrossMapLRN(size = 5, alpha  = 1.0, beta = 0.75, k = 1.0)  Python:  spatialCrossMapLRN = SpatialCrossMapLRN(size=5, alpha=1.0, beta=0.75, k=1.0)  SpatialCrossMapLRN applies Spatial Local Response Normalization between different feature maps                               x_f\n  y_f =  -------------------------------------------------\n          (k+(alpha/size)* sum_{l=l1 to l2} (x_l^2^))^beta^\n\nwhere  l1 corresponds to `max(0,f-ceil(size/2))` and l2 to `min(F, f-ceil(size/2) + size)`, `F` is the number  of feature maps          size   the number of channels to sum over  alpha   the scaling parameter  beta    the exponent  k  a constant  data_format  a string value (or DataFormat Object in Scala) of \"NHWC\" or \"NCHW\" to specify the input data format of this layer. In \"NHWC\" format\n                        data is stored in the order of [batch_size, height, width, channels], in \"NCHW\" format data is stored\n                        in the order of [batch_size, channels, height, width]   Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval spatialCrossMapLRN = SpatialCrossMapLRN(5, 0.01, 0.75, 1.0)\n\nval input = Tensor(2, 2, 2, 2).rand()  print(input)\n(1,1,.,.) =\n0.42596373  0.20075735  \n0.10307904  0.7486494   \n\n(1,2,.,.) =\n0.9887414   0.3554662   \n0.6291069   0.53952795  \n\n(2,1,.,.) =\n0.41220918  0.5463298   \n0.40766734  0.08064394  \n\n(2,2,.,.) =\n0.58255607  0.027811589 \n0.47811228  0.3082057   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x2x2]  print(spatialCrossMapLRN.forward(input))\n(1,1,.,.) =\n0.42522463  0.20070718  \n0.10301625  0.74769455  \n\n(1,2,.,.) =\n0.98702586  0.35537735  \n0.6287237   0.5388398   \n\n(2,1,.,.) =\n0.41189456  0.5460847   \n0.4074261   0.08063166  \n\n(2,2,.,.) =\n0.5821114   0.02779911  \n0.47782937  0.3081588   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2]  Python example:  from bigdl.nn.layer import *\nspatialCrossMapLRN = SpatialCrossMapLRN(5, 0.01, 0.75, 1.0)  spatialCrossMapLRN.forward(np.array([[[[1, 2],[3, 4]],[[5, 6],[7, 8]]],[[[9, 10],[11, 12]],[[13, 14],[15, 16]]]]))\n[array([[[[  0.96269381,   1.88782692],\n         [  2.76295042,   3.57862759]],\n\n        [[  4.81346893,   5.66348076],\n         [  6.44688463,   7.15725517]]],\n\n\n       [[[  6.6400919 ,   7.05574226],\n         [  7.41468   ,   7.72194815]],\n\n        [[  9.59124374,   9.87803936],\n         [ 10.11092758,  10.29593086]]]], dtype=float32)]", 
            "title": "SpatialCrossMapLRN"
        }, 
        {
            "location": "/APIGuide/Layers/Normalization-Layers/#spatialwithinchannellrn", 
            "text": "Scala:  val spatialWithinChannelLRN = SpatialWithinChannelLRN(size = 5, alpha  = 1.0, beta = 0.75)  Python:  spatialWithinChannelLRN = SpatialWithinChannelLRN(size=5, alpha=1.0, beta=0.75)  SpatialWithinChannelLRN performs a kind of \u201clateral inhibition\u201d\nby normalizing over local input regions. the local regions extend spatially,\nin separate channels (i.e., they have shape 1 x size x size).  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval spatialWithinChannelLRN = SpatialWithinChannelLRN(5, 0.01, 0.75)\n\nval input = Tensor(2, 2, 2, 2).rand()  print(input)\n(1,1,.,.) =\n0.8658837       0.1297312\n0.7559588       0.039047405\n\n(1,2,.,.) =\n0.79211944      0.84445393\n0.8854509       0.6596644\n\n(2,1,.,.) =\n0.96907943      0.7036902\n0.90358996      0.5719087\n\n(2,2,.,.) =\n0.52309155      0.8838519\n0.44981572      0.40950212\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x2x2]  print(spatialWithinChannelLRN.forward(input))\n(1,1,.,.) =\n0.8655359       0.12967908      \n0.75565517      0.03903172      \n\n(1,2,.,.) =\n0.7915117       0.843806        \n0.8847715       0.6591583       \n\n(2,1,.,.) =\n0.9683307       0.70314646      \n0.9028918       0.5714668       \n\n(2,2,.,.) =\n0.52286804      0.8834743       \n0.44962353      0.40932715      \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2]  Python example:  from bigdl.nn.layer import *\nspatialWithinChannelLRN = SpatialWithinChannelLRN(5, 0.01, 0.75)  spatialWithinChannelLRN.forward(np.array([[[[1, 2],[3, 4]],[[5, 6],[7, 8]]],[[[9, 10],[11, 12]],[[13, 14],[15, 16]]]]))\narray([[[[  0.99109352,   1.98218703],\n         [  2.97328043,   3.96437407]],\n\n        [[  4.75394297,   5.70473146],\n         [  6.65551996,   7.60630846]]],\n\n\n       [[[  7.95743227,   8.84159184],\n         [  9.72575092,  10.60991001]],\n\n        [[ 10.44729614,  11.2509346 ],\n         [ 12.05457211,  12.85821056]]]], dtype=float32)", 
            "title": "SpatialWithinChannelLRN"
        }, 
        {
            "location": "/APIGuide/Layers/Normalization-Layers/#normalize", 
            "text": "Scala:  val module = Normalize(p,eps=1e-10)  Python:  module = Normalize(p,eps=1e-10,bigdl_type= float )  Normalizes the input Tensor to have unit L_p norm. The smoothing parameter eps prevents\ndivision by zero when the input contains all zero elements (default = 1e-10).\nThe input can be 1d, 2d or 4d. If the input is 4d, it should follow the format (n, c, h, w) where n is the batch number,\nc is the channel number, h is the height and w is the width   p  L_p norm  eps  smoothing parameter   Scala example:  val module = Normalize(2.0,eps=1e-10)\nval input = Tensor(2,3).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.7075603       0.084298864     0.91339105\n0.22373432      0.8704987       0.6936567\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nmodule.forward(input)\nres8: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.6107763       0.072768        0.7884524\n0.19706465      0.76673317      0.61097115\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  module = Normalize(2.0,eps=1e-10,bigdl_type= float )\ninput = np.array([[1, 2, 3],[4, 5, 6]])\nmodule.forward(input)\n[array([\n[ 0.26726124,  0.53452247,  0.80178368],\n[ 0.45584232,  0.56980288,  0.68376344]], dtype=float32)]", 
            "title": "Normalize"
        }, 
        {
            "location": "/APIGuide/Layers/Normalization-Layers/#spatialdivisivenormalization", 
            "text": "Scala:  val layer = SpatialDivisiveNormalization()  Python:  layer = SpatialDivisiveNormalization()  Applies a spatial division operation on a series of 2D inputs using kernel for\ncomputing the weighted average in a neighborhood. The neighborhood is defined for\na local spatial region that is the size as kernel and across all features. For\nan input image, since there is only one feature, the region is only spatial. For\nan RGB image, the weighted average is taken over RGB channels and a spatial region.  If the kernel is 1D, then it will be used for constructing and separable 2D kernel.\nThe operations will be much more efficient in this case.  The kernel is generally chosen as a gaussian when it is believed that the correlation\nof two pixel locations decrease with increasing distance. On the feature dimension,\na uniform average is used since the weighting across features is not known.  Scala example:  \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval layer = SpatialDivisiveNormalization()\nval input = Tensor(1, 5, 5).rand\nval gradOutput = Tensor(1, 5, 5).rand\n\nval output = layer.forward(input)\nval gradInput = layer.backward(input, gradOutput)  println(input)\nres19: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.4022106       0.6872489       0.9712838       0.7769542       0.771034\n0.97930336      0.61022973      0.65092266      0.9507807       0.3158211\n0.12607759      0.320569        0.9267993       0.47579524      0.63989824\n0.713135        0.30836385      0.009723447     0.67723924      0.24405171\n0.51036286      0.115807846     0.123513035     0.28398398      0.271164\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x5]  println(output)\nres20: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.37849638      0.6467289       0.91401714      0.73114514      0.725574\n0.9215639       0.57425076      0.6125444       0.89472294      0.29720038\n0.11864409      0.30166835      0.8721555       0.4477425       0.60217\n0.67108876      0.2901828       0.009150156     0.6373094       0.2296625\n0.480272        0.10897984      0.11623074      0.26724035      0.25517625\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x5]  println(gradInput)\nres21: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.09343022     -0.25612304     0.25756648      -0.66132677     -0.44575396\n0.052990615     0.7899354       0.27205157      0.028260134     0.23150417\n-0.115425855    0.21133065      0.53093016      -0.36421964     -0.102551565\n0.7222408       0.46287358      0.0010696054    0.26336592      -0.050598443\n0.03733714      0.2775169       -0.21430963     0.3175013       0.6600435\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x5]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nlayer = SpatialDivisiveNormalization()\ninput = np.random.uniform(0, 1, (1, 5, 5)).astype( float32 )\ngradOutput = np.random.uniform(0, 1, (1, 5, 5)).astype( float32 )\n\noutput = layer.forward(input)\ngradInput = layer.backward(input, gradOutput)  output\n[array([[[ 0.30657911,  0.75221181,  0.2318386 ,  0.84053135,  0.24818985],\n         [ 0.32852787,  0.43504578,  0.0219258 ,  0.47856906,  0.31112722],\n         [ 0.12381417,  0.61807972,  0.90043157,  0.57342309,  0.65450585],\n         [ 0.00401461,  0.33700454,  0.79859954,  0.64382601,  0.51768768],\n         [ 0.38087726,  0.8963666 ,  0.7982524 ,  0.78525543,  0.09658573]]], dtype=float32)]  gradInput\n[array([[[ 0.08059166, -0.4616771 ,  0.11626807,  0.30253756,  0.7333734 ],\n         [ 0.2633073 , -0.01641282,  0.40653706,  0.07766753, -0.0237394 ],\n         [ 0.10733987,  0.23385212, -0.3291783 , -0.12808481,  0.4035565 ],\n         [ 0.56126803,  0.49945205, -0.40531909, -0.18559581,  0.27156472],\n         [ 0.28016835,  0.03791744, -0.17803842, -0.27817759,  0.42473239]]], dtype=float32)]", 
            "title": "SpatialDivisiveNormalization"
        }, 
        {
            "location": "/APIGuide/Layers/Normalization-Layers/#spatialsubtractivenormalization", 
            "text": "Scala:  val spatialSubtractiveNormalization = SpatialSubtractiveNormalization(nInputPlane = 1, kernel = null)  Python:  spatialSubtractiveNormalization = SpatialSubtractiveNormalization(n_input_plane=1, kernel=None)  SpatialSubtractiveNormalization applies a spatial subtraction operation on a series of 2D inputs using kernel for computing the weighted average in a neighborhood.The neighborhood is defined for a local spatial region that is the size as kernel and across all features. For an input image, since there is only one feature, the region is only spatial. For an RGB image, the weighted average is taken over RGB channels and a spatial region.  If the kernel is 1D, then it will be used for constructing and separable 2D kernel.\nThe operations will be much more efficient in this case.  The kernel is generally chosen as a gaussian when it is believed that the correlation\nof two pixel locations decrease with increasing distance. On the feature dimension,\na uniform average is used since the weighting across features is not known.   nInputPlane   number of input plane, default is 1.  kernel  kernel tensor, default is a 9 x 9 tensor.   Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval kernel = Tensor(3, 3).rand()  print(kernel)\n0.56141114  0.76815456  0.29409808  \n0.3599753   0.17142025  0.5243272   \n0.62450963  0.28084084  0.17154165  \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x3]\n\n\nval spatialSubtractiveNormalization = SpatialSubtractiveNormalization(1, kernel)\n\nval input = Tensor(1, 1, 1, 5).rand()  print(input)\n(1,1,.,.) =\n0.122356184 0.44442436  0.6394927   0.9349956   0.8226007   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x1x1x5]  print(spatialSubtractiveNormalization.forward(input))\n(1,1,.,.) =\n-0.2427161  0.012936085 -0.08024883 0.15658027  -0.07613802 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1x5]   Python example:  from bigdl.nn.layer import *\nkernel=np.array([[1, 2, 3],[4, 5, 6],[7, 8, 9]])\nspatialSubtractiveNormalization = SpatialSubtractiveNormalization(1, kernel)   spatialSubtractiveNormalization.forward(np.array([[[[1, 2, 3, 4, 5]]]]))\n[array([[[[ 0.,  0.,  0.,  0.,  0.]]]], dtype=float32)]", 
            "title": "SpatialSubtractiveNormalization"
        }, 
        {
            "location": "/APIGuide/Layers/Dropout-Layers/", 
            "text": "Dropout\n\n\nScala:\n\n\nval module = Dropout(\n  initP = 0.5,\n  inplace = false,\n  scale = true)\n\n\n\n\nPython:\n\n\nmodule = Dropout(\n  init_p=0.5,\n  inplace=False,\n  scale=True)\n\n\n\n\nDropout masks(set to zero) parts of input using a Bernoulli distribution.\nEach input element has a probability \ninitP\n of being dropped. If \nscale\n is\ntrue(true by default), the outputs are scaled by a factor of \n1/(1-initP)\n during training.\nDuring evaluating, output is the same as input.\n\n\nIt has been proven an effective approach for regularization and preventing\nco-adaptation of feature detectors. For more details, please see\n[Improving neural networks by preventing co-adaptation of feature detectors]\n(https://arxiv.org/abs/1207.0580)\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = Dropout()\nval x = Tensor.range(1, 8, 1).resize(2, 4)\n\nprintln(module.forward(x))\nprintln(module.backward(x, x.clone().mul(0.5f))) // backward drops out the gradients at the same location.\n\n\n\n\nOutput is\n\n\ncom.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.0     4.0     6.0     0.0\n10.0    12.0    0.0     16.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]\n\ncom.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.0    2.0    3.0    0.0\n5.0    6.0    0.0    8.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Dropout()\nx = np.arange(1, 9, 1).reshape(2, 4)\n\nprint(module.forward(x))\nprint(module.backward(x, x.copy() * 0.5)) # backward drops out the gradients at the same location.\n\n\n\n\nOutput is\n\n\n[array([[ 0.,  4.,  6.,  0.],\n       [ 0.,  0.,  0.,  0.]], dtype=float32)]\n\n[array([[ 0.,  2.,  3.,  0.],\n       [ 0.,  0.,  0.,  0.]], dtype=float32)]\n\n\n\n\nGaussianDropout\n\n\nScala:\n\n\nval module = GaussianDropout(rate)\n\n\n\n\nPython:\n\n\nmodule = GaussianDropout(rate)\n\n\n\n\nApply multiplicative 1-centered Gaussian noise.\nAs it is a regularization layer, it is only active at training time.\n\n\n\n\nrate\n is drop probability (as with \nDropout\n).\n\n\n\n\nReference: \nDropout: A Simple Way to Prevent Neural Networks from Overfitting Srivastava, Hinton, et al. 2014\n\n\nScala example:\n\n\nscala\n import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nscala\n val layer = GaussianDropout(0.5)\n2017-11-27 14:03:48 INFO  ThreadPool$:79 - Set mkl threads to 1 on thread 1\nlayer: com.intel.analytics.bigdl.nn.GaussianDropout[Float] = GaussianDropout[668c68cd](0.5)\n\nscala\n layer.training()\nres0: layer.type = GaussianDropout[668c68cd](0.5)\n\nscala\n val input = Tensor(T(T(1.0,1.0,1.0),T(1.0,1.0,1.0)))\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0     1.0     1.0\n1.0     1.0     1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nscala\n val output = layer.forward(input)\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.1833225       1.1171452       0.27325004\n0.436912        0.9357152       0.47588816\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nscala\n val gradout = Tensor(T(T(1.0,1.0,1.0),T(1.0,1.0,1.0)))\ngradout: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0     1.0     1.0\n1.0     1.0     1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nscala\n val gradin = layer.backward(input,gradout)\ngradin: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.4862849       1.0372512       0.91885364\n-0.18087652     2.3662233       0.9388555\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nscala\n layer.evaluate()\nres1: layer.type = GaussianDropout[668c68cd](0.5)\n\nscala\n val output = layer.forward(input)\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0     1.0     1.0\n1.0     1.0     1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\n\n\n\nPython example:\n\n\nlayer = GaussianDropout(0.5) # Try to create a Linear layer\n\n#training mode\nlayer.training()\ninp=np.ones([2,1])\noutp = layer.forward(inp)\n\ngradoutp = np.ones([2,1])\ngradinp = layer.backward(inp,gradoutp)\nprint \ntraining:forward=\n,outp\nprint \ntrainig:backward=\n,gradinp\n\n#evaluation mode\nlayer.evaluate()\nprint \nevaluate:forward=\n,layer.forward(inp)\n\n\n\n\n\nOutput is\n\n\ncreating: createGaussianDropout\ntraining:forward= [[ 0.80695641]\n [ 1.82794702]]\ntrainig:backward= [[ 0.1289842 ]\n [ 1.22549391]]\nevaluate:forward= [[ 1.]\n [ 1.]]\n\n\n\n\n\nGaussianNoise\n\n\nScala:\n\n\nval module = GaussianNoise(stddev)\n\n\n\n\nPython:\n\n\nmodule = GaussianNoise(stddev)\n\n\n\n\nApply additive zero-centered Gaussian noise. This is useful to mitigate overfitting (you could see it as a form of random data augmentation).\nGaussian Noise (GS) is a natural choice as corruption process for real valued inputs.\n\n\nAs it is a regularization layer, it is only active at training time.\n\n\n\n\nstddev\n is the standard deviation of the noise distribution.\n\n\n\n\nScala example:\n\n\nscala\n val layer = GaussianNoise(0.2)\nlayer: com.intel.analytics.bigdl.nn.GaussianNoise[Float] = GaussianNoise[77daa92e](0.2)\n\nscala\n layer.training()\nres3: layer.type = GaussianNoise[77daa92e](0.2)\n\nscala\n val input = Tensor(T(T(1.0,1.0,1.0),T(1.0,1.0,1.0)))\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0     1.0     1.0\n1.0     1.0     1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nscala\n val output = layer.forward(input)\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.263781        0.91440135      0.928574\n0.88923925      1.1450694       0.97276205\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nscala\n val gradout = Tensor(T(T(1.0,1.0,1.0),T(1.0,1.0,1.0)))\ngradout: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0     1.0     1.0\n1.0     1.0     1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nscala\n val gradin = layer.backward(input,gradout)\ngradin: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0     1.0     1.0\n1.0     1.0     1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nscala\n layer.evaluate()\nres2: layer.type = GaussianNoise[77daa92e](0.2)\n\nscala\n val output = layer.forward(input)\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0     1.0     1.0\n1.0     1.0     1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\n\n\n\nPython example:\n\n\nlayer = GaussianNoise(0.5) \n\n#training mode\nlayer.training()\ninp=np.ones([2,1])\noutp = layer.forward(inp)\n\ngradoutp = np.ones([2,1])\ngradinp = layer.backward(inp,gradoutp)\nprint \ntraining:forward=\n,outp\nprint \ntrainig:backward=\n,gradinp\n\n#evaluation mode\nlayer.evaluate()\nprint \nevaluate:forward=\n,layer.forward(inp)\n\n\n\n\n\nOutput is\n\n\ncreating: createGaussianNoise\ntraining:forward= [[ 0.99984151]\n [ 1.11269045]]\ntrainig:backward= [[ 1.]\n [ 1.]]\nevaluate:forward= [[ 1.]\n [ 1.]]\n\n\n\n\nSpatialDropout1D\n\n\nScala:\n\n\nval module = SpatialDropout1D(initP = 0.5)\n\n\n\n\nPython:\n\n\nmodule = SpatialDropout1D(\n  init_p=0.5)\n\n\n\n\nThis version performs the same function as Dropout, however it drops\n   entire 1D feature maps instead of individual elements. If adjacent frames\n   within feature maps are strongly correlated (as is normally the case in\n   early convolution layers) then regular dropout will not regularize the\n   activations and will otherwise just result in an effective learning rate\n   decrease. In this case, SpatialDropout1D will help promote independence\n   between feature maps and should be used instead.\n\n\n\n\ninitP\n the probability p\n\n\n\n\nScala example:\n\n\n    val module = SpatialDropout1D[Double](0.7)\n    val input = Tensor[Double](3, 4, 5)\n    val seed = 100\n\n    input.rand()\n\n    RNG.setSeed(seed)\n    val output = module.forward(input)\n    \n println(output)\n    (1,.,.) =\n    0.0 0.0 0.8925298328977078  0.0 0.0 \n    0.0 0.0 0.8951127317268401  0.0 0.0 \n    0.0 0.0 0.425491401925683   0.0 0.0 \n    0.0 0.0 0.31143878563307226 0.0 0.0 \n\n    (2,.,.) =\n    0.0 0.0 0.06833203043788671 0.5629170550964773  0.49213682673871517 \n    0.0 0.0 0.5263364950660616  0.5756838673260063  0.060498124454170465    \n    0.0 0.0 0.8886410375125706  0.539079936221242   0.4533065736759454  \n    0.0 0.0 0.8942249100655317  0.5489360291976482  0.05561425327323377 \n\n    (3,.,.) =\n    0.007322707446292043    0.07132467231713235 0.0 0.3080112475436181  0.0 \n    0.8506345122586936  0.383204679004848   0.0 0.9952241901773959  0.0 \n    0.6507184051442891  0.20175716653466225 0.0 0.28786351275630295 0.0 \n    0.19677149993367493 0.3048216907773167  0.0 0.5715036438778043  0.0 \n\n    [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x5]\n\n    val gradInput = module.backward(input, input.clone().fill(1))\n    \n println(gradInput)\n    (1,.,.) =\n    0.0 0.0 1.0 0.0 0.0 \n    0.0 0.0 1.0 0.0 0.0 \n    0.0 0.0 1.0 0.0 0.0 \n    0.0 0.0 1.0 0.0 0.0 \n\n    (2,.,.) =\n    0.0 0.0 1.0 1.0 1.0 \n    0.0 0.0 1.0 1.0 1.0 \n    0.0 0.0 1.0 1.0 1.0 \n    0.0 0.0 1.0 1.0 1.0 \n\n    (3,.,.) =\n    1.0 1.0 0.0 1.0 0.0 \n    1.0 1.0 0.0 1.0 0.0 \n    1.0 1.0 0.0 1.0 0.0 \n    1.0 1.0 0.0 1.0 0.0 \n\n    [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x5]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = SpatialDropout1D(0.7)\nx = np.arange(3, 4, 5)\n\nprint(module.forward(x))\nprint(module.backward(x, x.copy() * 0.5)) # backward drops out the gradients at the same location.\n\n\n\n\nOutput is\n\n\n [[[0.0 0.0 0.8925298328977078  0.0 0.0]    \n    [0.0    0.0 0.8951127317268401  0.0 0.0]    \n    [0.0    0.0 0.425491401925683   0.0 0.0]    \n    [0.0    0.0 0.31143878563307226 0.0 0.0]]   \n\n    [0.0    0.0 0.06833203043788671 0.5629170550964773  0.49213682673871517 ]   \n    [0.0    0.0 0.5263364950660616  0.5756838673260063  0.060498124454170465 ]  \n    [0.0    0.0 0.8886410375125706  0.539079936221242   0.4533065736759454 ]    \n    [0.0    0.0 0.8942249100655317  0.5489360291976482  0.05561425327323377 ]]\n\n    [0.007322707446292043   0.07132467231713235 0.0 0.3080112475436181  0.0 ]   \n    [0.8506345122586936 0.383204679004848   0.0 0.9952241901773959  0.0 ]   \n    [0.6507184051442891 0.20175716653466225 0.0 0.28786351275630295 0.0 ]   \n    [0.19677149993367493    0.3048216907773167  0.0 0.5715036438778043  0.0]]]\n\n\n     [[[0.0 0.0 1.0 0.0 0.0]\n        [0.0 0.0 1.0 0.0 0.0]   \n        [0.0 0.0 1.0 0.0 0.0]   \n        [0.0 0.0 1.0 0.0 0.0]]\n\n       [[0.0 0.0 1.0 1.0 1.0]   \n        [0.0 0.0 1.0 1.0 1.0]   \n        [0.0 0.0 1.0 1.0 1.0]   \n        [0.0 0.0 1.0 1.0 1.0]]\n\n       [[1.0 1.0 0.0 1.0 0.0]   \n        [1.0 1.0 0.0 1.0 0.0]   \n        [1.0 1.0 0.0 1.0 0.0]   \n        [1.0 1.0 0.0 1.0 0.0]]]\n\n\n\n\n\nSpatialDropout2D\n\n\nScala:\n\n\nval module = SpatialDropout2D(initP = 0.5, format = DataFormat.NCHW)\n\n\n\n\nPython:\n\n\nmodule = SpatialDropout2D(\n  init_p=0.5, data_format=\nNCHW\n)\n\n\n\n\nThis version performs the same function as Dropout, however it drops\n entire 2D feature maps instead of individual elements. If adjacent pixels\n within feature maps are strongly correlated (as is normally the case in\n early convolution layers) then regular dropout will not regularize the\n activations and will otherwise just result in an effective learning rate\n decrease. In this case, SpatialDropout2D will help promote independence\n between feature maps and should be used instead.\n\n\n\n\nparam initP the probability p\n\n\nparam format  'NCHW' or 'NHWC'.\n            In 'NCHW' mode, the channels dimension (the depth)\n            is at index 1, in 'NHWC' mode is it at index 4.\n\n\n\n\nScala example:\n\n\n    val module = SpatialDropout2D[Double](0.7)\n    val input = Tensor[Double](2, 3, 4, 5)\n    val seed = 100\n\n    input.rand()\n\n    RNG.setSeed(seed)\n    val output = module.forward(input)\n    \n println(output)\n    (1,1,.,.) =\n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n\n    (1,2,.,.) =\n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n\n    (1,3,.,.) =\n    0.9125777170993388  0.828888057731092   0.3860199467744678  0.4881938952021301  0.3932550342287868  \n    0.3380460755433887  0.32206087466329336 0.9833535915240645  0.7536576387938112  0.6055934554897249  \n    0.34218871919438243 0.045394203858450055    0.03498578444123268 0.6890419721603394  0.12134534679353237 \n    0.3766667563468218  0.8550574257969856  0.16245933924801648 0.8359398010652512  0.9934550793841481  \n\n    (2,1,.,.) =\n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n\n    (2,2,.,.) =\n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n\n    (2,3,.,.) =\n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n\n    [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4x5]\n\n\n    val gradInput = module.backward(input, input.clone().fill(1))\n    \n println(gradInput)\n    (1,1,.,.) =\n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n\n    (1,2,.,.) =## SpatialDropout2D ##\n\n**Scala:**\n```scala\nval module = SpatialDropout2D(initP = 0.5, format = DataFormat.NCHW)\n\n\n\n\nPython:\n\n\nmodule = SpatialDropout2D(\n  init_p=0.5, data_format=\nNCHW\n)\n\n\n\n\nThis version performs the same function as Dropout, however it drops\n entire 2D feature maps instead of individual elements. If adjacent pixels\n within feature maps are strongly correlated (as is normally the case in\n early convolution layers) then regular dropout will not regularize the\n activations and will otherwise just result in an effective learning rate\n decrease. In this case, SpatialDropout2D will help promote independence\n between feature maps and should be used instead.\n\n\n\n\nparam initP the probability p\n\n\n\n\nparam format  'NCHW' or 'NHWC'.\n            In 'NCHW' mode, the channels dimension (the depth)\n            is at index 1, in 'NHWC' mode is it at index 4.\n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n\n\n(1,3,.,.) =\n1.0 1.0 1.0 1.0 1.0 \n1.0 1.0 1.0 1.0 1.0 \n1.0 1.0 1.0 1.0 1.0 \n1.0 1.0 1.0 1.0 1.0 \n\n\n(2,1,.,.) =\n0.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0 \n\n\n(2,2,.,.) =\n0.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0 \n\n\n(2,3,.,.) =\n0.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0 \n\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4x5]\n\n\n\n\n\n\n\n\n**Python example:**\n```python\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = SpatialDropout1D(0.7)\nx = np.arange(3, 4, 5)\n\nprint(module.forward(x))\nprint(module.backward(x, x.copy() * 0.5)) # backward drops out the gradients at the same location.\n\n\n\n\nOutput is\n\n\noutput:\n[[[0.0  0.0 0.0 0.0 0.0]\n    [0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]]\n\n   [[0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]]\n\n   [[0.9125777170993388 0.828888057731092   0.3860199467744678  0.4881938952021301  0.3932550342287868] \n    [0.3380460755433887 0.32206087466329336 0.9833535915240645  0.7536576387938112  0.6055934554897249]\n    [0.34218871919438243    0.045394203858450055    0.03498578444123268 0.6890419721603394  0.12134534679353237]\n    [0.3766667563468218 0.8550574257969856  0.16245933924801648 0.8359398010652512  0.9934550793841481]\n\n   [[0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]]\n\n   [[0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]]\n\n   [[0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]]]  \n\n\ngradInput:\n [[[0.0 0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]]\n\n    [[0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]]\n\n    [[1.0   1.0 1.0 1.0 1.0]    \n     [1.0   1.0 1.0 1.0 1.0]    \n     [1.0   1.0 1.0 1.0 1.0]    \n     [1.0   1.0 1.0 1.0 1.0]]\n\n    [[0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]]\n\n    [[0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]]\n\n    [[0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]]]\n\n\n\n\nSpatialDropout3D\n\n\nScala:\n\n\nval module = SpatialDropout3D(initP = 0.5, format = DataFormat.NCHW)\n\n\n\n\nPython:\n\n\nmodule = SpatialDropout3D(\n  init_p=0.5, data_format=\nNCHW\n)\n\n\n\n\nThis version performs the same function as Dropout, however it drops\n entire 3D feature maps instead of individual elements. If adjacent voxels\n within feature maps are strongly correlated (as is normally the case in\n early convolution layers) then regular dropout will not regularize the\n activations and will otherwise just result in an effective learning rate\n decrease. In this case, SpatialDropout3D will help promote independence\n between feature maps and should be used instead.\n\n\n\n\ninitP\n the probability p\n\n\nformat\n  'NCHW' or 'NHWC'.\n               In 'NCHW' mode, the channels dimension (the depth)\n               is at index 1, in 'NHWC' mode is it at index 4.\n```", 
            "title": "Dropout Layers"
        }, 
        {
            "location": "/APIGuide/Layers/Dropout-Layers/#dropout", 
            "text": "Scala:  val module = Dropout(\n  initP = 0.5,\n  inplace = false,\n  scale = true)  Python:  module = Dropout(\n  init_p=0.5,\n  inplace=False,\n  scale=True)  Dropout masks(set to zero) parts of input using a Bernoulli distribution.\nEach input element has a probability  initP  of being dropped. If  scale  is\ntrue(true by default), the outputs are scaled by a factor of  1/(1-initP)  during training.\nDuring evaluating, output is the same as input.  It has been proven an effective approach for regularization and preventing\nco-adaptation of feature detectors. For more details, please see\n[Improving neural networks by preventing co-adaptation of feature detectors]\n(https://arxiv.org/abs/1207.0580)  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = Dropout()\nval x = Tensor.range(1, 8, 1).resize(2, 4)\n\nprintln(module.forward(x))\nprintln(module.backward(x, x.clone().mul(0.5f))) // backward drops out the gradients at the same location.  Output is  com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.0     4.0     6.0     0.0\n10.0    12.0    0.0     16.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]\n\ncom.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.0    2.0    3.0    0.0\n5.0    6.0    0.0    8.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Dropout()\nx = np.arange(1, 9, 1).reshape(2, 4)\n\nprint(module.forward(x))\nprint(module.backward(x, x.copy() * 0.5)) # backward drops out the gradients at the same location.  Output is  [array([[ 0.,  4.,  6.,  0.],\n       [ 0.,  0.,  0.,  0.]], dtype=float32)]\n\n[array([[ 0.,  2.,  3.,  0.],\n       [ 0.,  0.,  0.,  0.]], dtype=float32)]", 
            "title": "Dropout"
        }, 
        {
            "location": "/APIGuide/Layers/Dropout-Layers/#gaussiandropout", 
            "text": "Scala:  val module = GaussianDropout(rate)  Python:  module = GaussianDropout(rate)  Apply multiplicative 1-centered Gaussian noise.\nAs it is a regularization layer, it is only active at training time.   rate  is drop probability (as with  Dropout ).   Reference:  Dropout: A Simple Way to Prevent Neural Networks from Overfitting Srivastava, Hinton, et al. 2014  Scala example:  scala  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nscala  val layer = GaussianDropout(0.5)\n2017-11-27 14:03:48 INFO  ThreadPool$:79 - Set mkl threads to 1 on thread 1\nlayer: com.intel.analytics.bigdl.nn.GaussianDropout[Float] = GaussianDropout[668c68cd](0.5)\n\nscala  layer.training()\nres0: layer.type = GaussianDropout[668c68cd](0.5)\n\nscala  val input = Tensor(T(T(1.0,1.0,1.0),T(1.0,1.0,1.0)))\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0     1.0     1.0\n1.0     1.0     1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nscala  val output = layer.forward(input)\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.1833225       1.1171452       0.27325004\n0.436912        0.9357152       0.47588816\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nscala  val gradout = Tensor(T(T(1.0,1.0,1.0),T(1.0,1.0,1.0)))\ngradout: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0     1.0     1.0\n1.0     1.0     1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nscala  val gradin = layer.backward(input,gradout)\ngradin: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.4862849       1.0372512       0.91885364\n-0.18087652     2.3662233       0.9388555\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nscala  layer.evaluate()\nres1: layer.type = GaussianDropout[668c68cd](0.5)\n\nscala  val output = layer.forward(input)\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0     1.0     1.0\n1.0     1.0     1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]  Python example:  layer = GaussianDropout(0.5) # Try to create a Linear layer\n\n#training mode\nlayer.training()\ninp=np.ones([2,1])\noutp = layer.forward(inp)\n\ngradoutp = np.ones([2,1])\ngradinp = layer.backward(inp,gradoutp)\nprint  training:forward= ,outp\nprint  trainig:backward= ,gradinp\n\n#evaluation mode\nlayer.evaluate()\nprint  evaluate:forward= ,layer.forward(inp)  Output is  creating: createGaussianDropout\ntraining:forward= [[ 0.80695641]\n [ 1.82794702]]\ntrainig:backward= [[ 0.1289842 ]\n [ 1.22549391]]\nevaluate:forward= [[ 1.]\n [ 1.]]", 
            "title": "GaussianDropout"
        }, 
        {
            "location": "/APIGuide/Layers/Dropout-Layers/#gaussiannoise", 
            "text": "Scala:  val module = GaussianNoise(stddev)  Python:  module = GaussianNoise(stddev)  Apply additive zero-centered Gaussian noise. This is useful to mitigate overfitting (you could see it as a form of random data augmentation).\nGaussian Noise (GS) is a natural choice as corruption process for real valued inputs.  As it is a regularization layer, it is only active at training time.   stddev  is the standard deviation of the noise distribution.   Scala example:  scala  val layer = GaussianNoise(0.2)\nlayer: com.intel.analytics.bigdl.nn.GaussianNoise[Float] = GaussianNoise[77daa92e](0.2)\n\nscala  layer.training()\nres3: layer.type = GaussianNoise[77daa92e](0.2)\n\nscala  val input = Tensor(T(T(1.0,1.0,1.0),T(1.0,1.0,1.0)))\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0     1.0     1.0\n1.0     1.0     1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nscala  val output = layer.forward(input)\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.263781        0.91440135      0.928574\n0.88923925      1.1450694       0.97276205\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nscala  val gradout = Tensor(T(T(1.0,1.0,1.0),T(1.0,1.0,1.0)))\ngradout: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0     1.0     1.0\n1.0     1.0     1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nscala  val gradin = layer.backward(input,gradout)\ngradin: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0     1.0     1.0\n1.0     1.0     1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]\n\nscala  layer.evaluate()\nres2: layer.type = GaussianNoise[77daa92e](0.2)\n\nscala  val output = layer.forward(input)\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0     1.0     1.0\n1.0     1.0     1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x3]  Python example:  layer = GaussianNoise(0.5) \n\n#training mode\nlayer.training()\ninp=np.ones([2,1])\noutp = layer.forward(inp)\n\ngradoutp = np.ones([2,1])\ngradinp = layer.backward(inp,gradoutp)\nprint  training:forward= ,outp\nprint  trainig:backward= ,gradinp\n\n#evaluation mode\nlayer.evaluate()\nprint  evaluate:forward= ,layer.forward(inp)  Output is  creating: createGaussianNoise\ntraining:forward= [[ 0.99984151]\n [ 1.11269045]]\ntrainig:backward= [[ 1.]\n [ 1.]]\nevaluate:forward= [[ 1.]\n [ 1.]]", 
            "title": "GaussianNoise"
        }, 
        {
            "location": "/APIGuide/Layers/Dropout-Layers/#spatialdropout1d", 
            "text": "Scala:  val module = SpatialDropout1D(initP = 0.5)  Python:  module = SpatialDropout1D(\n  init_p=0.5)  This version performs the same function as Dropout, however it drops\n   entire 1D feature maps instead of individual elements. If adjacent frames\n   within feature maps are strongly correlated (as is normally the case in\n   early convolution layers) then regular dropout will not regularize the\n   activations and will otherwise just result in an effective learning rate\n   decrease. In this case, SpatialDropout1D will help promote independence\n   between feature maps and should be used instead.   initP  the probability p   Scala example:      val module = SpatialDropout1D[Double](0.7)\n    val input = Tensor[Double](3, 4, 5)\n    val seed = 100\n\n    input.rand()\n\n    RNG.setSeed(seed)\n    val output = module.forward(input)\n      println(output)\n    (1,.,.) =\n    0.0 0.0 0.8925298328977078  0.0 0.0 \n    0.0 0.0 0.8951127317268401  0.0 0.0 \n    0.0 0.0 0.425491401925683   0.0 0.0 \n    0.0 0.0 0.31143878563307226 0.0 0.0 \n\n    (2,.,.) =\n    0.0 0.0 0.06833203043788671 0.5629170550964773  0.49213682673871517 \n    0.0 0.0 0.5263364950660616  0.5756838673260063  0.060498124454170465    \n    0.0 0.0 0.8886410375125706  0.539079936221242   0.4533065736759454  \n    0.0 0.0 0.8942249100655317  0.5489360291976482  0.05561425327323377 \n\n    (3,.,.) =\n    0.007322707446292043    0.07132467231713235 0.0 0.3080112475436181  0.0 \n    0.8506345122586936  0.383204679004848   0.0 0.9952241901773959  0.0 \n    0.6507184051442891  0.20175716653466225 0.0 0.28786351275630295 0.0 \n    0.19677149993367493 0.3048216907773167  0.0 0.5715036438778043  0.0 \n\n    [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x5]\n\n    val gradInput = module.backward(input, input.clone().fill(1))\n      println(gradInput)\n    (1,.,.) =\n    0.0 0.0 1.0 0.0 0.0 \n    0.0 0.0 1.0 0.0 0.0 \n    0.0 0.0 1.0 0.0 0.0 \n    0.0 0.0 1.0 0.0 0.0 \n\n    (2,.,.) =\n    0.0 0.0 1.0 1.0 1.0 \n    0.0 0.0 1.0 1.0 1.0 \n    0.0 0.0 1.0 1.0 1.0 \n    0.0 0.0 1.0 1.0 1.0 \n\n    (3,.,.) =\n    1.0 1.0 0.0 1.0 0.0 \n    1.0 1.0 0.0 1.0 0.0 \n    1.0 1.0 0.0 1.0 0.0 \n    1.0 1.0 0.0 1.0 0.0 \n\n    [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x5]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = SpatialDropout1D(0.7)\nx = np.arange(3, 4, 5)\n\nprint(module.forward(x))\nprint(module.backward(x, x.copy() * 0.5)) # backward drops out the gradients at the same location.  Output is   [[[0.0 0.0 0.8925298328977078  0.0 0.0]    \n    [0.0    0.0 0.8951127317268401  0.0 0.0]    \n    [0.0    0.0 0.425491401925683   0.0 0.0]    \n    [0.0    0.0 0.31143878563307226 0.0 0.0]]   \n\n    [0.0    0.0 0.06833203043788671 0.5629170550964773  0.49213682673871517 ]   \n    [0.0    0.0 0.5263364950660616  0.5756838673260063  0.060498124454170465 ]  \n    [0.0    0.0 0.8886410375125706  0.539079936221242   0.4533065736759454 ]    \n    [0.0    0.0 0.8942249100655317  0.5489360291976482  0.05561425327323377 ]]\n\n    [0.007322707446292043   0.07132467231713235 0.0 0.3080112475436181  0.0 ]   \n    [0.8506345122586936 0.383204679004848   0.0 0.9952241901773959  0.0 ]   \n    [0.6507184051442891 0.20175716653466225 0.0 0.28786351275630295 0.0 ]   \n    [0.19677149993367493    0.3048216907773167  0.0 0.5715036438778043  0.0]]]\n\n\n     [[[0.0 0.0 1.0 0.0 0.0]\n        [0.0 0.0 1.0 0.0 0.0]   \n        [0.0 0.0 1.0 0.0 0.0]   \n        [0.0 0.0 1.0 0.0 0.0]]\n\n       [[0.0 0.0 1.0 1.0 1.0]   \n        [0.0 0.0 1.0 1.0 1.0]   \n        [0.0 0.0 1.0 1.0 1.0]   \n        [0.0 0.0 1.0 1.0 1.0]]\n\n       [[1.0 1.0 0.0 1.0 0.0]   \n        [1.0 1.0 0.0 1.0 0.0]   \n        [1.0 1.0 0.0 1.0 0.0]   \n        [1.0 1.0 0.0 1.0 0.0]]]", 
            "title": "SpatialDropout1D"
        }, 
        {
            "location": "/APIGuide/Layers/Dropout-Layers/#spatialdropout2d", 
            "text": "Scala:  val module = SpatialDropout2D(initP = 0.5, format = DataFormat.NCHW)  Python:  module = SpatialDropout2D(\n  init_p=0.5, data_format= NCHW )  This version performs the same function as Dropout, however it drops\n entire 2D feature maps instead of individual elements. If adjacent pixels\n within feature maps are strongly correlated (as is normally the case in\n early convolution layers) then regular dropout will not regularize the\n activations and will otherwise just result in an effective learning rate\n decrease. In this case, SpatialDropout2D will help promote independence\n between feature maps and should be used instead.   param initP the probability p  param format  'NCHW' or 'NHWC'.\n            In 'NCHW' mode, the channels dimension (the depth)\n            is at index 1, in 'NHWC' mode is it at index 4.   Scala example:      val module = SpatialDropout2D[Double](0.7)\n    val input = Tensor[Double](2, 3, 4, 5)\n    val seed = 100\n\n    input.rand()\n\n    RNG.setSeed(seed)\n    val output = module.forward(input)\n      println(output)\n    (1,1,.,.) =\n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n\n    (1,2,.,.) =\n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n\n    (1,3,.,.) =\n    0.9125777170993388  0.828888057731092   0.3860199467744678  0.4881938952021301  0.3932550342287868  \n    0.3380460755433887  0.32206087466329336 0.9833535915240645  0.7536576387938112  0.6055934554897249  \n    0.34218871919438243 0.045394203858450055    0.03498578444123268 0.6890419721603394  0.12134534679353237 \n    0.3766667563468218  0.8550574257969856  0.16245933924801648 0.8359398010652512  0.9934550793841481  \n\n    (2,1,.,.) =\n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n\n    (2,2,.,.) =\n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n\n    (2,3,.,.) =\n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n\n    [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4x5]\n\n\n    val gradInput = module.backward(input, input.clone().fill(1))\n      println(gradInput)\n    (1,1,.,.) =\n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n\n    (1,2,.,.) =## SpatialDropout2D ##\n\n**Scala:**\n```scala\nval module = SpatialDropout2D(initP = 0.5, format = DataFormat.NCHW)  Python:  module = SpatialDropout2D(\n  init_p=0.5, data_format= NCHW )  This version performs the same function as Dropout, however it drops\n entire 2D feature maps instead of individual elements. If adjacent pixels\n within feature maps are strongly correlated (as is normally the case in\n early convolution layers) then regular dropout will not regularize the\n activations and will otherwise just result in an effective learning rate\n decrease. In this case, SpatialDropout2D will help promote independence\n between feature maps and should be used instead.   param initP the probability p   param format  'NCHW' or 'NHWC'.\n            In 'NCHW' mode, the channels dimension (the depth)\n            is at index 1, in 'NHWC' mode is it at index 4.\n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0 \n    0.0 0.0 0.0 0.0 0.0   (1,3,.,.) =\n1.0 1.0 1.0 1.0 1.0 \n1.0 1.0 1.0 1.0 1.0 \n1.0 1.0 1.0 1.0 1.0 \n1.0 1.0 1.0 1.0 1.0   (2,1,.,.) =\n0.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0   (2,2,.,.) =\n0.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0   (2,3,.,.) =\n0.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0   [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4x5]    \n\n**Python example:**\n```python\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = SpatialDropout1D(0.7)\nx = np.arange(3, 4, 5)\n\nprint(module.forward(x))\nprint(module.backward(x, x.copy() * 0.5)) # backward drops out the gradients at the same location.  Output is  output:\n[[[0.0  0.0 0.0 0.0 0.0]\n    [0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]]\n\n   [[0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]]\n\n   [[0.9125777170993388 0.828888057731092   0.3860199467744678  0.4881938952021301  0.3932550342287868] \n    [0.3380460755433887 0.32206087466329336 0.9833535915240645  0.7536576387938112  0.6055934554897249]\n    [0.34218871919438243    0.045394203858450055    0.03498578444123268 0.6890419721603394  0.12134534679353237]\n    [0.3766667563468218 0.8550574257969856  0.16245933924801648 0.8359398010652512  0.9934550793841481]\n\n   [[0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]]\n\n   [[0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]]\n\n   [[0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]    \n    [0.0    0.0 0.0 0.0 0.0]]]  \n\n\ngradInput:\n [[[0.0 0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]]\n\n    [[0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]]\n\n    [[1.0   1.0 1.0 1.0 1.0]    \n     [1.0   1.0 1.0 1.0 1.0]    \n     [1.0   1.0 1.0 1.0 1.0]    \n     [1.0   1.0 1.0 1.0 1.0]]\n\n    [[0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]]\n\n    [[0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]]\n\n    [[0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]    \n     [0.0   0.0 0.0 0.0 0.0]]]", 
            "title": "SpatialDropout2D"
        }, 
        {
            "location": "/APIGuide/Layers/Dropout-Layers/#spatialdropout3d", 
            "text": "Scala:  val module = SpatialDropout3D(initP = 0.5, format = DataFormat.NCHW)  Python:  module = SpatialDropout3D(\n  init_p=0.5, data_format= NCHW )  This version performs the same function as Dropout, however it drops\n entire 3D feature maps instead of individual elements. If adjacent voxels\n within feature maps are strongly correlated (as is normally the case in\n early convolution layers) then regular dropout will not regularize the\n activations and will otherwise just result in an effective learning rate\n decrease. In this case, SpatialDropout3D will help promote independence\n between feature maps and should be used instead.   initP  the probability p  format   'NCHW' or 'NHWC'.\n               In 'NCHW' mode, the channels dimension (the depth)\n               is at index 1, in 'NHWC' mode is it at index 4.\n```", 
            "title": "SpatialDropout3D"
        }, 
        {
            "location": "/APIGuide/Layers/Distance-Layers/", 
            "text": "PairwiseDistance\n\n\nScala:\n\n\nval pd = PairwiseDistance(norm=2)\n\n\n\n\nPython:\n\n\npd = PairwiseDistance(norm=2)\n\n\n\n\nIt is a module that takes a table of two vectors as input and outputs\nthe distance between them using the p-norm.\nThe input given in \nforward(input)\n is a [[Table]] that contains two tensors which\nmust be either a vector (1D tensor) or matrix (2D tensor). If the input is a vector,\nit must have the size of \ninputSize\n. If it is a matrix, then each row is assumed to be\nan input sample of the given batch (the number of rows means the batch size and\nthe number of columns should be equal to the \ninputSize\n).\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.PairwiseDistance\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval pd = PairwiseDistance()\nval input1 = Tensor(3, 3).randn()\nval input2 = Tensor(3, 3).randn()\nval input = T(1 -\n input1, 2 -\n input2)\n\nval output = pd.forward(input)\n\nval gradOutput = Tensor(3).randn()\nval gradInput = pd.backward(input, gradOutput)\n\n\n\n\n\nThe ouotput is,\n\n\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n4.155246\n1.1267666\n2.1415536\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\ngradOutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.32565984\n-1.0108998\n-0.030873261\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n\n\n\n\nThe gradInput is,\n\n\ngradInput: com.intel.analytics.bigdl.utils.Table =\n {\n        2: 0.012723052  0.31482473      0.08232752\n           0.7552968    -0.27292773     -0.6139655\n           0.0062761847 -0.018232936    -0.024110721\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n        1: -0.012723052 -0.31482473     -0.08232752\n           -0.7552968   0.27292773      0.6139655\n           -0.0062761847        0.018232936     0.024110721\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n }\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\npd = PairwiseDistance()\n\ninput1 = np.random.uniform(0, 1, [3, 3]).astype(\nfloat32\n)\ninput2 = np.random.uniform(0, 1, [3, 3]).astype(\nfloat32\n)\ninput1 = input1.reshape(3, 3)\ninput2 = input2.reshape(3, 3)\n\ninput = [input1, input2]\n\noutput = pd.forward(input)\nprint output\n\ngradOutput = np.random.uniform(0, 1, [3]).astype(\nfloat32\n)\ngradOutput = gradOutput.reshape(3)\n\ngradInput = pd.backward(input, gradOutput)\nprint gradInput\n\n\n\n\nThe output is,\n\n\n[ 0.99588805  0.65620303  1.11735415]\n\n\n\n\nThe gradInput is,\n\n\n[array([[-0.27412388,  0.32756016, -0.02032043],\n       [-0.16920818,  0.60189474,  0.21347123],\n       [ 0.57771122,  0.28602061,  0.58044904]], dtype=float32), array([[ 0.27412388, -0.32756016,  0.02032043],\n       [ 0.16920818, -0.60189474, -0.21347123],\n       [-0.57771122, -0.28602061, -0.58044904]], dtype=float32)]\n\n\n\n\nCosineDistance\n\n\nScala:\n\n\nval module = CosineDistance()\n\n\n\n\nPython:\n\n\nmodule = CosineDistance()\n\n\n\n\nCosineDistance creates a module that takes a table of two vectors (or matrices if in batch mode) as input and outputs the cosine distance between them.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = CosineDistance()\nval t1 = Tensor().range(1, 3)\nval t2 = Tensor().range(4, 6)\nval input = T(t1, t2)\nval output = module.forward(input)\n\n\n input\ninput: com.intel.analytics.bigdl.utils.Table =\n {\n    2: 4.0\n       5.0\n       6.0\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n    1: 1.0\n       2.0\n       3.0\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n }\n\n\n output\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.9746319\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = CosineDistance()\nt1 = np.array([1.0, 2.0, 3.0])\nt2 = np.array([4.0, 5.0, 6.0])\ninput = [t1, t2]\noutput = module.forward(input)\n\n\n input\n[array([ 1.,  2.,  3.]), array([ 4.,  5.,  6.])]\n\n\n output\n[ 0.97463191]\n\n\n\n\nEuclidean\n\n\nScala:\n\n\nval module = Euclidean(\n  inputSize,\n  outputSize,\n  fastBackward = true)\n\n\n\n\nPython:\n\n\nmodule = Euclidean(\n  input_size,\n  output_size,\n  fast_backward=True)\n\n\n\n\nOutputs the Euclidean distance of the input to \noutputSize\n centers.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = Euclidean(3, 3)\n\nprintln(module.forward(Tensor.range(1, 3, 1)))\n\n\n\n\nOutput is\n\n\ncom.intel.analytics.bigdl.tensor.Tensor[Float] =\n4.0323668\n3.7177157\n3.8736997\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Euclidean(3, 3)\n\nprint(module.forward(np.arange(1, 4, 1)))\n\n\n\n\nOutput is\n\n\n[array([ 3.86203027,  4.02212906,  3.2648952 ], dtype=float32)]", 
            "title": "Distance Layers"
        }, 
        {
            "location": "/APIGuide/Layers/Distance-Layers/#pairwisedistance", 
            "text": "Scala:  val pd = PairwiseDistance(norm=2)  Python:  pd = PairwiseDistance(norm=2)  It is a module that takes a table of two vectors as input and outputs\nthe distance between them using the p-norm.\nThe input given in  forward(input)  is a [[Table]] that contains two tensors which\nmust be either a vector (1D tensor) or matrix (2D tensor). If the input is a vector,\nit must have the size of  inputSize . If it is a matrix, then each row is assumed to be\nan input sample of the given batch (the number of rows means the batch size and\nthe number of columns should be equal to the  inputSize ).  Scala example:  import com.intel.analytics.bigdl.nn.PairwiseDistance\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval pd = PairwiseDistance()\nval input1 = Tensor(3, 3).randn()\nval input2 = Tensor(3, 3).randn()\nval input = T(1 -  input1, 2 -  input2)\n\nval output = pd.forward(input)\n\nval gradOutput = Tensor(3).randn()\nval gradInput = pd.backward(input, gradOutput)  The ouotput is,  output: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n4.155246\n1.1267666\n2.1415536\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\ngradOutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.32565984\n-1.0108998\n-0.030873261\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]  The gradInput is,  gradInput: com.intel.analytics.bigdl.utils.Table =\n {\n        2: 0.012723052  0.31482473      0.08232752\n           0.7552968    -0.27292773     -0.6139655\n           0.0062761847 -0.018232936    -0.024110721\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n        1: -0.012723052 -0.31482473     -0.08232752\n           -0.7552968   0.27292773      0.6139655\n           -0.0062761847        0.018232936     0.024110721\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n }  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\npd = PairwiseDistance()\n\ninput1 = np.random.uniform(0, 1, [3, 3]).astype( float32 )\ninput2 = np.random.uniform(0, 1, [3, 3]).astype( float32 )\ninput1 = input1.reshape(3, 3)\ninput2 = input2.reshape(3, 3)\n\ninput = [input1, input2]\n\noutput = pd.forward(input)\nprint output\n\ngradOutput = np.random.uniform(0, 1, [3]).astype( float32 )\ngradOutput = gradOutput.reshape(3)\n\ngradInput = pd.backward(input, gradOutput)\nprint gradInput  The output is,  [ 0.99588805  0.65620303  1.11735415]  The gradInput is,  [array([[-0.27412388,  0.32756016, -0.02032043],\n       [-0.16920818,  0.60189474,  0.21347123],\n       [ 0.57771122,  0.28602061,  0.58044904]], dtype=float32), array([[ 0.27412388, -0.32756016,  0.02032043],\n       [ 0.16920818, -0.60189474, -0.21347123],\n       [-0.57771122, -0.28602061, -0.58044904]], dtype=float32)]", 
            "title": "PairwiseDistance"
        }, 
        {
            "location": "/APIGuide/Layers/Distance-Layers/#cosinedistance", 
            "text": "Scala:  val module = CosineDistance()  Python:  module = CosineDistance()  CosineDistance creates a module that takes a table of two vectors (or matrices if in batch mode) as input and outputs the cosine distance between them.  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = CosineDistance()\nval t1 = Tensor().range(1, 3)\nval t2 = Tensor().range(4, 6)\nval input = T(t1, t2)\nval output = module.forward(input)  input\ninput: com.intel.analytics.bigdl.utils.Table =\n {\n    2: 4.0\n       5.0\n       6.0\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n    1: 1.0\n       2.0\n       3.0\n       [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n }  output\noutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.9746319\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = CosineDistance()\nt1 = np.array([1.0, 2.0, 3.0])\nt2 = np.array([4.0, 5.0, 6.0])\ninput = [t1, t2]\noutput = module.forward(input)  input\n[array([ 1.,  2.,  3.]), array([ 4.,  5.,  6.])]  output\n[ 0.97463191]", 
            "title": "CosineDistance"
        }, 
        {
            "location": "/APIGuide/Layers/Distance-Layers/#euclidean", 
            "text": "Scala:  val module = Euclidean(\n  inputSize,\n  outputSize,\n  fastBackward = true)  Python:  module = Euclidean(\n  input_size,\n  output_size,\n  fast_backward=True)  Outputs the Euclidean distance of the input to  outputSize  centers.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = Euclidean(3, 3)\n\nprintln(module.forward(Tensor.range(1, 3, 1)))  Output is  com.intel.analytics.bigdl.tensor.Tensor[Float] =\n4.0323668\n3.7177157\n3.8736997\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Euclidean(3, 3)\n\nprint(module.forward(np.arange(1, 4, 1)))  Output is  [array([ 3.86203027,  4.02212906,  3.2648952 ], dtype=float32)]", 
            "title": "Euclidean"
        }, 
        {
            "location": "/APIGuide/Layers/Recurrent-Layers/", 
            "text": "Recurrent\n\n\nScala:\n\n\nval module = Recurrent()\n\n\n\n\nPython:\n\n\nmodule = Recurrent()\n\n\n\n\nRecurrent module is a container of rnn cells. Different types of rnn cells can be added using add() function.  \n\n\nRecurrent supports returning state and cell of its rnn cells at last time step by using getHiddenState. output of getHiddenState\nis an Activity.\n\n\nIf contained cell is simple rnn, getHiddenState return value is a tensor(hidden state) which is \nbatch x hiddenSize\n.\n\nIf contained cell is lstm, getHiddenState return value is a table [hidden state, cell], both size is \nbatch x hiddenSize\n.\n\nIf contained cell is convlstm, getHiddenState return value is a table [hidden state, cell], both size is \nbatch x outputPlane x height x width\n.\n\nIf contained cell is convlstm3D, getHiddenState return value is a table [hidden state, cell], both size is \nbatch x outputPlane x height x width x length\n.\n\n\nRecurrent also support init hidden state by using setHiddenState, currently only scala version. After we get hidden state from getHiddenState, we can directly used it in setHiddenState, which will set hidden state and cell at the first time step.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.RandomGenerator.RNG\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval hiddenSize = 4\nval inputSize = 5\nval module = Recurrent().add(RnnCell(inputSize, hiddenSize, Tanh()))\nval input = Tensor(Array(1, 5, inputSize))\nfor (i \n- 1 to 5) {\n  val rdmInput = Math.ceil(RNG.uniform(0.0, 1.0)*inputSize).toInt\n  input.setValue(1, i, rdmInput, 1.0f)\n}\n\nval output = module.forward(input)\n\nval state = module.getHiddenState()\nmodule.setHiddenState(state)\n\n\n input\n(1,.,.) =\n0.0 0.0 0.0 1.0 0.0 \n0.0 0.0 0.0 0.0 1.0 \n0.0 1.0 0.0 0.0 0.0 \n0.0 1.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 1.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x5x5]\n\n\n output\n(1,.,.) =\n0.23312 -0.5702369  -0.29894134 -0.46780553 \n-0.020703634    -0.6821252  -0.71641463 -0.3367952  \n0.031236319 -0.29233444 -0.730908   0.13494356  \n-0.22310422 -0.25562853 -0.59091455 -0.25055867 \n0.007001166 -0.7096118  -0.778529   -0.47429603 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x4]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nhiddenSize = 4\ninputSize = 5\nmodule = Recurrent().add(RnnCell(inputSize, hiddenSize, Tanh()))\ninput = np.zeros((1, 5, 5))\ninput[0][0][4] = 1\ninput[0][1][0] = 1\ninput[0][2][4] = 1\ninput[0][3][3] = 1\ninput[0][4][0] = 1\n\noutput = module.forward(input)\n\nres = module.get_hidden_state()\n\n\n input\n[[[ 0.  0.  0.  0.  1.]\n  [ 1.  0.  0.  0.  0.]\n  [ 0.  0.  0.  0.  1.]\n  [ 0.  0.  0.  1.  0.]\n  [ 1.  0.  0.  0.  0.]]]\n\n\n output\n[[[-0.43169451 -0.27838707  0.41472727  0.4450382 ]\n  [-0.10717546  0.59218317  0.67959404  0.62824875]\n  [-0.56745911 -0.31170678  0.44158491  0.31494498]\n  [ 0.13328044  0.41262615  0.37388939  0.10983802]\n  [-0.51452565  0.13222042  0.59192103  0.8393243 ]]]\n\n\n\n\n\n\n\nBiRecurrent\n\n\nScala:\n\n\nval module = BiRecurrent(merge=null)\n\n\n\n\nPython:\n\n\nmodule = BiRecurrent(merge=None,bigdl_type=\nfloat\n)\n\n\n\n\nThis layer implement a bidirectional recurrent neural network\n\n\n\n\nmerge\n concat or add the output tensor of the two RNNs. Default is add\n\n\n\n\nScala example:\n\n\nval module = BiRecurrent(CAddTable())\n.add(RnnCell(6, 4, Sigmoid()))\nval input = Tensor(Array(1, 2, 6)).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.55511624      0.44330198      0.9025551       0.26096714      0.3434667       0.20060952\n0.24903035      0.24026379      0.89252585      0.23025699      0.8131796       0.4013688\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x2x6]\n\nmodule.forward(input)\nres10: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.3577285       0.8861933       0.52908427      0.86278\n1.2850789       0.82549953      0.5560188       0.81468254\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4]\n\n\n\n\nPython example:\n\n\nmodule = BiRecurrent(CAddTable()).add(RnnCell(6, 4, Sigmoid()))\ninput = np.random.rand(1, 2, 6)\narray([[[ 0.75637438,  0.2642816 ,  0.61973312,  0.68565282,  0.73571443,\n          0.17167681],\n        [ 0.16439321,  0.06853251,  0.42257202,  0.42814042,  0.15706152,\n          0.57866659]]])\n\nmodule.forward(input)\narray([[[ 0.69091094,  0.97150528,  0.9562254 ,  1.14894259],\n        [ 0.83814102,  1.11358368,  0.96752423,  1.00913286]]], dtype=float32)\n\n\n\n\n\n\nRecurrentDecoder\n\n\nScala:\n\n\nval module = RecurrentDecoder(outputLength = 5)\n\n\n\n\nPython:\n\n\nmodule = RecurrentDecoder(output_length = 5)\n\n\n\n\nRecurrentDecoder module is a container of rnn cells which used to make\na prediction of the next timestep based on the prediction we made from\nthe previous timestep.\n\n\nInput for RecurrentDecoder has to be batch x stepShape(shape of the input at a single time step). \n\n\nDuring training, input at t(i) is output at t(i-1), input at t(0) is\nuser input.\n\n\nOutput for RecurrentDecoder has to be batch x outputLen x shape.\n\n\nWith RecurrentDecoder, inputsize and hiddensize of the cell must be the same.\n\n\nDifferent types of rnn cells can be added using add() function.\n\n\nParameters:\n\n\n\n\noutputLength\n sequence length of output\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.RandomGenerator.RNG\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval hiddenSize = 4\nval inputSize = 4\nval batchSize = 2\nval module = RecurrentDecoder(5).add(LSTMPeephole(inputSize, hiddenSize))\nval input = Tensor(Array(batchSize, inputSize)).rand()\n\nval output = module.forward(input)\n\n\n input\n0.32985476  0.5081215   0.95177317  0.24744023  \n0.030384725 0.4868633   0.7781735   0.8046177   \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x4]\n\n\n output\n(1,.,.) =\n-0.055717956    -0.14357334 0.011429226 0.10056843  \n-0.013699859    -0.078585915    0.050289743 0.027037282 \n0.011173044 -0.07941696 0.07381668  0.0020067326    \n0.016142089 -0.081511036    0.08775896  -0.011746041    \n0.0149942655    -0.08317861 0.09522702  -0.018894192    \n\n(2,.,.) =\n-0.041173447    -0.10931831 -0.04198869 0.1287807   \n0.010115819 -0.07071178 0.011613955 0.04737701  \n0.027745798 -0.07493171 0.054053202 0.010752724 \n0.02633817  -0.07929653 0.07783712  -0.008406129    \n0.020732995 -0.08214355 0.09030104  -0.017894702    \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5x4]\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nhidden_size = 4\ninput_size = 4\nbatch_size = 2\nmodule = RecurrentDecoder(5).add(LSTMPeephole(input_size, hidden_size))\ninput = np.random.randn(batch_size, input_size)\n\noutput = module.forward(input)\n\n\n input\n[[ 0.81779139 -0.55165689 -1.5898894   0.03572801]\n [ 0.77645041 -0.39702404  0.16826132  1.37081681]]\n\n\n output\n[[[ 0.0492445  -0.26821002 -0.13461511  0.13712646]\n  [ 0.11038809 -0.22399209 -0.15706871  0.17625453]\n  [ 0.12579349 -0.20708388 -0.17392202  0.19129401]\n  [ 0.12953098 -0.20042329 -0.1886536   0.20086248]\n  [ 0.12905654 -0.19860952 -0.19987412  0.20697045]]\n\n [[ 0.146652   -0.12099689  0.05711044  0.03263233]\n  [ 0.15229702 -0.12689863 -0.05258115  0.09761411]\n  [ 0.14552552 -0.13706802 -0.11870711  0.13544162]\n  [ 0.13672781 -0.15158641 -0.16068494  0.16216366]\n  [ 0.13007095 -0.16579619 -0.18658556  0.18039529]]]\n\n\n\n\n\n\nRNN\n\n\nScala:\n\n\nval rnnCell = RnnCell[Double](\n  inputSize,\n  hiddenSize,\n  activation,\n  isInputWithBias = true,\n  isHiddenWithBias = true,\n  wRegularizer = null,\n  uRegularizer = null,\n  bRegularizer = null)\n\n\n\n\nPython:\n\n\nrnnCell = RnnCell(\n  input_size,\n  hidden_size,\n  activation,\n  isInputWithBias=True,\n  isHiddenWithBias=True,\n  wRegularizer=None,\n  uRegularizer=None,\n  bRegularizer=None)\n\n\n\n\nImplementation of vanilla recurrent neural network cell\n\n\nThe input tensor in \nforward(input)\n is expected to be a 3D tensor (\nbatch x time x inputSize\n). output of\n\nforward(input)\n is also expected to be a 3D tensor (\nbatch x time x hiddenSize\n).\n\n\nThe updating is defined as:\n\n\nh_t = f(i2h * x_t + h2h * h_{t-1})\n\n\n\n\nwhere\n\n \ni2h\n weight matrix of input to hidden units\n\n \nh2h\n weight matrix of hidden units to themselves through time\n\n\nParameters:\n\n\n\n\ninputSize\n input size. Default: 4\n\n\nhiddenSize\n  hidden layer size. Default: 3\n\n\nactivation\n instance of activation function for non-linearity.\n  For Python, one can also pass the name of an existing activation as a string, eg. 'tanh', 'relu', 'sigmoid', 'hard_sigmoid', 'softmax' etc.\n\n\nisInputWithBias\n boolean, whether to contain bias for input. Default: true\n\n\nisHiddenWithBias\n boolean, whether to contain bias for hidden layer. Default: true\n\n\nwRegularizer\n instance of \nRegularizer\n(eg. L1 or L2 regularization), applied to the input weights matrices. Default: null\n\n\nuRegularizer\n instance of \nRegularizer\n(eg. L1 or L2 regularization), applied to the recurrent weights matrices. Default: null\n\n\nbRegularizer\n instance of \nRegularizer\n(eg. L1 or L2 regularization), applied to the bias. Default: null\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval hiddenSize = 2\nval inputSize = 2\nval outputSize = 2\nval seqLength = 2\nval input = Tensor(T(\n  T(1.0f, 2.0f),\n  T(2.0f, 3.0f)\n)).resize(Array(1, seqLength, inputSize))\nval gradOutput = Tensor(T(\n  T(2.0f, 3.0f),\n  T(4.0f, 5.0f)\n)).resize(Array(1, seqLength, inputSize))\nval rec = Recurrent()\n\nval model = Sequential()\n    .add(rec.add(RnnCell(inputSize, hiddenSize, Tanh())))\n    .add(TimeDistributed(Linear(hiddenSize, outputSize)))\nval output = model.forward(input)\nval gradient = model.backward(input, gradOutput)\n-\n print(output)\n# There's random factor. An output could be\n(1,.,.) =\n0.41442442      0.1663357       \n0.5339842       0.57332826      \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2]\n-\n print(gradient)\n# There's random factor. An output could be\n(1,.,.) =\n1.1512008       2.181274        \n-0.4805725      1.6620052       \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nhidden_size = 2\ninput_size = 2\noutput_size = 2\nseq_length = 2\ninput = np.array([[\n  [1.0, 2.0],\n  [2.0, 3.0]\n]])\ngrad_output = np.array([[\n  [2.0, 3.0],\n  [4.0, 5.0]\n]])\nrec = Recurrent()\n\nmodel = Sequential() \\\n    .add(rec.add(RnnCell(input_size, hidden_size, Tanh()))) \\\n    .add(TimeDistributed(Linear(hidden_size, output_size)))\noutput = model.forward(input)\ngradient = model.backward(input, grad_output)\n-\n print output\n# There's random factor. An output could be\n[[[-0.67860311  0.80307233]\n  [-0.77462083  0.97191858]]]\n\n-\n print gradient\n# There's random factor. An output could be\n[[[-0.90771425  1.24791598]\n  [-0.70141178  0.97821164]]]\n\n\n\n\n\n\nLSTM\n\n\nScala:\n\n\nval lstm = LSTM(\n  inputSize,\n  hiddenSize,\n  p = 0.0,\n  activation = null,\n  innerActivation = null,\n  wRegularizer = null,\n  uRegularizer = null,\n  bRegularizer = null)\n\n\n\n\nPython:\n\n\nlstm = LSTM(\n  input_size,\n  hidden_size,\n  p=0.0,\n  activation=None,\n  inner_activation=None,\n  wRegularizer=None,\n  uRegularizer=None,\n  bRegularizer=None)\n\n\n\n\nLong Short Term Memory architecture.\nThe input tensor in \nforward(input)\n is expected to be a 3D tensor (\nbatch x time x inputSize\n). output of\n\nforward(input)\n is also expected to be a 3D tensor (\nbatch x time x hiddenSize\n).\n\n\nRef:\n\n\n\n\nhttp://arxiv.org/pdf/1303.5778v1 (blueprint for this module)\n\n\nhttp://web.eecs.utk.edu/~itamar/courses/ECE-692/Bobby_paper1.pdf\n\n\nhttp://arxiv.org/pdf/1503.04069v1.pdf\n\n\nhttps://github.com/wojzaremba/lstm\n\n\n\n\nParameters:\n\n\n\n\ninputSize\n the size of each input vector\n\n\nhiddenSize\n Hidden unit size in the LSTM\n\n\np\n is used for [[Dropout]] probability. For more details about\n           RNN dropouts, please refer to\n           [RnnDrop: A Novel Dropout for RNNs in ASR]\n           (http://www.stat.berkeley.edu/~tsmoon/files/Conference/asru2015.pdf)\n           [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks]\n           (https://arxiv.org/pdf/1512.05287.pdf)\n\n\nactivation\n activation function, by default to be \nTanh\n if not specified.\n  For Python, one can also pass the name of an existing activation as a string, eg. 'tanh', 'relu', 'sigmoid', 'hard_sigmoid', 'softmax' etc.\n\n\ninnerActivation\n activation function for inner cells, by default to be \nSigmoid\n if not specified.\n  For Python, one can also pass the name of an existing activation as a string, eg. 'tanh', 'relu', 'sigmoid', 'hard_sigmoid', 'softmax' etc.\n\n\nwRegularizer\n instance of [[Regularizer]] (eg. L1 or L2 regularization), applied to the input weights matrices.\n\n\nuRegularizer\n instance of [[Regularizer]] (eg. L1 or L2 regularization), applied to the recurrent weights matrices.\n\n\nbRegularizer\n instance of [[Regularizer]], applied to the bias.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.optim.SGD\nimport com.intel.analytics.bigdl.utils.RandomGenerator._\nimport com.intel.analytics.bigdl.tensor.{Storage, Tensor}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval hiddenSize = 4\nval inputSize = 6\nval outputSize = 5\nval seqLength = 5\nval seed = 100\n\nRNG.setSeed(seed)\nval input = Tensor(Array(1, seqLength, inputSize))\nval labels = Tensor(Array(1, seqLength))\nfor (i \n- 1 to seqLength) {\n  val rdmLabel = Math.ceil(RNG.uniform(0, 1) * outputSize).toInt\n  val rdmInput = Math.ceil(RNG.uniform(0, 1) * inputSize).toInt\n  input.setValue(1, i, rdmInput, 1.0f)\n  labels.setValue(1, i, rdmLabel)\n}\n\nprintln(input)\nval rec = Recurrent(hiddenSize)\nval model = Sequential().add(\n  rec.add(\n      LSTM(inputSize, hiddenSize))).add(\n        TimeDistributed(Linear(hiddenSize, outputSize)))\n\nval criterion = TimeDistributedCriterion(\n  CrossEntropyCriterion(), false)\n\nval sgd = new SGD(learningRate=0.1, learningRateDecay=5e-7, weightDecay=0.1, momentum=0.002)\n\nval (weight, grad) = model.getParameters()\n\nval output = model.forward(input).toTensor\nval _loss = criterion.forward(output, labels)\nmodel.zeroGradParameters()\nval gradInput = criterion.backward(output, labels)\nmodel.backward(input, gradInput)\n\ndef feval(x: Tensor[Float]): (Float, Tensor[Float]) = {\n  val output = model.forward(input).toTensor\n  val _loss = criterion.forward(output, labels)\n  model.zeroGradParameters()\n  val gradInput = criterion.backward(output, labels)\n  model.backward(input, gradInput)\n  (_loss, grad)\n}\n\nvar loss: Array[Float] = null\nfor (i \n- 1 to 100) {\n  loss = sgd.optimize(feval, weight)._2\n  println(s\n${i}-th loss = ${loss(0)}\n)\n}\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nhidden_size = 4\ninput_size = 6\noutput_size = 5\nseq_length = 5\n\ninput = np.random.uniform(0, 1, [1, seq_length, input_size]).astype(\nfloat32\n)\nlabels = np.random.uniform(1, 5, [1, seq_length]).astype(\nint\n)\n\nprint labels\nprint input\n\nrec = Recurrent()\nrec.add(LSTM(input_size, hidden_size))\n\nmodel = Sequential()\nmodel.add(rec)\nmodel.add(TimeDistributed(Linear(hidden_size, output_size)))\n\ncriterion = TimeDistributedCriterion(CrossEntropyCriterion(), False)\n\nsgd = SGD(learningrate=0.1, learningrate_decay=5e-7)\n\nweight, grad = model.parameters()\n\noutput = model.forward(input)\nloss = criterion.forward(input, labels)\ngradInput = criterion.backward(output, labels)\nmodel.backward(input, gradInput)\n\n\n\n\n\n\nLSTMPeephole\n\n\nScala:\n\n\nval model = LSTMPeephole(\n  inputSize = 4,\n  hiddenSize = 3,\n  p = 0.0,\n  wRegularizer = null,\n  uRegularizer = null,\n  bRegularizer = null)\n\n\n\n\nPython:\n\n\nmodel = LSTMPeephole(\n  input_size,\n  hidden_size,\n  p=0.0,\n  wRegularizer=None,\n  uRegularizer=None,\n  bRegularizer=None)\n\n\n\n\nLong Short Term Memory architecture with peephole.\nThe input tensor in \nforward(input)\n is expected to be a 3D tensor (\nbatch x time x inputSize\n). output of\n\nforward(input)\n is also expected to be a 3D tensor (\nbatch x time x hiddenSize\n).\n\n\nRef.\n\n\n\n\nhttp://arxiv.org/pdf/1303.5778v1 (blueprint for this module)\n\n\nhttp://web.eecs.utk.edu/~itamar/courses/ECE-692/Bobby_paper1.pdf\n\n\nhttp://arxiv.org/pdf/1503.04069v1.pdf\n\n\nhttps://github.com/wojzaremba/lstm\n\n\n\n\nParameters:\n\n\n\n\ninputSize\n the size of each input vector\n\n\nhiddenSize\n Hidden unit size in the LSTM\n\n\np\n is used for [[Dropout]] probability. For more details about\n           RNN dropouts, please refer to\n           [RnnDrop: A Novel Dropout for RNNs in ASR]\n           (http://www.stat.berkeley.edu/~tsmoon/files/Conference/asru2015.pdf)\n           [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks]\n           (https://arxiv.org/pdf/1512.05287.pdf)\n\n\nwRegularizer\n instance of [[Regularizer]] (eg. L1 or L2 regularization), applied to the input weights matrices.\n\n\nuRegularizer\n instance of [[Regularizer]] (eg. L1 or L2 regularization), applied to the recurrent weights matrices.\n\n\nbRegularizer\n instance of [[Regularizer]], applied to the bias.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.RandomGenerator._\n\nval hiddenSize = 4\nval inputSize = 6\nval outputSize = 5\nval seqLength = 5\nval batchSize = 1\n\nval input = Tensor(Array(batchSize, seqLength, inputSize))\nfor (b \n- 1 to batchSize) {\n  for (i \n- 1 to seqLength) {\n    val rdmInput = Math.ceil(RNG.uniform(0.0, 1.0) * inputSize).toInt\n    input.setValue(b, i, rdmInput, 1.0f)\n  }\n}\n\nval rec = Recurrent(hiddenSize)\nval model = Sequential().add(rec.add(LSTMPeephole(inputSize, hiddenSize))).add(TimeDistributed(Linear(hiddenSize, outputSize)))\nval output = model.forward(input).toTensor\n\nscala\n print(input)\n(1,.,.) =\n1.0 0.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0 1.0 \n0.0 1.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0 1.0 \n1.0 0.0 0.0 0.0 0.0 0.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x5x6]\n\nscala\n print(output)\n(1,.,.) =\n0.34764957  -0.31453514 -0.45646006 -0.42966008 -0.13651063 \n0.3624894   -0.2926056  -0.4347164  -0.40951455 -0.1775867  \n0.33391106  -0.29304913 -0.4748538  -0.45285955 -0.14919288 \n0.35499972  -0.29385415 -0.4419502  -0.42135617 -0.17544147 \n0.32911295  -0.30237123 -0.47175884 -0.4409852  -0.15733294 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x5]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nhiddenSize = 4\ninputSize = 6\noutputSize = 5\nseqLength = 5\nbatchSize = 1\n\ninput = np.random.randn(batchSize, seqLength, inputSize)\nrec = Recurrent(hiddenSize)\nmodel = Sequential().add(rec.add(LSTMPeephole(inputSize, hiddenSize))).add(TimeDistributed(Linear(hiddenSize, outputSize)))\noutput = model.forward(input)\n\n\n print(input)\n[[[ 0.73624017 -0.91135209 -0.30627796 -1.07902111 -1.13549159  0.52868762]\n  [-0.07251559 -0.45596589  1.64020513  0.53218623  1.37993166 -0.47724947]\n  [-1.24958366 -1.22220259 -0.52454306  0.17382396  1.77666173 -1.2961758 ]\n  [ 0.45407533  0.82944329  0.02155243  1.82168093 -0.06022129  2.23823013]\n  [ 1.09100802  0.28555387 -0.94312648  0.55774033 -0.54895792  0.79885853]]]\n\n\n print(output)\n[[[ 0.4034881  -0.26156989  0.46799076  0.06283229  0.11794794]\n  [ 0.37359846 -0.17925361  0.31623816  0.06038529  0.10813089]\n  [ 0.34150451 -0.16565879  0.25264332  0.1187657   0.05118144]\n  [ 0.40773875 -0.2028828   0.24765283  0.0986848   0.12132661]\n  [ 0.40263647 -0.22403356  0.38489845  0.04720671  0.1686969 ]]]\n\n\n\n\n\n\nGRU\n\n\nScala:\n\n\nval gru = GRU(\n  inputSize,\n  outputSize,\n  p = 0.0,\n  activation = null,\n  innerActivation = null,\n  wRegularizer = null,\n  uRegularizer = null,\n  bRegularizer = null)\n\n\n\n\nPython:\n\n\ngru = GRU(\n  inputSize,\n  outputSize,\n  p=0.0,\n  activation=None,\n  inner_activation=None,\n  wRegularizer=None,\n  uRegularizer=None,\n  bRegularizer=None)\n\n\n\n\nGated Recurrent Units architecture. The first input in sequence uses zero value for cell and hidden state.\nThe input tensor in \nforward(input)\n is expected to be a 3D tensor (\nbatch x time x inputSize\n). output of\n\nforward(input)\n is also expected to be a 3D tensor (\nbatch x time x outputSize\n).\n\n\nRef.\n\n\n\n\nhttp://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/\n\n\nhttps://github.com/Element-Research/rnn/blob/master/GRU.lua\n\n\n\n\nParameters:\n\n\n\n\ninputSize\n the size of each input vector\n\n\noutputSize\n hidden unit size in GRU\n\n\np\n is used for [[Dropout]] probability. For more details about\n          RNN dropouts, please refer to\n           \nRnnDrop: A Novel Dropout for RNNs in ASR\n\n            and \nA Theoretically Grounded Application of Dropout in Recurrent Neural Networks\n. Default: 0.0\n\n\nactivation\n activation function, by default to be \nTanh\n if not specified.\n  For Python, one can also pass the name of an existing activation as a string, eg. 'tanh', 'relu', 'sigmoid', 'hard_sigmoid', 'softmax' etc.\n\n\ninnerActivation\n activation function for inner cells, by default to be \nSigmoid\n if not specified.\n  For Python, one can also pass the name of an existing activation as a string, eg. 'tanh', 'relu', 'sigmoid', 'hard_sigmoid', 'softmax' etc.\n\n\nwRegularizer\n instance of \nRegularizer\n(eg. L1 or L2 regularization), applied to the input weights matrices. Default: null\n\n\nuRegularizer\n instance of \nRegularizer\n(eg. L1 or L2 regularization), applied to the recurrent weights matrices. Default: null\n\n\nbRegularizer\n instance of \nRegularizer\n(eg. L1 or L2 regularization), applied to the bias. Default: null\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval hiddenSize = 2\nval inputSize = 2\nval outputSize = 2\nval seqLength = 2\nval input = Tensor(T(\n  T(1.0f, 2.0f),\n  T(2.0f, 3.0f)\n)).resize(Array(1, seqLength, inputSize))\nval gradOutput = Tensor(T(\n  T(2.0f, 3.0f),\n  T(4.0f, 5.0f)\n)).resize(Array(1, seqLength, inputSize))\nval rec = Recurrent()\n\nval model = Sequential()\n    .add(rec.add(GRU(inputSize, hiddenSize)))\n    .add(TimeDistributed(Linear(hiddenSize, outputSize)))\nval output = model.forward(input)\nval gradient = model.backward(input, gradOutput)\n\n-\n print(output)\n# There's random factor. An output could be\n(1,.,.) =\n0.3833429       0.0082434565    \n-0.041063666    -0.08152798     \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2]\n\n\n-\n print(gradient)\n# There's random factor. An output could be\n(1,.,.) =\n-0.7684499      -0.49320614     \n-0.98002595     -0.47857404     \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nhidden_size = 2\ninput_size = 2\noutput_size = 2\nseq_length = 2\ninput = np.array([[\n  [1.0, 2.0],\n  [2.0, 3.0]\n]])\ngrad_output = np.array([[\n  [2.0, 3.0],\n  [4.0, 5.0]\n]])\nrec = Recurrent()\n\nmodel = Sequential() \\\n    .add(rec.add(GRU(input_size, hidden_size))) \\\n    .add(TimeDistributed(Linear(hidden_size, output_size)))\noutput = model.forward(input)\ngradient = model.backward(input, grad_output)\n-\n print output\n# There's random factor. An output could be\n[[[ 0.27857888  0.20263115]\n  [ 0.29470384  0.22594413]]]\n-\n print gradient\n[[[-0.32956457  0.27405274]\n  [-0.32718879  0.32963118]]]\n\n\n\n\n\n\nConvLSTMPeephole\n\n\nScala:\n\n\nval model = ConvLSTMPeephole(\n  inputSize = 2,\n  outputSize = 4,\n  kernelI = 3,\n  kernelC = 3,\n  stride = 1,\n  padding = -1,\n  activation = null,\n  innerActivation = null,\n  wRegularizer = null,\n  uRegularizer = null,\n  bRegularizer = null,\n  cRegularizer = null,\n  withPeephole = true)\n\n\n\n\nPython:\n\n\nmodel = ConvLSTMPeephole(\n  input_size = 2,\n  output_size = 4,\n  kernel_i = 3,\n  kernel_c = 3,\n  stride = 1,\n  padding = -1,\n  activation = None,\n  inner_activation = None,\n  wRegularizer = None,\n  uRegularizer = None,\n  bRegularizer = None,\n  cRegularizer = None,\n  with_peephole = True)\n\n\n\n\nConvolution Long Short Term Memory architecture with peephole for 2 dimension images.\nThe input tensor in \nforward(input)\n is expected to be a 4D or 5D tensor\nIf ConvLSTM work with Recurrent, input is 5D tensor (\nbatch x time x nInputPlane x height x width\n). output of\n\nforward(input)\n is also expected to be a 5D tensor (\nbatch x time x outputPlane x height x width\n).\n\n\nIf ConvLSTM work with RecurrentDecoder, input is 4D tensor (\nbatch x nInputPlane x height x width\n). output of\n\nforward(input)\n is expected to be a 5D tensor (\nbatch x outputLen x outputPlane x height x width\n).\n\n\nRef.\n\n\n\n\nhttps://arxiv.org/abs/1506.04214 (blueprint for this module)\n\n\nhttps://github.com/viorik/ConvLSTM\n\n\n\n\nParameters:\n\n\n\n\ninputSize\n number of input planes in the image given into forward()\n\n\noutputSize\n number of output planes the convolution layer will produce\n\n\nkernelI\n convolutional filter size to convolve input\n\n\nkernelC\n convolutional filter size to convolve cell\n\n\nstride\n step of the convolution, default is 1\n\n\npadding\n step of the convolution, default is -1, behaves same with SAME padding in tensorflow\n                 Default stride,padding value ensure last 2 dim of output shape is the same with input\n\n\nactivation\n activation function, by default to be \nTanh\n if not specified.\n  For Python, one can also pass the name of an existing activation as a string, eg. 'tanh', 'relu', 'sigmoid', 'hard_sigmoid', 'softmax' etc.\n\n\ninnerActivation\n activation function for inner cells, by default to be \nSigmoid\n if not specified.\n  For Python, one can also pass the name of an existing activation as a string, eg. 'tanh', 'relu', 'sigmoid', 'hard_sigmoid', 'softmax' etc.\n\n\nwRegularizer\n instance of [[Regularizer]] (eg. L1 or L2 regularization), applied to the input weights matrices.\n\n\nuRegularizer\n instance of [[Regularizer]] (eg. L1 or L2 regularization), applied to the recurrent weights matrices.\n\n\nbRegularizer\n instance of [[Regularizer]], applied to the bias.\n\n\ncRegularizer\n instance of [[Regularizer]], applied to peephole.\n\n\nwithPeephole\n whether use last cell status control a gate\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.RandomGenerator._\n\nval outputSize = 4\nval inputSize = 3\nval seqLength = 2\nval batchSize = 1\n\nval input = Tensor(Array(batchSize, seqLength, inputSize, 3, 3)).rand()\n\nval rec = Recurrent()\n    val model = Sequential()\n      .add(rec\n        .add(ConvLSTMPeephole(inputSize, outputSize, 3, 3, 1, withPeephole = false)))\n\nval output = model.forward(input).toTensor\n\nscala\n print(input)\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n0.32810056      0.23436882      0.1387327\n0.98273766      0.76427716      0.73554766\n0.47947738      0.72805804      0.43982902\n\n(1,1,2,.,.) =\n0.58144385      0.7534736       0.94412255\n0.05087549      0.021427812     0.91333073\n0.6844351       0.62977004      0.68027127\n\n(1,1,3,.,.) =\n0.48504198      0.16233416      0.7612549\n0.5387952       0.8391377       0.3687795\n0.85271466      0.71726906      0.79466575\n\n(1,2,1,.,.) =\n0.727532        0.05341824      0.32531977\n0.79593664      0.60162276      0.99931896\n0.7534103       0.71214366      0.031062916\n\n(1,2,2,.,.) =\n0.7343414       0.053005006     0.7448063\n0.2277985       0.47414783      0.21945253\n0.0034818714    0.11545401      0.73085403\n\n(1,2,3,.,.) =\n0.9644807       0.30755267      0.42099005\n0.6831594       0.50683653      0.14237563\n0.65172654      0.86954886      0.5077393\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x2x3x3x3]\n\nscala\n print(output)\n(1,1,1,.,.) =\n-0.04460164     -0.023752786    -0.014343993\n0.0067705153    0.08542874      0.020885356\n-0.042719357    -0.012113815    -0.030324051\n\n(1,1,2,.,.) =\n-0.038318213    -0.056998547    -0.02303889\n0.027873239     -0.040311974    -0.03261278\n0.015056128     0.11064132      0.0034682436\n\n(1,1,3,.,.) =\n0.006952648     0.011758738     -0.047590334\n0.052022297     0.040250845     -0.046224136\n-0.0084472215   -0.02629062     -0.0737972\n\n(1,1,4,.,.) =\n-0.087721705    0.0382758       0.027436329\n-0.030658737    -0.022953996    0.15838619\n0.055106055     0.004877564     0.098199464\n\n(1,2,1,.,.) =\n-0.069991425    -0.022071177    -0.06291955\n-0.006841902    0.010781053     0.05410414\n-0.03933395     -0.003422904    -0.106903486\n\n(1,2,2,.,.) =\n-0.059429795    -0.098534085    -0.068920344\n0.008100101     0.01948546      -0.040567685\n0.048763007     0.06001041      0.003068042\n\n(1,2,3,.,.) =\n0.02817994      0.006684172     -0.0962587\n0.022453573     0.014425971     -0.06118475\n-0.013392928    -0.04574135     -0.12722406\n\n(1,2,4,.,.) =\n-0.074006446    -0.028510522    0.06808455\n-0.021926142    0.036675904     0.18708621\n0.08240187      0.12469789      0.17341805\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x3x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\noutput_size = 4\ninput_size= 3\nseq_len = 2\nbatch_size = 1\n\ninput = np.random.randn(batch_size, seq_len, input_size, 3, 3)\nrec = Recurrent()\nmodel = Sequential().add(\n    rec.add(ConvLSTMPeephole(input_size, output_size, 3, 3, 1, with_peephole = False)))\noutput = model.forward(input)\n\n\n print(input)\n[[[[[ 2.39979422  0.75647109  0.88928214]\n    [-0.07132477 -0.4348564   0.38270011]\n    [-1.03522309  0.38399781  0.20369625]]\n\n   [[-0.48392771  0.54371842 -1.42064221]\n    [-0.3711481  -0.16019682  0.82116693]\n    [ 0.15922215  1.79676148  0.38362552]]\n\n   [[-0.69402482  1.11930766 -1.29138064]\n    [ 0.92755002 -0.31138235  0.34953374]\n    [-0.0176643   1.13839126  0.02133309]]]\n\n\n  [[[-0.40704988  0.1819258  -0.21400335]\n    [ 0.65717965  0.75912824  1.49077775]\n    [-0.74917913 -1.48460681  1.06098727]]\n\n   [[ 1.04942415  1.2558929  -1.24367776]\n    [-0.13452707  0.01485188  2.41215047]\n    [ 0.59776321 -0.38602613  0.57937933]]\n\n   [[ 0.55007301  1.22571134  0.11656841]\n    [-0.4722457   1.79801493  0.59698431]\n    [ 0.25119458 -0.27323404  1.5516505 ]]]]]\n\n\n print(output)\n[[[[[-0.22908808 -0.08243818 -0.10530333]\n    [ 0.04545299  0.0347576   0.06448466]\n    [ 0.00148075 -0.01422587 -0.04424585]]\n\n   [[-0.08625289  0.00121372  0.00961097]\n    [-0.08068027  0.2389598  -0.08875058]\n    [-0.10860988 -0.08109165  0.05274875]]\n\n   [[ 0.01545026 -0.14079301  0.0162897 ]\n    [ 0.0114354   0.01696588  0.09375648]\n    [ 0.06766916  0.16015787 -0.01530124]]\n\n   [[-0.00311095  0.07033439  0.05258823]\n    [-0.04846094 -0.11335927 -0.22434352]\n    [-0.09923813 -0.064981   -0.05341392]]]\n\n\n  [[[-0.01070079  0.01705431 -0.10199456]\n    [-0.19023973 -0.1359819   0.11552753]\n    [ 0.04331793  0.00603994 -0.19059387]]\n\n   [[-0.12100818 -0.01191896  0.08049219]\n    [-0.10134248  0.02910084 -0.00024394]\n    [-0.09548382 -0.18623565  0.18261637]]\n\n   [[-0.00644266  0.03494127  0.09105418]\n    [ 0.03467004 -0.1236406   0.23844369]\n    [ 0.12281432  0.09469442  0.04526915]]\n\n   [[ 0.00190313  0.01997324 -0.17609949]\n    [-0.0937     -0.03763293 -0.04860835]\n    [-0.15700462 -0.17341313 -0.06551415]]]]]\n\n\n\n\n\n\nConvLSTMPeephole3D\n\n\nScala:\n\n\nval model = ConvLSTMPeephole3D(\n  inputSize = 2,\n  outputSize = 4,\n  kernelI = 3,\n  kernelC = 3,\n  stride = 1,\n  padding = -1,\n  wRegularizer = null,\n  uRegularizer = null,\n  bRegularizer = null,\n  cRegularizer = null,\n  withPeephole = true)\n\n\n\n\nPython:\n\n\nmodel = ConvLSTMPeephole3D(\n  input_size = 2,\n  output_size = 4,\n  kernel_i = 3,\n  kernel_c = 3,\n  stride = 1,\n  padding = -1,\n  wRegularizer=None,\n  uRegularizer=None,\n  bRegularizer=None,\n  cRegularizer=None,\n  with_peephole = True)\n\n\n\n\nSimilar to Convlstm2D, it's a Convolution Long Short Term Memory architecture with peephole but for 3 spatial dimension images.\nThe input tensor in \nforward(input)\n is expected to be a 5D or 6D tensor\nIf work with Recurrent, input is 6D tensor (\nbatch x time x nInputPlane x height x width x length\n). output of\n\nforward(input)\n is also expected to be a 6D tensor (\nbatch x time x outputPlane x height x width x length\n).\n\n\nIf work with RecurrentDecoder, input is 5D tensor (\nbatch x nInputPlane x height x width x length\n). output of\n\nforward(input)\n is expected to be a 6D tensor (\nbatch x outputLen x outputPlane x height x width x length\n).\n\n\nParameters:\n\n\n\n\ninputSize\n number of input planes in the image given into forward()\n\n\noutputSize\n number of output planes the convolution layer will produce\n\n\nkernelI\n convolutional filter size to convolve input\n\n\nkernelC\n convolutional filter size to convolve cell\n\n\nstride\n step of the convolution, default is 1\n\n\npadding\n step of the convolution, default is -1, behaves same with SAME padding in tensorflow\n                 Default stride,padding value ensure last 3 dim of output shape is the same with input\n\n\nwRegularizer\n instance of [[Regularizer]] (eg. L1 or L2 regularization), applied to the input weights matrices.\n\n\nuRegularizer\n instance of [[Regularizer]] (eg. L1 or L2 regularization), applied to the recurrent weights matrices.\n\n\nbRegularizer\n instance of [[Regularizer]], applied to the bias.\n\n\ncRegularizer\n instance of [[Regularizer]], applied to peephole.\n\n\nwithPeephole\n whether use last cell status control a gate\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.RandomGenerator._\n\nval outputSize = 4\nval inputSize = 3\nval seqLength = 2\nval batchSize = 1\n\nval input = Tensor(Array(batchSize, seqLength, inputSize, 3, 3, 3)).rand()\n\nval rec = Recurrent()\n    val model = Sequential()\n      .add(rec\n        .add(ConvLSTMPeephole3D(inputSize, outputSize, 3, 3, 1, withPeephole = false)))\n\nval output = model.forward(input).toTensor\n\nscala\n print(input)\n(1,1,1,1,.,.) =\n0.42592695  0.32742274  0.7926296   \n0.21923159  0.7427106   0.31764257  \n0.121872835 0.54231954  0.32091624  \n\n(1,1,1,2,.,.) =\n0.06762145  0.8054027   0.8297814   \n0.95535785  0.20807801  0.46387103  \n0.90996957  0.7849159   0.79179865  \n\n(1,1,1,3,.,.) =\n0.22927228  0.29869995  0.1145133   \n0.12646529  0.8917339   0.7545332   \n0.8044227   0.5340327   0.9784876   \n\n(1,1,2,1,.,.) =\n0.68444395  0.47932255  0.28224406  \n0.5083046   0.9364489   0.27006733  \n0.24699332  0.55712855  0.50037974  \n\n(1,1,2,2,.,.) =\n0.46334672  0.10979338  0.6378528   \n0.8557069   0.10780747  0.73767877  \n0.12505454  0.72492164  0.5440267   \n\n(1,1,2,3,.,.) =\n0.15598479  0.52033675  0.64091414  \n0.15149859  0.64515823  0.6023936   \n0.31461328  0.1901752   0.98015004  \n\n(1,1,3,1,.,.) =\n0.9700778   0.24109624  0.23764393  \n0.16602103  0.97310185  0.072756775 \n0.849201    0.825025    0.2753475   \n\n(1,1,3,2,.,.) =\n0.8621034   0.24596989  0.56645423  \n0.004375741 0.9873366   0.89219636  \n0.56948274  0.291723    0.5503815   \n\n(1,1,3,3,.,.) =\n0.626368    0.9389012   0.8974684   \n0.8553843   0.39709046  0.372683    \n0.38087663  0.94703597  0.71530545  \n\n(1,2,1,1,.,.) =\n0.74050623  0.39862877  0.57509166  \n0.87832487  0.41345102  0.6262451   \n0.665165    0.49570015  0.8304163   \n\n(1,2,1,2,.,.) =\n0.30847755  0.51876235  0.10555197  \n0.10103849  0.9479695   0.11847988  \n0.60081536  0.003097216 0.22800316  \n\n(1,2,1,3,.,.) =\n0.113101795 0.76638913  0.091707565 \n0.30347276  0.029687135 0.37973404  \n0.67719024  0.02180517  0.12747364  \n\n(1,2,2,1,.,.) =\n0.12513511  0.74210113  0.82569206  \n0.1406212   0.7400157   0.041633762 \n0.26903376  0.6195371   0.618376    \n\n(1,2,2,2,.,.) =\n0.068732955 0.09746146  0.15479624  \n0.57418007  0.7181547   0.6494809   \n0.29213288  0.35022008  0.15421997  \n\n(1,2,2,3,.,.) =\n0.47196773  0.55650383  0.938309    \n0.70717365  0.68351734  0.32646814  \n0.99775004  0.2596666   0.6803594   \n\n(1,2,3,1,.,.) =\n0.6320722   0.105437785 0.36752152  \n0.8347324   0.38376364  0.641918    \n0.40254018  0.5421287   0.792421    \n\n(1,2,3,2,.,.) =\n0.2652298   0.6261154   0.21971565  \n0.31418183  0.44987184  0.43880364  \n0.76821107  0.17070894  0.47295105  \n\n(1,2,3,3,.,.) =\n0.16514553  0.37016368  0.23397927  \n0.19776458  0.07518195  0.48995376  \n0.13584352  0.23562871  0.41726747  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x2x3x3x3x3]\n\nscala\n print(output)\n(1,1,1,1,.,.) =\n0.014528348 0.03160259  0.05313618  \n-0.011796958    0.027994404 0.028153816 \n-0.010374474    0.029486801 0.033610236 \n\n(1,1,1,2,.,.) =\n0.07966786  0.041255455 0.09181337  \n0.025984935 0.06594588  0.07572434  \n0.019637575 0.0068716113    0.03775029  \n\n(1,1,1,3,.,.) =\n0.07043511  0.044567406 0.08229201  \n0.10589862  0.109124646 0.0888148   \n0.018544039 0.04097363  0.09130414  \n\n(1,1,2,1,.,.) =\n0.1032162   -0.01981514 -0.0016546922   \n0.026028564 0.0100736385    0.009424217 \n-0.048695907    -0.009172593    -0.029458746    \n\n(1,1,2,2,.,.) =\n0.058081806 0.101963215 0.056670886 \n0.09300327  0.035424378 0.02410931  \n0.056604195 -0.0032351227   0.027961217 \n\n(1,1,2,3,.,.) =\n0.11710516  0.09371774  -0.013825272    \n0.02930173  0.06391968  0.04034334  \n0.010447707 -0.004905071    0.011929871 \n\n(1,1,3,1,.,.) =\n-0.020980358    0.08554982  -0.07644813 \n0.06367171  -0.06037125 0.019925931 \n0.0026421212    0.051610045 0.023478134 \n\n(1,1,3,2,.,.) =\n-0.033074334    -0.0381583  -0.019341394    \n-0.0625153  -0.06907081 -0.019746307    \n-0.010362335    0.0062695937    0.054116223 \n\n(1,1,3,3,.,.) =\n0.00461099  -0.03308314 -6.8137434E-4   \n-0.075023845    -0.024970314    0.008133534 \n0.019836657 0.051302493 0.043689556 \n\n(1,1,4,1,.,.) =\n0.027088374 0.008537832 -0.020948375    \n0.021569671 0.016515112 -0.019221392    \n-0.0074050943   -0.03274501 0.003256779 \n\n(1,1,4,2,.,.) =\n8.967657E-4 0.019020535 -0.05990117 \n0.06226491  -0.017516658    -0.028854925    \n0.048010994 0.031080479 -4.8373322E-4   \n\n(1,1,4,3,.,.) =\n0.03253352  -0.023469497    -0.047273926    \n-0.03765316 0.011091222 0.0036612307    \n0.050733108 0.01736545  0.0061482657    \n\n(1,2,1,1,.,.) =\n-0.0037416879   0.03895818  0.102294624 \n0.011019588 0.03201482  0.07654998  \n-0.015550408    0.009587483 0.027655594 \n\n(1,2,1,2,.,.) =\n0.089279816 0.03306113  0.11713534  \n0.07299529  0.057692382 0.11090511  \n-0.0031341386   0.091527686 0.07210587  \n\n(1,2,1,3,.,.) =\n0.080724075 0.07707712  0.07624206  \n0.06552311  0.104010254 0.09213451  \n0.07030998  0.0022800618    0.12461836  \n\n(1,2,2,1,.,.) =\n0.10180804  0.020320226 -0.0025817656   \n0.016294254 -0.024293585    -0.004399727    \n-0.032854877    1.1120379E-4    -0.02109197 \n\n(1,2,2,2,.,.) =\n0.0968586   0.07098973  0.07648221  \n0.0918679   0.10268471  0.056947876 \n0.027774762 -0.03927014 0.04663368  \n\n(1,2,2,3,.,.) =\n0.10225944  0.08460646  -8.393754E-4    \n0.051307157 0.011988232 0.037762236 \n0.029469138 0.023369621 0.037675448 \n\n(1,2,3,1,.,.) =\n-0.017874755    0.08561468  -0.066132575    \n0.010558257 -0.01448278 0.0073027355    \n-0.007930762    0.052643955 0.008378773 \n\n(1,2,3,2,.,.) =\n-0.009250246    -0.06543376 -0.025082456    \n-0.093004115    -0.08637037 -0.063408665    \n-0.06941878 0.010163672 0.07595171  \n\n(1,2,3,3,.,.) =\n0.014756428 -0.040423956    -0.011537984    \n-0.046337806    -0.008416044    0.068246834 \n3.5782385E-4    0.056929104 0.052956138 \n\n(1,2,4,1,.,.) =\n0.033539586 0.013915413 -0.024538055    \n0.042590756 0.034134552 0.021031722 \n-0.026687687    0.0012957935    -0.0053077694   \n\n(1,2,4,2,.,.) =\n0.0033482902    -0.037335612    -0.0956953  \n0.007350738 -0.05237038 -0.08849126 \n0.016356941 0.032067236 -0.0012172575   \n\n(1,2,4,3,.,.) =\n-0.020006038    -0.030038685    -0.054900024    \n-0.014171911    0.01270077  -0.004130667    \n0.04607582  0.040028486 0.011846061 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x3x3x3]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\noutput_size = 4\ninput_size= 3\nseq_len = 2\nbatch_size = 1\n\ninput = np.random.randn(batch_size, seq_len, input_size, 3, 3, 3)\nrec = Recurrent()\nmodel = Sequential().add(\n    rec.add(ConvLSTMPeephole3D(input_size, output_size, 3, 3, 1, with_peephole = False)))\noutput = model.forward(input)\n\n\n print(input)\n[[[[[[ -8.92954769e-02  -9.77685543e-03   1.97566296e+00]\n     [ -5.76910662e-01  -9.08404346e-01  -4.70799006e-01]\n     [ -9.86229768e-01   7.87303916e-01   2.29691167e+00]]\n\n    [[ -7.48240036e-01   4.12766483e-01  -3.88947296e-01]\n     [ -1.39879028e+00   2.43984720e+00  -2.43947000e-01]\n     [  1.86468980e-01   1.34599111e+00  -6.97932324e-01]]\n\n    [[  1.23278710e+00  -4.02661913e-01   8.50721265e-01]\n     [ -1.79452089e-01  -5.58813385e-01   1.10060751e+00]\n     [ -6.27181580e-01  -2.69531726e-01  -1.07857962e-01]]]\n\n\n   [[[ -1.01462355e+00   5.47520811e-02   3.06976674e-01]\n     [  9.64871158e-01  -1.16953916e+00   1.41880629e+00]\n     [  1.19127007e+00   1.71403439e-01  -1.30787798e+00]]\n\n    [[ -6.44313121e-01  -8.45131087e-01   6.99275525e-02]\n     [ -3.07656855e-01   1.25746926e+00   3.89980508e-02]\n     [ -2.59853355e-01   8.78915612e-01  -9.37204072e-02]]\n\n    [[  7.69958423e-02  -3.22523203e-01  -7.31295167e-01]\n     [  1.46184856e+00   1.88641278e+00   1.46645372e-01]\n     [  4.38390570e-01  -2.85102515e-01  -1.81269541e+00]]]\n\n\n   [[[  2.95126419e-01  -1.13715815e+00   9.36848777e-01]\n     [ -1.62071909e+00  -1.06018926e+00   1.88416944e+00]\n     [ -5.81248254e-01   1.05162543e+00  -3.58790528e-01]]\n\n    [[ -7.54710826e-01   2.29994522e+00   7.24276828e-01]\n     [  5.77031441e-01   7.36132125e-01   2.24719266e+00]\n     [ -4.53710071e-05   1.98478259e-01  -2.62825655e-01]]\n\n    [[  1.68124733e+00  -9.97417864e-01  -3.73490116e-01]\n     [ -1.12558844e+00   2.60032255e-01   9.67994680e-01]\n     [  1.78486852e+00   1.17514142e+00  -1.96871551e-01]]]]\n\n\n\n  [[[[  4.43156770e-01  -4.42279658e-01   8.00893010e-01]\n     [ -2.04817319e-01  -3.89658940e-01  -1.10950351e+00]\n     [  6.61008455e-01  -4.07251176e-01   1.14871901e+00]]\n\n    [[ -2.07785815e-01  -8.92450022e-01  -4.23830113e-02]\n     [ -5.26555807e-01   3.76671145e-02  -2.17877979e-01]\n     [ -7.68371469e-01   1.53052409e-01   1.02405949e+00]]\n\n    [[  5.75018628e-01  -9.47162716e-01   6.47917376e-01]\n     [  4.66967303e-01   1.00917068e-01  -1.60894238e+00]\n     [ -1.46491032e-01   3.17782758e+00   1.12581079e-01]]]\n\n\n   [[[  9.32343396e-01  -1.03853742e+00   5.67577254e-02]\n     [  1.25266813e+00   3.52463164e-01  -1.86783652e-01]\n     [ -1.20321270e+00   3.95144053e-01   2.09975625e-01]]\n\n    [[  2.68240844e-01  -1.34931544e+00   1.34259455e+00]\n     [  6.34339337e-01  -5.21231073e-02  -3.91895492e-01]\n     [  1.53872699e-01  -5.07236962e-02  -2.90772390e-01]]\n\n    [[ -5.07933749e-01   3.78036493e-01   7.41781186e-01]\n     [  1.62736825e+00   1.24125644e+00  -3.97490478e-01]\n     [  5.77762257e-01   1.10372911e+00   1.58060183e-01]]]\n\n\n   [[[  5.31859839e-01   1.72805654e+00  -3.77124271e-01]\n     [  1.24638369e+00  -1.54061928e+00   6.22001793e-01]\n     [  1.92447446e+00   7.71351435e-01  -1.59998400e+00]]\n\n    [[  1.44289958e+00   5.41433535e-01   9.19769038e-01]\n     [  9.92873720e-01  -9.05746035e-01   1.35906705e+00]\n     [  1.38994943e+00   2.11451648e+00  -1.58783119e-01]]\n\n    [[ -1.44024889e+00  -5.12269041e-01   8.56761529e-02]\n     [  1.16668889e+00   7.58164067e-01  -1.04304927e+00]\n     [  6.34138215e-01  -7.89939971e-01  -5.52376307e-01]]]]]]\n\n\n print(output)\n[[[[[[ 0.08801123 -0.15533912 -0.08897342]\n     [ 0.01158205 -0.01103314  0.02793931]\n     [-0.01269898 -0.09544773  0.03573112]]\n\n    [[-0.15603164 -0.16063154 -0.09672774]\n     [ 0.15531734  0.05808824 -0.01653268]\n     [-0.06348733 -0.10497692 -0.13086422]]\n\n    [[ 0.002062   -0.01604773 -0.14802884]\n     [-0.0934701  -0.06831796  0.07375477]\n     [-0.01157693  0.17962074  0.13433206]]]\n\n\n   [[[ 0.03571969 -0.20905718 -0.05286504]\n     [-0.18766534 -0.10728011  0.04605131]\n     [-0.07477143  0.02631984  0.02496208]]\n\n    [[ 0.06653454  0.06536704  0.01587131]\n     [-0.00348636 -0.04439256  0.12680793]\n     [ 0.00328905  0.01904229 -0.06607334]]\n\n    [[-0.04666118 -0.06754828  0.07643934]\n     [-0.05434367 -0.09878142  0.06385987]\n     [ 0.02643086 -0.01466259 -0.1031612 ]]]\n\n\n   [[[-0.0572568   0.13133277 -0.0435285 ]\n     [-0.11612531  0.09036689 -0.09608591]\n     [-0.01049453 -0.02091818 -0.00642477]]\n\n    [[ 0.1255362  -0.07545673 -0.07554446]\n     [ 0.07270454 -0.24932131 -0.13024282]\n     [ 0.05507039 -0.0109083   0.00408967]]\n\n    [[-0.1099453  -0.11417828  0.06235902]\n     [ 0.03701246 -0.02138007 -0.05719795]\n     [-0.02627739 -0.15853535 -0.01103899]]]\n\n\n   [[[ 0.10380347 -0.05826453 -0.00690799]\n     [ 0.01000955 -0.11808137 -0.039118  ]\n     [ 0.02591963 -0.03464907 -0.21320052]]\n\n    [[-0.03449376 -0.00601143  0.05562805]\n     [ 0.09242225  0.01035819  0.09432289]\n     [-0.12854564  0.189775   -0.06698175]]\n\n    [[ 0.03462109  0.02545513 -0.14716192]\n     [ 0.02003146 -0.03616474  0.04574323]\n     [ 0.04782774 -0.04594192  0.01773669]]]]\n\n\n\n  [[[[ 0.04205685 -0.05454008 -0.0389443 ]\n     [ 0.07172828  0.03370164  0.00703573]\n     [ 0.01299563 -0.06371058  0.02505058]]\n\n    [[-0.09191396  0.06227853 -0.15412274]\n     [ 0.09069916  0.01907965 -0.05783302]\n     [-0.03441796 -0.11438221 -0.1011953 ]]\n\n    [[-0.00837748 -0.06554071 -0.14735688]\n     [-0.04640726  0.01484136  0.14445931]\n     [-0.09255736 -0.12196805 -0.0444463 ]]]\n\n\n   [[[ 0.01632853  0.01925437  0.02539274]\n     [-0.09239745 -0.13713452  0.06149488]\n     [-0.01742462  0.06624916  0.01490385]]\n\n    [[ 0.03866836  0.19375585  0.06069621]\n     [-0.11291414 -0.29582706  0.11678439]\n     [-0.09451667  0.05238266 -0.05152772]]\n\n    [[-0.11206269  0.09128021  0.09243178]\n     [ 0.01127258 -0.05845089  0.09795895]\n     [ 0.00747248  0.02055444  0.0121724 ]]]\n\n\n   [[[-0.11144694 -0.0030012  -0.03507657]\n     [-0.15461211 -0.00992483  0.02500556]\n     [-0.07733752 -0.09037463  0.02955181]]\n\n    [[-0.00988597  0.0264726  -0.14286363]\n     [-0.06936073 -0.01345975 -0.16290392]\n     [-0.07821255 -0.02489748  0.05186536]]\n\n    [[-0.12142604  0.04658077  0.00509979]\n     [-0.16115788 -0.19458961 -0.04082467]\n     [ 0.10544231 -0.10425973  0.01532217]]]\n\n\n   [[[ 0.08169251  0.05370622  0.00506061]\n     [ 0.08195242  0.08890768  0.03178475]\n     [-0.03648232  0.02655745 -0.18274172]]\n\n    [[ 0.07358464 -0.09604233  0.06556321]\n     [-0.02229194  0.17364709  0.07240117]\n     [-0.18307404  0.04115544 -0.15400645]]\n\n    [[ 0.0156146  -0.15857749 -0.12837477]\n     [ 0.07957774  0.06684072  0.0719762 ]\n     [-0.13781127 -0.03935293 -0.096707  ]]]]]]\n\n\n\n\n\n\n\nTimeDistributed\n\n\nScala:\n\n\nval layer = TimeDistributed(layer)\n\n\n\n\nPython:\n\n\nlayer = TimeDistributed(layer)\n\n\n\n\nThis layer is intended to apply contained layer to each temporal time slice\nof input tensor.\n\n\nThe input data format is [Batch, Time, Other dims]. For the contained layer, it must not change\nthe Other dims length.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = TimeDistributed(Linear(3, 2))\nval input = Tensor(2, 3, 3).rand()\nlayer.forward(input)\n\n\n\n\nInput:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.101178855 0.24703512  0.5021639\n0.44016296  0.5694682   0.9227419\n0.44305947  0.99880695  0.061260134\n\n(2,.,.) =\n0.7969414   0.20669454  0.27941006\n0.22917499  0.21765763  0.22535545\n0.389746    0.3487412   0.09982143\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x3]\n\n\n\n\nGives the output,\n\n\nres0: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.38540328  -0.4002408\n0.64361376  -0.33423418\n0.4066636   -0.36263257\n\n(2,.,.) =\n0.023447769 -0.77664447\n0.18752512  -0.53049827\n0.13314348  -0.5799509\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x2]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import TimeDistributed,Linear\nimport numpy as np\n\nlayer = TimeDistributed(Linear(3, 2))\n\ninput = np.random.random([2, 3, 3])\nlayer.forward(input)\n\n\n\n\nInput:\n\n\narray([[[ 0.3033118 ,  0.14485594,  0.58064829],\n        [ 0.72854527,  0.5051743 ,  0.42110462],\n        [ 0.78737995,  0.62032715,  0.20156085]],\n\n       [[ 0.17852246,  0.72772084,  0.24014506],\n        [ 0.01344367,  0.47754396,  0.65238232],\n        [ 0.29103965,  0.50614159,  0.2816109 ]]])\n\n\n\n\nGives the output,\n\n\narray([[[-0.10115834, -0.19001636],\n        [-0.1446743 , -0.47479331],\n        [-0.14148773, -0.61194205]],\n\n       [[-0.28484675, -0.58061397],\n        [-0.28640711, -0.29945394],\n        [-0.18956462, -0.46879411]]], dtype=float32)\n\n\n\n\n\n\nMultiRNNCell\n\n\nScala:\n\n\n// cells should be an array of Cell\nval model = MultiRNNCell(cells = multiRNNCells)\n\n\n\n\n\nPython:\n\n\n# cells should be a list of Cell\nmodel = MultiRNNCell(cells = multiRNNCells)\n\n\n\n\nA cell that stack multiple rnn cells(simpleRNN/LSTM/LSTMPeephole/GRU/ConvLSTMPeephole/ConvLSTMPeephole3D).\nOnly works with RecurrentDecoder. If you want to stack multiple cells with Recurrent. Use Sequential().add(Recurrent(cell)).add(Recurrent(cell))... instead\n\n\nParameters:\n\n\n\n\ncells\n list of RNNCell that will be composed in this order.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval hiddenSize = 2\nval inputSize = 2\nval batchSize = 2\nval seqLength = 2\nval input = Tensor(batchSize, inputSize, 3, 3).rand()\nval gradOutput = Tensor(batchSize, seqLength, hiddenSize, 3, 3).rand()\n\nval cells = Array(ConvLSTMPeephole(\n  inputSize, hiddenSize, 3, 3, 1), ConvLSTMPeephole(\n  inputSize, hiddenSize, 3, 3, 1)).asInstanceOf[Array[Cell[Float]]]\nval model = RecurrentDecoder(seqLength).add(MultiRNNCell[Float](cells))\n\nval output = model.forward(input)\nval gradientInput = model.backward(input, gradOutput)\n\nval states = model.getStates()\nmodel.setStates(states)\n-\n print(output)\n(1,1,1,.,.) =\n0.035993136 0.04062611  0.038863156 \n0.038338557 0.035591327 0.030849852 \n0.03203216  0.026839556 0.033618193 \n\n(1,1,2,.,.) =\n-0.011673012    -0.013518209    -0.0079738535   \n-0.013537201    -0.018129712    -0.013903147    \n-0.015891023    -0.016045166    -0.015133085    \n\n(1,2,1,.,.) =\n0.051638972 0.06415851  0.0562743   \n0.052649997 0.0433068   0.03683649  \n0.0408955   0.0315791   0.043429054 \n\n(1,2,2,.,.) =\n-0.019818805    -0.024628056    -0.014551916    \n-0.028422609    -0.036376823    -0.027259855    \n-0.030024627    -0.033032943    -0.030440552    \n\n(2,1,1,.,.) =\n0.037235383 0.03971467  0.039468434 \n0.032075796 0.031177454 0.029096292 \n0.03708834  0.031535562 0.036211465 \n\n(2,1,2,.,.) =\n-0.010179557    -0.011387618    -0.008739926    \n-0.013536877    -0.015962215    -0.017361978    \n-0.014717996    -0.014296502    -0.016867846    \n\n(2,2,1,.,.) =\n0.053095814 0.05863748  0.05486801  \n0.048524074 0.043160528 0.040398546 \n0.04628137  0.04125476  0.043807983 \n\n(2,2,2,.,.) =\n-0.017849356    -0.019537563    -0.018888   \n-0.025026768    -0.034455147    -0.02970969 \n-0.026703741    -0.033036336    -0.027824042    \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x2x3x3]\n-\n print(gradientInput)\n(1,1,1,.,.) =\n-0.021843424    -0.015910733    -0.013524098    \n-0.019261343    -0.017457811    -0.013539563    \n-0.016062422    -0.00383057 -0.0021248849   \n\n(1,1,2,.,.) =\n-0.0067594885   -0.012176989    -0.009976602    \n-0.007914364    -0.012559764    -7.768459E-4    \n-0.0026864496   -3.4671678E-4   -0.004467619    \n\n(1,2,1,.,.) =\n-0.011175868    -0.011886302    -0.0074315416   \n-0.009660093    -0.009753445    -0.008733444    \n-0.007047931    -0.0055002044   8.1458344E-4    \n\n(1,2,2,.,.) =\n-0.0016122719   -0.003776702    -0.006306042    \n-0.0032693855   -0.005982614    -0.0010739439   \n-0.0020354516   -9.59815E-4 -0.0010912241   \n\n(2,1,1,.,.) =\n-0.01399023 -0.01809205 -0.015330672    \n-0.025769815    -0.00905557 -0.021059947    \n4.068871E-4 -0.0060698274   -0.0048879837   \n\n(2,1,2,.,.) =\n-0.0013799625   -0.012721367    -0.008014497    \n-0.014288196    -0.0185386  -0.017980032    \n-0.0022621946   -0.015537363    -0.0024578157   \n\n(2,2,1,.,.) =\n-0.009561457    -0.007107652    -0.009356419    \n-0.009839717    -0.0021937331   -0.011457165    \n-0.0044140965   -0.0031195688   -0.0034824142   \n\n(2,2,2,.,.) =\n-3.2559165E-4   -0.0054697054   -0.0073612086   \n-0.0014059425   -0.006272946    -0.0028436938   \n0.0028391986    -0.005325649    -0.0028171889   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\ninput_size = 2\noutput_size = 2\nseq_length = 2\nbatch_size = 2\ninput = np.random.randn(batch_size, input_size, 3, 3)\ngrad_output = np.random.randn(batch_size, seq_length, output_size, 3, 3)\ncells = []\ncells.append(ConvLSTMPeephole(input_size, output_size, 3, 3, 1, with_peephole = False))\ncells.append(ConvLSTMPeephole(input_size, output_size, 3, 3, 1, with_peephole = False))\n\nmodel = RecurrentDecoder(seq_length).add(MultiRNNCell(cells))\n\noutput = model.forward(input)\ngradient_input = model.backward(input, grad_output)\n\nstates = model.get_states()\nmodel.set_states(states)\n-\n print output\n[[[[[ 0.01858711  0.03114421  0.02070103]\n    [ 0.01312863  0.00865137  0.02380039]\n    [ 0.02127378  0.02221535  0.02805275]]\n\n   [[ 0.05865936  0.06254016  0.07285608]\n    [ 0.07795827  0.06420417  0.06744433]\n    [ 0.07241444  0.06128554  0.0572256 ]]]\n\n\n  [[[ 0.01813958  0.0388087   0.03606314]\n    [ 0.00914392  0.01012017  0.03544089]\n    [ 0.02192647  0.02542255  0.04978891]]\n\n   [[ 0.06317041  0.07505058  0.10311646]\n    [ 0.10012341  0.06632978  0.09895241]\n    [ 0.10852461  0.08559311  0.07942865]]]]\n\n\n\n [[[[ 0.01352384  0.02394648  0.02436183]\n    [ 0.00793007  0.01043395  0.03022798]\n    [ 0.01539317  0.01955615  0.01543968]]\n\n   [[ 0.05844339  0.05187995  0.05877664]\n    [ 0.06405409  0.08493486  0.07711712]\n    [ 0.0737301   0.05892281  0.05127344]]]\n\n\n  [[[ 0.01918509  0.037876    0.04408969]\n    [ 0.01470916  0.01985376  0.03152689]\n    [ 0.02578159  0.04284319  0.0319238 ]]\n\n   [[ 0.08844157  0.07580076  0.07929584]\n    [ 0.09811849  0.08237181  0.09161879]\n    [ 0.11196285  0.08747569  0.09312635]]]]]\n\n-\n print gradient_input\n[[[[[-0.01967927  0.0118104   0.00034992]\n    [-0.0132792  -0.0127134   0.01193821]\n    [ 0.01297736  0.00550178  0.00874622]]\n\n   [[-0.00718097  0.01717402  0.00893286]\n    [-0.01143209  0.00079105  0.00920936]\n    [ 0.01638926  0.02479215  0.01613754]]]\n\n\n  [[[-0.02959971 -0.00214246 -0.00665301]\n    [-0.02010076  0.00135842  0.01485039]\n    [ 0.01877127  0.00205219 -0.01012903]]\n\n   [[-0.01455194  0.00882864  0.00075077]\n    [-0.0089175  -0.00774059  0.00534623]\n    [ 0.00421638  0.01152828  0.00886414]]]]\n\n\n\n [[[[ 0.00945553  0.01345219 -0.01787379]\n    [-0.02221245 -0.0047606   0.03430083]\n    [ 0.01496986 -0.01156155  0.00733263]]\n\n   [[ 0.02018309  0.00937438 -0.00253335]\n    [-0.00616324  0.00972739  0.02758386]\n    [ 0.01057806  0.01101648  0.00341856]]]\n\n\n  [[[ 0.00486301 -0.00717946 -0.01368812]\n    [-0.01296435  0.0466785  -0.0126987 ]\n    [ 0.01161697 -0.01207331  0.01638841]]\n\n   [[ 0.02077198 -0.00770913 -0.00807941]\n    [-0.00096983  0.01721167  0.0265876 ]\n    [ 0.00845431  0.01232574  0.0126167 ]]]]]\n\n\n\n\n\n\n\nHighway\n\n\nScala:\n\n\nval layer = Highway(size, withBias = true,\n                    activation = null,\n                    wRegularizer = null,\n                    bRegularizer = null)\n\n\n\n\nPython:\n\n\nlayer = Highway(size, with_bias=True,\n                activation=None,\n                wRegularizer=None,\n                bRegularizer=None)\n\n\n\n\nThis layer is Densely connected highway network.\nHighway layers are a natural extension of LSTMs to feedforward networks.\n\n\nParameters:\n\n\n\n\nsize\n input size\n\n\nwith_bias\n whether to include a bias\n\n\nactivation\n activation function, by default no activation will be used.\n  For Python, one can also pass the name of an existing activation as a string, eg. 'tanh', 'relu', 'sigmoid', 'hard_sigmoid', 'softmax' etc.\n\n\nwRegularizer\n instance of [[Regularizer]] (eg. L1 or L2 regularization), applied to the input weights matrices.\n\n\nbRegularizer\n instance of [[Regularizer]], applied to the bias.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = Highway(2, activation = Tanh())\n\nval input = Tensor(3, 2).randn()\nprintln(input)\nval output = module.forward(input)\nprintln(output)\n\n\n\n\nGives the output,\n\n\n1.096164    0.08578972\n0.2580359   1.629636\n-0.7571692  0.28832582\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x2]\n0.65883696  0.108842306\n-0.032798193    0.047720015\n-0.5495165  -0.16949607\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x2]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\ninput = np.random.rand(3, 2)\nprint \ninput is :\n,input\n\nm = Highway(2, activation=Tanh())\nout = m.forward(input)\nprint \noutput is :\n,out\n\n\n\n\nGives the output,\n\n\ninput is : [[ 0.65776902  0.63354682]\n [ 0.57766285  0.50117516]\n [ 0.15317826  0.60807496]]\ncreating: createHighway\noutput is : [[ 0.44779509 -0.10608637]\n [ 0.41307163 -0.14994906]\n [ 0.25687078  0.00718814]]", 
            "title": "Recurrent Layers"
        }, 
        {
            "location": "/APIGuide/Layers/Recurrent-Layers/#recurrent", 
            "text": "Scala:  val module = Recurrent()  Python:  module = Recurrent()  Recurrent module is a container of rnn cells. Different types of rnn cells can be added using add() function.    Recurrent supports returning state and cell of its rnn cells at last time step by using getHiddenState. output of getHiddenState\nis an Activity.  If contained cell is simple rnn, getHiddenState return value is a tensor(hidden state) which is  batch x hiddenSize . \nIf contained cell is lstm, getHiddenState return value is a table [hidden state, cell], both size is  batch x hiddenSize . \nIf contained cell is convlstm, getHiddenState return value is a table [hidden state, cell], both size is  batch x outputPlane x height x width . \nIf contained cell is convlstm3D, getHiddenState return value is a table [hidden state, cell], both size is  batch x outputPlane x height x width x length .  Recurrent also support init hidden state by using setHiddenState, currently only scala version. After we get hidden state from getHiddenState, we can directly used it in setHiddenState, which will set hidden state and cell at the first time step.  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.RandomGenerator.RNG\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval hiddenSize = 4\nval inputSize = 5\nval module = Recurrent().add(RnnCell(inputSize, hiddenSize, Tanh()))\nval input = Tensor(Array(1, 5, inputSize))\nfor (i  - 1 to 5) {\n  val rdmInput = Math.ceil(RNG.uniform(0.0, 1.0)*inputSize).toInt\n  input.setValue(1, i, rdmInput, 1.0f)\n}\n\nval output = module.forward(input)\n\nval state = module.getHiddenState()\nmodule.setHiddenState(state)  input\n(1,.,.) =\n0.0 0.0 0.0 1.0 0.0 \n0.0 0.0 0.0 0.0 1.0 \n0.0 1.0 0.0 0.0 0.0 \n0.0 1.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 1.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x5x5]  output\n(1,.,.) =\n0.23312 -0.5702369  -0.29894134 -0.46780553 \n-0.020703634    -0.6821252  -0.71641463 -0.3367952  \n0.031236319 -0.29233444 -0.730908   0.13494356  \n-0.22310422 -0.25562853 -0.59091455 -0.25055867 \n0.007001166 -0.7096118  -0.778529   -0.47429603 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x4]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nhiddenSize = 4\ninputSize = 5\nmodule = Recurrent().add(RnnCell(inputSize, hiddenSize, Tanh()))\ninput = np.zeros((1, 5, 5))\ninput[0][0][4] = 1\ninput[0][1][0] = 1\ninput[0][2][4] = 1\ninput[0][3][3] = 1\ninput[0][4][0] = 1\n\noutput = module.forward(input)\n\nres = module.get_hidden_state()  input\n[[[ 0.  0.  0.  0.  1.]\n  [ 1.  0.  0.  0.  0.]\n  [ 0.  0.  0.  0.  1.]\n  [ 0.  0.  0.  1.  0.]\n  [ 1.  0.  0.  0.  0.]]]  output\n[[[-0.43169451 -0.27838707  0.41472727  0.4450382 ]\n  [-0.10717546  0.59218317  0.67959404  0.62824875]\n  [-0.56745911 -0.31170678  0.44158491  0.31494498]\n  [ 0.13328044  0.41262615  0.37388939  0.10983802]\n  [-0.51452565  0.13222042  0.59192103  0.8393243 ]]]", 
            "title": "Recurrent"
        }, 
        {
            "location": "/APIGuide/Layers/Recurrent-Layers/#birecurrent", 
            "text": "Scala:  val module = BiRecurrent(merge=null)  Python:  module = BiRecurrent(merge=None,bigdl_type= float )  This layer implement a bidirectional recurrent neural network   merge  concat or add the output tensor of the two RNNs. Default is add   Scala example:  val module = BiRecurrent(CAddTable())\n.add(RnnCell(6, 4, Sigmoid()))\nval input = Tensor(Array(1, 2, 6)).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.55511624      0.44330198      0.9025551       0.26096714      0.3434667       0.20060952\n0.24903035      0.24026379      0.89252585      0.23025699      0.8131796       0.4013688\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x2x6]\n\nmodule.forward(input)\nres10: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.3577285       0.8861933       0.52908427      0.86278\n1.2850789       0.82549953      0.5560188       0.81468254\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4]  Python example:  module = BiRecurrent(CAddTable()).add(RnnCell(6, 4, Sigmoid()))\ninput = np.random.rand(1, 2, 6)\narray([[[ 0.75637438,  0.2642816 ,  0.61973312,  0.68565282,  0.73571443,\n          0.17167681],\n        [ 0.16439321,  0.06853251,  0.42257202,  0.42814042,  0.15706152,\n          0.57866659]]])\n\nmodule.forward(input)\narray([[[ 0.69091094,  0.97150528,  0.9562254 ,  1.14894259],\n        [ 0.83814102,  1.11358368,  0.96752423,  1.00913286]]], dtype=float32)", 
            "title": "BiRecurrent"
        }, 
        {
            "location": "/APIGuide/Layers/Recurrent-Layers/#recurrentdecoder", 
            "text": "Scala:  val module = RecurrentDecoder(outputLength = 5)  Python:  module = RecurrentDecoder(output_length = 5)  RecurrentDecoder module is a container of rnn cells which used to make\na prediction of the next timestep based on the prediction we made from\nthe previous timestep.  Input for RecurrentDecoder has to be batch x stepShape(shape of the input at a single time step).   During training, input at t(i) is output at t(i-1), input at t(0) is\nuser input.  Output for RecurrentDecoder has to be batch x outputLen x shape.  With RecurrentDecoder, inputsize and hiddensize of the cell must be the same.  Different types of rnn cells can be added using add() function.  Parameters:   outputLength  sequence length of output   Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.RandomGenerator.RNG\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval hiddenSize = 4\nval inputSize = 4\nval batchSize = 2\nval module = RecurrentDecoder(5).add(LSTMPeephole(inputSize, hiddenSize))\nval input = Tensor(Array(batchSize, inputSize)).rand()\n\nval output = module.forward(input)  input\n0.32985476  0.5081215   0.95177317  0.24744023  \n0.030384725 0.4868633   0.7781735   0.8046177   \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x4]  output\n(1,.,.) =\n-0.055717956    -0.14357334 0.011429226 0.10056843  \n-0.013699859    -0.078585915    0.050289743 0.027037282 \n0.011173044 -0.07941696 0.07381668  0.0020067326    \n0.016142089 -0.081511036    0.08775896  -0.011746041    \n0.0149942655    -0.08317861 0.09522702  -0.018894192    \n\n(2,.,.) =\n-0.041173447    -0.10931831 -0.04198869 0.1287807   \n0.010115819 -0.07071178 0.011613955 0.04737701  \n0.027745798 -0.07493171 0.054053202 0.010752724 \n0.02633817  -0.07929653 0.07783712  -0.008406129    \n0.020732995 -0.08214355 0.09030104  -0.017894702    \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5x4]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nhidden_size = 4\ninput_size = 4\nbatch_size = 2\nmodule = RecurrentDecoder(5).add(LSTMPeephole(input_size, hidden_size))\ninput = np.random.randn(batch_size, input_size)\n\noutput = module.forward(input)  input\n[[ 0.81779139 -0.55165689 -1.5898894   0.03572801]\n [ 0.77645041 -0.39702404  0.16826132  1.37081681]]  output\n[[[ 0.0492445  -0.26821002 -0.13461511  0.13712646]\n  [ 0.11038809 -0.22399209 -0.15706871  0.17625453]\n  [ 0.12579349 -0.20708388 -0.17392202  0.19129401]\n  [ 0.12953098 -0.20042329 -0.1886536   0.20086248]\n  [ 0.12905654 -0.19860952 -0.19987412  0.20697045]]\n\n [[ 0.146652   -0.12099689  0.05711044  0.03263233]\n  [ 0.15229702 -0.12689863 -0.05258115  0.09761411]\n  [ 0.14552552 -0.13706802 -0.11870711  0.13544162]\n  [ 0.13672781 -0.15158641 -0.16068494  0.16216366]\n  [ 0.13007095 -0.16579619 -0.18658556  0.18039529]]]", 
            "title": "RecurrentDecoder"
        }, 
        {
            "location": "/APIGuide/Layers/Recurrent-Layers/#rnn", 
            "text": "Scala:  val rnnCell = RnnCell[Double](\n  inputSize,\n  hiddenSize,\n  activation,\n  isInputWithBias = true,\n  isHiddenWithBias = true,\n  wRegularizer = null,\n  uRegularizer = null,\n  bRegularizer = null)  Python:  rnnCell = RnnCell(\n  input_size,\n  hidden_size,\n  activation,\n  isInputWithBias=True,\n  isHiddenWithBias=True,\n  wRegularizer=None,\n  uRegularizer=None,\n  bRegularizer=None)  Implementation of vanilla recurrent neural network cell  The input tensor in  forward(input)  is expected to be a 3D tensor ( batch x time x inputSize ). output of forward(input)  is also expected to be a 3D tensor ( batch x time x hiddenSize ).  The updating is defined as:  h_t = f(i2h * x_t + h2h * h_{t-1})  where   i2h  weight matrix of input to hidden units   h2h  weight matrix of hidden units to themselves through time  Parameters:   inputSize  input size. Default: 4  hiddenSize   hidden layer size. Default: 3  activation  instance of activation function for non-linearity.\n  For Python, one can also pass the name of an existing activation as a string, eg. 'tanh', 'relu', 'sigmoid', 'hard_sigmoid', 'softmax' etc.  isInputWithBias  boolean, whether to contain bias for input. Default: true  isHiddenWithBias  boolean, whether to contain bias for hidden layer. Default: true  wRegularizer  instance of  Regularizer (eg. L1 or L2 regularization), applied to the input weights matrices. Default: null  uRegularizer  instance of  Regularizer (eg. L1 or L2 regularization), applied to the recurrent weights matrices. Default: null  bRegularizer  instance of  Regularizer (eg. L1 or L2 regularization), applied to the bias. Default: null   Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval hiddenSize = 2\nval inputSize = 2\nval outputSize = 2\nval seqLength = 2\nval input = Tensor(T(\n  T(1.0f, 2.0f),\n  T(2.0f, 3.0f)\n)).resize(Array(1, seqLength, inputSize))\nval gradOutput = Tensor(T(\n  T(2.0f, 3.0f),\n  T(4.0f, 5.0f)\n)).resize(Array(1, seqLength, inputSize))\nval rec = Recurrent()\n\nval model = Sequential()\n    .add(rec.add(RnnCell(inputSize, hiddenSize, Tanh())))\n    .add(TimeDistributed(Linear(hiddenSize, outputSize)))\nval output = model.forward(input)\nval gradient = model.backward(input, gradOutput)\n-  print(output)\n# There's random factor. An output could be\n(1,.,.) =\n0.41442442      0.1663357       \n0.5339842       0.57332826      \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2]\n-  print(gradient)\n# There's random factor. An output could be\n(1,.,.) =\n1.1512008       2.181274        \n-0.4805725      1.6620052       \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nhidden_size = 2\ninput_size = 2\noutput_size = 2\nseq_length = 2\ninput = np.array([[\n  [1.0, 2.0],\n  [2.0, 3.0]\n]])\ngrad_output = np.array([[\n  [2.0, 3.0],\n  [4.0, 5.0]\n]])\nrec = Recurrent()\n\nmodel = Sequential() \\\n    .add(rec.add(RnnCell(input_size, hidden_size, Tanh()))) \\\n    .add(TimeDistributed(Linear(hidden_size, output_size)))\noutput = model.forward(input)\ngradient = model.backward(input, grad_output)\n-  print output\n# There's random factor. An output could be\n[[[-0.67860311  0.80307233]\n  [-0.77462083  0.97191858]]]\n\n-  print gradient\n# There's random factor. An output could be\n[[[-0.90771425  1.24791598]\n  [-0.70141178  0.97821164]]]", 
            "title": "RNN"
        }, 
        {
            "location": "/APIGuide/Layers/Recurrent-Layers/#lstm", 
            "text": "Scala:  val lstm = LSTM(\n  inputSize,\n  hiddenSize,\n  p = 0.0,\n  activation = null,\n  innerActivation = null,\n  wRegularizer = null,\n  uRegularizer = null,\n  bRegularizer = null)  Python:  lstm = LSTM(\n  input_size,\n  hidden_size,\n  p=0.0,\n  activation=None,\n  inner_activation=None,\n  wRegularizer=None,\n  uRegularizer=None,\n  bRegularizer=None)  Long Short Term Memory architecture.\nThe input tensor in  forward(input)  is expected to be a 3D tensor ( batch x time x inputSize ). output of forward(input)  is also expected to be a 3D tensor ( batch x time x hiddenSize ).  Ref:   http://arxiv.org/pdf/1303.5778v1 (blueprint for this module)  http://web.eecs.utk.edu/~itamar/courses/ECE-692/Bobby_paper1.pdf  http://arxiv.org/pdf/1503.04069v1.pdf  https://github.com/wojzaremba/lstm   Parameters:   inputSize  the size of each input vector  hiddenSize  Hidden unit size in the LSTM  p  is used for [[Dropout]] probability. For more details about\n           RNN dropouts, please refer to\n           [RnnDrop: A Novel Dropout for RNNs in ASR]\n           (http://www.stat.berkeley.edu/~tsmoon/files/Conference/asru2015.pdf)\n           [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks]\n           (https://arxiv.org/pdf/1512.05287.pdf)  activation  activation function, by default to be  Tanh  if not specified.\n  For Python, one can also pass the name of an existing activation as a string, eg. 'tanh', 'relu', 'sigmoid', 'hard_sigmoid', 'softmax' etc.  innerActivation  activation function for inner cells, by default to be  Sigmoid  if not specified.\n  For Python, one can also pass the name of an existing activation as a string, eg. 'tanh', 'relu', 'sigmoid', 'hard_sigmoid', 'softmax' etc.  wRegularizer  instance of [[Regularizer]] (eg. L1 or L2 regularization), applied to the input weights matrices.  uRegularizer  instance of [[Regularizer]] (eg. L1 or L2 regularization), applied to the recurrent weights matrices.  bRegularizer  instance of [[Regularizer]], applied to the bias.   Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.optim.SGD\nimport com.intel.analytics.bigdl.utils.RandomGenerator._\nimport com.intel.analytics.bigdl.tensor.{Storage, Tensor}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval hiddenSize = 4\nval inputSize = 6\nval outputSize = 5\nval seqLength = 5\nval seed = 100\n\nRNG.setSeed(seed)\nval input = Tensor(Array(1, seqLength, inputSize))\nval labels = Tensor(Array(1, seqLength))\nfor (i  - 1 to seqLength) {\n  val rdmLabel = Math.ceil(RNG.uniform(0, 1) * outputSize).toInt\n  val rdmInput = Math.ceil(RNG.uniform(0, 1) * inputSize).toInt\n  input.setValue(1, i, rdmInput, 1.0f)\n  labels.setValue(1, i, rdmLabel)\n}\n\nprintln(input)\nval rec = Recurrent(hiddenSize)\nval model = Sequential().add(\n  rec.add(\n      LSTM(inputSize, hiddenSize))).add(\n        TimeDistributed(Linear(hiddenSize, outputSize)))\n\nval criterion = TimeDistributedCriterion(\n  CrossEntropyCriterion(), false)\n\nval sgd = new SGD(learningRate=0.1, learningRateDecay=5e-7, weightDecay=0.1, momentum=0.002)\n\nval (weight, grad) = model.getParameters()\n\nval output = model.forward(input).toTensor\nval _loss = criterion.forward(output, labels)\nmodel.zeroGradParameters()\nval gradInput = criterion.backward(output, labels)\nmodel.backward(input, gradInput)\n\ndef feval(x: Tensor[Float]): (Float, Tensor[Float]) = {\n  val output = model.forward(input).toTensor\n  val _loss = criterion.forward(output, labels)\n  model.zeroGradParameters()\n  val gradInput = criterion.backward(output, labels)\n  model.backward(input, gradInput)\n  (_loss, grad)\n}\n\nvar loss: Array[Float] = null\nfor (i  - 1 to 100) {\n  loss = sgd.optimize(feval, weight)._2\n  println(s ${i}-th loss = ${loss(0)} )\n}  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nhidden_size = 4\ninput_size = 6\noutput_size = 5\nseq_length = 5\n\ninput = np.random.uniform(0, 1, [1, seq_length, input_size]).astype( float32 )\nlabels = np.random.uniform(1, 5, [1, seq_length]).astype( int )\n\nprint labels\nprint input\n\nrec = Recurrent()\nrec.add(LSTM(input_size, hidden_size))\n\nmodel = Sequential()\nmodel.add(rec)\nmodel.add(TimeDistributed(Linear(hidden_size, output_size)))\n\ncriterion = TimeDistributedCriterion(CrossEntropyCriterion(), False)\n\nsgd = SGD(learningrate=0.1, learningrate_decay=5e-7)\n\nweight, grad = model.parameters()\n\noutput = model.forward(input)\nloss = criterion.forward(input, labels)\ngradInput = criterion.backward(output, labels)\nmodel.backward(input, gradInput)", 
            "title": "LSTM"
        }, 
        {
            "location": "/APIGuide/Layers/Recurrent-Layers/#lstmpeephole", 
            "text": "Scala:  val model = LSTMPeephole(\n  inputSize = 4,\n  hiddenSize = 3,\n  p = 0.0,\n  wRegularizer = null,\n  uRegularizer = null,\n  bRegularizer = null)  Python:  model = LSTMPeephole(\n  input_size,\n  hidden_size,\n  p=0.0,\n  wRegularizer=None,\n  uRegularizer=None,\n  bRegularizer=None)  Long Short Term Memory architecture with peephole.\nThe input tensor in  forward(input)  is expected to be a 3D tensor ( batch x time x inputSize ). output of forward(input)  is also expected to be a 3D tensor ( batch x time x hiddenSize ).  Ref.   http://arxiv.org/pdf/1303.5778v1 (blueprint for this module)  http://web.eecs.utk.edu/~itamar/courses/ECE-692/Bobby_paper1.pdf  http://arxiv.org/pdf/1503.04069v1.pdf  https://github.com/wojzaremba/lstm   Parameters:   inputSize  the size of each input vector  hiddenSize  Hidden unit size in the LSTM  p  is used for [[Dropout]] probability. For more details about\n           RNN dropouts, please refer to\n           [RnnDrop: A Novel Dropout for RNNs in ASR]\n           (http://www.stat.berkeley.edu/~tsmoon/files/Conference/asru2015.pdf)\n           [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks]\n           (https://arxiv.org/pdf/1512.05287.pdf)  wRegularizer  instance of [[Regularizer]] (eg. L1 or L2 regularization), applied to the input weights matrices.  uRegularizer  instance of [[Regularizer]] (eg. L1 or L2 regularization), applied to the recurrent weights matrices.  bRegularizer  instance of [[Regularizer]], applied to the bias.   Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.RandomGenerator._\n\nval hiddenSize = 4\nval inputSize = 6\nval outputSize = 5\nval seqLength = 5\nval batchSize = 1\n\nval input = Tensor(Array(batchSize, seqLength, inputSize))\nfor (b  - 1 to batchSize) {\n  for (i  - 1 to seqLength) {\n    val rdmInput = Math.ceil(RNG.uniform(0.0, 1.0) * inputSize).toInt\n    input.setValue(b, i, rdmInput, 1.0f)\n  }\n}\n\nval rec = Recurrent(hiddenSize)\nval model = Sequential().add(rec.add(LSTMPeephole(inputSize, hiddenSize))).add(TimeDistributed(Linear(hiddenSize, outputSize)))\nval output = model.forward(input).toTensor\n\nscala  print(input)\n(1,.,.) =\n1.0 0.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0 1.0 \n0.0 1.0 0.0 0.0 0.0 0.0 \n0.0 0.0 0.0 0.0 0.0 1.0 \n1.0 0.0 0.0 0.0 0.0 0.0 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x5x6]\n\nscala  print(output)\n(1,.,.) =\n0.34764957  -0.31453514 -0.45646006 -0.42966008 -0.13651063 \n0.3624894   -0.2926056  -0.4347164  -0.40951455 -0.1775867  \n0.33391106  -0.29304913 -0.4748538  -0.45285955 -0.14919288 \n0.35499972  -0.29385415 -0.4419502  -0.42135617 -0.17544147 \n0.32911295  -0.30237123 -0.47175884 -0.4409852  -0.15733294 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x5]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nhiddenSize = 4\ninputSize = 6\noutputSize = 5\nseqLength = 5\nbatchSize = 1\n\ninput = np.random.randn(batchSize, seqLength, inputSize)\nrec = Recurrent(hiddenSize)\nmodel = Sequential().add(rec.add(LSTMPeephole(inputSize, hiddenSize))).add(TimeDistributed(Linear(hiddenSize, outputSize)))\noutput = model.forward(input)  print(input)\n[[[ 0.73624017 -0.91135209 -0.30627796 -1.07902111 -1.13549159  0.52868762]\n  [-0.07251559 -0.45596589  1.64020513  0.53218623  1.37993166 -0.47724947]\n  [-1.24958366 -1.22220259 -0.52454306  0.17382396  1.77666173 -1.2961758 ]\n  [ 0.45407533  0.82944329  0.02155243  1.82168093 -0.06022129  2.23823013]\n  [ 1.09100802  0.28555387 -0.94312648  0.55774033 -0.54895792  0.79885853]]]  print(output)\n[[[ 0.4034881  -0.26156989  0.46799076  0.06283229  0.11794794]\n  [ 0.37359846 -0.17925361  0.31623816  0.06038529  0.10813089]\n  [ 0.34150451 -0.16565879  0.25264332  0.1187657   0.05118144]\n  [ 0.40773875 -0.2028828   0.24765283  0.0986848   0.12132661]\n  [ 0.40263647 -0.22403356  0.38489845  0.04720671  0.1686969 ]]]", 
            "title": "LSTMPeephole"
        }, 
        {
            "location": "/APIGuide/Layers/Recurrent-Layers/#gru", 
            "text": "Scala:  val gru = GRU(\n  inputSize,\n  outputSize,\n  p = 0.0,\n  activation = null,\n  innerActivation = null,\n  wRegularizer = null,\n  uRegularizer = null,\n  bRegularizer = null)  Python:  gru = GRU(\n  inputSize,\n  outputSize,\n  p=0.0,\n  activation=None,\n  inner_activation=None,\n  wRegularizer=None,\n  uRegularizer=None,\n  bRegularizer=None)  Gated Recurrent Units architecture. The first input in sequence uses zero value for cell and hidden state.\nThe input tensor in  forward(input)  is expected to be a 3D tensor ( batch x time x inputSize ). output of forward(input)  is also expected to be a 3D tensor ( batch x time x outputSize ).  Ref.   http://www.wildml.com/2015/10/recurrent-neural-network-tutorial-part-4-implementing-a-grulstm-rnn-with-python-and-theano/  https://github.com/Element-Research/rnn/blob/master/GRU.lua   Parameters:   inputSize  the size of each input vector  outputSize  hidden unit size in GRU  p  is used for [[Dropout]] probability. For more details about\n          RNN dropouts, please refer to\n            RnnDrop: A Novel Dropout for RNNs in ASR \n            and  A Theoretically Grounded Application of Dropout in Recurrent Neural Networks . Default: 0.0  activation  activation function, by default to be  Tanh  if not specified.\n  For Python, one can also pass the name of an existing activation as a string, eg. 'tanh', 'relu', 'sigmoid', 'hard_sigmoid', 'softmax' etc.  innerActivation  activation function for inner cells, by default to be  Sigmoid  if not specified.\n  For Python, one can also pass the name of an existing activation as a string, eg. 'tanh', 'relu', 'sigmoid', 'hard_sigmoid', 'softmax' etc.  wRegularizer  instance of  Regularizer (eg. L1 or L2 regularization), applied to the input weights matrices. Default: null  uRegularizer  instance of  Regularizer (eg. L1 or L2 regularization), applied to the recurrent weights matrices. Default: null  bRegularizer  instance of  Regularizer (eg. L1 or L2 regularization), applied to the bias. Default: null   Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval hiddenSize = 2\nval inputSize = 2\nval outputSize = 2\nval seqLength = 2\nval input = Tensor(T(\n  T(1.0f, 2.0f),\n  T(2.0f, 3.0f)\n)).resize(Array(1, seqLength, inputSize))\nval gradOutput = Tensor(T(\n  T(2.0f, 3.0f),\n  T(4.0f, 5.0f)\n)).resize(Array(1, seqLength, inputSize))\nval rec = Recurrent()\n\nval model = Sequential()\n    .add(rec.add(GRU(inputSize, hiddenSize)))\n    .add(TimeDistributed(Linear(hiddenSize, outputSize)))\nval output = model.forward(input)\nval gradient = model.backward(input, gradOutput)\n\n-  print(output)\n# There's random factor. An output could be\n(1,.,.) =\n0.3833429       0.0082434565    \n-0.041063666    -0.08152798     \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2]\n\n\n-  print(gradient)\n# There's random factor. An output could be\n(1,.,.) =\n-0.7684499      -0.49320614     \n-0.98002595     -0.47857404     \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\nhidden_size = 2\ninput_size = 2\noutput_size = 2\nseq_length = 2\ninput = np.array([[\n  [1.0, 2.0],\n  [2.0, 3.0]\n]])\ngrad_output = np.array([[\n  [2.0, 3.0],\n  [4.0, 5.0]\n]])\nrec = Recurrent()\n\nmodel = Sequential() \\\n    .add(rec.add(GRU(input_size, hidden_size))) \\\n    .add(TimeDistributed(Linear(hidden_size, output_size)))\noutput = model.forward(input)\ngradient = model.backward(input, grad_output)\n-  print output\n# There's random factor. An output could be\n[[[ 0.27857888  0.20263115]\n  [ 0.29470384  0.22594413]]]\n-  print gradient\n[[[-0.32956457  0.27405274]\n  [-0.32718879  0.32963118]]]", 
            "title": "GRU"
        }, 
        {
            "location": "/APIGuide/Layers/Recurrent-Layers/#convlstmpeephole", 
            "text": "Scala:  val model = ConvLSTMPeephole(\n  inputSize = 2,\n  outputSize = 4,\n  kernelI = 3,\n  kernelC = 3,\n  stride = 1,\n  padding = -1,\n  activation = null,\n  innerActivation = null,\n  wRegularizer = null,\n  uRegularizer = null,\n  bRegularizer = null,\n  cRegularizer = null,\n  withPeephole = true)  Python:  model = ConvLSTMPeephole(\n  input_size = 2,\n  output_size = 4,\n  kernel_i = 3,\n  kernel_c = 3,\n  stride = 1,\n  padding = -1,\n  activation = None,\n  inner_activation = None,\n  wRegularizer = None,\n  uRegularizer = None,\n  bRegularizer = None,\n  cRegularizer = None,\n  with_peephole = True)  Convolution Long Short Term Memory architecture with peephole for 2 dimension images.\nThe input tensor in  forward(input)  is expected to be a 4D or 5D tensor\nIf ConvLSTM work with Recurrent, input is 5D tensor ( batch x time x nInputPlane x height x width ). output of forward(input)  is also expected to be a 5D tensor ( batch x time x outputPlane x height x width ).  If ConvLSTM work with RecurrentDecoder, input is 4D tensor ( batch x nInputPlane x height x width ). output of forward(input)  is expected to be a 5D tensor ( batch x outputLen x outputPlane x height x width ).  Ref.   https://arxiv.org/abs/1506.04214 (blueprint for this module)  https://github.com/viorik/ConvLSTM   Parameters:   inputSize  number of input planes in the image given into forward()  outputSize  number of output planes the convolution layer will produce  kernelI  convolutional filter size to convolve input  kernelC  convolutional filter size to convolve cell  stride  step of the convolution, default is 1  padding  step of the convolution, default is -1, behaves same with SAME padding in tensorflow\n                 Default stride,padding value ensure last 2 dim of output shape is the same with input  activation  activation function, by default to be  Tanh  if not specified.\n  For Python, one can also pass the name of an existing activation as a string, eg. 'tanh', 'relu', 'sigmoid', 'hard_sigmoid', 'softmax' etc.  innerActivation  activation function for inner cells, by default to be  Sigmoid  if not specified.\n  For Python, one can also pass the name of an existing activation as a string, eg. 'tanh', 'relu', 'sigmoid', 'hard_sigmoid', 'softmax' etc.  wRegularizer  instance of [[Regularizer]] (eg. L1 or L2 regularization), applied to the input weights matrices.  uRegularizer  instance of [[Regularizer]] (eg. L1 or L2 regularization), applied to the recurrent weights matrices.  bRegularizer  instance of [[Regularizer]], applied to the bias.  cRegularizer  instance of [[Regularizer]], applied to peephole.  withPeephole  whether use last cell status control a gate   Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.RandomGenerator._\n\nval outputSize = 4\nval inputSize = 3\nval seqLength = 2\nval batchSize = 1\n\nval input = Tensor(Array(batchSize, seqLength, inputSize, 3, 3)).rand()\n\nval rec = Recurrent()\n    val model = Sequential()\n      .add(rec\n        .add(ConvLSTMPeephole(inputSize, outputSize, 3, 3, 1, withPeephole = false)))\n\nval output = model.forward(input).toTensor\n\nscala  print(input)\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n0.32810056      0.23436882      0.1387327\n0.98273766      0.76427716      0.73554766\n0.47947738      0.72805804      0.43982902\n\n(1,1,2,.,.) =\n0.58144385      0.7534736       0.94412255\n0.05087549      0.021427812     0.91333073\n0.6844351       0.62977004      0.68027127\n\n(1,1,3,.,.) =\n0.48504198      0.16233416      0.7612549\n0.5387952       0.8391377       0.3687795\n0.85271466      0.71726906      0.79466575\n\n(1,2,1,.,.) =\n0.727532        0.05341824      0.32531977\n0.79593664      0.60162276      0.99931896\n0.7534103       0.71214366      0.031062916\n\n(1,2,2,.,.) =\n0.7343414       0.053005006     0.7448063\n0.2277985       0.47414783      0.21945253\n0.0034818714    0.11545401      0.73085403\n\n(1,2,3,.,.) =\n0.9644807       0.30755267      0.42099005\n0.6831594       0.50683653      0.14237563\n0.65172654      0.86954886      0.5077393\n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x2x3x3x3]\n\nscala  print(output)\n(1,1,1,.,.) =\n-0.04460164     -0.023752786    -0.014343993\n0.0067705153    0.08542874      0.020885356\n-0.042719357    -0.012113815    -0.030324051\n\n(1,1,2,.,.) =\n-0.038318213    -0.056998547    -0.02303889\n0.027873239     -0.040311974    -0.03261278\n0.015056128     0.11064132      0.0034682436\n\n(1,1,3,.,.) =\n0.006952648     0.011758738     -0.047590334\n0.052022297     0.040250845     -0.046224136\n-0.0084472215   -0.02629062     -0.0737972\n\n(1,1,4,.,.) =\n-0.087721705    0.0382758       0.027436329\n-0.030658737    -0.022953996    0.15838619\n0.055106055     0.004877564     0.098199464\n\n(1,2,1,.,.) =\n-0.069991425    -0.022071177    -0.06291955\n-0.006841902    0.010781053     0.05410414\n-0.03933395     -0.003422904    -0.106903486\n\n(1,2,2,.,.) =\n-0.059429795    -0.098534085    -0.068920344\n0.008100101     0.01948546      -0.040567685\n0.048763007     0.06001041      0.003068042\n\n(1,2,3,.,.) =\n0.02817994      0.006684172     -0.0962587\n0.022453573     0.014425971     -0.06118475\n-0.013392928    -0.04574135     -0.12722406\n\n(1,2,4,.,.) =\n-0.074006446    -0.028510522    0.06808455\n-0.021926142    0.036675904     0.18708621\n0.08240187      0.12469789      0.17341805\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x3x3]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\noutput_size = 4\ninput_size= 3\nseq_len = 2\nbatch_size = 1\n\ninput = np.random.randn(batch_size, seq_len, input_size, 3, 3)\nrec = Recurrent()\nmodel = Sequential().add(\n    rec.add(ConvLSTMPeephole(input_size, output_size, 3, 3, 1, with_peephole = False)))\noutput = model.forward(input)  print(input)\n[[[[[ 2.39979422  0.75647109  0.88928214]\n    [-0.07132477 -0.4348564   0.38270011]\n    [-1.03522309  0.38399781  0.20369625]]\n\n   [[-0.48392771  0.54371842 -1.42064221]\n    [-0.3711481  -0.16019682  0.82116693]\n    [ 0.15922215  1.79676148  0.38362552]]\n\n   [[-0.69402482  1.11930766 -1.29138064]\n    [ 0.92755002 -0.31138235  0.34953374]\n    [-0.0176643   1.13839126  0.02133309]]]\n\n\n  [[[-0.40704988  0.1819258  -0.21400335]\n    [ 0.65717965  0.75912824  1.49077775]\n    [-0.74917913 -1.48460681  1.06098727]]\n\n   [[ 1.04942415  1.2558929  -1.24367776]\n    [-0.13452707  0.01485188  2.41215047]\n    [ 0.59776321 -0.38602613  0.57937933]]\n\n   [[ 0.55007301  1.22571134  0.11656841]\n    [-0.4722457   1.79801493  0.59698431]\n    [ 0.25119458 -0.27323404  1.5516505 ]]]]]  print(output)\n[[[[[-0.22908808 -0.08243818 -0.10530333]\n    [ 0.04545299  0.0347576   0.06448466]\n    [ 0.00148075 -0.01422587 -0.04424585]]\n\n   [[-0.08625289  0.00121372  0.00961097]\n    [-0.08068027  0.2389598  -0.08875058]\n    [-0.10860988 -0.08109165  0.05274875]]\n\n   [[ 0.01545026 -0.14079301  0.0162897 ]\n    [ 0.0114354   0.01696588  0.09375648]\n    [ 0.06766916  0.16015787 -0.01530124]]\n\n   [[-0.00311095  0.07033439  0.05258823]\n    [-0.04846094 -0.11335927 -0.22434352]\n    [-0.09923813 -0.064981   -0.05341392]]]\n\n\n  [[[-0.01070079  0.01705431 -0.10199456]\n    [-0.19023973 -0.1359819   0.11552753]\n    [ 0.04331793  0.00603994 -0.19059387]]\n\n   [[-0.12100818 -0.01191896  0.08049219]\n    [-0.10134248  0.02910084 -0.00024394]\n    [-0.09548382 -0.18623565  0.18261637]]\n\n   [[-0.00644266  0.03494127  0.09105418]\n    [ 0.03467004 -0.1236406   0.23844369]\n    [ 0.12281432  0.09469442  0.04526915]]\n\n   [[ 0.00190313  0.01997324 -0.17609949]\n    [-0.0937     -0.03763293 -0.04860835]\n    [-0.15700462 -0.17341313 -0.06551415]]]]]", 
            "title": "ConvLSTMPeephole"
        }, 
        {
            "location": "/APIGuide/Layers/Recurrent-Layers/#convlstmpeephole3d", 
            "text": "Scala:  val model = ConvLSTMPeephole3D(\n  inputSize = 2,\n  outputSize = 4,\n  kernelI = 3,\n  kernelC = 3,\n  stride = 1,\n  padding = -1,\n  wRegularizer = null,\n  uRegularizer = null,\n  bRegularizer = null,\n  cRegularizer = null,\n  withPeephole = true)  Python:  model = ConvLSTMPeephole3D(\n  input_size = 2,\n  output_size = 4,\n  kernel_i = 3,\n  kernel_c = 3,\n  stride = 1,\n  padding = -1,\n  wRegularizer=None,\n  uRegularizer=None,\n  bRegularizer=None,\n  cRegularizer=None,\n  with_peephole = True)  Similar to Convlstm2D, it's a Convolution Long Short Term Memory architecture with peephole but for 3 spatial dimension images.\nThe input tensor in  forward(input)  is expected to be a 5D or 6D tensor\nIf work with Recurrent, input is 6D tensor ( batch x time x nInputPlane x height x width x length ). output of forward(input)  is also expected to be a 6D tensor ( batch x time x outputPlane x height x width x length ).  If work with RecurrentDecoder, input is 5D tensor ( batch x nInputPlane x height x width x length ). output of forward(input)  is expected to be a 6D tensor ( batch x outputLen x outputPlane x height x width x length ).  Parameters:   inputSize  number of input planes in the image given into forward()  outputSize  number of output planes the convolution layer will produce  kernelI  convolutional filter size to convolve input  kernelC  convolutional filter size to convolve cell  stride  step of the convolution, default is 1  padding  step of the convolution, default is -1, behaves same with SAME padding in tensorflow\n                 Default stride,padding value ensure last 3 dim of output shape is the same with input  wRegularizer  instance of [[Regularizer]] (eg. L1 or L2 regularization), applied to the input weights matrices.  uRegularizer  instance of [[Regularizer]] (eg. L1 or L2 regularization), applied to the recurrent weights matrices.  bRegularizer  instance of [[Regularizer]], applied to the bias.  cRegularizer  instance of [[Regularizer]], applied to peephole.  withPeephole  whether use last cell status control a gate   Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.RandomGenerator._\n\nval outputSize = 4\nval inputSize = 3\nval seqLength = 2\nval batchSize = 1\n\nval input = Tensor(Array(batchSize, seqLength, inputSize, 3, 3, 3)).rand()\n\nval rec = Recurrent()\n    val model = Sequential()\n      .add(rec\n        .add(ConvLSTMPeephole3D(inputSize, outputSize, 3, 3, 1, withPeephole = false)))\n\nval output = model.forward(input).toTensor\n\nscala  print(input)\n(1,1,1,1,.,.) =\n0.42592695  0.32742274  0.7926296   \n0.21923159  0.7427106   0.31764257  \n0.121872835 0.54231954  0.32091624  \n\n(1,1,1,2,.,.) =\n0.06762145  0.8054027   0.8297814   \n0.95535785  0.20807801  0.46387103  \n0.90996957  0.7849159   0.79179865  \n\n(1,1,1,3,.,.) =\n0.22927228  0.29869995  0.1145133   \n0.12646529  0.8917339   0.7545332   \n0.8044227   0.5340327   0.9784876   \n\n(1,1,2,1,.,.) =\n0.68444395  0.47932255  0.28224406  \n0.5083046   0.9364489   0.27006733  \n0.24699332  0.55712855  0.50037974  \n\n(1,1,2,2,.,.) =\n0.46334672  0.10979338  0.6378528   \n0.8557069   0.10780747  0.73767877  \n0.12505454  0.72492164  0.5440267   \n\n(1,1,2,3,.,.) =\n0.15598479  0.52033675  0.64091414  \n0.15149859  0.64515823  0.6023936   \n0.31461328  0.1901752   0.98015004  \n\n(1,1,3,1,.,.) =\n0.9700778   0.24109624  0.23764393  \n0.16602103  0.97310185  0.072756775 \n0.849201    0.825025    0.2753475   \n\n(1,1,3,2,.,.) =\n0.8621034   0.24596989  0.56645423  \n0.004375741 0.9873366   0.89219636  \n0.56948274  0.291723    0.5503815   \n\n(1,1,3,3,.,.) =\n0.626368    0.9389012   0.8974684   \n0.8553843   0.39709046  0.372683    \n0.38087663  0.94703597  0.71530545  \n\n(1,2,1,1,.,.) =\n0.74050623  0.39862877  0.57509166  \n0.87832487  0.41345102  0.6262451   \n0.665165    0.49570015  0.8304163   \n\n(1,2,1,2,.,.) =\n0.30847755  0.51876235  0.10555197  \n0.10103849  0.9479695   0.11847988  \n0.60081536  0.003097216 0.22800316  \n\n(1,2,1,3,.,.) =\n0.113101795 0.76638913  0.091707565 \n0.30347276  0.029687135 0.37973404  \n0.67719024  0.02180517  0.12747364  \n\n(1,2,2,1,.,.) =\n0.12513511  0.74210113  0.82569206  \n0.1406212   0.7400157   0.041633762 \n0.26903376  0.6195371   0.618376    \n\n(1,2,2,2,.,.) =\n0.068732955 0.09746146  0.15479624  \n0.57418007  0.7181547   0.6494809   \n0.29213288  0.35022008  0.15421997  \n\n(1,2,2,3,.,.) =\n0.47196773  0.55650383  0.938309    \n0.70717365  0.68351734  0.32646814  \n0.99775004  0.2596666   0.6803594   \n\n(1,2,3,1,.,.) =\n0.6320722   0.105437785 0.36752152  \n0.8347324   0.38376364  0.641918    \n0.40254018  0.5421287   0.792421    \n\n(1,2,3,2,.,.) =\n0.2652298   0.6261154   0.21971565  \n0.31418183  0.44987184  0.43880364  \n0.76821107  0.17070894  0.47295105  \n\n(1,2,3,3,.,.) =\n0.16514553  0.37016368  0.23397927  \n0.19776458  0.07518195  0.48995376  \n0.13584352  0.23562871  0.41726747  \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x2x3x3x3x3]\n\nscala  print(output)\n(1,1,1,1,.,.) =\n0.014528348 0.03160259  0.05313618  \n-0.011796958    0.027994404 0.028153816 \n-0.010374474    0.029486801 0.033610236 \n\n(1,1,1,2,.,.) =\n0.07966786  0.041255455 0.09181337  \n0.025984935 0.06594588  0.07572434  \n0.019637575 0.0068716113    0.03775029  \n\n(1,1,1,3,.,.) =\n0.07043511  0.044567406 0.08229201  \n0.10589862  0.109124646 0.0888148   \n0.018544039 0.04097363  0.09130414  \n\n(1,1,2,1,.,.) =\n0.1032162   -0.01981514 -0.0016546922   \n0.026028564 0.0100736385    0.009424217 \n-0.048695907    -0.009172593    -0.029458746    \n\n(1,1,2,2,.,.) =\n0.058081806 0.101963215 0.056670886 \n0.09300327  0.035424378 0.02410931  \n0.056604195 -0.0032351227   0.027961217 \n\n(1,1,2,3,.,.) =\n0.11710516  0.09371774  -0.013825272    \n0.02930173  0.06391968  0.04034334  \n0.010447707 -0.004905071    0.011929871 \n\n(1,1,3,1,.,.) =\n-0.020980358    0.08554982  -0.07644813 \n0.06367171  -0.06037125 0.019925931 \n0.0026421212    0.051610045 0.023478134 \n\n(1,1,3,2,.,.) =\n-0.033074334    -0.0381583  -0.019341394    \n-0.0625153  -0.06907081 -0.019746307    \n-0.010362335    0.0062695937    0.054116223 \n\n(1,1,3,3,.,.) =\n0.00461099  -0.03308314 -6.8137434E-4   \n-0.075023845    -0.024970314    0.008133534 \n0.019836657 0.051302493 0.043689556 \n\n(1,1,4,1,.,.) =\n0.027088374 0.008537832 -0.020948375    \n0.021569671 0.016515112 -0.019221392    \n-0.0074050943   -0.03274501 0.003256779 \n\n(1,1,4,2,.,.) =\n8.967657E-4 0.019020535 -0.05990117 \n0.06226491  -0.017516658    -0.028854925    \n0.048010994 0.031080479 -4.8373322E-4   \n\n(1,1,4,3,.,.) =\n0.03253352  -0.023469497    -0.047273926    \n-0.03765316 0.011091222 0.0036612307    \n0.050733108 0.01736545  0.0061482657    \n\n(1,2,1,1,.,.) =\n-0.0037416879   0.03895818  0.102294624 \n0.011019588 0.03201482  0.07654998  \n-0.015550408    0.009587483 0.027655594 \n\n(1,2,1,2,.,.) =\n0.089279816 0.03306113  0.11713534  \n0.07299529  0.057692382 0.11090511  \n-0.0031341386   0.091527686 0.07210587  \n\n(1,2,1,3,.,.) =\n0.080724075 0.07707712  0.07624206  \n0.06552311  0.104010254 0.09213451  \n0.07030998  0.0022800618    0.12461836  \n\n(1,2,2,1,.,.) =\n0.10180804  0.020320226 -0.0025817656   \n0.016294254 -0.024293585    -0.004399727    \n-0.032854877    1.1120379E-4    -0.02109197 \n\n(1,2,2,2,.,.) =\n0.0968586   0.07098973  0.07648221  \n0.0918679   0.10268471  0.056947876 \n0.027774762 -0.03927014 0.04663368  \n\n(1,2,2,3,.,.) =\n0.10225944  0.08460646  -8.393754E-4    \n0.051307157 0.011988232 0.037762236 \n0.029469138 0.023369621 0.037675448 \n\n(1,2,3,1,.,.) =\n-0.017874755    0.08561468  -0.066132575    \n0.010558257 -0.01448278 0.0073027355    \n-0.007930762    0.052643955 0.008378773 \n\n(1,2,3,2,.,.) =\n-0.009250246    -0.06543376 -0.025082456    \n-0.093004115    -0.08637037 -0.063408665    \n-0.06941878 0.010163672 0.07595171  \n\n(1,2,3,3,.,.) =\n0.014756428 -0.040423956    -0.011537984    \n-0.046337806    -0.008416044    0.068246834 \n3.5782385E-4    0.056929104 0.052956138 \n\n(1,2,4,1,.,.) =\n0.033539586 0.013915413 -0.024538055    \n0.042590756 0.034134552 0.021031722 \n-0.026687687    0.0012957935    -0.0053077694   \n\n(1,2,4,2,.,.) =\n0.0033482902    -0.037335612    -0.0956953  \n0.007350738 -0.05237038 -0.08849126 \n0.016356941 0.032067236 -0.0012172575   \n\n(1,2,4,3,.,.) =\n-0.020006038    -0.030038685    -0.054900024    \n-0.014171911    0.01270077  -0.004130667    \n0.04607582  0.040028486 0.011846061 \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x3x3x3]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\noutput_size = 4\ninput_size= 3\nseq_len = 2\nbatch_size = 1\n\ninput = np.random.randn(batch_size, seq_len, input_size, 3, 3, 3)\nrec = Recurrent()\nmodel = Sequential().add(\n    rec.add(ConvLSTMPeephole3D(input_size, output_size, 3, 3, 1, with_peephole = False)))\noutput = model.forward(input)  print(input)\n[[[[[[ -8.92954769e-02  -9.77685543e-03   1.97566296e+00]\n     [ -5.76910662e-01  -9.08404346e-01  -4.70799006e-01]\n     [ -9.86229768e-01   7.87303916e-01   2.29691167e+00]]\n\n    [[ -7.48240036e-01   4.12766483e-01  -3.88947296e-01]\n     [ -1.39879028e+00   2.43984720e+00  -2.43947000e-01]\n     [  1.86468980e-01   1.34599111e+00  -6.97932324e-01]]\n\n    [[  1.23278710e+00  -4.02661913e-01   8.50721265e-01]\n     [ -1.79452089e-01  -5.58813385e-01   1.10060751e+00]\n     [ -6.27181580e-01  -2.69531726e-01  -1.07857962e-01]]]\n\n\n   [[[ -1.01462355e+00   5.47520811e-02   3.06976674e-01]\n     [  9.64871158e-01  -1.16953916e+00   1.41880629e+00]\n     [  1.19127007e+00   1.71403439e-01  -1.30787798e+00]]\n\n    [[ -6.44313121e-01  -8.45131087e-01   6.99275525e-02]\n     [ -3.07656855e-01   1.25746926e+00   3.89980508e-02]\n     [ -2.59853355e-01   8.78915612e-01  -9.37204072e-02]]\n\n    [[  7.69958423e-02  -3.22523203e-01  -7.31295167e-01]\n     [  1.46184856e+00   1.88641278e+00   1.46645372e-01]\n     [  4.38390570e-01  -2.85102515e-01  -1.81269541e+00]]]\n\n\n   [[[  2.95126419e-01  -1.13715815e+00   9.36848777e-01]\n     [ -1.62071909e+00  -1.06018926e+00   1.88416944e+00]\n     [ -5.81248254e-01   1.05162543e+00  -3.58790528e-01]]\n\n    [[ -7.54710826e-01   2.29994522e+00   7.24276828e-01]\n     [  5.77031441e-01   7.36132125e-01   2.24719266e+00]\n     [ -4.53710071e-05   1.98478259e-01  -2.62825655e-01]]\n\n    [[  1.68124733e+00  -9.97417864e-01  -3.73490116e-01]\n     [ -1.12558844e+00   2.60032255e-01   9.67994680e-01]\n     [  1.78486852e+00   1.17514142e+00  -1.96871551e-01]]]]\n\n\n\n  [[[[  4.43156770e-01  -4.42279658e-01   8.00893010e-01]\n     [ -2.04817319e-01  -3.89658940e-01  -1.10950351e+00]\n     [  6.61008455e-01  -4.07251176e-01   1.14871901e+00]]\n\n    [[ -2.07785815e-01  -8.92450022e-01  -4.23830113e-02]\n     [ -5.26555807e-01   3.76671145e-02  -2.17877979e-01]\n     [ -7.68371469e-01   1.53052409e-01   1.02405949e+00]]\n\n    [[  5.75018628e-01  -9.47162716e-01   6.47917376e-01]\n     [  4.66967303e-01   1.00917068e-01  -1.60894238e+00]\n     [ -1.46491032e-01   3.17782758e+00   1.12581079e-01]]]\n\n\n   [[[  9.32343396e-01  -1.03853742e+00   5.67577254e-02]\n     [  1.25266813e+00   3.52463164e-01  -1.86783652e-01]\n     [ -1.20321270e+00   3.95144053e-01   2.09975625e-01]]\n\n    [[  2.68240844e-01  -1.34931544e+00   1.34259455e+00]\n     [  6.34339337e-01  -5.21231073e-02  -3.91895492e-01]\n     [  1.53872699e-01  -5.07236962e-02  -2.90772390e-01]]\n\n    [[ -5.07933749e-01   3.78036493e-01   7.41781186e-01]\n     [  1.62736825e+00   1.24125644e+00  -3.97490478e-01]\n     [  5.77762257e-01   1.10372911e+00   1.58060183e-01]]]\n\n\n   [[[  5.31859839e-01   1.72805654e+00  -3.77124271e-01]\n     [  1.24638369e+00  -1.54061928e+00   6.22001793e-01]\n     [  1.92447446e+00   7.71351435e-01  -1.59998400e+00]]\n\n    [[  1.44289958e+00   5.41433535e-01   9.19769038e-01]\n     [  9.92873720e-01  -9.05746035e-01   1.35906705e+00]\n     [  1.38994943e+00   2.11451648e+00  -1.58783119e-01]]\n\n    [[ -1.44024889e+00  -5.12269041e-01   8.56761529e-02]\n     [  1.16668889e+00   7.58164067e-01  -1.04304927e+00]\n     [  6.34138215e-01  -7.89939971e-01  -5.52376307e-01]]]]]]  print(output)\n[[[[[[ 0.08801123 -0.15533912 -0.08897342]\n     [ 0.01158205 -0.01103314  0.02793931]\n     [-0.01269898 -0.09544773  0.03573112]]\n\n    [[-0.15603164 -0.16063154 -0.09672774]\n     [ 0.15531734  0.05808824 -0.01653268]\n     [-0.06348733 -0.10497692 -0.13086422]]\n\n    [[ 0.002062   -0.01604773 -0.14802884]\n     [-0.0934701  -0.06831796  0.07375477]\n     [-0.01157693  0.17962074  0.13433206]]]\n\n\n   [[[ 0.03571969 -0.20905718 -0.05286504]\n     [-0.18766534 -0.10728011  0.04605131]\n     [-0.07477143  0.02631984  0.02496208]]\n\n    [[ 0.06653454  0.06536704  0.01587131]\n     [-0.00348636 -0.04439256  0.12680793]\n     [ 0.00328905  0.01904229 -0.06607334]]\n\n    [[-0.04666118 -0.06754828  0.07643934]\n     [-0.05434367 -0.09878142  0.06385987]\n     [ 0.02643086 -0.01466259 -0.1031612 ]]]\n\n\n   [[[-0.0572568   0.13133277 -0.0435285 ]\n     [-0.11612531  0.09036689 -0.09608591]\n     [-0.01049453 -0.02091818 -0.00642477]]\n\n    [[ 0.1255362  -0.07545673 -0.07554446]\n     [ 0.07270454 -0.24932131 -0.13024282]\n     [ 0.05507039 -0.0109083   0.00408967]]\n\n    [[-0.1099453  -0.11417828  0.06235902]\n     [ 0.03701246 -0.02138007 -0.05719795]\n     [-0.02627739 -0.15853535 -0.01103899]]]\n\n\n   [[[ 0.10380347 -0.05826453 -0.00690799]\n     [ 0.01000955 -0.11808137 -0.039118  ]\n     [ 0.02591963 -0.03464907 -0.21320052]]\n\n    [[-0.03449376 -0.00601143  0.05562805]\n     [ 0.09242225  0.01035819  0.09432289]\n     [-0.12854564  0.189775   -0.06698175]]\n\n    [[ 0.03462109  0.02545513 -0.14716192]\n     [ 0.02003146 -0.03616474  0.04574323]\n     [ 0.04782774 -0.04594192  0.01773669]]]]\n\n\n\n  [[[[ 0.04205685 -0.05454008 -0.0389443 ]\n     [ 0.07172828  0.03370164  0.00703573]\n     [ 0.01299563 -0.06371058  0.02505058]]\n\n    [[-0.09191396  0.06227853 -0.15412274]\n     [ 0.09069916  0.01907965 -0.05783302]\n     [-0.03441796 -0.11438221 -0.1011953 ]]\n\n    [[-0.00837748 -0.06554071 -0.14735688]\n     [-0.04640726  0.01484136  0.14445931]\n     [-0.09255736 -0.12196805 -0.0444463 ]]]\n\n\n   [[[ 0.01632853  0.01925437  0.02539274]\n     [-0.09239745 -0.13713452  0.06149488]\n     [-0.01742462  0.06624916  0.01490385]]\n\n    [[ 0.03866836  0.19375585  0.06069621]\n     [-0.11291414 -0.29582706  0.11678439]\n     [-0.09451667  0.05238266 -0.05152772]]\n\n    [[-0.11206269  0.09128021  0.09243178]\n     [ 0.01127258 -0.05845089  0.09795895]\n     [ 0.00747248  0.02055444  0.0121724 ]]]\n\n\n   [[[-0.11144694 -0.0030012  -0.03507657]\n     [-0.15461211 -0.00992483  0.02500556]\n     [-0.07733752 -0.09037463  0.02955181]]\n\n    [[-0.00988597  0.0264726  -0.14286363]\n     [-0.06936073 -0.01345975 -0.16290392]\n     [-0.07821255 -0.02489748  0.05186536]]\n\n    [[-0.12142604  0.04658077  0.00509979]\n     [-0.16115788 -0.19458961 -0.04082467]\n     [ 0.10544231 -0.10425973  0.01532217]]]\n\n\n   [[[ 0.08169251  0.05370622  0.00506061]\n     [ 0.08195242  0.08890768  0.03178475]\n     [-0.03648232  0.02655745 -0.18274172]]\n\n    [[ 0.07358464 -0.09604233  0.06556321]\n     [-0.02229194  0.17364709  0.07240117]\n     [-0.18307404  0.04115544 -0.15400645]]\n\n    [[ 0.0156146  -0.15857749 -0.12837477]\n     [ 0.07957774  0.06684072  0.0719762 ]\n     [-0.13781127 -0.03935293 -0.096707  ]]]]]]", 
            "title": "ConvLSTMPeephole3D"
        }, 
        {
            "location": "/APIGuide/Layers/Recurrent-Layers/#timedistributed", 
            "text": "Scala:  val layer = TimeDistributed(layer)  Python:  layer = TimeDistributed(layer)  This layer is intended to apply contained layer to each temporal time slice\nof input tensor.  The input data format is [Batch, Time, Other dims]. For the contained layer, it must not change\nthe Other dims length.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval layer = TimeDistributed(Linear(3, 2))\nval input = Tensor(2, 3, 3).rand()\nlayer.forward(input)  Input:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.101178855 0.24703512  0.5021639\n0.44016296  0.5694682   0.9227419\n0.44305947  0.99880695  0.061260134\n\n(2,.,.) =\n0.7969414   0.20669454  0.27941006\n0.22917499  0.21765763  0.22535545\n0.389746    0.3487412   0.09982143\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x3]  Gives the output,  res0: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.38540328  -0.4002408\n0.64361376  -0.33423418\n0.4066636   -0.36263257\n\n(2,.,.) =\n0.023447769 -0.77664447\n0.18752512  -0.53049827\n0.13314348  -0.5799509\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x2]  Python example:  from bigdl.nn.layer import TimeDistributed,Linear\nimport numpy as np\n\nlayer = TimeDistributed(Linear(3, 2))\n\ninput = np.random.random([2, 3, 3])\nlayer.forward(input)  Input:  array([[[ 0.3033118 ,  0.14485594,  0.58064829],\n        [ 0.72854527,  0.5051743 ,  0.42110462],\n        [ 0.78737995,  0.62032715,  0.20156085]],\n\n       [[ 0.17852246,  0.72772084,  0.24014506],\n        [ 0.01344367,  0.47754396,  0.65238232],\n        [ 0.29103965,  0.50614159,  0.2816109 ]]])  Gives the output,  array([[[-0.10115834, -0.19001636],\n        [-0.1446743 , -0.47479331],\n        [-0.14148773, -0.61194205]],\n\n       [[-0.28484675, -0.58061397],\n        [-0.28640711, -0.29945394],\n        [-0.18956462, -0.46879411]]], dtype=float32)", 
            "title": "TimeDistributed"
        }, 
        {
            "location": "/APIGuide/Layers/Recurrent-Layers/#multirnncell", 
            "text": "Scala:  // cells should be an array of Cell\nval model = MultiRNNCell(cells = multiRNNCells)  Python:  # cells should be a list of Cell\nmodel = MultiRNNCell(cells = multiRNNCells)  A cell that stack multiple rnn cells(simpleRNN/LSTM/LSTMPeephole/GRU/ConvLSTMPeephole/ConvLSTMPeephole3D).\nOnly works with RecurrentDecoder. If you want to stack multiple cells with Recurrent. Use Sequential().add(Recurrent(cell)).add(Recurrent(cell))... instead  Parameters:   cells  list of RNNCell that will be composed in this order.   Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval hiddenSize = 2\nval inputSize = 2\nval batchSize = 2\nval seqLength = 2\nval input = Tensor(batchSize, inputSize, 3, 3).rand()\nval gradOutput = Tensor(batchSize, seqLength, hiddenSize, 3, 3).rand()\n\nval cells = Array(ConvLSTMPeephole(\n  inputSize, hiddenSize, 3, 3, 1), ConvLSTMPeephole(\n  inputSize, hiddenSize, 3, 3, 1)).asInstanceOf[Array[Cell[Float]]]\nval model = RecurrentDecoder(seqLength).add(MultiRNNCell[Float](cells))\n\nval output = model.forward(input)\nval gradientInput = model.backward(input, gradOutput)\n\nval states = model.getStates()\nmodel.setStates(states)\n-  print(output)\n(1,1,1,.,.) =\n0.035993136 0.04062611  0.038863156 \n0.038338557 0.035591327 0.030849852 \n0.03203216  0.026839556 0.033618193 \n\n(1,1,2,.,.) =\n-0.011673012    -0.013518209    -0.0079738535   \n-0.013537201    -0.018129712    -0.013903147    \n-0.015891023    -0.016045166    -0.015133085    \n\n(1,2,1,.,.) =\n0.051638972 0.06415851  0.0562743   \n0.052649997 0.0433068   0.03683649  \n0.0408955   0.0315791   0.043429054 \n\n(1,2,2,.,.) =\n-0.019818805    -0.024628056    -0.014551916    \n-0.028422609    -0.036376823    -0.027259855    \n-0.030024627    -0.033032943    -0.030440552    \n\n(2,1,1,.,.) =\n0.037235383 0.03971467  0.039468434 \n0.032075796 0.031177454 0.029096292 \n0.03708834  0.031535562 0.036211465 \n\n(2,1,2,.,.) =\n-0.010179557    -0.011387618    -0.008739926    \n-0.013536877    -0.015962215    -0.017361978    \n-0.014717996    -0.014296502    -0.016867846    \n\n(2,2,1,.,.) =\n0.053095814 0.05863748  0.05486801  \n0.048524074 0.043160528 0.040398546 \n0.04628137  0.04125476  0.043807983 \n\n(2,2,2,.,.) =\n-0.017849356    -0.019537563    -0.018888   \n-0.025026768    -0.034455147    -0.02970969 \n-0.026703741    -0.033036336    -0.027824042    \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x2x2x3x3]\n-  print(gradientInput)\n(1,1,1,.,.) =\n-0.021843424    -0.015910733    -0.013524098    \n-0.019261343    -0.017457811    -0.013539563    \n-0.016062422    -0.00383057 -0.0021248849   \n\n(1,1,2,.,.) =\n-0.0067594885   -0.012176989    -0.009976602    \n-0.007914364    -0.012559764    -7.768459E-4    \n-0.0026864496   -3.4671678E-4   -0.004467619    \n\n(1,2,1,.,.) =\n-0.011175868    -0.011886302    -0.0074315416   \n-0.009660093    -0.009753445    -0.008733444    \n-0.007047931    -0.0055002044   8.1458344E-4    \n\n(1,2,2,.,.) =\n-0.0016122719   -0.003776702    -0.006306042    \n-0.0032693855   -0.005982614    -0.0010739439   \n-0.0020354516   -9.59815E-4 -0.0010912241   \n\n(2,1,1,.,.) =\n-0.01399023 -0.01809205 -0.015330672    \n-0.025769815    -0.00905557 -0.021059947    \n4.068871E-4 -0.0060698274   -0.0048879837   \n\n(2,1,2,.,.) =\n-0.0013799625   -0.012721367    -0.008014497    \n-0.014288196    -0.0185386  -0.017980032    \n-0.0022621946   -0.015537363    -0.0024578157   \n\n(2,2,1,.,.) =\n-0.009561457    -0.007107652    -0.009356419    \n-0.009839717    -0.0021937331   -0.011457165    \n-0.0044140965   -0.0031195688   -0.0034824142   \n\n(2,2,2,.,.) =\n-3.2559165E-4   -0.0054697054   -0.0073612086   \n-0.0014059425   -0.006272946    -0.0028436938   \n0.0028391986    -0.005325649    -0.0028171889   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3x3]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\ninput_size = 2\noutput_size = 2\nseq_length = 2\nbatch_size = 2\ninput = np.random.randn(batch_size, input_size, 3, 3)\ngrad_output = np.random.randn(batch_size, seq_length, output_size, 3, 3)\ncells = []\ncells.append(ConvLSTMPeephole(input_size, output_size, 3, 3, 1, with_peephole = False))\ncells.append(ConvLSTMPeephole(input_size, output_size, 3, 3, 1, with_peephole = False))\n\nmodel = RecurrentDecoder(seq_length).add(MultiRNNCell(cells))\n\noutput = model.forward(input)\ngradient_input = model.backward(input, grad_output)\n\nstates = model.get_states()\nmodel.set_states(states)\n-  print output\n[[[[[ 0.01858711  0.03114421  0.02070103]\n    [ 0.01312863  0.00865137  0.02380039]\n    [ 0.02127378  0.02221535  0.02805275]]\n\n   [[ 0.05865936  0.06254016  0.07285608]\n    [ 0.07795827  0.06420417  0.06744433]\n    [ 0.07241444  0.06128554  0.0572256 ]]]\n\n\n  [[[ 0.01813958  0.0388087   0.03606314]\n    [ 0.00914392  0.01012017  0.03544089]\n    [ 0.02192647  0.02542255  0.04978891]]\n\n   [[ 0.06317041  0.07505058  0.10311646]\n    [ 0.10012341  0.06632978  0.09895241]\n    [ 0.10852461  0.08559311  0.07942865]]]]\n\n\n\n [[[[ 0.01352384  0.02394648  0.02436183]\n    [ 0.00793007  0.01043395  0.03022798]\n    [ 0.01539317  0.01955615  0.01543968]]\n\n   [[ 0.05844339  0.05187995  0.05877664]\n    [ 0.06405409  0.08493486  0.07711712]\n    [ 0.0737301   0.05892281  0.05127344]]]\n\n\n  [[[ 0.01918509  0.037876    0.04408969]\n    [ 0.01470916  0.01985376  0.03152689]\n    [ 0.02578159  0.04284319  0.0319238 ]]\n\n   [[ 0.08844157  0.07580076  0.07929584]\n    [ 0.09811849  0.08237181  0.09161879]\n    [ 0.11196285  0.08747569  0.09312635]]]]]\n\n-  print gradient_input\n[[[[[-0.01967927  0.0118104   0.00034992]\n    [-0.0132792  -0.0127134   0.01193821]\n    [ 0.01297736  0.00550178  0.00874622]]\n\n   [[-0.00718097  0.01717402  0.00893286]\n    [-0.01143209  0.00079105  0.00920936]\n    [ 0.01638926  0.02479215  0.01613754]]]\n\n\n  [[[-0.02959971 -0.00214246 -0.00665301]\n    [-0.02010076  0.00135842  0.01485039]\n    [ 0.01877127  0.00205219 -0.01012903]]\n\n   [[-0.01455194  0.00882864  0.00075077]\n    [-0.0089175  -0.00774059  0.00534623]\n    [ 0.00421638  0.01152828  0.00886414]]]]\n\n\n\n [[[[ 0.00945553  0.01345219 -0.01787379]\n    [-0.02221245 -0.0047606   0.03430083]\n    [ 0.01496986 -0.01156155  0.00733263]]\n\n   [[ 0.02018309  0.00937438 -0.00253335]\n    [-0.00616324  0.00972739  0.02758386]\n    [ 0.01057806  0.01101648  0.00341856]]]\n\n\n  [[[ 0.00486301 -0.00717946 -0.01368812]\n    [-0.01296435  0.0466785  -0.0126987 ]\n    [ 0.01161697 -0.01207331  0.01638841]]\n\n   [[ 0.02077198 -0.00770913 -0.00807941]\n    [-0.00096983  0.01721167  0.0265876 ]\n    [ 0.00845431  0.01232574  0.0126167 ]]]]]", 
            "title": "MultiRNNCell"
        }, 
        {
            "location": "/APIGuide/Layers/Recurrent-Layers/#highway", 
            "text": "Scala:  val layer = Highway(size, withBias = true,\n                    activation = null,\n                    wRegularizer = null,\n                    bRegularizer = null)  Python:  layer = Highway(size, with_bias=True,\n                activation=None,\n                wRegularizer=None,\n                bRegularizer=None)  This layer is Densely connected highway network.\nHighway layers are a natural extension of LSTMs to feedforward networks.  Parameters:   size  input size  with_bias  whether to include a bias  activation  activation function, by default no activation will be used.\n  For Python, one can also pass the name of an existing activation as a string, eg. 'tanh', 'relu', 'sigmoid', 'hard_sigmoid', 'softmax' etc.  wRegularizer  instance of [[Regularizer]] (eg. L1 or L2 regularization), applied to the input weights matrices.  bRegularizer  instance of [[Regularizer]], applied to the bias.   Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = Highway(2, activation = Tanh())\n\nval input = Tensor(3, 2).randn()\nprintln(input)\nval output = module.forward(input)\nprintln(output)  Gives the output,  1.096164    0.08578972\n0.2580359   1.629636\n-0.7571692  0.28832582\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x2]\n0.65883696  0.108842306\n-0.032798193    0.047720015\n-0.5495165  -0.16949607\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x2]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\ninput = np.random.rand(3, 2)\nprint  input is : ,input\n\nm = Highway(2, activation=Tanh())\nout = m.forward(input)\nprint  output is : ,out  Gives the output,  input is : [[ 0.65776902  0.63354682]\n [ 0.57766285  0.50117516]\n [ 0.15317826  0.60807496]]\ncreating: createHighway\noutput is : [[ 0.44779509 -0.10608637]\n [ 0.41307163 -0.14994906]\n [ 0.25687078  0.00718814]]", 
            "title": "Highway"
        }, 
        {
            "location": "/APIGuide/Layers/Recursive-Layers/", 
            "text": "TensorTree\n\n\nTensorTree class is used to decode a tensor to a tree structure.\nThe given input \ncontent\n is a tensor which encodes a constituency parse tree.\nThe tensor should have the following structure:\n\n\nEach row of the tensor represents a tree node and the row number is node number.\nFor each row, except the last column, all other columns represent the children\nnode number of this node. Assume the value of a certain column of the row is not zero,\nthe value \np\n means this node has a child whose node number is \np\n (lies in the \np\n-th)\nrow. Each leaf has a leaf number, in the tensor, the last column represents the leaf number.\nEach leaf does not have any children, so all the columns of a leaf except the last should\nbe zero. If a node is the root, the last column should equal to \n-1\n.\n\n\nNote: if any row for padding, the padding rows should be placed at the last rows with all\nelements equal to \n-1\n.\n\n\neg. a tensor represents a binary tree:\n\n\n[11, 10, -1;\n 0, 0, 1;\n 0, 0, 2;\n 0, 0, 3;\n 0, 0, 4;\n 0, 0, 5;\n 0, 0, 6;\n 4, 5, 0;\n 6, 7, 0;\n 8, 9, 0;\n 2, 3, 0;\n -1, -1, -1;\n -1, -1, -1]\n\n\n\n\nParameters:\n* \ncontent\n the tensor to be encoded\n\n\nTreeLSTM\n\n\nTreeLSTM is a base class of all other kinds of tree lstms,\n, as described in the paper \n\nImproved Semantic Representations From Tree-Structured Long Short-Term Memory Networks\n\n by Kai Sheng Tai, Richard Socher, and Christopher Manning.\n\n\n\n\nBinaryTreeLSTM\n\n\nScala:\n\n\nval treeLSTM = BinaryTreeLSTM(\n  inputSize,\n  hiddenSize,\n  gateOutput,\n  withGraph)\n\n\n\n\nPython:\n\n\ntree_lstm = BinaryTreeLSTM(\n  input_size,\n  hidden_size,\n  gate_output,\n  with_graph)\n\n\n\n\nThis class is an implementation of Binary TreeLSTM (Constituency Tree LSTM)\nreceiving \nConstituency-based parse trees\n.\nTree-LSTM is a kind of recursive neural networks, as described in the paper \n\nImproved Semantic Representations From Tree-Structured Long Short-Term Memory Networks\n\n by Kai Sheng Tai, Richard Socher, and Christopher Manning.\n\n\nThe input tensor in \nforward(input)\n is expected to be a table, in which the first element is a 3D tensor (\nbatch x leaf number x inputSize\n) and the second elment is the 3D embedding tensor tree\n(\nbatch x tree node number x (number of branches + 1)\n]. output of\n\nforward(input)\n is expected to be a 3D tensor (\nbatch x tree node number x hiddenSize\n).\n\n\nParameters:\n\n \ninputSize\n the size of each input vector\n\n \nhiddenSize\n hidden unit size in GRU\n\n \ngateOutput\n whether gate the output. Default is \ntrue\n\n\n \nwithGraph\n whether create lstms with \ncom.intel.analytics.bigdl.nn.Graph\n. Default is \ntrue\n.\n\n\nScala example:\n\n\n    import com.intel.analytics.bigdl.numeric.NumericFloat\n    import com.intel.analytics.bigdl.utils.RandomGenerator.RNG\n\n    RNG.setSeed(100)\n\n    val hiddenSize = 2\n    val inputSize = 2\n\n    val inputs =\n      Tensor(\n        T(T(T(1f, 2f),\n          T(2f, 3f),\n          T(4f, 5f))))\n\n    val tree =\n      Tensor(\n        T(T(T(2f, 5f, -1f),\n          T(0f, 0f, 1f),\n          T(0f, 0f, 2f),\n          T(0f, 0f, 3f),\n          T(3f, 4f, 0f))))\n\n    val input = T(inputs, tree)\n\n    val gradOutput =\n      Tensor(\n        T(T(T(2f, 5f),\n          T(2f, 3f),\n          T(4f, 5f),\n          T(2f, 3f),\n          T(4f, 5f),\n          T(6f, 7f))))\n\n    val model = BinaryTreeLSTM(inputSize, hiddenSize)\n\n    val output = model.forward(input)\n    println(output)\n    (1,.,.) =\n    -0.07799375 -0.14419462 \n    -0.23495524 -0.04679072 \n    -0.15945151 -0.026039641    \n    -0.0454074  -0.007066241    \n    -0.058696028    -0.13559057 \n\n    [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x2]\n\n    val gradInput = model.backward(input, gradOutput)\n    println(gradInput)\n      {\n        2: (1,.,.) =\n           0.0  0.0 0.0 \n           0.0  0.0 0.0 \n           0.0  0.0 0.0 \n           0.0  0.0 0.0 \n           0.0  0.0 0.0 \n\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x3]\n        1: (1,.,.) =\n           0.56145966   -0.3383652  \n           0.81720364   -0.46767634 \n           0.37739626   -0.23355529 \n\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x2]\n      }\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\n\nhidden_size = 2\ninput_size = 2\ninputs = np.array([[\n  [1.0, 2.0],\n  [2.0, 3.0],\n  [4.0, 5.0]\n]])\n\ntree = np.array([[\n  [2.0, 5.0, -1.0],\n  [0.0, 0.0, 1.0],\n  [0.0, 0.0, 2.0],\n  [0.0, 0.0, 3.0],\n  [3.0, 4.0, 0.0]\n]])\n\ninput = [inputs, tree]\n\ngrad_output = np.array([[\n  [2.0, 3.0],\n  [4.0, 5.0],\n  [2.0, 3.0],\n  [4.0, 5.0],\n  [6.0, 7.0]\n]])\n\nmodel = BinaryTreeLSTM(input_size, hidden_size)\noutput = model.forward(input)\nprint output\n[[[-0.08113038 -0.0289295 ]\n  [ 0.1378704   0.00550814]\n  [ 0.33053339 -0.02395477]\n  [ 0.26895314 -0.02019646]\n  [ 0.34085754 -0.12480961]]]\n\ngradient = model.backward(input, grad_output)\nprint gradient\n[array([[[ 0.43623093,  0.97416967],\n        [-0.02283204,  0.99245077],\n        [-1.11290622,  0.84173977]]], dtype=float32), array([[[ 0.,  0.,  0.],\n        [ 0.,  0.,  0.],\n        [ 0.,  0.,  0.],\n        [ 0.,  0.,  0.],\n        [ 0.,  0.,  0.]]], dtype=float32)]", 
            "title": "Recursive Layers"
        }, 
        {
            "location": "/APIGuide/Layers/Recursive-Layers/#tensortree", 
            "text": "TensorTree class is used to decode a tensor to a tree structure.\nThe given input  content  is a tensor which encodes a constituency parse tree.\nThe tensor should have the following structure:  Each row of the tensor represents a tree node and the row number is node number.\nFor each row, except the last column, all other columns represent the children\nnode number of this node. Assume the value of a certain column of the row is not zero,\nthe value  p  means this node has a child whose node number is  p  (lies in the  p -th)\nrow. Each leaf has a leaf number, in the tensor, the last column represents the leaf number.\nEach leaf does not have any children, so all the columns of a leaf except the last should\nbe zero. If a node is the root, the last column should equal to  -1 .  Note: if any row for padding, the padding rows should be placed at the last rows with all\nelements equal to  -1 .  eg. a tensor represents a binary tree:  [11, 10, -1;\n 0, 0, 1;\n 0, 0, 2;\n 0, 0, 3;\n 0, 0, 4;\n 0, 0, 5;\n 0, 0, 6;\n 4, 5, 0;\n 6, 7, 0;\n 8, 9, 0;\n 2, 3, 0;\n -1, -1, -1;\n -1, -1, -1]  Parameters:\n*  content  the tensor to be encoded", 
            "title": "TensorTree"
        }, 
        {
            "location": "/APIGuide/Layers/Recursive-Layers/#treelstm", 
            "text": "TreeLSTM is a base class of all other kinds of tree lstms,\n, as described in the paper  Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks \n by Kai Sheng Tai, Richard Socher, and Christopher Manning.", 
            "title": "TreeLSTM"
        }, 
        {
            "location": "/APIGuide/Layers/Recursive-Layers/#binarytreelstm", 
            "text": "Scala:  val treeLSTM = BinaryTreeLSTM(\n  inputSize,\n  hiddenSize,\n  gateOutput,\n  withGraph)  Python:  tree_lstm = BinaryTreeLSTM(\n  input_size,\n  hidden_size,\n  gate_output,\n  with_graph)  This class is an implementation of Binary TreeLSTM (Constituency Tree LSTM)\nreceiving  Constituency-based parse trees .\nTree-LSTM is a kind of recursive neural networks, as described in the paper  Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks \n by Kai Sheng Tai, Richard Socher, and Christopher Manning.  The input tensor in  forward(input)  is expected to be a table, in which the first element is a 3D tensor ( batch x leaf number x inputSize ) and the second elment is the 3D embedding tensor tree\n( batch x tree node number x (number of branches + 1) ]. output of forward(input)  is expected to be a 3D tensor ( batch x tree node number x hiddenSize ).  Parameters:   inputSize  the size of each input vector   hiddenSize  hidden unit size in GRU   gateOutput  whether gate the output. Default is  true    withGraph  whether create lstms with  com.intel.analytics.bigdl.nn.Graph . Default is  true .  Scala example:      import com.intel.analytics.bigdl.numeric.NumericFloat\n    import com.intel.analytics.bigdl.utils.RandomGenerator.RNG\n\n    RNG.setSeed(100)\n\n    val hiddenSize = 2\n    val inputSize = 2\n\n    val inputs =\n      Tensor(\n        T(T(T(1f, 2f),\n          T(2f, 3f),\n          T(4f, 5f))))\n\n    val tree =\n      Tensor(\n        T(T(T(2f, 5f, -1f),\n          T(0f, 0f, 1f),\n          T(0f, 0f, 2f),\n          T(0f, 0f, 3f),\n          T(3f, 4f, 0f))))\n\n    val input = T(inputs, tree)\n\n    val gradOutput =\n      Tensor(\n        T(T(T(2f, 5f),\n          T(2f, 3f),\n          T(4f, 5f),\n          T(2f, 3f),\n          T(4f, 5f),\n          T(6f, 7f))))\n\n    val model = BinaryTreeLSTM(inputSize, hiddenSize)\n\n    val output = model.forward(input)\n    println(output)\n    (1,.,.) =\n    -0.07799375 -0.14419462 \n    -0.23495524 -0.04679072 \n    -0.15945151 -0.026039641    \n    -0.0454074  -0.007066241    \n    -0.058696028    -0.13559057 \n\n    [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x2]\n\n    val gradInput = model.backward(input, gradOutput)\n    println(gradInput)\n      {\n        2: (1,.,.) =\n           0.0  0.0 0.0 \n           0.0  0.0 0.0 \n           0.0  0.0 0.0 \n           0.0  0.0 0.0 \n           0.0  0.0 0.0 \n\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5x3]\n        1: (1,.,.) =\n           0.56145966   -0.3383652  \n           0.81720364   -0.46767634 \n           0.37739626   -0.23355529 \n\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x3x2]\n      }  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\n\nhidden_size = 2\ninput_size = 2\ninputs = np.array([[\n  [1.0, 2.0],\n  [2.0, 3.0],\n  [4.0, 5.0]\n]])\n\ntree = np.array([[\n  [2.0, 5.0, -1.0],\n  [0.0, 0.0, 1.0],\n  [0.0, 0.0, 2.0],\n  [0.0, 0.0, 3.0],\n  [3.0, 4.0, 0.0]\n]])\n\ninput = [inputs, tree]\n\ngrad_output = np.array([[\n  [2.0, 3.0],\n  [4.0, 5.0],\n  [2.0, 3.0],\n  [4.0, 5.0],\n  [6.0, 7.0]\n]])\n\nmodel = BinaryTreeLSTM(input_size, hidden_size)\noutput = model.forward(input)\nprint output\n[[[-0.08113038 -0.0289295 ]\n  [ 0.1378704   0.00550814]\n  [ 0.33053339 -0.02395477]\n  [ 0.26895314 -0.02019646]\n  [ 0.34085754 -0.12480961]]]\n\ngradient = model.backward(input, grad_output)\nprint gradient\n[array([[[ 0.43623093,  0.97416967],\n        [-0.02283204,  0.99245077],\n        [-1.11290622,  0.84173977]]], dtype=float32), array([[[ 0.,  0.,  0.],\n        [ 0.,  0.,  0.],\n        [ 0.,  0.,  0.],\n        [ 0.,  0.,  0.],\n        [ 0.,  0.,  0.]]], dtype=float32)]", 
            "title": "BinaryTreeLSTM"
        }, 
        {
            "location": "/APIGuide/Layers/Sparse-Layers/", 
            "text": "SparseLinear\n\n\nScala:\n\n\nval module = SparseLinear(\n  inputSize,\n  outputSize,\n  withBias = true,\n  backwardStart: Int = -1,\n  backwardLength: Int = -1,\n  wRegularizer = null,\n  bRegularizer = null,\n  initWeight = null,\n  initBias = null,\n  initGradWeight = null,\n  initGradBias = null)\n\n\n\n\nPython:\n\n\nmodule = SparseLinear(\n  input_size,\n  output_size,\n  init_method=\ndefault\n,\n  with_bias=True,\n  backwardStart=-1,\n  backwardLength=-1,\n  wRegularizer=None,\n  bRegularizer=None,\n  init_weight=None,\n  init_bias=None,\n  init_grad_weight=None,\n  init_grad_bias=None)\n\n\n\n\nSparseLinear is the sparse version of module Linear. SparseLinear has two different from Linear: firstly, SparseLinear's input Tensor is a SparseTensor. Secondly, SparseLinear doesn't backward gradient to next layer in the backpropagation by default, as the gradInput of SparseLinear is useless and very big in most cases.\n\n\nBut, considering model like Wide\nDeep, we provide backwardStart and backwardLength to backward part of the gradient to next layer.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = SparseLinear(1000, 5)\n\nval input = Tensor.sparse(Array(Array(0, 0, 0, 1, 1, 1), Array(1, 5, 300, 2, 100, 500)),\n    Array(1f, 3f, 5f, 2f, 4f, 6f),\n    Array(2, 1000))\n\nprintln(module.forward(input))\n\n\n\n\nGives the output,\n\n\n0.047791008 0.069045454 0.020120896 0.019826084 0.10610865  \n-0.059406646    -0.13536823 -0.13861635 0.070304416 0.009570055 \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x5]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.util.common import *\nimport numpy as np\n\nmodule = SparseLinear(1000, 5)\n\ninput = JTensor.sparse(\n    np.array([1, 3, 5, 2, 4, 6]),\n    np.array([0, 0, 0, 1, 1, 1, 1, 5, 300, 2, 100, 500]),\n    np.array([2, 1000]))\n\nprint(module.forward(input))\n\n\n\n\nGives the output,\n\n\n[[ 10.09569263 -10.94844246  -4.1086688    1.02527523  11.80737209]\n [  7.9651413    9.7131443  -10.22719955   0.02345783  -3.74368906]]\n\n\n\n\n\n\nSparseJoinTable\n\n\nScala:\n\n\nval module = SparseJoinTable(dimension)\n\n\n\n\nPython:\n\n\nmodule = SparseLinear(dimension)\n\n\n\n\nExperimental layer.\n\n\nSparse version of JoinTable. Backward just pass the origin gradOutput back to the next layers without split. So this layer may just works in Wide\nDeep like models.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils._\n\nval module = SparseJoinTable(2)\n\nval input1 = Tensor.sparse(Array(Array(0, 0, 0, 1, 1, 1), Array(1, 2, 3, 2, 3, 4)),\n    Array(1f, 2f, 3f, 4f, 5f, 6f),\n    Array(2, 5))\nval input2 = Tensor.sparse(Array(Array(0, 0, 0, 1, 1, 1), Array(2, 3, 4, 1, 2, 3)),\n    Array(7f, 8f, 9f, 10f, 11f, 12f),\n    Array(2, 5))\n\nprintln(module.forward(T(input1, input2)))\n\n\n\n\nGives the output,\n\n\n(0, 1) : 1.0\n(0, 2) : 2.0\n(0, 3) : 3.0\n(0, 7) : 7.0\n(0, 8) : 8.0\n(0, 9) : 9.0\n(1, 2) : 4.0\n(1, 3) : 5.0\n(1, 4) : 6.0\n(1, 6) : 10.0\n(1, 7) : 11.0\n(1, 8) : 12.0\n[com.intel.analytics.bigdl.tensor.SparseTensor of size 2x10]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.util.common import *\nimport numpy as np\n\nmodule = SparseJoinTable(2)\n\ninput1 = JTensor.sparse(np.array([1, 2, 3, 4, 5, 6]),\n    np.array([0, 0, 0, 1, 1, 1, 1, 2, 3, 2, 3, 4]),\n    np.array([2, 5]))\ninput2 = JTensor.sparse(np.array([7, 8, 9, 10, 11, 12]),\n    np.array([0, 0, 0, 1, 1, 1, 2, 3, 4, 1, 2, 3]),\n    np.array([2, 5]))\n\nprint(module.forward([input1, input2]))\n\n\n\n\nGives the output,\nthis output is a dense numpy array, due to we couldn't pick SparseTensor back to python currently.\n\n\n[[  0.   1.   2.   3.   0.   0.   0.   7.   8.   9.]\n [  0.   0.   4.   5.   6.   0.  10.  11.  12.   0.]]\n\n\n\n\n\n\nDenseToSparse\n\n\nScala:\n\n\nval module = DenseToSparse()\n\n\n\n\nPython:\n\n\nmodule = DenseToSparse()\n\n\n\n\nConvert DenseTensor to SparseTensor.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = DenseToSparse()\n\nval input = Tensor(2, 3)\ninput.setValue(1, 1, 1)\ninput.setValue(2, 2, 2)\n\nprintln(module.forward(input))\n\n\n\n\nGives the output,\n\n\n(0, 0) : 1.0\n(1, 1) : 2.0\n[com.intel.analytics.bigdl.tensor.SparseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.util.common import *\nimport numpy as np\n\nmodule = DenseToSparse()\n\ninput = np.zeros([2, 3])\ninput[0, 0] = 1\ninput[1, 1] = 2\n\nprint(module.forward(input))\n\n\n\n\nGives the output,\nthis output is a dense numpy array, due to we couldn't pick SparseTensor back to python currently.\n\n\n[[ 1.  0.  0.]\n [ 0.  2.  0.]]", 
            "title": "Sparse Layers"
        }, 
        {
            "location": "/APIGuide/Layers/Sparse-Layers/#sparselinear", 
            "text": "Scala:  val module = SparseLinear(\n  inputSize,\n  outputSize,\n  withBias = true,\n  backwardStart: Int = -1,\n  backwardLength: Int = -1,\n  wRegularizer = null,\n  bRegularizer = null,\n  initWeight = null,\n  initBias = null,\n  initGradWeight = null,\n  initGradBias = null)  Python:  module = SparseLinear(\n  input_size,\n  output_size,\n  init_method= default ,\n  with_bias=True,\n  backwardStart=-1,\n  backwardLength=-1,\n  wRegularizer=None,\n  bRegularizer=None,\n  init_weight=None,\n  init_bias=None,\n  init_grad_weight=None,\n  init_grad_bias=None)  SparseLinear is the sparse version of module Linear. SparseLinear has two different from Linear: firstly, SparseLinear's input Tensor is a SparseTensor. Secondly, SparseLinear doesn't backward gradient to next layer in the backpropagation by default, as the gradInput of SparseLinear is useless and very big in most cases.  But, considering model like Wide Deep, we provide backwardStart and backwardLength to backward part of the gradient to next layer.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = SparseLinear(1000, 5)\n\nval input = Tensor.sparse(Array(Array(0, 0, 0, 1, 1, 1), Array(1, 5, 300, 2, 100, 500)),\n    Array(1f, 3f, 5f, 2f, 4f, 6f),\n    Array(2, 1000))\n\nprintln(module.forward(input))  Gives the output,  0.047791008 0.069045454 0.020120896 0.019826084 0.10610865  \n-0.059406646    -0.13536823 -0.13861635 0.070304416 0.009570055 \n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2x5]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.util.common import *\nimport numpy as np\n\nmodule = SparseLinear(1000, 5)\n\ninput = JTensor.sparse(\n    np.array([1, 3, 5, 2, 4, 6]),\n    np.array([0, 0, 0, 1, 1, 1, 1, 5, 300, 2, 100, 500]),\n    np.array([2, 1000]))\n\nprint(module.forward(input))  Gives the output,  [[ 10.09569263 -10.94844246  -4.1086688    1.02527523  11.80737209]\n [  7.9651413    9.7131443  -10.22719955   0.02345783  -3.74368906]]", 
            "title": "SparseLinear"
        }, 
        {
            "location": "/APIGuide/Layers/Sparse-Layers/#sparsejointable", 
            "text": "Scala:  val module = SparseJoinTable(dimension)  Python:  module = SparseLinear(dimension)  Experimental layer.  Sparse version of JoinTable. Backward just pass the origin gradOutput back to the next layers without split. So this layer may just works in Wide Deep like models.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.utils._\n\nval module = SparseJoinTable(2)\n\nval input1 = Tensor.sparse(Array(Array(0, 0, 0, 1, 1, 1), Array(1, 2, 3, 2, 3, 4)),\n    Array(1f, 2f, 3f, 4f, 5f, 6f),\n    Array(2, 5))\nval input2 = Tensor.sparse(Array(Array(0, 0, 0, 1, 1, 1), Array(2, 3, 4, 1, 2, 3)),\n    Array(7f, 8f, 9f, 10f, 11f, 12f),\n    Array(2, 5))\n\nprintln(module.forward(T(input1, input2)))  Gives the output,  (0, 1) : 1.0\n(0, 2) : 2.0\n(0, 3) : 3.0\n(0, 7) : 7.0\n(0, 8) : 8.0\n(0, 9) : 9.0\n(1, 2) : 4.0\n(1, 3) : 5.0\n(1, 4) : 6.0\n(1, 6) : 10.0\n(1, 7) : 11.0\n(1, 8) : 12.0\n[com.intel.analytics.bigdl.tensor.SparseTensor of size 2x10]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.util.common import *\nimport numpy as np\n\nmodule = SparseJoinTable(2)\n\ninput1 = JTensor.sparse(np.array([1, 2, 3, 4, 5, 6]),\n    np.array([0, 0, 0, 1, 1, 1, 1, 2, 3, 2, 3, 4]),\n    np.array([2, 5]))\ninput2 = JTensor.sparse(np.array([7, 8, 9, 10, 11, 12]),\n    np.array([0, 0, 0, 1, 1, 1, 2, 3, 4, 1, 2, 3]),\n    np.array([2, 5]))\n\nprint(module.forward([input1, input2]))  Gives the output,\nthis output is a dense numpy array, due to we couldn't pick SparseTensor back to python currently.  [[  0.   1.   2.   3.   0.   0.   0.   7.   8.   9.]\n [  0.   0.   4.   5.   6.   0.  10.  11.  12.   0.]]", 
            "title": "SparseJoinTable"
        }, 
        {
            "location": "/APIGuide/Layers/Sparse-Layers/#densetosparse", 
            "text": "Scala:  val module = DenseToSparse()  Python:  module = DenseToSparse()  Convert DenseTensor to SparseTensor.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\n\nval module = DenseToSparse()\n\nval input = Tensor(2, 3)\ninput.setValue(1, 1, 1)\ninput.setValue(2, 2, 2)\n\nprintln(module.forward(input))  Gives the output,  (0, 0) : 1.0\n(1, 1) : 2.0\n[com.intel.analytics.bigdl.tensor.SparseTensor of size 2x3]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.util.common import *\nimport numpy as np\n\nmodule = DenseToSparse()\n\ninput = np.zeros([2, 3])\ninput[0, 0] = 1\ninput[1, 1] = 2\n\nprint(module.forward(input))  Gives the output,\nthis output is a dense numpy array, due to we couldn't pick SparseTensor back to python currently.  [[ 1.  0.  0.]\n [ 0.  2.  0.]]", 
            "title": "DenseToSparse"
        }, 
        {
            "location": "/APIGuide/Layers/Utilities/", 
            "text": "Input\n\n\nScala:\n\n\nval input = Input()\n\n\n\n\nPython:\n\n\ninput = Input()\n\n\n\n\nInput layer do nothing to the input tensors, just passing them through.\nIt is used as input to the \nGraph container\n when the first layer of the graph container accepts multiple tensors as inputs.\n\n\nEach input node of the graph container should accept one tensor as input. If you want a module\naccepting multiple tensors as input, you should add some Input module before it and connect\nthe outputs of the Input nodes to it. Please see the example of the Graph document.\n\n\nPlease note that the return is not a layer but a Node containing input layer.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = Input()\nval input = Tensor(3, 2).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.93366385      0.82551944\n0.71642804      0.4798109\n0.83710635      0.068483874\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\nmodule.element.forward(input)\n com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.93366385      0.82551944\n0.71642804      0.4798109\n0.83710635      0.068483874\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Input()\ninput = np.random.rand(3,2)\narray([[ 0.7006678 ,  0.29719472],\n       [ 0.76668255,  0.59518023],\n       [ 0.65543809,  0.41172803]])\n\nmodule.element().forward(input)\narray([[ 0.7006678 ,  0.29719472],\n       [ 0.76668257,  0.59518021],\n       [ 0.65543807,  0.41172802]], dtype=float32)\n\n\n\n\n\nEcho\n\n\nScala:\n\n\nval module = Echo()\n\n\n\n\nPython:\n\n\nmodule = Echo()\n\n\n\n\nThis module is for debug purpose, which can print activation and gradient size in your model topology\n\n\nScala example:\n\n\nval module = Echo()\nval input = Tensor(3, 2).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.24058184      0.22737113\n0.0028103297    0.18359558\n0.80443156      0.07047854\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\nmodule.forward(input)\nres13: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.24058184      0.22737113\n0.0028103297    0.18359558\n0.80443156      0.07047854\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\n\n\n\nPython example:\n\n\nmodule = Echo()\ninput = np.random.rand(3,2)\n[array([\n[ 0.87273163,  0.59974301],\n[ 0.09416127,  0.135765  ],\n[ 0.11577505,  0.46095625]], dtype=float32)]\n\nmodule.forward(input)\ncom.intel.analytics.bigdl.nn.Echo@535c681 : Activation size is 3x2\n[array([\n[ 0.87273163,  0.59974301],\n[ 0.09416127,  0.135765  ],\n[ 0.11577505,  0.46095625]], dtype=float32)]", 
            "title": "Utilities"
        }, 
        {
            "location": "/APIGuide/Layers/Utilities/#input", 
            "text": "Scala:  val input = Input()  Python:  input = Input()  Input layer do nothing to the input tensors, just passing them through.\nIt is used as input to the  Graph container  when the first layer of the graph container accepts multiple tensors as inputs.  Each input node of the graph container should accept one tensor as input. If you want a module\naccepting multiple tensors as input, you should add some Input module before it and connect\nthe outputs of the Input nodes to it. Please see the example of the Graph document.  Please note that the return is not a layer but a Node containing input layer.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval module = Input()\nval input = Tensor(3, 2).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.93366385      0.82551944\n0.71642804      0.4798109\n0.83710635      0.068483874\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\nmodule.element.forward(input)\n com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.93366385      0.82551944\n0.71642804      0.4798109\n0.83710635      0.068483874\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]  Python example:  from bigdl.nn.layer import *\nimport numpy as np\n\nmodule = Input()\ninput = np.random.rand(3,2)\narray([[ 0.7006678 ,  0.29719472],\n       [ 0.76668255,  0.59518023],\n       [ 0.65543809,  0.41172803]])\n\nmodule.element().forward(input)\narray([[ 0.7006678 ,  0.29719472],\n       [ 0.76668257,  0.59518021],\n       [ 0.65543807,  0.41172802]], dtype=float32)", 
            "title": "Input"
        }, 
        {
            "location": "/APIGuide/Layers/Utilities/#echo", 
            "text": "Scala:  val module = Echo()  Python:  module = Echo()  This module is for debug purpose, which can print activation and gradient size in your model topology  Scala example:  val module = Echo()\nval input = Tensor(3, 2).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.24058184      0.22737113\n0.0028103297    0.18359558\n0.80443156      0.07047854\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\nmodule.forward(input)\nres13: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.24058184      0.22737113\n0.0028103297    0.18359558\n0.80443156      0.07047854\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]  Python example:  module = Echo()\ninput = np.random.rand(3,2)\n[array([\n[ 0.87273163,  0.59974301],\n[ 0.09416127,  0.135765  ],\n[ 0.11577505,  0.46095625]], dtype=float32)]\n\nmodule.forward(input)\ncom.intel.analytics.bigdl.nn.Echo@535c681 : Activation size is 3x2\n[array([\n[ 0.87273163,  0.59974301],\n[ 0.09416127,  0.135765  ],\n[ 0.11577505,  0.46095625]], dtype=float32)]", 
            "title": "Echo"
        }, 
        {
            "location": "/APIGuide/Losses/", 
            "text": "L1Cost\n\n\nScala:\n\n\nval layer = L1Cost[Float]()\n\n\n\n\nPython:\n\n\nlayer = L1Cost()\n\n\n\n\nCompute L1 norm for input, and sign of input\n\n\nScala example:\n\n\nval layer = L1Cost[Float]()\nval input = Tensor[Float](2, 2).rand\nval target = Tensor[Float](2, 2).rand\n\nval output = layer.forward(input, target)\nval gradInput = layer.backward(input, target)\n\n\n println(input)\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.48145306      0.476887\n0.23729686      0.5169516\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n println(target)\ntarget: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.42999148      0.22272833\n0.49723643      0.17884709\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n println(output)\noutput: Float = 1.7125885\n\n println(gradInput)\ngradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0     1.0\n1.0     1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nlayer = L1Cost()\n\ninput = np.random.uniform(0, 1, (2, 2)).astype(\nfloat32\n)\ntarget = np.random.uniform(0, 1, (2, 2)).astype(\nfloat32\n)\n\noutput = layer.forward(input, target)\ngradInput = layer.backward(input, target)\n\n\n output\n2.522411\n\n gradInput\n[array([[ 1.,  1.],\n        [ 1.,  1.]], dtype=float32)]\n\n\n\n\n\n\nTimeDistributedCriterion\n\n\nScala:\n\n\nval module = TimeDistributedCriterion(critrn, sizeAverage)\n\n\n\n\nPython:\n\n\nmodule = TimeDistributedCriterion(critrn, sizeAverage)\n\n\n\n\nThis class is intended to support inputs with 3 or more dimensions.\nApply Any Provided Criterion to every temporal slice of an input.\n\n\n\n\ncritrn\n embedded criterion\n\n\nsizeAverage\n whether to divide the sequence length. Default is false.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval criterion = ClassNLLCriterion[Double]()\nval layer = TimeDistributedCriterion[Double](criterion, true)\nval input = Tensor[Double](Storage(Array(\n    1.0262627674932,\n    -1.2412600935171,\n    -1.0423174168648,\n    -1.0262627674932,\n    -1.2412600935171,\n    -1.0423174168648,\n    -0.90330565804228,\n    -1.3686840144413,\n    -1.0778380454479,\n    -0.90330565804228,\n    -1.3686840144413,\n    -1.0778380454479,\n    -0.99131220658219,\n    -1.0559142847536,\n    -1.2692712660404,\n    -0.99131220658219,\n    -1.0559142847536,\n    -1.2692712660404))).resize(3, 2, 3)\nval target = Tensor[Double](3, 2)\n    target(Array(1, 1)) = 1\n    target(Array(1, 2)) = 1\n    target(Array(2, 1)) = 2\n    target(Array(2, 2)) = 2\n    target(Array(3, 1)) = 3\n    target(Array(3, 2)) = 3\n\n print(layer.forward(input, target))\n0.8793184268272332\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.criterion import *\n\ncriterion = ClassNLLCriterion()\nlayer = TimeDistributedCriterion(criterion, True)\ninput = np.array([1.0262627674932,\n                      -1.2412600935171,\n                      -1.0423174168648,\n                      -1.0262627674932,\n                      -1.2412600935171,\n                      -1.0423174168648,\n                      -0.90330565804228,\n                      -1.3686840144413,\n                      -1.0778380454479,\n                      -0.90330565804228,\n                      -1.3686840144413,\n                      -1.0778380454479,\n                      -0.99131220658219,\n                      -1.0559142847536,\n                      -1.2692712660404,\n                      -0.99131220658219,\n                      -1.0559142847536,\n                      -1.2692712660404]).reshape(3,2,3)\ntarget = np.array([[1,1],[2,2],[3,3]])                      \n\nlayer.forward(input, target)\n0.8793184\n\n\n\n\n\n\nMarginRankingCriterion\n\n\nScala:\n\n\nval mse = new MarginRankingCriterion(margin=1.0, sizeAverage=true)\n\n\n\n\nPython:\n\n\nmse = MarginRankingCriterion(margin=1.0, size_average=true)\n\n\n\n\nCreates a criterion that measures the loss given an input \nx = {x1, x2}\n,\na table of two Tensors of size 1 (they contain only scalars), and a label y (1 or -1).\nIn batch mode, x is a table of two Tensors of size batchsize, and y is a Tensor of size\nbatchsize containing 1 or -1 for each corresponding pair of elements in the input Tensor.\nIf \ny == 1\n then it assumed the first input should be ranked higher (have a larger value) than\nthe second input, and vice-versa for \ny == -1\n.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.MarginRankingCriterion\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.Storage\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nimport scala.util.Random\n\nval input1Arr = Array(1, 2, 3, 4, 5)\nval input2Arr = Array(5, 4, 3, 2, 1)\n\nval target1Arr = Array(-1, 1, -1, 1, 1)\n\nval input1 = Tensor(Storage(input1Arr.map(x =\n x.toFloat)))\nval input2 = Tensor(Storage(input2Arr.map(x =\n x.toFloat)))\n\nval input = T((1.toFloat, input1), (2.toFloat, input2))\n\nval target1 = Tensor(Storage(target1Arr.map(x =\n x.toFloat)))\nval target = T((1.toFloat, target1))\n\nval mse = new MarginRankingCriterion()\n\nval output = mse.forward(input, target)\nval gradInput = mse.backward(input, target)\n\nprintln(output)\nprintln(gradInput)\n\n\n\n\nGives the output\n\n\noutput: Float = 0.8                                                                                                                                                                    [21/154]\n\n\n\n\nGives the gradInput,\n\n\ngradInput: com.intel.analytics.bigdl.utils.Table =\n {\n        2: -0.0\n           0.2\n           -0.2\n           0.0\n           0.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n        1: 0.0\n           -0.2\n           0.2\n           -0.0\n           -0.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n }\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nmse = MarginRankingCriterion()\n\ninput1 = np.array([1, 2, 3, 4, 5]).astype(\nfloat32\n)\ninput2 = np.array([5, 4, 3, 2, 1]).astype(\nfloat32\n)\ninput = [input1, input2]\n\ntarget1 = np.array([-1, 1, -1, 1, 1]).astype(\nfloat32\n)\ntarget = [target1, target1]\n\noutput = mse.forward(input, target)\ngradInput = mse.backward(input, target)\n\nprint output\nprint gradInput\n\n\n\n\nGives the output,\n\n\n0.8\n\n\n\n\nGives the gradInput,\n\n\n[array([ 0. , -0.2,  0.2, -0. , -0. ], dtype=float32), array([-0. ,  0.2, -0.2,  0. ,  0. ], dtype=float32)] \n\n\n\n\n\n\nClassNLLCriterion\n\n\nScala:\n\n\nval criterion = ClassNLLCriterion(weights = null, sizeAverage = true, logProbAsInput=true)\n\n\n\n\nPython:\n\n\ncriterion = ClassNLLCriterion(weights=None, size_average=True, logProbAsInput=true)\n\n\n\n\nThe negative log likelihood criterion. It is useful to train a classification problem with n\nclasses. If provided, the optional argument weights should be a 1D Tensor assigning weight to\neach of the classes. This is particularly useful when you have an unbalanced training set.\n\n\nThe input given through a \nforward()\n is expected to contain log-probabilities/probabilities of each class:\ninput has to be a 1D Tensor of size \nn\n. Obtaining log-probabilities/probabilities in a neural network is easily\nachieved by adding a \nLogSoftMax\n/\nSoftMax\n layer in the last layer of your neural network. You may use\n\nCrossEntropyCriterion\n instead, if you prefer not to add an extra layer to your network. This\ncriterion expects a class index (1 to the number of class) as target when calling\n\nforward(input, target)\n and \nbackward(input, target)\n.\n\n\nIn the log-probabilities case,\n The loss can be described as:\n     \nloss(x, class) = -x[class]\n\n or in the case of the weights argument it is specified as follows:\n     \nloss(x, class) = -weights[class] * x[class]\n\n Due to the behaviour of the backend code, it is necessary to set sizeAverage to false when\n calculating losses in non-batch mode.\n\n\nNote that if the target is \n-1\n, the training process will skip this sample.\n In other words, the forward process will return zero output and the backward process\n will also return zero \ngradInput\n.\n\n\nBy default, the losses are averaged over observations for each minibatch. However, if the field\n \nsizeAverage\n is set to false, the losses are instead summed for each minibatch.\n\n\nParameters:\n\n\n\n\nweights\n weights of each element of the input\n\n\nsizeAverage\n A boolean indicating whether normalizing by the number of elements in the input.\n                  Default: true\n\n\nlogProbAsInput\n indicating whether to accept log-probabilities or probabilities as input. True means accepting\n               log-probabilities as input.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.ClassNLLCriterion\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval criterion = ClassNLLCriterion()\nval input = Tensor(T(\n              T(1f, 2f, 3f),\n              T(2f, 3f, 4f),\n              T(3f, 4f, 5f)\n          ))\n\nval target = Tensor(T(1f, 2f, 3f))\n\nval loss = criterion.forward(input, target)\nval grad = criterion.backward(input, target)\n\nprint(loss)\n-3.0\nprintln(grad)\n-0.33333334 0.0 0.0\n0.0 -0.33333334 0.0\n0.0 0.0 -0.33333334\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\n\ncriterion = ClassNLLCriterion()\ninput = np.array([\n              [1.0, 2.0, 3.0],\n              [2.0, 3.0, 4.0],\n              [3.0, 4.0, 5.0]\n          ])\n\ntarget = np.array([1.0, 2.0, 3.0])\n\nloss = criterion.forward(input, target)\ngradient= criterion.backward(input, target)\n\nprint loss\n-3.0\nprint gradient\n-3.0\n[[-0.33333334  0.          0.        ]\n [ 0.         -0.33333334  0.        ]\n [ 0.          0.         -0.33333334]]\n\n\n\n\n\n\nSoftmaxWithCriterion\n\n\nScala:\n\n\nval model = SoftmaxWithCriterion(ignoreLabel, normalizeMode)\n\n\n\n\nPython:\n\n\nmodel = SoftmaxWithCriterion(ignoreLabel, normalizeMode)\n\n\n\n\nComputes the multinomial logistic loss for a one-of-many classification task, passing real-valued predictions through a softmax to\nget a probability distribution over classes. It should be preferred over separate SoftmaxLayer + MultinomialLogisticLossLayer as \nits gradient computation is more numerically stable.\n\n\n\n\nignoreLabel\n   (optional) Specify a label value that should be ignored when computing the loss.\n\n\nnormalizeMode\n How to normalize the output loss.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.{Storage, Tensor}\n\nval input = Tensor(1, 5, 2, 3).rand()\nval target = Tensor(Storage(Array(2.0f, 4.0f, 2.0f, 4.0f, 1.0f, 2.0f))).resize(1, 1, 2, 3)\n\nval model = SoftmaxWithCriterion[Float]()\nval output = model.forward(input, target)\n\nscala\n print(input)\n(1,1,.,.) =\n0.65131104  0.9332143   0.5618989   \n0.9965054   0.9370902   0.108070895 \n\n(1,2,.,.) =\n0.46066576  0.9636703   0.8123812   \n0.31076035  0.16386998  0.37894428  \n\n(1,3,.,.) =\n0.49111295  0.3704862   0.9938375   \n0.87996656  0.8695406   0.53354675  \n\n(1,4,.,.) =\n0.8502225   0.9033509   0.8518651   \n0.0692618   0.10121379  0.970959    \n\n(1,5,.,.) =\n0.9397213   0.49688303  0.75739735  \n0.25074655  0.11416598  0.6594504   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x5x2x3]\n\nscala\n print(output)\n1.6689054\n\n\n\n\nPython example:\n\n\ninput = np.random.randn(1, 5, 2, 3)\ntarget = np.array([[[[2.0, 4.0, 2.0], [4.0, 1.0, 2.0]]]])\n\nmodel = SoftmaxWithCriterion()\noutput = model.forward(input, target)\n\n\n print input\n[[[[ 0.78455689  0.01402084  0.82539628]\n   [-1.06448238  2.58168413  0.60053703]]\n\n  [[-0.48617618  0.44538094  0.46611658]\n   [-1.41509329  0.40038991 -0.63505732]]\n\n  [[ 0.91266769  1.68667933  0.92423611]\n   [ 0.1465411   0.84637557  0.14917515]]\n\n  [[-0.7060493  -2.02544114  0.89070726]\n   [ 0.14535539  0.73980064 -0.33130613]]\n\n  [[ 0.64538791 -0.44384233 -0.40112523]\n   [ 0.44346658 -2.22303621  0.35715986]]]]\n\n\n print output\n2.1002123\n\n\n\n\n\n\n\nSmoothL1Criterion\n\n\nScala:\n\n\nval slc = SmoothL1Criterion(sizeAverage=true)\n\n\n\n\nPython:\n\n\nslc = SmoothL1Criterion(size_average=True)\n\n\n\n\nCreates a criterion that can be thought of as a smooth version of the AbsCriterion.\nIt uses a squared term if the absolute element-wise error falls below 1.\nIt is less sensitive to outliers than the MSECriterion and in some\ncases prevents exploding gradients (e.g. see \"Fast R-CNN\" paper by Ross Girshick).\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.{Tensor, Storage}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.SmoothL1Criterion\n\nval slc = SmoothL1Criterion()\n\nval inputArr = Array(\n  0.17503996845335,\n  0.83220188552514,\n  0.48450597329065,\n  0.64701424003579,\n  0.62694586534053,\n  0.34398410236463,\n  0.55356747563928,\n  0.20383032318205\n)\nval targetArr = Array(\n  0.69956525065936,\n  0.86074831243604,\n  0.54923197557218,\n  0.57388074393384,\n  0.63334444304928,\n  0.99680578662083,\n  0.49997645849362,\n  0.23869121982716\n)\n\nval input = Tensor(Storage(inputArr.map(x =\n x.toFloat))).reshape(Array(2, 2, 2))\nval target = Tensor(Storage(targetArr.map(x =\n x.toFloat))).reshape(Array(2, 2, 2))\n\nval output = slc.forward(input, target)\nval gradInput = slc.backward(input, target)\n\n\n\n\nGives the output,\n\n\noutput: Float = 0.0447365\n\n\n\n\nGives the gradInput,\n\n\ngradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.06556566     -0.003568299\n-0.008090746    0.009141691\n\n(2,.,.) =\n-7.998273E-4    -0.08160271\n0.0066988766    -0.0043576136\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nslc = SmoothL1Criterion()\n\ninput = np.array([\n    0.17503996845335,\n    0.83220188552514,\n    0.48450597329065,\n    0.64701424003579,\n    0.62694586534053,\n    0.34398410236463,\n    0.55356747563928,\n    0.20383032318205\n])\ninput.reshape(2, 2, 2)\n\ntarget = np.array([\n    0.69956525065936,\n    0.86074831243604,\n    0.54923197557218,\n    0.57388074393384,\n    0.63334444304928,\n    0.99680578662083,\n    0.49997645849362,\n    0.23869121982716\n])\n\ntarget.reshape(2, 2, 2)\n\noutput = slc.forward(input, target)\ngradInput = slc.backward(input, target)\n\nprint output\nprint gradInput\n\n\n\n\n\n\nSmoothL1CriterionWithWeights\n\n\nScala:\n\n\nval smcod = SmoothL1CriterionWithWeights[Float](sigma: Float = 2.4f, num: Int = 2)\n\n\n\n\nPython:\n\n\nsmcod = SmoothL1CriterionWithWeights(sigma, num)\n\n\n\n\na smooth version of the AbsCriterion\nIt uses a squared term if the absolute element-wise error falls below 1.\nIt is less sensitive to outliers than the MSECriterion and in some cases\nprevents exploding gradients (e.g. see \"Fast R-CNN\" paper by Ross Girshick).\n\n\n   d = (x - y) * w_in\n\n  loss(x, y, w_in, w_out)\n              | 0.5 * (sigma * d_i)^2 * w_out          if |d_i| \n 1 / sigma / sigma\n   = 1/n \\sum |\n              | (|d_i| - 0.5 / sigma / sigma) * w_out   otherwise\n\n\n\n\nScala example:\n\n\nval smcod = SmoothL1CriterionWithWeights[Float](2.4f, 2)\n\nval inputArr = Array(1.1, -0.8, 0.1, 0.4, 1.3, 0.2, 0.2, 0.03)\nval targetArr = Array(0.9, 1.5, -0.08, -1.68, -0.68, -1.17, -0.92, 1.58)\nval inWArr = Array(-0.1, 1.7, -0.8, -1.9, 1.0, 1.4, 0.8, 0.8)\nval outWArr = Array(-1.9, -0.5, 1.9, -1.0, -0.2, 0.1, 0.3, 1.1)\n\nval input = Tensor(Storage(inputArr.map(x =\n x.toFloat)))\nval target = T()\ntarget.insert(Tensor(Storage(targetArr.map(x =\n x.toFloat))))\ntarget.insert(Tensor(Storage(inWArr.map(x =\n x.toFloat))))\ntarget.insert(Tensor(Storage(outWArr.map(x =\n x.toFloat))))\n\nval output = smcod.forward(input, target)\nval gradInput = smcod.backward(input, target)\n\n\n println(output)\n  output: Float = -2.17488\n\n println(gradInput)\n-0.010944003\n0.425\n0.63037443\n-0.95\n-0.1\n0.07\n0.120000005\n-0.44000003\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 8]\n\n\n\n\nPython example:\n\n\nsmcod = SmoothL1CriterionWithWeights(2.4, 2)\n\ninput = np.array([1.1, -0.8, 0.1, 0.4, 1.3, 0.2, 0.2, 0.03]).astype(\nfloat32\n)\ntargetArr = np.array([0.9, 1.5, -0.08, -1.68, -0.68, -1.17, -0.92, 1.58]).astype(\nfloat32\n)\ninWArr = np.array([-0.1, 1.7, -0.8, -1.9, 1.0, 1.4, 0.8, 0.8]).astype(\nfloat32\n)\noutWArr = np.array([-1.9, -0.5, 1.9, -1.0, -0.2, 0.1, 0.3, 1.1]).astype(\nfloat32\n)\ntarget = [targetArr, inWArr, outWArr]\n\noutput = smcod.forward(input, target)\ngradInput = smcod.backward(input, target)\n\n\n output\n-2.17488\n\n gradInput\n[array([-0.010944  ,  0.42500001,  0.63037443, -0.94999999, -0.1       ,\n         0.07      ,  0.12      , -0.44000003], dtype=float32)]\n\n\n\n\n\n\nMultiMarginCriterion\n\n\nScala:\n\n\nval loss = MultiMarginCriterion(p=1,weights=null,margin=1.0,sizeAverage=true)\n\n\n\n\nPython:\n\n\nloss = MultiMarginCriterion(p=1,weights=None,margin=1.0,size_average=True)\n\n\n\n\nMultiMarginCriterion is a loss function that optimizes a multi-class classification hinge loss (margin-based loss) between input \nx\n and output \ny\n (\ny\n is the target class index).\n\n\nScala example:\n\n\n\nscala\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval input = Tensor(3,2).randn()\nval target = Tensor(Storage(Array(2.0f, 1.0f, 2.0f)))\nval loss = MultiMarginCriterion(1)\nval output = loss.forward(input,target)\nval grad = loss.backward(input,target)\n\nscala\n print(input)\n-0.45896783     -0.80141246\n0.22560088      -0.13517438\n0.2601126       0.35492152\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\nscala\n print(target)\n2.0\n1.0\n2.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n\nscala\n print(output)\n0.4811434\n\nscala\n print(grad)\n0.16666667      -0.16666667\n-0.16666667     0.16666667\n0.16666667      -0.16666667\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x2]\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.criterion import *\nimport numpy as np\n\ninput  = np.random.randn(3,2)\ntarget = np.array([2,1,2])\nprint \ninput=\n,input\nprint \ntarget=\n,target\n\nloss = MultiMarginCriterion(1)\nout = loss.forward(input, target)\nprint \noutput of loss is : \n,out\n\ngrad_out = loss.backward(input,target)\nprint \ngrad out of loss is : \n,grad_out\n\n\n\n\nGives the output,\n\n\ninput= [[ 0.46868305 -2.28562261]\n [ 0.8076243  -0.67809689]\n [-0.20342555 -0.66264743]]\ntarget= [2 1 2]\ncreating: createMultiMarginCriterion\noutput of loss is :  0.8689213\ngrad out of loss is :  [[ 0.16666667 -0.16666667]\n [ 0.          0.        ]\n [ 0.16666667 -0.16666667]]\n\n\n\n\n\n\n\n\nHingeEmbeddingCriterion\n\n\nScala:\n\n\nval m = HingeEmbeddingCriterion(margin = 1, sizeAverage = true)\n\n\n\n\nPython:\n\n\nm = HingeEmbeddingCriterion(margin=1, size_average=True)\n\n\n\n\nCreates a criterion that measures the loss given an input \nx\n which is a 1-dimensional vector and a label \ny\n (\n1\n or \n-1\n).\nThis is usually used for measuring whether two inputs are similar or dissimilar, e.g. using the L1 pairwise distance, and is typically used for learning nonlinear embeddings or semi-supervised learning.\n\n\n                 \u23a7 x_i,                  if y_i ==  1\nloss(x, y) = 1/n \u23a8\n                 \u23a9 max(0, margin - x_i), if y_i == -1\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.utils.{T}\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.{T}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval loss = HingeEmbeddingCriterion(1, sizeAverage = false)\nval input = Tensor(T(0.1f, 2.0f, 2.0f, 2.0f))\nprintln(\ninput: \\n\n + input)\nprintln(\nouput: \n)\n\nprintln(\nTarget=1: \n + loss.forward(input, Tensor(4, 1).fill(1f)))\n\nprintln(\nTarget=-1: \n + loss.forward(input, Tensor(4, 1).fill(-1f)))\n\n\n\n\ninput: \n0.1\n2.0\n2.0\n2.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\nouput: \nTarget=1: 6.1\nTarget=-1: 0.9\n\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.criterion import *\ninput = np.array([0.1, 2.0, 2.0, 2.0])\ntarget = np.full(4, 1)\nprint(\ninput: \n )\nprint(input)\nprint(\ntarget: \n)\nprint(target)\nprint(\noutput: \n)\nprint(HingeEmbeddingCriterion(1.0, size_average= False).forward(input, target))\nprint(HingeEmbeddingCriterion(1.0, size_average= False).forward(input, np.full(4, -1)))\n\n\n\n\ninput: \n[ 0.1  2.   2.   2. ]\ntarget: \n[1 1 1 1]\noutput: \ncreating: createHingeEmbeddingCriterion\n6.1\ncreating: createHingeEmbeddingCriterion\n0.9\n\n\n\n\n\n\nMarginCriterion\n\n\nScala:\n\n\ncriterion = MarginCriterion(margin=1.0, sizeAverage=true, squared=false)\n\n\n\n\nPython:\n\n\ncriterion = MarginCriterion(margin=1.0, sizeAverage=True, squared=False, bigdl_type=\nfloat\n)\n\n\n\n\nCreates a criterion that optimizes a two-class classification (squared) hinge loss (margin-based loss) between input x (a Tensor of dimension 1) and output y.\n * \nmargin\n if unspecified, is by default 1.\n * \nsizeAverage\n whether to average the loss, is by default true\n * \nsquared\n whether to calculate the squared hinge loss\n\n\nScala example:\n\n\nval criterion = MarginCriterion(margin=1.0, sizeAverage=true)\n\nval input = Tensor(3, 2).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.33753583      0.3575501\n0.23477706      0.7240361\n0.92835575      0.4737949\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\nval target = Tensor(3, 2).rand()\ntarget: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.27280563      0.7022703\n0.3348442       0.43332106\n0.08935371      0.17876455\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\ncriterion.forward(input, target)\nres5: Float = 0.84946966\n\n\n\n\nPython example:\n\n\ncriterion = MarginCriterion(margin=1.0,size_average=True,bigdl_type=\nfloat\n)\ninput = np.random.rand(3, 2)\narray([[ 0.20824672,  0.67299837],\n       [ 0.80561452,  0.19564743],\n       [ 0.42501441,  0.19408184]])\n\ntarget = np.random.rand(3, 2)\narray([[ 0.67882632,  0.61257846],\n       [ 0.10111138,  0.75225082],\n       [ 0.60404296,  0.31373273]])\n\ncriterion.forward(input, target)\n0.8166871\n\n\n\n\n\n\nCosineEmbeddingCriterion\n\n\nScala:\n\n\nval cosineEmbeddingCriterion = CosineEmbeddingCriterion(margin  = 0.0, sizeAverage = true)\n\n\n\n\nPython:\n\n\ncosineEmbeddingCriterion = CosineEmbeddingCriterion( margin=0.0,size_average=True)\n\n\n\n\nCosineEmbeddingCriterion creates a criterion that measures the loss given an input x = {x1, x2},\na table of two Tensors, and a Tensor label y with values 1 or -1.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimpot com.intel.analytics.bigdl.utils.T\nval cosineEmbeddingCriterion = CosineEmbeddingCriterion(0.0, false)\nval input1 = Tensor(5).rand()\nval input2 = Tensor(5).rand()\nval input = T()\ninput(1.0) = input1\ninput(2.0) = input2\nval target1 = Tensor(Storage(Array(-0.5f)))\nval target = T()\ntarget(1.0) = target1\n\n\n print(input)\n {\n    2.0: 0.4110882\n         0.57726574\n         0.1949834\n         0.67670715\n         0.16984987\n         [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n    1.0: 0.16878392\n         0.24124223\n         0.8964794\n         0.11156334\n         0.5101486\n         [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n }\n\n\n print(cosineEmbeddingCriterion.forward(input, target))\n0.49919847\n\n\n print(cosineEmbeddingCriterion.backward(input, target))\n {\n    2: -0.045381278\n       -0.059856333\n       0.72547954\n       -0.2268434\n       0.3842142\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n    1: 0.30369008\n       0.42463788\n       -0.20637506\n       0.5712836\n       -0.06355385\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n }\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\ncosineEmbeddingCriterion = CosineEmbeddingCriterion(0.0, False)\n\n cosineEmbeddingCriterion.forward([np.array([1.0, 2.0, 3.0, 4.0 ,5.0]),np.array([5.0, 4.0, 3.0, 2.0, 1.0])],[np.array(-0.5)])\n0.6363636\n\n cosineEmbeddingCriterion.backward([np.array([1.0, 2.0, 3.0, 4.0 ,5.0]),np.array([5.0, 4.0, 3.0, 2.0, 1.0])],[np.array(-0.5)])\n[array([ 0.07933884,  0.04958678,  0.01983471, -0.00991735, -0.03966942], dtype=float32), array([-0.03966942, -0.00991735,  0.01983471,  0.04958678,  0.07933884], dtype=float32)]\n\n\n\n\n\n\n\nBCECriterion\n\n\nScala:\n\n\nval criterion = BCECriterion[Float]()\n\n\n\n\nPython:\n\n\ncriterion = BCECriterion()\n\n\n\n\nThis loss function measures the Binary Cross Entropy between the target and the output\n\n\n loss(o, t) = - 1/n sum_i (t[i] * log(o[i]) + (1 - t[i]) * log(1 - o[i]))\n\n\n\n\nor in the case of the weights argument being specified:\n\n\n loss(o, t) = - 1/n sum_i weights[i] * (t[i] * log(o[i]) + (1 - t[i]) * log(1 - o[i]))\n\n\n\n\nBy default, the losses are averaged for each mini-batch over observations as well as over\n dimensions. However, if the field sizeAverage is set to false, the losses are instead summed.\n\n\nScala example:\n\n\n\nval criterion = BCECriterion[Float]()\nval input = Tensor[Float](3, 1).rand\n\nval target = Tensor[Float](3)\ntarget(1) = 1\ntarget(2) = 0\ntarget(3) = 1\n\nval output = criterion.forward(input, target)\nval gradInput = criterion.backward(input, target)\n\n\n println(target)\nres25: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0\n0.0\n1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n\n\n println(output)\noutput: Float = 0.9009579\n\n\n println(gradInput)\ngradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-1.5277504\n1.0736246\n-0.336957\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x1]\n\n\n\n\n\nPython example:\n\n\n\ncriterion = BCECriterion()\ninput = np.random.uniform(0, 1, (3, 1)).astype(\nfloat32\n)\ntarget = np.array([1, 0, 1])\noutput = criterion.forward(input, target)\ngradInput = criterion.backward(input, target)\n\n\n output\n1.9218739\n\n gradInput\n[array([[-4.3074522 ],\n        [ 2.24244714],\n        [-1.22368968]], dtype=float32)]\n\n\n\n\n\n\n\nDiceCoefficientCriterion\n\n\nScala:\n\n\nval loss = DiceCoefficientCriterion(sizeAverage=true, epsilon=1.0f)\n\n\n\n\nPython:\n\n\nloss = DiceCoefficientCriterion(size_average=True,epsilon=1.0)\n\n\n\n\nDiceCoefficientCriterion is the Dice-Coefficient objective function. \n\n\nBoth \nforward\n and \nbackward\n accept two tensors : input and target. The \nforward\n result is formulated as \n          \n1 - (2 * (input intersection target) / (input union target))\n\n\nScala example:\n\n\n\nscala\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval input = Tensor(2).randn()\nval target = Tensor(Storage(Array(2.0f, 1.0f)))\nval loss = DiceCoefficientCriterion(epsilon = 1.0f)\nval output = loss.forward(input,target)\nval grad = loss.backward(input,target)\n\nscala\n print(input)\n-0.50278\n0.51387966\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2]\n\nscala\n print(target)\n2.0\n1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2]\n\nscala\n print(output)\n0.9958517\n\nscala\n print(grad)\n-0.99619853     -0.49758217\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.criterion import *\nimport numpy as np\n\ninput  = np.random.randn(2)\ntarget = np.array([2,1],dtype='float64')\n\nprint \ninput=\n, input\nprint \ntarget=\n, target\nloss = DiceCoefficientCriterion(size_average=True,epsilon=1.0)\nout = loss.forward(input,target)\nprint \noutput of loss is :\n,out\n\ngrad_out = loss.backward(input,target)\nprint \ngrad out of loss is :\n,grad_out\n\n\n\n\nproduces output:\n\n\ninput= [ 0.4440505  2.9430301]\ntarget= [ 2.  1.]\ncreating: createDiceCoefficientCriterion\noutput of loss is : -0.17262316\ngrad out of loss is : [[-0.38274616 -0.11200322]]\n\n\n\n\n\n\nMSECriterion\n\n\nScala:\n\n\nval criterion = MSECriterion()\n\n\n\n\nPython:\n\n\ncriterion = MSECriterion()\n\n\n\n\nThe mean squared error criterion e.g. input: a, target: b, total elements: n\n\n\nloss(a, b) = 1/n * sum(|a_i - b_i|^2)\n\n\n\n\nParameters:\n\n\n\n\nsizeAverage\n a boolean indicating whether to divide the sum of squared error by n. \n                 Default: true\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = MSECriterion()\nval input = Tensor(T(\n T(1.0f, 2.0f),\n T(3.0f, 4.0f))\n)\nval target = Tensor(T(\n T(2.0f, 3.0f),\n T(4.0f, 5.0f))\n)\nval output = criterion.forward(input, target)\nval gradient = criterion.backward(input, target)\n-\n print(output)\n1.0\n-\n print(gradient)\n-0.5    -0.5    \n-0.5    -0.5    \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\ncriterion = MSECriterion()\ninput = np.array([\n          [1.0, 2.0],\n          [3.0, 4.0]\n        ])\ntarget = np.array([\n           [2.0, 3.0],\n           [4.0, 5.0]\n         ])\noutput = criterion.forward(input, target)\ngradient= criterion.backward(input, target)\n-\n print output\n1.0\n-\n print gradient\n[[-0.5 -0.5]\n [-0.5 -0.5]]\n\n\n\n\n\n\nSoftMarginCriterion\n\n\nScala:\n\n\nval criterion = SoftMarginCriterion(sizeAverage)\n\n\n\n\nPython:\n\n\ncriterion = SoftMarginCriterion(size_average)\n\n\n\n\nCreates a criterion that optimizes a two-class classification logistic loss between\ninput x (a Tensor of dimension 1) and output y (which is a tensor containing either\n1s or -1s).\n\n\nloss(x, y) = sum_i (log(1 + exp(-y[i]*x[i]))) / x:nElement()\n\n\n\n\nParameters:\n* \nsizeAverage\n A boolean indicating whether normalizing by the number of elements in the input.\n                    Default: true\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = SoftMarginCriterion()\nval input = Tensor(T(\n T(1.0f, 2.0f),\n T(3.0f, 4.0f))\n)\nval target = Tensor(T(\n T(1.0f, -1.0f),\n T(-1.0f, 1.0f))\n)\nval output = criterion.forward(input, target)\nval gradient = criterion.backward(input, target)\n-\n print(output)\n1.3767318\n-\n print(gradient)\n-0.06723536     0.22019927      \n0.23814353      -0.0044965525   \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\ncriterion = SoftMarginCriterion()\ninput = np.array([\n          [1.0, 2.0],\n          [3.0, 4.0]\n        ])\ntarget = np.array([\n           [2.0, 3.0],\n           [4.0, 5.0]\n         ])\noutput = criterion.forward(input, target)\ngradient = criterion.backward(input, target)\n-\n print output\n1.3767318\n-\n print gradient\n[[-0.06723536  0.22019927]\n [ 0.23814353 -0.00449655]]\n\n\n\n\n\n\nDistKLDivCriterion\n\n\nScala:\n\n\nval loss = DistKLDivCriterion[T](sizeAverage=true)\n\n\n\n\nPython:\n\n\nloss = DistKLDivCriterion(size_average=True)\n\n\n\n\nDistKLDivCriterion is the Kullback\u2013Leibler divergence loss.\n\n\nScala example:\n\n\n\nscala\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval input = Tensor(2).randn()\nval target = Tensor(Storage(Array(2.0f, 1.0f)))\nval loss = DistKLDivCriterion()\nval output = loss.forward(input,target)\nval grad = loss.backward(input,target)\n\nscala\n print(input)\n-0.3854126\n-0.7707398\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2]\n\nscala\n print(target)\n2.0\n1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2]\n\nscala\n print(output)\n1.4639297\n\nscala\n print(grad)\n-1.0\n-0.5\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.criterion import *\nimport numpy as np\n\ninput  = np.random.randn(2)\ntarget = np.array([2,1])\n\nprint \ninput=\n, input\nprint \ntarget=\n, target\nloss = DistKLDivCriterion()\nout = loss.forward(input,target)\nprint \noutput of loss is :\n,out\n\ngrad_out = loss.backward(input,target)\nprint \ngrad out of loss is :\n,grad_out\n\n\n\n\nGives the output\n\n\ninput= [-1.14333924  0.97662296]\ntarget= [2 1]\ncreating: createDistKLDivCriterion\noutput of loss is : 1.348175\ngrad out of loss is : [-1.  -0.5]\n\n\n\n\n\n\nClassSimplexCriterion\n\n\nScala:\n\n\nval criterion = ClassSimplexCriterion(nClasses)\n\n\n\n\nPython:\n\n\ncriterion = ClassSimplexCriterion(nClasses)\n\n\n\n\nClassSimplexCriterion implements a criterion for classification.\nIt learns an embedding per class, where each class' embedding is a\npoint on an (N-1)-dimensional simplex, where N is the number of classes.\n\n\nParameters:\n* \nnClasses\n An integer, the number of classes.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = ClassSimplexCriterion(5)\nval input = Tensor(T(\n T(1.0f, 2.0f, 3.0f, 4.0f, 5.0f),\n T(4.0f, 5.0f, 6.0f, 7.0f, 8.0f)\n))\nval target = Tensor(2)\ntarget(1) = 2.0f\ntarget(2) = 1.0f\nval output = criterion.forward(input, target)\nval gradient = criterion.backward(input, target)\n-\n print(output)\n23.562702\n-\n print(gradient)\n0.25    0.20635083      0.6     0.8     1.0     \n0.6     1.0     1.2     1.4     1.6     \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\ncriterion = ClassSimplexCriterion(5)\ninput = np.array([\n   [1.0, 2.0, 3.0, 4.0, 5.0],\n   [4.0, 5.0, 6.0, 7.0, 8.0]\n])\ntarget = np.array([2.0, 1.0])\noutput = criterion.forward(input, target)\ngradient = criterion.backward(input, target)\n-\n print output\n23.562702\n-\n print gradient\n[[ 0.25        0.20635083  0.60000002  0.80000001  1.        ]\n [ 0.60000002  1.          1.20000005  1.39999998  1.60000002]]\n\n\n\n\n\n\nL1HingeEmbeddingCriterion\n\n\nScala:\n\n\nval model = L1HingeEmbeddingCriterion(margin)\n\n\n\n\nPython:\n\n\nmodel = L1HingeEmbeddingCriterion(margin)\n\n\n\n\nCreates a criterion that measures the loss given an input \nx = {x1, x2}\n, a table of two Tensors, and a label y (1 or -1).\nThis is used for measuring whether two inputs are similar or dissimilar, using the L1 distance, and is typically used for learning nonlinear embeddings or semi-supervised learning.\n\n\n             \u23a7 ||x1 - x2||_1,                  if y ==  1\nloss(x, y) = \u23a8\n             \u23a9 max(0, margin - ||x1 - x2||_1), if y == -1\n\n\n\n\nThe margin has a default value of 1, or can be set in the constructor.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = L1HingeEmbeddingCriterion(0.6)\nval input1 = Tensor(T(1.0f, -0.1f))\nval input2 = Tensor(T(2.0f, -0.2f))\nval input = T(input1, input2)\nval target = Tensor(1)\ntarget(Array(1)) = 1.0f\n\nval output = model.forward(input, target)\n\nscala\n print(output)\n1.1\n\n\n\n\nPython example:\n\n\nmodel = L1HingeEmbeddingCriterion(0.6)\ninput1 = np.array(1.0, -0.1)\ninput2 = np.array(2.0, -0.2)\ninput = [input1, input2]\ntarget = np.array([1.0])\n\noutput = model.forward(input, target)\n\n\n print output\n1.1\n\n\n\n\n\n\nCrossEntropyCriterion\n\n\nScala:\n\n\nval module = CrossEntropyCriterion(weights, sizeAverage)\n\n\n\n\nPython:\n\n\nmodule = CrossEntropyCriterion(weights, sizeAverage)\n\n\n\n\nThis criterion combines LogSoftMax and ClassNLLCriterion in one single class.\n\n\n\n\nweights\n A tensor assigning weight to each of the classes\n\n\nsizeAverage\n whether to divide the sequence length. Default is true.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval layer = CrossEntropyCriterion[Double]()\nval input = Tensor[Double](Storage(Array(\n    1.0262627674932,\n    -1.2412600935171,\n    -1.0423174168648,\n    -0.90330565804228,\n    -1.3686840144413,\n    -1.0778380454479,\n    -0.99131220658219,\n    -1.0559142847536,\n    -1.2692712660404\n    ))).resize(3, 3)\nval target = Tensor[Double](3)\n    target(Array(1)) = 1\n    target(Array(2)) = 2\n    target(Array(3)) = 3\n\n print(layer.forward(input, target))\n0.9483051199107635\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.criterion import *\n\nlayer = CrossEntropyCriterion()\ninput = np.array([1.0262627674932,\n                      -1.2412600935171,\n                      -1.0423174168648,\n                      -0.90330565804228,\n                      -1.3686840144413,\n                      -1.0778380454479,\n                      -0.99131220658219,\n                      -1.0559142847536,\n                      -1.2692712660404\n                      ]).reshape(3,3)\ntarget = np.array([1, 2, 3])                      \n\nlayer.forward(input, target)\n0.94830513\n\n\n\n\n\n\nParallelCriterion\n\n\nScala:\n\n\nval pc = ParallelCriterion(repeatTarget=false)\n\n\n\n\nPython:\n\n\npc = ParallelCriterion(repeat_target=False)\n\n\n\n\nParallelCriterion is a weighted sum of other criterions each applied to a different input\nand target. Set repeatTarget = true to share the target for criterions.\nUse add(criterion[, weight]) method to add criterion. Where weight is a scalar(default 1).\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.{Tensor, Storage}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.{ParallelCriterion, ClassNLLCriterion, MSECriterion}\n\nval pc = ParallelCriterion()\n\nval input = T(Tensor(2, 10), Tensor(2, 10))\nvar i = 0\ninput[Tensor](1).apply1(_ =\n {i += 1; i})\ninput[Tensor](2).apply1(_ =\n {i -= 1; i})\nval target = T(Tensor(Storage(Array(1.0f, 8.0f))), Tensor(2, 10).fill(1.0f))\n\nval nll = ClassNLLCriterion()\nval mse = MSECriterion()\npc.add(nll, 0.5).add(mse)\n\nval output = pc.forward(input, target)\nval gradInput = pc.backward(input, target)\n\nprintln(output)\nprintln(gradInput)\n\n\n\n\n\nGives the output,\n\n\n100.75\n\n\n\n\n\nGives the gradInput,\n\n\n {\n        2: 1.8000001    1.7     1.6     1.5     1.4     1.3000001       1.2     1.1     1.0     0.90000004\n           0.8  0.7     0.6     0.5     0.4     0.3     0.2     0.1     0.0     -0.1\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x10]\n        1: -0.25        0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0\n           0.0  0.0     0.0     0.0     0.0     0.0     0.0     -0.25   0.0     0.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x10]\n }\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\npc = ParallelCriterion()\n\ninput1 = np.arange(1, 21, 1).astype(\nfloat32\n)\ninput2 = np.arange(0, 20, 1).astype(\nfloat32\n)[::-1]\ninput1 = input1.reshape(2, 10)\ninput2 = input2.reshape(2, 10)\n\ninput = [input1, input2]\n\ntarget1 = np.array([1.0, 8.0]).astype(\nfloat32\n)\ntarget1 = target1.reshape(2)\ntarget2 = np.full([2, 10], 1).astype(\nfloat32\n)\ntarget2 = target2.reshape(2, 10)\ntarget = [target1, target2]\n\nnll = ClassNLLCriterion()\nmse = MSECriterion()\n\npc.add(nll, weight = 0.5).add(mse)\n\nprint \ninput = \\n %s \n % input\nprint \ntarget = \\n %s\n % target\n\noutput = pc.forward(input, target)\ngradInput = pc.backward(input, target)\n\nprint \noutput = %s \n % output\nprint \ngradInput = %s \n % gradInput\n\n\n\n\nGives the output,\n\n\ninput = \n [array([[  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.],\n       [ 11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.]], dtype=float32), array([[ 19.,  18.,  17.,  16.,  15.,  14.,  13.,  12.,  11.,  10.],\n       [  9.,   8.,   7.,   6.,   5.,   4.,   3.,   2.,   1.,   0.]], dtype=float32)] \ntarget = \n [array([ 1.,  8.], dtype=float32), array([[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n       [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]], dtype=float32)]\noutput = 100.75 \ngradInput = [array([[-0.25,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  , -0.25,  0.  ,  0.  ]], dtype=float32), array([[ 1.80000007,  1.70000005,  1.60000002,  1.5       ,  1.39999998,\n         1.30000007,  1.20000005,  1.10000002,  1.        ,  0.90000004],\n       [ 0.80000001,  0.69999999,  0.60000002,  0.5       ,  0.40000001,\n         0.30000001,  0.2       ,  0.1       ,  0.        , -0.1       ]], dtype=float32)]\n\n\n\n\n\n\nMultiLabelMarginCriterion\n\n\nScala:\n\n\nval multiLabelMarginCriterion = MultiLabelMarginCriterion(sizeAverage = true)\n\n\n\n\nPython:\n\n\nmultiLabelMarginCriterion = MultiLabelMarginCriterion(size_average=True)\n\n\n\n\nMultiLabelMarginCriterion creates a criterion that optimizes a multi-class multi-classification hinge loss (margin-based loss) between input x and output y \n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval multiLabelMarginCriterion = MultiLabelMarginCriterion(false)\nval input = Tensor(4).rand()\nval target = Tensor(4)\ntarget(Array(1)) = 3\ntarget(Array(2)) = 2\ntarget(Array(3)) = 1\ntarget(Array(4)) = 0\n\n\n print(input)\n0.40267515\n0.5913795\n0.84936756\n0.05999674\n\n\n  print(multiLabelMarginCriterion.forward(input, target))\n0.33414197\n\n\n print(multiLabelMarginCriterion.backward(input, target))\n-0.25\n-0.25\n-0.25\n0.75\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nmultiLabelMarginCriterion = MultiLabelMarginCriterion(False)\n\n\n multiLabelMarginCriterion.forward(np.array([0.3, 0.4, 0.2, 0.6]), np.array([3, 2, 1, 0]))\n0.975\n\n\n multiLabelMarginCriterion.backward(np.array([0.3, 0.4, 0.2, 0.6]), np.array([3, 2, 1, 0]))\n[array([-0.25, -0.25, -0.25,  0.75], dtype=float32)]\n\n\n\n\n\n\n\nMultiLabelSoftMarginCriterion\n\n\nScala:\n\n\nval criterion = MultiLabelSoftMarginCriterion(weights = null, sizeAverage = true)\n\n\n\n\nPython:\n\n\ncriterion = MultiLabelSoftMarginCriterion(weights=None, size_average=True)\n\n\n\n\nMultiLabelSoftMarginCriterion is a multiLabel multiclass criterion based on sigmoid:\n\n\nl(x,y) = - sum_i y[i] * log(p[i]) + (1 - y[i]) * log (1 - p[i])\n\n\n\n\nwhere \np[i] = exp(x[i]) / (1 + exp(x[i]))\n\n\nIf with weights,\n \nl(x,y) = - sum_i weights[i] (y[i] * log(p[i]) + (1 - y[i]) * log (1 - p[i]))\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = MultiLabelSoftMarginCriterion()\nval input = Tensor(3)\ninput(Array(1)) = 0.4f\ninput(Array(2)) = 0.5f\ninput(Array(3)) = 0.6f\nval target = Tensor(3)\ntarget(Array(1)) = 0\ntarget(Array(2)) = 1\ntarget(Array(3)) = 1\n\n\n criterion.forward(input, target)\nres0: Float = 0.6081934\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.criterion import *\nimport numpy as np\n\ncriterion = MultiLabelSoftMarginCriterion()\ninput = np.array([0.4, 0.5, 0.6])\ntarget = np.array([0, 1, 1])\n\n\n criterion.forward(input, target)\n0.6081934\n\n\n\n\n\n\nAbsCriterion\n\n\nScala:\n\n\nval criterion = AbsCriterion(sizeAverage)\n\n\n\n\nPython:\n\n\ncriterion = AbsCriterion(sizeAverage)\n\n\n\n\nMeasures the mean absolute value of the element-wise difference between input and target\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = AbsCriterion()\nval input = Tensor(T(1.0f, 2.0f, 3.0f))\nval target = Tensor(T(4.0f, 5.0f, 6.0f))\nval output = criterion.forward(input, target)\n\nscala\n print(output)\n3.0\n\n\n\n\nPython example:\n\n\ncriterion = AbsCriterion()\ninput = np.array([1.0, 2.0, 3.0])\ntarget = np.array([4.0, 5.0, 6.0])\noutput=criterion.forward(input, target)\n\n\n print output\n3.0\n\n\n\n\n\n\nMultiCriterion\n\n\nScala:\n\n\nval criterion = MultiCriterion()\n\n\n\n\nPython:\n\n\ncriterion = MultiCriterion()\n\n\n\n\nMultiCriterion is a weighted sum of other criterions each applied to the same input and target\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = MultiCriterion()\nval nll = ClassNLLCriterion()\nval mse = MSECriterion()\ncriterion.add(nll, 0.5)\ncriterion.add(mse)\n\nval input = Tensor(5).randn()\nval target = Tensor(5)\ntarget(Array(1)) = 1\ntarget(Array(2)) = 2\ntarget(Array(3)) = 3\ntarget(Array(4)) = 2\ntarget(Array(5)) = 1\n\nval output = criterion.forward(input, target)\n\n\n input\n1.0641425\n-0.33507252\n1.2345984\n0.08065767\n0.531199\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n\n\n\n output\nres7: Float = 1.9633228\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.criterion import *\nimport numpy as np\n\ncriterion = MultiCriterion()\nnll = ClassNLLCriterion()\nmse = MSECriterion()\ncriterion.add(nll, 0.5)\ncriterion.add(mse)\n\ninput = np.array([0.9682213801388531,\n0.35258855644097503,\n0.04584479998452568,\n-0.21781499692588918,\n-1.02721844006879])\ntarget = np.array([1, 2, 3, 2, 1])\n\noutput = criterion.forward(input, target)\n\n\n output\n3.6099546\n\n\n\n\nGaussianCriterion\n\n\nScala:\n\n\nval criterion = GaussianCriterion()\n\n\n\n\nPython:\n\n\ncriterion = GaussianCriterion()\n\n\n\n\nGaussianCriterion computes the log-likelihood of a sample given a Gaussian distribution.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.GaussianCriterion\nimport com.intel.analytics.bigdl.utils.T\n\nval criterion = GaussianCriterion()\n\nval input1 = Tensor[Float](2, 3).range(1, 6, 1)\nval input2 = Tensor[Float](2, 3).range(1, 12, 2)\nval input = T(input1, input2)\n\nval target = Tensor[Float](2, 3).range(2, 13, 2)\n\nval loss = criterion.forward(input, target)\n\n\n loss\nloss: Float = 23.836603\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ncriterion = GaussianCriterion()\n\ninput1 = np.arange(1, 7, 1).astype(\nfloat32\n)\ninput2 = np.arange(1, 12, 2).astype(\nfloat32\n)\ninput1 = input1.reshape(2, 3)\ninput2 = input2.reshape(2, 3)\ninput = [input1, input2]\n\ntarget = np.arange(2, 13, 2).astype(\nfloat32\n)\ntarget = target.reshape(2, 3)\n\nloss = criterion.forward(input, target)\n\n\n output\n23.836603\n\n\n\n\nKLDCriterion\n\n\nScala:\n\n\nval criterion = KLDCriterion()\n\n\n\n\nPython:\n\n\ncriterion = KLDCriterion()\n\n\n\n\nComputes the KL-divergence of the input normal distribution to a standard normal distribution.\nThe input has to be a table. The first element of input is the mean of the distribution,\nthe second element of input is the log_variance of the distribution. The input distribution is\nassumed to be diagonal.\n\n\nThe mean and log_variance are both assumed to be two dimensional tensors. The first dimension are\ninterpreted as batch. The output is the average/sum of each observation\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.KLDCriterion\nimport com.intel.analytics.bigdl.utils.T\n\nval criterion = KLDCriterion()\n\nval input1 = Tensor[Float](2, 3).range(1, 6, 1)\nval input2 = Tensor[Float](2, 3).range(1, 12, 2)\nval input = T(input1, input2)\n\nval target = Tensor[Float](2, 3).range(2, 13, 2)\n\nval loss = criterion.forward(input, target)\n\n\n loss\nloss: Float = 34647.04\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ncriterion = KLDCriterion()\n\ninput1 = np.arange(1, 7, 1).astype(\nfloat32\n)\ninput2 = np.arange(1, 12, 2).astype(\nfloat32\n)\ninput1 = input1.reshape(2, 3)\ninput2 = input2.reshape(2, 3)\ninput = [input1, input2]\n\ntarget = np.arange(2, 13, 2).astype(\nfloat32\n)\ntarget = target.reshape(2, 3)\n\nloss = criterion.forward(input, target)\n\n\n loss\n34647.04\n\n\n\n\nCosineProximityCriterion\n\n\nScala:\n\n\nval criterion = CosineProximityCriterion()\n\n\n\n\nPython:\n\n\ncriterion = CosineProximityCriterion()\n\n\n\n\nComputes the negative of the mean cosine proximity between predictions and targets.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.CosineProximityCriterion\n\nval criterion = CosineProximityCriterion()\n\nval input = Tensor[Float](2, 3).rand()\n\nval target = Tensor[Float](2, 3).rand()\n\nval loss = criterion.forward(input, target)\n\n\n loss\nloss: Float = -0.28007346\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.criterion import *\n\ncriterion = CosineProximityCriterion()\n\ninput = np.arange(1, 7, 1).astype(\nfloat32\n)\ninput = input.reshape(2, 3)\ntarget = np.arange(2, 13, 2).astype(\nfloat32\n)\ntarget = target.reshape(2, 3)\n\nloss = criterion.forward(input, target)\n\n\n loss\n-0.3333333\n\n\n\n\nMeanSquaredLogarithmicCriterion\n\n\nScala:\n\n\nval criterion = MeanSquaredLogarithmicCriterion()\n\n\n\n\nPython:\n\n\ncriterion = MeanSquaredLogarithmicCriterion()\n\n\n\n\ncompute mean squared logarithmic error for input and target\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.MeanSquaredLogarithmicCriterion\nimport com.intel.analytics.bigdl.utils.T\n\nval criterion = MeanSquaredLogarithmicCriterion()\nval input = Tensor[Float](2, 3).range(1, 6, 1)\nval target = Tensor[Float](2, 3).range(2, 13, 2)\nval loss = criterion.forward(input, target)\n\n\n loss\nloss: Float = 0.30576965\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ncriterion = MeanSquaredLogarithmicCriterion()\n\ninput = np.arange(1, 7, 1).astype(\nfloat32\n)\ninput = input.reshape(2, 3)\ntarget = np.arange(2, 13, 2).astype(\nfloat32\n)\ntarget = target.reshape(2, 3)\n\nloss = criterion.forward(input, target)\n\n\n loss\n0.30576965\n\n\n\n\nMeanAbsolutePercentageCriterion\n\n\nScala:\n\n\nval criterion = MeanAbsolutePercentageCriterion()\n\n\n\n\nPython:\n\n\ncriterion = MeanAbsolutePercentageCriterion()\n\n\n\n\ncompute mean absolute percentage error for intput and target\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.MeanAbsolutePercentageCriterion\nimport com.intel.analytics.bigdl.utils.T\n\nval criterion = MeanAbsolutePercentageCriterion()\n\nval input = Tensor[Float](2, 3).range(1, 6, 1)\nval target = Tensor[Float](2, 3).range(2, 13, 2)\nval loss = criterion.forward(input, target)\n\n\n loss\nloss: Float = 50.0\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ncriterion = MeanAbsolutePercentageCriterion()\n\ninput = np.arange(1, 7, 1).astype(\nfloat32\n)\ninput = input.reshape(2, 3)\ntarget = np.arange(2, 13, 2).astype(\nfloat32\n)\ntarget = target.reshape(2, 3)\n\nloss = criterion.forward(input, target)\n\n\n loss\n50.0\n\n\n\n\nKullbackLeiblerDivergenceCriterion\n\n\nScala:\n\n\nval criterion = KullbackLeiblerDivergenceCriterion()\n\n\n\n\nPython:\n\n\ncriterion = KullbackLeiblerDivergenceCriterion()\n\n\n\n\ncompute Kullback Leibler Divergence Criterion error for intput and target\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.KullbackLeiblerDivergenceCriterion\nimport com.intel.analytics.bigdl.utils.T\n\nval criterion = KullbackLeiblerDivergenceCriterion[Float]()\nval input = Tensor[Float](Array(0.1f, 0.2f, 0.3f, 0.4f, 0.5f, 0.6f), Array(2, 3))\nval target = Tensor[Float](Array(0.6f, 0.5f, 0.4f, 0.3f, 0.2f, 0.1f), Array(2, 3))\nval loss = criterion.forward(input, target)\n\n\n loss\nloss: Float = 0.59976757\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ncriterion = KullbackLeiblerDivergenceCriterion()\n\ny_pred = np.matrix('0.1 0.2 0.3; 0.4 0.5 0.6')\ny_true = np.matrix('0.6 0.5 0.4; 0.3 0.2 0.1')\n\nloss = criterion.forward(y_pred, y_true)\n\n\n loss\n0.59976757\n\n\n\n\nPoissonCriterion\n\n\nScala:\n\n\nval criterion = PoissonCriterion()\n\n\n\n\nPython:\n\n\ncriterion = PoissonCriterion()\n\n\n\n\ncompute Poisson error for intput and target\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.PoissonCriterion\nimport com.intel.analytics.bigdl.utils.T\n\nval criterion = PoissonCriterion()\nval input = Tensor[Float](2, 3).range(1, 6, 1)\nval target = Tensor[Float](2, 3).range(2, 13, 2)\nval loss = criterion.forward(input, target)\n\n\n loss\nloss = -6.1750183\n\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ncriterion = PoissonCriterion()\ninput = np.arange(1, 7, 1).astype(\nfloat32\n)\ninput = input.reshape(2, 3)\ntarget = np.arange(2, 13, 2).astype(\nfloat32\n)\ntarget = target.reshape(2, 3)\n\nloss = criterion.forward(input, target)\n\n\n loss\n-6.1750183\n\n\n\n\nTransformerCriterion\n\n\nScala:\n\n\nval criterion = TransformerCriterion(criterion, Some(inputTransformer), Some(targetTransformer))\n\n\n\n\nPython:\n\n\ncriterion = TransformerCriterion(criterion, input_transformer, targetTransformer)\n\n\n\n\nThe criterion that takes two modules (optional) to transform input and target, and take\none criterion to compute the loss with the transformed input and target.\n\n\nThis criterion can be used to construct complex criterion. For example, the\n\ninputTransformer\n and \ntargetTransformer\n can be pre-trained CNN networks,\nand we can use the networks' output to compute the high-level feature\nreconstruction loss, which is commonly used in areas like neural style transfer\n(https://arxiv.org/abs/1508.06576), texture synthesis (https://arxiv.org/abs/1505.07376),\n.etc.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.TransformerCriterion\nimport com.intel.analytics.bigdl.utils.T\n\nval criterion = MSECriterion()\nval input = Tensor[Float](2, 3).range(1, 6, 1)\nval target = Tensor[Float](2, 3).range(2, 13, 2)\nval inputTransformer = Identity()\nval targetTransformer = Identity()\nval transCriterion = TransformerCriterion(criterion,\n     Some(inputTransformer), Some(targetTransformer))\nval loss = transCriterion.forward(input, target)\n\n\n loss\n15.166667\n\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ncriterion = MSECriterion()\ninput = np.arange(1, 7, 1).astype(\nfloat32\n)\ninput = input.reshape(2, 3)\ntarget = np.arange(2, 13, 2).astype(\nfloat32\n)\ntarget = target.reshape(2, 3)\n\ninputTransformer = Identity()\ntargetTransformer = Identity()\ntransCriterion = TransformerCriterion(criterion, inputTransformer, targetTransformer)\nloss = transCriterion.forward(input, target)\n\n\n\n loss\n15.166667\n\n\n\n\nDotProductCriterion\n\n\nScala:\n\n\nval criterion = DotProductCriterion(sizeAverage=false)\n\n\n\n\nPython:\n\n\ncriterion = DotProductCriterion(sizeAverage=False)\n\n\n\n\nCompute the dot product of input and target tensor.\nInput and target are required to have the same size.\n\n\n\n\nsizeAverage:  whether to average over each observations in the same batch\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = DotProductCriterion()\nval input = Tensor[Float](2, 3).range(1, 6, 1)\nval target = Tensor[Float](2, 3).range(2, 13, 2)\n\nval loss = criterion.forward(input, target)\n\n\n loss\n182.0\n\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ncriterion = DotProductCriterion()\ninput = np.arange(1, 7, 1).astype(\nfloat32\n)\ninput = input.reshape(2, 3)\ntarget = np.arange(2, 13, 2).astype(\nfloat32\n)\ntarget = target.reshape(2, 3)\n\nloss = criterion.forward(input, target)\n\n\n\n loss\n182.0\n\n\n\n\nPGCriterion\n\n\nScala:\n\n\nval criterion = PGCriterion(sizeAverage=false)\n\n\n\n\nPython:\n\n\ncriterion = PGCriterion(sizeAverage=False)\n\n\n\n\nThe Criterion to compute the negative policy gradient given a\nmultinomial distribution and the sampled action and reward.\n\n\nThe input to this criterion should be a 2-D tensor representing\na batch of multinomial distribution, the target should also be\na 2-D tensor with the same size of input, representing the sampled\naction and reward/advantage with the index of non-zero element in the vector\nrepresents the sampled action and the non-zero element itself represents\nthe reward. If the action is space is large, you should consider using\nSparseTensor for target.\n\n\nThe loss computed is simple the standard policy gradient,\n\n\nloss = - 1/n * sum(R_{n} dot_product log(P_{n}))\n\n\nwhere R_{n} is the reward vector, and P_{n} is the input distribution.\n\n\n\n\nsizeAverage:  whether to average over each observations in the same batch\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = PGCriterion()\nval input = Tensor[Float](2, 3).range(1, 6, 1)\nval target = Tensor[Float](2, 3).range(2, 13, 2)\n\nval loss = criterion.forward(input, target)\n\n\n loss\n-58.05011\n\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ncriterion = PGCriterion()\ninput = np.arange(1, 7, 1).astype(\nfloat32\n)\ninput = input.reshape(2, 3)\ntarget = np.arange(2, 13, 2).astype(\nfloat32\n)\ntarget = target.reshape(2, 3)\n\nloss = criterion.forward(input, target)\n\n\n\n loss\n-58.05011\n\n\n\n\nCosineDistanceCriterion\n\n\nScala:\n\n\nval criterion = CosineDistanceCriterion()\n\n\n\n\nPython:\n\n\ncriterion = CosineDistanceCriterion(size_average = True)\n\n\n\n\nThis loss function measures the Cosine Distance between the target and the output\n\n\n loss(o, t) = 1 - cos(o, t)\n\n\n\n\nBy default, the losses are averaged for each mini-batch over observations as well as over\n dimensions. However, if the field sizeAverage is set to false, the losses are instead summed.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.numeric.NumericFloat\n\nval criterion = CosineDistanceCriterion()\nval input = Tensor(1, 5).rand\nval target = Tensor(1, 5).rand\nval loss = criterion.forward(input, target)\n\n\n println(target)\ntarget: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.95363826  0.3175587   0.90366143  0.10316128  0.05317958\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5]\n\n\n\n println(input)\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.5895327   0.20547494  0.43118918  0.28824696  0.032088008\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5]\n\n\n\n println(loss)\nloss: Float = 0.048458755\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ncriterion = CosineDistanceCriterion(size_average = True)\ninput = np.random.uniform(0, 1, (1, 5)).astype(\nfloat32\n)\ntarget = np.random.uniform(0, 1, (1, 5)).astype(\nfloat32\n)\nloss = criterion.forward(input, target)\n\n\n input\narray([[ 0.34291017,  0.95894575,  0.23869193,  0.42518589,  0.73902631]], dtype=float32)\n\n\n target \narray([[ 0.00489056,  0.7253111 ,  0.94344038,  0.69811821,  0.45532107]], dtype=float32)\n\n\n loss\n0.20651573\n\n\n\n\n\nCategoricalCrossEntropy\n\n\nScala:\n\n\nval criterion = CategoricalCrossEntropy()\n\n\n\n\nPython:\n\n\ncriterion = CategoricalCrossEntropy()\n\n\n\n\nThis is same with cross entropy criterion, except the target tensor is a\none-hot tensor.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval criterion = CategoricalCrossEntropy()\nval input = Tensor(1, 5).rand()\nval target = Tensor(1, 5).zero().setValue(1, 3, 1)\nval loss = criterion.forward(input, target)\n\n\n println(target)\ntarget: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.0     0.0     1.0     0.0     0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5]\n\n\n\n println(input)\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.95245546      0.8304343       0.8296352       0.13989972      0.17466335\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5]\n\n\n\n println(loss)\nloss: Float = 1.2607772\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.criterion import *\n\ncriterion = CategoricalCrossEntropy()\ninput = np.random.uniform(0, 1, (1, 5)).astype(\nfloat32\n)\ntarget = np.zeros((1, 5)).astype(\nfloat32\n)\ntarget[0, 2] = 1\nloss = criterion.forward(input, target)\n\n\n input\narray([[ 0.31309742,  0.75959802,  0.01649681,  0.65792692,  0.21528937]], dtype=float32)\n\n\n target \narray([[ 0.,  0.,  1.,  0.,  0.]], dtype=float32)\n\n\n loss\n4.7787604", 
            "title": "Losses"
        }, 
        {
            "location": "/APIGuide/Losses/#l1cost", 
            "text": "Scala:  val layer = L1Cost[Float]()  Python:  layer = L1Cost()  Compute L1 norm for input, and sign of input  Scala example:  val layer = L1Cost[Float]()\nval input = Tensor[Float](2, 2).rand\nval target = Tensor[Float](2, 2).rand\n\nval output = layer.forward(input, target)\nval gradInput = layer.backward(input, target)  println(input)\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.48145306      0.476887\n0.23729686      0.5169516\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  println(target)\ntarget: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.42999148      0.22272833\n0.49723643      0.17884709\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  println(output)\noutput: Float = 1.7125885  println(gradInput)\ngradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0     1.0\n1.0     1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  layer = L1Cost()\n\ninput = np.random.uniform(0, 1, (2, 2)).astype( float32 )\ntarget = np.random.uniform(0, 1, (2, 2)).astype( float32 )\n\noutput = layer.forward(input, target)\ngradInput = layer.backward(input, target)  output\n2.522411  gradInput\n[array([[ 1.,  1.],\n        [ 1.,  1.]], dtype=float32)]", 
            "title": "L1Cost"
        }, 
        {
            "location": "/APIGuide/Losses/#timedistributedcriterion", 
            "text": "Scala:  val module = TimeDistributedCriterion(critrn, sizeAverage)  Python:  module = TimeDistributedCriterion(critrn, sizeAverage)  This class is intended to support inputs with 3 or more dimensions.\nApply Any Provided Criterion to every temporal slice of an input.   critrn  embedded criterion  sizeAverage  whether to divide the sequence length. Default is false.   Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval criterion = ClassNLLCriterion[Double]()\nval layer = TimeDistributedCriterion[Double](criterion, true)\nval input = Tensor[Double](Storage(Array(\n    1.0262627674932,\n    -1.2412600935171,\n    -1.0423174168648,\n    -1.0262627674932,\n    -1.2412600935171,\n    -1.0423174168648,\n    -0.90330565804228,\n    -1.3686840144413,\n    -1.0778380454479,\n    -0.90330565804228,\n    -1.3686840144413,\n    -1.0778380454479,\n    -0.99131220658219,\n    -1.0559142847536,\n    -1.2692712660404,\n    -0.99131220658219,\n    -1.0559142847536,\n    -1.2692712660404))).resize(3, 2, 3)\nval target = Tensor[Double](3, 2)\n    target(Array(1, 1)) = 1\n    target(Array(1, 2)) = 1\n    target(Array(2, 1)) = 2\n    target(Array(2, 2)) = 2\n    target(Array(3, 1)) = 3\n    target(Array(3, 2)) = 3  print(layer.forward(input, target))\n0.8793184268272332  Python example:  from bigdl.nn.criterion import *\n\ncriterion = ClassNLLCriterion()\nlayer = TimeDistributedCriterion(criterion, True)\ninput = np.array([1.0262627674932,\n                      -1.2412600935171,\n                      -1.0423174168648,\n                      -1.0262627674932,\n                      -1.2412600935171,\n                      -1.0423174168648,\n                      -0.90330565804228,\n                      -1.3686840144413,\n                      -1.0778380454479,\n                      -0.90330565804228,\n                      -1.3686840144413,\n                      -1.0778380454479,\n                      -0.99131220658219,\n                      -1.0559142847536,\n                      -1.2692712660404,\n                      -0.99131220658219,\n                      -1.0559142847536,\n                      -1.2692712660404]).reshape(3,2,3)\ntarget = np.array([[1,1],[2,2],[3,3]])                       layer.forward(input, target)\n0.8793184", 
            "title": "TimeDistributedCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#marginrankingcriterion", 
            "text": "Scala:  val mse = new MarginRankingCriterion(margin=1.0, sizeAverage=true)  Python:  mse = MarginRankingCriterion(margin=1.0, size_average=true)  Creates a criterion that measures the loss given an input  x = {x1, x2} ,\na table of two Tensors of size 1 (they contain only scalars), and a label y (1 or -1).\nIn batch mode, x is a table of two Tensors of size batchsize, and y is a Tensor of size\nbatchsize containing 1 or -1 for each corresponding pair of elements in the input Tensor.\nIf  y == 1  then it assumed the first input should be ranked higher (have a larger value) than\nthe second input, and vice-versa for  y == -1 .  Scala example:  import com.intel.analytics.bigdl.nn.MarginRankingCriterion\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.Storage\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nimport scala.util.Random\n\nval input1Arr = Array(1, 2, 3, 4, 5)\nval input2Arr = Array(5, 4, 3, 2, 1)\n\nval target1Arr = Array(-1, 1, -1, 1, 1)\n\nval input1 = Tensor(Storage(input1Arr.map(x =  x.toFloat)))\nval input2 = Tensor(Storage(input2Arr.map(x =  x.toFloat)))\n\nval input = T((1.toFloat, input1), (2.toFloat, input2))\n\nval target1 = Tensor(Storage(target1Arr.map(x =  x.toFloat)))\nval target = T((1.toFloat, target1))\n\nval mse = new MarginRankingCriterion()\n\nval output = mse.forward(input, target)\nval gradInput = mse.backward(input, target)\n\nprintln(output)\nprintln(gradInput)  Gives the output  output: Float = 0.8                                                                                                                                                                    [21/154]  Gives the gradInput,  gradInput: com.intel.analytics.bigdl.utils.Table =\n {\n        2: -0.0\n           0.2\n           -0.2\n           0.0\n           0.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n        1: 0.0\n           -0.2\n           0.2\n           -0.0\n           -0.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n }  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nmse = MarginRankingCriterion()\n\ninput1 = np.array([1, 2, 3, 4, 5]).astype( float32 )\ninput2 = np.array([5, 4, 3, 2, 1]).astype( float32 )\ninput = [input1, input2]\n\ntarget1 = np.array([-1, 1, -1, 1, 1]).astype( float32 )\ntarget = [target1, target1]\n\noutput = mse.forward(input, target)\ngradInput = mse.backward(input, target)\n\nprint output\nprint gradInput  Gives the output,  0.8  Gives the gradInput,  [array([ 0. , -0.2,  0.2, -0. , -0. ], dtype=float32), array([-0. ,  0.2, -0.2,  0. ,  0. ], dtype=float32)]", 
            "title": "MarginRankingCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#classnllcriterion", 
            "text": "Scala:  val criterion = ClassNLLCriterion(weights = null, sizeAverage = true, logProbAsInput=true)  Python:  criterion = ClassNLLCriterion(weights=None, size_average=True, logProbAsInput=true)  The negative log likelihood criterion. It is useful to train a classification problem with n\nclasses. If provided, the optional argument weights should be a 1D Tensor assigning weight to\neach of the classes. This is particularly useful when you have an unbalanced training set.  The input given through a  forward()  is expected to contain log-probabilities/probabilities of each class:\ninput has to be a 1D Tensor of size  n . Obtaining log-probabilities/probabilities in a neural network is easily\nachieved by adding a  LogSoftMax / SoftMax  layer in the last layer of your neural network. You may use CrossEntropyCriterion  instead, if you prefer not to add an extra layer to your network. This\ncriterion expects a class index (1 to the number of class) as target when calling forward(input, target)  and  backward(input, target) .  In the log-probabilities case,\n The loss can be described as:\n      loss(x, class) = -x[class] \n or in the case of the weights argument it is specified as follows:\n      loss(x, class) = -weights[class] * x[class] \n Due to the behaviour of the backend code, it is necessary to set sizeAverage to false when\n calculating losses in non-batch mode.  Note that if the target is  -1 , the training process will skip this sample.\n In other words, the forward process will return zero output and the backward process\n will also return zero  gradInput .  By default, the losses are averaged over observations for each minibatch. However, if the field\n  sizeAverage  is set to false, the losses are instead summed for each minibatch.  Parameters:   weights  weights of each element of the input  sizeAverage  A boolean indicating whether normalizing by the number of elements in the input.\n                  Default: true  logProbAsInput  indicating whether to accept log-probabilities or probabilities as input. True means accepting\n               log-probabilities as input.   Scala example:  import com.intel.analytics.bigdl.nn.ClassNLLCriterion\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval criterion = ClassNLLCriterion()\nval input = Tensor(T(\n              T(1f, 2f, 3f),\n              T(2f, 3f, 4f),\n              T(3f, 4f, 5f)\n          ))\n\nval target = Tensor(T(1f, 2f, 3f))\n\nval loss = criterion.forward(input, target)\nval grad = criterion.backward(input, target)\n\nprint(loss)\n-3.0\nprintln(grad)\n-0.33333334 0.0 0.0\n0.0 -0.33333334 0.0\n0.0 0.0 -0.33333334\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x3]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\n\ncriterion = ClassNLLCriterion()\ninput = np.array([\n              [1.0, 2.0, 3.0],\n              [2.0, 3.0, 4.0],\n              [3.0, 4.0, 5.0]\n          ])\n\ntarget = np.array([1.0, 2.0, 3.0])\n\nloss = criterion.forward(input, target)\ngradient= criterion.backward(input, target)\n\nprint loss\n-3.0\nprint gradient\n-3.0\n[[-0.33333334  0.          0.        ]\n [ 0.         -0.33333334  0.        ]\n [ 0.          0.         -0.33333334]]", 
            "title": "ClassNLLCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#softmaxwithcriterion", 
            "text": "Scala:  val model = SoftmaxWithCriterion(ignoreLabel, normalizeMode)  Python:  model = SoftmaxWithCriterion(ignoreLabel, normalizeMode)  Computes the multinomial logistic loss for a one-of-many classification task, passing real-valued predictions through a softmax to\nget a probability distribution over classes. It should be preferred over separate SoftmaxLayer + MultinomialLogisticLossLayer as \nits gradient computation is more numerically stable.   ignoreLabel    (optional) Specify a label value that should be ignored when computing the loss.  normalizeMode  How to normalize the output loss.   Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.{Storage, Tensor}\n\nval input = Tensor(1, 5, 2, 3).rand()\nval target = Tensor(Storage(Array(2.0f, 4.0f, 2.0f, 4.0f, 1.0f, 2.0f))).resize(1, 1, 2, 3)\n\nval model = SoftmaxWithCriterion[Float]()\nval output = model.forward(input, target)\n\nscala  print(input)\n(1,1,.,.) =\n0.65131104  0.9332143   0.5618989   \n0.9965054   0.9370902   0.108070895 \n\n(1,2,.,.) =\n0.46066576  0.9636703   0.8123812   \n0.31076035  0.16386998  0.37894428  \n\n(1,3,.,.) =\n0.49111295  0.3704862   0.9938375   \n0.87996656  0.8695406   0.53354675  \n\n(1,4,.,.) =\n0.8502225   0.9033509   0.8518651   \n0.0692618   0.10121379  0.970959    \n\n(1,5,.,.) =\n0.9397213   0.49688303  0.75739735  \n0.25074655  0.11416598  0.6594504   \n\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 1x5x2x3]\n\nscala  print(output)\n1.6689054  Python example:  input = np.random.randn(1, 5, 2, 3)\ntarget = np.array([[[[2.0, 4.0, 2.0], [4.0, 1.0, 2.0]]]])\n\nmodel = SoftmaxWithCriterion()\noutput = model.forward(input, target)  print input\n[[[[ 0.78455689  0.01402084  0.82539628]\n   [-1.06448238  2.58168413  0.60053703]]\n\n  [[-0.48617618  0.44538094  0.46611658]\n   [-1.41509329  0.40038991 -0.63505732]]\n\n  [[ 0.91266769  1.68667933  0.92423611]\n   [ 0.1465411   0.84637557  0.14917515]]\n\n  [[-0.7060493  -2.02544114  0.89070726]\n   [ 0.14535539  0.73980064 -0.33130613]]\n\n  [[ 0.64538791 -0.44384233 -0.40112523]\n   [ 0.44346658 -2.22303621  0.35715986]]]]  print output\n2.1002123", 
            "title": "SoftmaxWithCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#smoothl1criterion", 
            "text": "Scala:  val slc = SmoothL1Criterion(sizeAverage=true)  Python:  slc = SmoothL1Criterion(size_average=True)  Creates a criterion that can be thought of as a smooth version of the AbsCriterion.\nIt uses a squared term if the absolute element-wise error falls below 1.\nIt is less sensitive to outliers than the MSECriterion and in some\ncases prevents exploding gradients (e.g. see \"Fast R-CNN\" paper by Ross Girshick).  Scala example:  import com.intel.analytics.bigdl.tensor.{Tensor, Storage}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.SmoothL1Criterion\n\nval slc = SmoothL1Criterion()\n\nval inputArr = Array(\n  0.17503996845335,\n  0.83220188552514,\n  0.48450597329065,\n  0.64701424003579,\n  0.62694586534053,\n  0.34398410236463,\n  0.55356747563928,\n  0.20383032318205\n)\nval targetArr = Array(\n  0.69956525065936,\n  0.86074831243604,\n  0.54923197557218,\n  0.57388074393384,\n  0.63334444304928,\n  0.99680578662083,\n  0.49997645849362,\n  0.23869121982716\n)\n\nval input = Tensor(Storage(inputArr.map(x =  x.toFloat))).reshape(Array(2, 2, 2))\nval target = Tensor(Storage(targetArr.map(x =  x.toFloat))).reshape(Array(2, 2, 2))\n\nval output = slc.forward(input, target)\nval gradInput = slc.backward(input, target)  Gives the output,  output: Float = 0.0447365  Gives the gradInput,  gradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.06556566     -0.003568299\n-0.008090746    0.009141691\n\n(2,.,.) =\n-7.998273E-4    -0.08160271\n0.0066988766    -0.0043576136  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\nslc = SmoothL1Criterion()\n\ninput = np.array([\n    0.17503996845335,\n    0.83220188552514,\n    0.48450597329065,\n    0.64701424003579,\n    0.62694586534053,\n    0.34398410236463,\n    0.55356747563928,\n    0.20383032318205\n])\ninput.reshape(2, 2, 2)\n\ntarget = np.array([\n    0.69956525065936,\n    0.86074831243604,\n    0.54923197557218,\n    0.57388074393384,\n    0.63334444304928,\n    0.99680578662083,\n    0.49997645849362,\n    0.23869121982716\n])\n\ntarget.reshape(2, 2, 2)\n\noutput = slc.forward(input, target)\ngradInput = slc.backward(input, target)\n\nprint output\nprint gradInput", 
            "title": "SmoothL1Criterion"
        }, 
        {
            "location": "/APIGuide/Losses/#smoothl1criterionwithweights", 
            "text": "Scala:  val smcod = SmoothL1CriterionWithWeights[Float](sigma: Float = 2.4f, num: Int = 2)  Python:  smcod = SmoothL1CriterionWithWeights(sigma, num)  a smooth version of the AbsCriterion\nIt uses a squared term if the absolute element-wise error falls below 1.\nIt is less sensitive to outliers than the MSECriterion and in some cases\nprevents exploding gradients (e.g. see \"Fast R-CNN\" paper by Ross Girshick).     d = (x - y) * w_in\n\n  loss(x, y, w_in, w_out)\n              | 0.5 * (sigma * d_i)^2 * w_out          if |d_i|   1 / sigma / sigma\n   = 1/n \\sum |\n              | (|d_i| - 0.5 / sigma / sigma) * w_out   otherwise  Scala example:  val smcod = SmoothL1CriterionWithWeights[Float](2.4f, 2)\n\nval inputArr = Array(1.1, -0.8, 0.1, 0.4, 1.3, 0.2, 0.2, 0.03)\nval targetArr = Array(0.9, 1.5, -0.08, -1.68, -0.68, -1.17, -0.92, 1.58)\nval inWArr = Array(-0.1, 1.7, -0.8, -1.9, 1.0, 1.4, 0.8, 0.8)\nval outWArr = Array(-1.9, -0.5, 1.9, -1.0, -0.2, 0.1, 0.3, 1.1)\n\nval input = Tensor(Storage(inputArr.map(x =  x.toFloat)))\nval target = T()\ntarget.insert(Tensor(Storage(targetArr.map(x =  x.toFloat))))\ntarget.insert(Tensor(Storage(inWArr.map(x =  x.toFloat))))\ntarget.insert(Tensor(Storage(outWArr.map(x =  x.toFloat))))\n\nval output = smcod.forward(input, target)\nval gradInput = smcod.backward(input, target)  println(output)\n  output: Float = -2.17488  println(gradInput)\n-0.010944003\n0.425\n0.63037443\n-0.95\n-0.1\n0.07\n0.120000005\n-0.44000003\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 8]  Python example:  smcod = SmoothL1CriterionWithWeights(2.4, 2)\n\ninput = np.array([1.1, -0.8, 0.1, 0.4, 1.3, 0.2, 0.2, 0.03]).astype( float32 )\ntargetArr = np.array([0.9, 1.5, -0.08, -1.68, -0.68, -1.17, -0.92, 1.58]).astype( float32 )\ninWArr = np.array([-0.1, 1.7, -0.8, -1.9, 1.0, 1.4, 0.8, 0.8]).astype( float32 )\noutWArr = np.array([-1.9, -0.5, 1.9, -1.0, -0.2, 0.1, 0.3, 1.1]).astype( float32 )\ntarget = [targetArr, inWArr, outWArr]\n\noutput = smcod.forward(input, target)\ngradInput = smcod.backward(input, target)  output\n-2.17488  gradInput\n[array([-0.010944  ,  0.42500001,  0.63037443, -0.94999999, -0.1       ,\n         0.07      ,  0.12      , -0.44000003], dtype=float32)]", 
            "title": "SmoothL1CriterionWithWeights"
        }, 
        {
            "location": "/APIGuide/Losses/#multimargincriterion", 
            "text": "Scala:  val loss = MultiMarginCriterion(p=1,weights=null,margin=1.0,sizeAverage=true)  Python:  loss = MultiMarginCriterion(p=1,weights=None,margin=1.0,size_average=True)  MultiMarginCriterion is a loss function that optimizes a multi-class classification hinge loss (margin-based loss) between input  x  and output  y  ( y  is the target class index).  Scala example:  \nscala \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval input = Tensor(3,2).randn()\nval target = Tensor(Storage(Array(2.0f, 1.0f, 2.0f)))\nval loss = MultiMarginCriterion(1)\nval output = loss.forward(input,target)\nval grad = loss.backward(input,target)\n\nscala  print(input)\n-0.45896783     -0.80141246\n0.22560088      -0.13517438\n0.2601126       0.35492152\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\nscala  print(target)\n2.0\n1.0\n2.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3]\n\nscala  print(output)\n0.4811434\n\nscala  print(grad)\n0.16666667      -0.16666667\n-0.16666667     0.16666667\n0.16666667      -0.16666667\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x2]  Python example:  from bigdl.nn.criterion import *\nimport numpy as np\n\ninput  = np.random.randn(3,2)\ntarget = np.array([2,1,2])\nprint  input= ,input\nprint  target= ,target\n\nloss = MultiMarginCriterion(1)\nout = loss.forward(input, target)\nprint  output of loss is :  ,out\n\ngrad_out = loss.backward(input,target)\nprint  grad out of loss is :  ,grad_out  Gives the output,  input= [[ 0.46868305 -2.28562261]\n [ 0.8076243  -0.67809689]\n [-0.20342555 -0.66264743]]\ntarget= [2 1 2]\ncreating: createMultiMarginCriterion\noutput of loss is :  0.8689213\ngrad out of loss is :  [[ 0.16666667 -0.16666667]\n [ 0.          0.        ]\n [ 0.16666667 -0.16666667]]", 
            "title": "MultiMarginCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#hingeembeddingcriterion", 
            "text": "Scala:  val m = HingeEmbeddingCriterion(margin = 1, sizeAverage = true)  Python:  m = HingeEmbeddingCriterion(margin=1, size_average=True)  Creates a criterion that measures the loss given an input  x  which is a 1-dimensional vector and a label  y  ( 1  or  -1 ).\nThis is usually used for measuring whether two inputs are similar or dissimilar, e.g. using the L1 pairwise distance, and is typically used for learning nonlinear embeddings or semi-supervised learning.                   \u23a7 x_i,                  if y_i ==  1\nloss(x, y) = 1/n \u23a8\n                 \u23a9 max(0, margin - x_i), if y_i == -1  Scala example:  import com.intel.analytics.bigdl.utils.{T}\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.{T}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval loss = HingeEmbeddingCriterion(1, sizeAverage = false)\nval input = Tensor(T(0.1f, 2.0f, 2.0f, 2.0f))\nprintln( input: \\n  + input)\nprintln( ouput:  )\n\nprintln( Target=1:   + loss.forward(input, Tensor(4, 1).fill(1f)))\n\nprintln( Target=-1:   + loss.forward(input, Tensor(4, 1).fill(-1f)))  input: \n0.1\n2.0\n2.0\n2.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]\nouput: \nTarget=1: 6.1\nTarget=-1: 0.9  Python example:  import numpy as np\nfrom bigdl.nn.criterion import *\ninput = np.array([0.1, 2.0, 2.0, 2.0])\ntarget = np.full(4, 1)\nprint( input:   )\nprint(input)\nprint( target:  )\nprint(target)\nprint( output:  )\nprint(HingeEmbeddingCriterion(1.0, size_average= False).forward(input, target))\nprint(HingeEmbeddingCriterion(1.0, size_average= False).forward(input, np.full(4, -1)))  input: \n[ 0.1  2.   2.   2. ]\ntarget: \n[1 1 1 1]\noutput: \ncreating: createHingeEmbeddingCriterion\n6.1\ncreating: createHingeEmbeddingCriterion\n0.9", 
            "title": "HingeEmbeddingCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#margincriterion", 
            "text": "Scala:  criterion = MarginCriterion(margin=1.0, sizeAverage=true, squared=false)  Python:  criterion = MarginCriterion(margin=1.0, sizeAverage=True, squared=False, bigdl_type= float )  Creates a criterion that optimizes a two-class classification (squared) hinge loss (margin-based loss) between input x (a Tensor of dimension 1) and output y.\n *  margin  if unspecified, is by default 1.\n *  sizeAverage  whether to average the loss, is by default true\n *  squared  whether to calculate the squared hinge loss  Scala example:  val criterion = MarginCriterion(margin=1.0, sizeAverage=true)\n\nval input = Tensor(3, 2).rand()\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.33753583      0.3575501\n0.23477706      0.7240361\n0.92835575      0.4737949\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\nval target = Tensor(3, 2).rand()\ntarget: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.27280563      0.7022703\n0.3348442       0.43332106\n0.08935371      0.17876455\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x2]\n\ncriterion.forward(input, target)\nres5: Float = 0.84946966  Python example:  criterion = MarginCriterion(margin=1.0,size_average=True,bigdl_type= float )\ninput = np.random.rand(3, 2)\narray([[ 0.20824672,  0.67299837],\n       [ 0.80561452,  0.19564743],\n       [ 0.42501441,  0.19408184]])\n\ntarget = np.random.rand(3, 2)\narray([[ 0.67882632,  0.61257846],\n       [ 0.10111138,  0.75225082],\n       [ 0.60404296,  0.31373273]])\n\ncriterion.forward(input, target)\n0.8166871", 
            "title": "MarginCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#cosineembeddingcriterion", 
            "text": "Scala:  val cosineEmbeddingCriterion = CosineEmbeddingCriterion(margin  = 0.0, sizeAverage = true)  Python:  cosineEmbeddingCriterion = CosineEmbeddingCriterion( margin=0.0,size_average=True)  CosineEmbeddingCriterion creates a criterion that measures the loss given an input x = {x1, x2},\na table of two Tensors, and a Tensor label y with values 1 or -1.  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimpot com.intel.analytics.bigdl.utils.T\nval cosineEmbeddingCriterion = CosineEmbeddingCriterion(0.0, false)\nval input1 = Tensor(5).rand()\nval input2 = Tensor(5).rand()\nval input = T()\ninput(1.0) = input1\ninput(2.0) = input2\nval target1 = Tensor(Storage(Array(-0.5f)))\nval target = T()\ntarget(1.0) = target1  print(input)\n {\n    2.0: 0.4110882\n         0.57726574\n         0.1949834\n         0.67670715\n         0.16984987\n         [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n    1.0: 0.16878392\n         0.24124223\n         0.8964794\n         0.11156334\n         0.5101486\n         [com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]\n }  print(cosineEmbeddingCriterion.forward(input, target))\n0.49919847  print(cosineEmbeddingCriterion.backward(input, target))\n {\n    2: -0.045381278\n       -0.059856333\n       0.72547954\n       -0.2268434\n       0.3842142\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n    1: 0.30369008\n       0.42463788\n       -0.20637506\n       0.5712836\n       -0.06355385\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 5]\n }  Python example:  from bigdl.nn.layer import *\ncosineEmbeddingCriterion = CosineEmbeddingCriterion(0.0, False)  cosineEmbeddingCriterion.forward([np.array([1.0, 2.0, 3.0, 4.0 ,5.0]),np.array([5.0, 4.0, 3.0, 2.0, 1.0])],[np.array(-0.5)])\n0.6363636  cosineEmbeddingCriterion.backward([np.array([1.0, 2.0, 3.0, 4.0 ,5.0]),np.array([5.0, 4.0, 3.0, 2.0, 1.0])],[np.array(-0.5)])\n[array([ 0.07933884,  0.04958678,  0.01983471, -0.00991735, -0.03966942], dtype=float32), array([-0.03966942, -0.00991735,  0.01983471,  0.04958678,  0.07933884], dtype=float32)]", 
            "title": "CosineEmbeddingCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#bcecriterion", 
            "text": "Scala:  val criterion = BCECriterion[Float]()  Python:  criterion = BCECriterion()  This loss function measures the Binary Cross Entropy between the target and the output   loss(o, t) = - 1/n sum_i (t[i] * log(o[i]) + (1 - t[i]) * log(1 - o[i]))  or in the case of the weights argument being specified:   loss(o, t) = - 1/n sum_i weights[i] * (t[i] * log(o[i]) + (1 - t[i]) * log(1 - o[i]))  By default, the losses are averaged for each mini-batch over observations as well as over\n dimensions. However, if the field sizeAverage is set to false, the losses are instead summed.  Scala example:  \nval criterion = BCECriterion[Float]()\nval input = Tensor[Float](3, 1).rand\n\nval target = Tensor[Float](3)\ntarget(1) = 1\ntarget(2) = 0\ntarget(3) = 1\n\nval output = criterion.forward(input, target)\nval gradInput = criterion.backward(input, target)  println(target)\nres25: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0\n0.0\n1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3]  println(output)\noutput: Float = 0.9009579  println(gradInput)\ngradInput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-1.5277504\n1.0736246\n-0.336957\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x1]  Python example:  \ncriterion = BCECriterion()\ninput = np.random.uniform(0, 1, (3, 1)).astype( float32 )\ntarget = np.array([1, 0, 1])\noutput = criterion.forward(input, target)\ngradInput = criterion.backward(input, target)  output\n1.9218739  gradInput\n[array([[-4.3074522 ],\n        [ 2.24244714],\n        [-1.22368968]], dtype=float32)]", 
            "title": "BCECriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#dicecoefficientcriterion", 
            "text": "Scala:  val loss = DiceCoefficientCriterion(sizeAverage=true, epsilon=1.0f)  Python:  loss = DiceCoefficientCriterion(size_average=True,epsilon=1.0)  DiceCoefficientCriterion is the Dice-Coefficient objective function.   Both  forward  and  backward  accept two tensors : input and target. The  forward  result is formulated as \n           1 - (2 * (input intersection target) / (input union target))  Scala example:  \nscala \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval input = Tensor(2).randn()\nval target = Tensor(Storage(Array(2.0f, 1.0f)))\nval loss = DiceCoefficientCriterion(epsilon = 1.0f)\nval output = loss.forward(input,target)\nval grad = loss.backward(input,target)\n\nscala  print(input)\n-0.50278\n0.51387966\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2]\n\nscala  print(target)\n2.0\n1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2]\n\nscala  print(output)\n0.9958517\n\nscala  print(grad)\n-0.99619853     -0.49758217\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2]  Python example:  from bigdl.nn.criterion import *\nimport numpy as np\n\ninput  = np.random.randn(2)\ntarget = np.array([2,1],dtype='float64')\n\nprint  input= , input\nprint  target= , target\nloss = DiceCoefficientCriterion(size_average=True,epsilon=1.0)\nout = loss.forward(input,target)\nprint  output of loss is : ,out\n\ngrad_out = loss.backward(input,target)\nprint  grad out of loss is : ,grad_out  produces output:  input= [ 0.4440505  2.9430301]\ntarget= [ 2.  1.]\ncreating: createDiceCoefficientCriterion\noutput of loss is : -0.17262316\ngrad out of loss is : [[-0.38274616 -0.11200322]]", 
            "title": "DiceCoefficientCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#msecriterion", 
            "text": "Scala:  val criterion = MSECriterion()  Python:  criterion = MSECriterion()  The mean squared error criterion e.g. input: a, target: b, total elements: n  loss(a, b) = 1/n * sum(|a_i - b_i|^2)  Parameters:   sizeAverage  a boolean indicating whether to divide the sum of squared error by n. \n                 Default: true   Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = MSECriterion()\nval input = Tensor(T(\n T(1.0f, 2.0f),\n T(3.0f, 4.0f))\n)\nval target = Tensor(T(\n T(2.0f, 3.0f),\n T(4.0f, 5.0f))\n)\nval output = criterion.forward(input, target)\nval gradient = criterion.backward(input, target)\n-  print(output)\n1.0\n-  print(gradient)\n-0.5    -0.5    \n-0.5    -0.5    \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\ncriterion = MSECriterion()\ninput = np.array([\n          [1.0, 2.0],\n          [3.0, 4.0]\n        ])\ntarget = np.array([\n           [2.0, 3.0],\n           [4.0, 5.0]\n         ])\noutput = criterion.forward(input, target)\ngradient= criterion.backward(input, target)\n-  print output\n1.0\n-  print gradient\n[[-0.5 -0.5]\n [-0.5 -0.5]]", 
            "title": "MSECriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#softmargincriterion", 
            "text": "Scala:  val criterion = SoftMarginCriterion(sizeAverage)  Python:  criterion = SoftMarginCriterion(size_average)  Creates a criterion that optimizes a two-class classification logistic loss between\ninput x (a Tensor of dimension 1) and output y (which is a tensor containing either\n1s or -1s).  loss(x, y) = sum_i (log(1 + exp(-y[i]*x[i]))) / x:nElement()  Parameters:\n*  sizeAverage  A boolean indicating whether normalizing by the number of elements in the input.\n                    Default: true  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = SoftMarginCriterion()\nval input = Tensor(T(\n T(1.0f, 2.0f),\n T(3.0f, 4.0f))\n)\nval target = Tensor(T(\n T(1.0f, -1.0f),\n T(-1.0f, 1.0f))\n)\nval output = criterion.forward(input, target)\nval gradient = criterion.backward(input, target)\n-  print(output)\n1.3767318\n-  print(gradient)\n-0.06723536     0.22019927      \n0.23814353      -0.0044965525   \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\ncriterion = SoftMarginCriterion()\ninput = np.array([\n          [1.0, 2.0],\n          [3.0, 4.0]\n        ])\ntarget = np.array([\n           [2.0, 3.0],\n           [4.0, 5.0]\n         ])\noutput = criterion.forward(input, target)\ngradient = criterion.backward(input, target)\n-  print output\n1.3767318\n-  print gradient\n[[-0.06723536  0.22019927]\n [ 0.23814353 -0.00449655]]", 
            "title": "SoftMarginCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#distkldivcriterion", 
            "text": "Scala:  val loss = DistKLDivCriterion[T](sizeAverage=true)  Python:  loss = DistKLDivCriterion(size_average=True)  DistKLDivCriterion is the Kullback\u2013Leibler divergence loss.  Scala example:  \nscala \nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval input = Tensor(2).randn()\nval target = Tensor(Storage(Array(2.0f, 1.0f)))\nval loss = DistKLDivCriterion()\nval output = loss.forward(input,target)\nval grad = loss.backward(input,target)\n\nscala  print(input)\n-0.3854126\n-0.7707398\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2]\n\nscala  print(target)\n2.0\n1.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2]\n\nscala  print(output)\n1.4639297\n\nscala  print(grad)\n-1.0\n-0.5\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2]  Python example:  from bigdl.nn.criterion import *\nimport numpy as np\n\ninput  = np.random.randn(2)\ntarget = np.array([2,1])\n\nprint  input= , input\nprint  target= , target\nloss = DistKLDivCriterion()\nout = loss.forward(input,target)\nprint  output of loss is : ,out\n\ngrad_out = loss.backward(input,target)\nprint  grad out of loss is : ,grad_out  Gives the output  input= [-1.14333924  0.97662296]\ntarget= [2 1]\ncreating: createDistKLDivCriterion\noutput of loss is : 1.348175\ngrad out of loss is : [-1.  -0.5]", 
            "title": "DistKLDivCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#classsimplexcriterion", 
            "text": "Scala:  val criterion = ClassSimplexCriterion(nClasses)  Python:  criterion = ClassSimplexCriterion(nClasses)  ClassSimplexCriterion implements a criterion for classification.\nIt learns an embedding per class, where each class' embedding is a\npoint on an (N-1)-dimensional simplex, where N is the number of classes.  Parameters:\n*  nClasses  An integer, the number of classes.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = ClassSimplexCriterion(5)\nval input = Tensor(T(\n T(1.0f, 2.0f, 3.0f, 4.0f, 5.0f),\n T(4.0f, 5.0f, 6.0f, 7.0f, 8.0f)\n))\nval target = Tensor(2)\ntarget(1) = 2.0f\ntarget(2) = 1.0f\nval output = criterion.forward(input, target)\nval gradient = criterion.backward(input, target)\n-  print(output)\n23.562702\n-  print(gradient)\n0.25    0.20635083      0.6     0.8     1.0     \n0.6     1.0     1.2     1.4     1.6     \n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nimport numpy as np\ncriterion = ClassSimplexCriterion(5)\ninput = np.array([\n   [1.0, 2.0, 3.0, 4.0, 5.0],\n   [4.0, 5.0, 6.0, 7.0, 8.0]\n])\ntarget = np.array([2.0, 1.0])\noutput = criterion.forward(input, target)\ngradient = criterion.backward(input, target)\n-  print output\n23.562702\n-  print gradient\n[[ 0.25        0.20635083  0.60000002  0.80000001  1.        ]\n [ 0.60000002  1.          1.20000005  1.39999998  1.60000002]]", 
            "title": "ClassSimplexCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#l1hingeembeddingcriterion", 
            "text": "Scala:  val model = L1HingeEmbeddingCriterion(margin)  Python:  model = L1HingeEmbeddingCriterion(margin)  Creates a criterion that measures the loss given an input  x = {x1, x2} , a table of two Tensors, and a label y (1 or -1).\nThis is used for measuring whether two inputs are similar or dissimilar, using the L1 distance, and is typically used for learning nonlinear embeddings or semi-supervised learning.               \u23a7 ||x1 - x2||_1,                  if y ==  1\nloss(x, y) = \u23a8\n             \u23a9 max(0, margin - ||x1 - x2||_1), if y == -1  The margin has a default value of 1, or can be set in the constructor.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval model = L1HingeEmbeddingCriterion(0.6)\nval input1 = Tensor(T(1.0f, -0.1f))\nval input2 = Tensor(T(2.0f, -0.2f))\nval input = T(input1, input2)\nval target = Tensor(1)\ntarget(Array(1)) = 1.0f\n\nval output = model.forward(input, target)\n\nscala  print(output)\n1.1  Python example:  model = L1HingeEmbeddingCriterion(0.6)\ninput1 = np.array(1.0, -0.1)\ninput2 = np.array(2.0, -0.2)\ninput = [input1, input2]\ntarget = np.array([1.0])\n\noutput = model.forward(input, target)  print output\n1.1", 
            "title": "L1HingeEmbeddingCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#crossentropycriterion", 
            "text": "Scala:  val module = CrossEntropyCriterion(weights, sizeAverage)  Python:  module = CrossEntropyCriterion(weights, sizeAverage)  This criterion combines LogSoftMax and ClassNLLCriterion in one single class.   weights  A tensor assigning weight to each of the classes  sizeAverage  whether to divide the sequence length. Default is true.   Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.Storage\n\nval layer = CrossEntropyCriterion[Double]()\nval input = Tensor[Double](Storage(Array(\n    1.0262627674932,\n    -1.2412600935171,\n    -1.0423174168648,\n    -0.90330565804228,\n    -1.3686840144413,\n    -1.0778380454479,\n    -0.99131220658219,\n    -1.0559142847536,\n    -1.2692712660404\n    ))).resize(3, 3)\nval target = Tensor[Double](3)\n    target(Array(1)) = 1\n    target(Array(2)) = 2\n    target(Array(3)) = 3  print(layer.forward(input, target))\n0.9483051199107635  Python example:  from bigdl.nn.criterion import *\n\nlayer = CrossEntropyCriterion()\ninput = np.array([1.0262627674932,\n                      -1.2412600935171,\n                      -1.0423174168648,\n                      -0.90330565804228,\n                      -1.3686840144413,\n                      -1.0778380454479,\n                      -0.99131220658219,\n                      -1.0559142847536,\n                      -1.2692712660404\n                      ]).reshape(3,3)\ntarget = np.array([1, 2, 3])                       layer.forward(input, target)\n0.94830513", 
            "title": "CrossEntropyCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#parallelcriterion", 
            "text": "Scala:  val pc = ParallelCriterion(repeatTarget=false)  Python:  pc = ParallelCriterion(repeat_target=False)  ParallelCriterion is a weighted sum of other criterions each applied to a different input\nand target. Set repeatTarget = true to share the target for criterions.\nUse add(criterion[, weight]) method to add criterion. Where weight is a scalar(default 1).  Scala example:  import com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.{Tensor, Storage}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.{ParallelCriterion, ClassNLLCriterion, MSECriterion}\n\nval pc = ParallelCriterion()\n\nval input = T(Tensor(2, 10), Tensor(2, 10))\nvar i = 0\ninput[Tensor](1).apply1(_ =  {i += 1; i})\ninput[Tensor](2).apply1(_ =  {i -= 1; i})\nval target = T(Tensor(Storage(Array(1.0f, 8.0f))), Tensor(2, 10).fill(1.0f))\n\nval nll = ClassNLLCriterion()\nval mse = MSECriterion()\npc.add(nll, 0.5).add(mse)\n\nval output = pc.forward(input, target)\nval gradInput = pc.backward(input, target)\n\nprintln(output)\nprintln(gradInput)  Gives the output,  100.75  Gives the gradInput,   {\n        2: 1.8000001    1.7     1.6     1.5     1.4     1.3000001       1.2     1.1     1.0     0.90000004\n           0.8  0.7     0.6     0.5     0.4     0.3     0.2     0.1     0.0     -0.1\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x10]\n        1: -0.25        0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0\n           0.0  0.0     0.0     0.0     0.0     0.0     0.0     -0.25   0.0     0.0\n           [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x10]\n }  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\npc = ParallelCriterion()\n\ninput1 = np.arange(1, 21, 1).astype( float32 )\ninput2 = np.arange(0, 20, 1).astype( float32 )[::-1]\ninput1 = input1.reshape(2, 10)\ninput2 = input2.reshape(2, 10)\n\ninput = [input1, input2]\n\ntarget1 = np.array([1.0, 8.0]).astype( float32 )\ntarget1 = target1.reshape(2)\ntarget2 = np.full([2, 10], 1).astype( float32 )\ntarget2 = target2.reshape(2, 10)\ntarget = [target1, target2]\n\nnll = ClassNLLCriterion()\nmse = MSECriterion()\n\npc.add(nll, weight = 0.5).add(mse)\n\nprint  input = \\n %s   % input\nprint  target = \\n %s  % target\n\noutput = pc.forward(input, target)\ngradInput = pc.backward(input, target)\n\nprint  output = %s   % output\nprint  gradInput = %s   % gradInput  Gives the output,  input = \n [array([[  1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.],\n       [ 11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.]], dtype=float32), array([[ 19.,  18.,  17.,  16.,  15.,  14.,  13.,  12.,  11.,  10.],\n       [  9.,   8.,   7.,   6.,   5.,   4.,   3.,   2.,   1.,   0.]], dtype=float32)] \ntarget = \n [array([ 1.,  8.], dtype=float32), array([[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.],\n       [ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]], dtype=float32)]\noutput = 100.75 \ngradInput = [array([[-0.25,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  , -0.25,  0.  ,  0.  ]], dtype=float32), array([[ 1.80000007,  1.70000005,  1.60000002,  1.5       ,  1.39999998,\n         1.30000007,  1.20000005,  1.10000002,  1.        ,  0.90000004],\n       [ 0.80000001,  0.69999999,  0.60000002,  0.5       ,  0.40000001,\n         0.30000001,  0.2       ,  0.1       ,  0.        , -0.1       ]], dtype=float32)]", 
            "title": "ParallelCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#multilabelmargincriterion", 
            "text": "Scala:  val multiLabelMarginCriterion = MultiLabelMarginCriterion(sizeAverage = true)  Python:  multiLabelMarginCriterion = MultiLabelMarginCriterion(size_average=True)  MultiLabelMarginCriterion creates a criterion that optimizes a multi-class multi-classification hinge loss (margin-based loss) between input x and output y   Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor._\nval multiLabelMarginCriterion = MultiLabelMarginCriterion(false)\nval input = Tensor(4).rand()\nval target = Tensor(4)\ntarget(Array(1)) = 3\ntarget(Array(2)) = 2\ntarget(Array(3)) = 1\ntarget(Array(4)) = 0  print(input)\n0.40267515\n0.5913795\n0.84936756\n0.05999674   print(multiLabelMarginCriterion.forward(input, target))\n0.33414197  print(multiLabelMarginCriterion.backward(input, target))\n-0.25\n-0.25\n-0.25\n0.75\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 4]  Python example:  from bigdl.nn.layer import *\nmultiLabelMarginCriterion = MultiLabelMarginCriterion(False)  multiLabelMarginCriterion.forward(np.array([0.3, 0.4, 0.2, 0.6]), np.array([3, 2, 1, 0]))\n0.975  multiLabelMarginCriterion.backward(np.array([0.3, 0.4, 0.2, 0.6]), np.array([3, 2, 1, 0]))\n[array([-0.25, -0.25, -0.25,  0.75], dtype=float32)]", 
            "title": "MultiLabelMarginCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#multilabelsoftmargincriterion", 
            "text": "Scala:  val criterion = MultiLabelSoftMarginCriterion(weights = null, sizeAverage = true)  Python:  criterion = MultiLabelSoftMarginCriterion(weights=None, size_average=True)  MultiLabelSoftMarginCriterion is a multiLabel multiclass criterion based on sigmoid:  l(x,y) = - sum_i y[i] * log(p[i]) + (1 - y[i]) * log (1 - p[i])  where  p[i] = exp(x[i]) / (1 + exp(x[i]))  If with weights,\n  l(x,y) = - sum_i weights[i] (y[i] * log(p[i]) + (1 - y[i]) * log (1 - p[i]))  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = MultiLabelSoftMarginCriterion()\nval input = Tensor(3)\ninput(Array(1)) = 0.4f\ninput(Array(2)) = 0.5f\ninput(Array(3)) = 0.6f\nval target = Tensor(3)\ntarget(Array(1)) = 0\ntarget(Array(2)) = 1\ntarget(Array(3)) = 1  criterion.forward(input, target)\nres0: Float = 0.6081934  Python example:  from bigdl.nn.criterion import *\nimport numpy as np\n\ncriterion = MultiLabelSoftMarginCriterion()\ninput = np.array([0.4, 0.5, 0.6])\ntarget = np.array([0, 1, 1])  criterion.forward(input, target)\n0.6081934", 
            "title": "MultiLabelSoftMarginCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#abscriterion", 
            "text": "Scala:  val criterion = AbsCriterion(sizeAverage)  Python:  criterion = AbsCriterion(sizeAverage)  Measures the mean absolute value of the element-wise difference between input and target  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.utils.T\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = AbsCriterion()\nval input = Tensor(T(1.0f, 2.0f, 3.0f))\nval target = Tensor(T(4.0f, 5.0f, 6.0f))\nval output = criterion.forward(input, target)\n\nscala  print(output)\n3.0  Python example:  criterion = AbsCriterion()\ninput = np.array([1.0, 2.0, 3.0])\ntarget = np.array([4.0, 5.0, 6.0])\noutput=criterion.forward(input, target)  print output\n3.0", 
            "title": "AbsCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#multicriterion", 
            "text": "Scala:  val criterion = MultiCriterion()  Python:  criterion = MultiCriterion()  MultiCriterion is a weighted sum of other criterions each applied to the same input and target  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = MultiCriterion()\nval nll = ClassNLLCriterion()\nval mse = MSECriterion()\ncriterion.add(nll, 0.5)\ncriterion.add(mse)\n\nval input = Tensor(5).randn()\nval target = Tensor(5)\ntarget(Array(1)) = 1\ntarget(Array(2)) = 2\ntarget(Array(3)) = 3\ntarget(Array(4)) = 2\ntarget(Array(5)) = 1\n\nval output = criterion.forward(input, target)  input\n1.0641425\n-0.33507252\n1.2345984\n0.08065767\n0.531199\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 5]  output\nres7: Float = 1.9633228  Python example:  from bigdl.nn.criterion import *\nimport numpy as np\n\ncriterion = MultiCriterion()\nnll = ClassNLLCriterion()\nmse = MSECriterion()\ncriterion.add(nll, 0.5)\ncriterion.add(mse)\n\ninput = np.array([0.9682213801388531,\n0.35258855644097503,\n0.04584479998452568,\n-0.21781499692588918,\n-1.02721844006879])\ntarget = np.array([1, 2, 3, 2, 1])\n\noutput = criterion.forward(input, target)  output\n3.6099546", 
            "title": "MultiCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#gaussiancriterion", 
            "text": "Scala:  val criterion = GaussianCriterion()  Python:  criterion = GaussianCriterion()  GaussianCriterion computes the log-likelihood of a sample given a Gaussian distribution.  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.GaussianCriterion\nimport com.intel.analytics.bigdl.utils.T\n\nval criterion = GaussianCriterion()\n\nval input1 = Tensor[Float](2, 3).range(1, 6, 1)\nval input2 = Tensor[Float](2, 3).range(1, 12, 2)\nval input = T(input1, input2)\n\nval target = Tensor[Float](2, 3).range(2, 13, 2)\n\nval loss = criterion.forward(input, target)  loss\nloss: Float = 23.836603  Python example:  import numpy as np\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ncriterion = GaussianCriterion()\n\ninput1 = np.arange(1, 7, 1).astype( float32 )\ninput2 = np.arange(1, 12, 2).astype( float32 )\ninput1 = input1.reshape(2, 3)\ninput2 = input2.reshape(2, 3)\ninput = [input1, input2]\n\ntarget = np.arange(2, 13, 2).astype( float32 )\ntarget = target.reshape(2, 3)\n\nloss = criterion.forward(input, target)  output\n23.836603", 
            "title": "GaussianCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#kldcriterion", 
            "text": "Scala:  val criterion = KLDCriterion()  Python:  criterion = KLDCriterion()  Computes the KL-divergence of the input normal distribution to a standard normal distribution.\nThe input has to be a table. The first element of input is the mean of the distribution,\nthe second element of input is the log_variance of the distribution. The input distribution is\nassumed to be diagonal.  The mean and log_variance are both assumed to be two dimensional tensors. The first dimension are\ninterpreted as batch. The output is the average/sum of each observation  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.KLDCriterion\nimport com.intel.analytics.bigdl.utils.T\n\nval criterion = KLDCriterion()\n\nval input1 = Tensor[Float](2, 3).range(1, 6, 1)\nval input2 = Tensor[Float](2, 3).range(1, 12, 2)\nval input = T(input1, input2)\n\nval target = Tensor[Float](2, 3).range(2, 13, 2)\n\nval loss = criterion.forward(input, target)  loss\nloss: Float = 34647.04  Python example:  import numpy as np\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ncriterion = KLDCriterion()\n\ninput1 = np.arange(1, 7, 1).astype( float32 )\ninput2 = np.arange(1, 12, 2).astype( float32 )\ninput1 = input1.reshape(2, 3)\ninput2 = input2.reshape(2, 3)\ninput = [input1, input2]\n\ntarget = np.arange(2, 13, 2).astype( float32 )\ntarget = target.reshape(2, 3)\n\nloss = criterion.forward(input, target)  loss\n34647.04", 
            "title": "KLDCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#cosineproximitycriterion", 
            "text": "Scala:  val criterion = CosineProximityCriterion()  Python:  criterion = CosineProximityCriterion()  Computes the negative of the mean cosine proximity between predictions and targets.  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.CosineProximityCriterion\n\nval criterion = CosineProximityCriterion()\n\nval input = Tensor[Float](2, 3).rand()\n\nval target = Tensor[Float](2, 3).rand()\n\nval loss = criterion.forward(input, target)  loss\nloss: Float = -0.28007346  Python example:  import numpy as np\nfrom bigdl.nn.criterion import *\n\ncriterion = CosineProximityCriterion()\n\ninput = np.arange(1, 7, 1).astype( float32 )\ninput = input.reshape(2, 3)\ntarget = np.arange(2, 13, 2).astype( float32 )\ntarget = target.reshape(2, 3)\n\nloss = criterion.forward(input, target)  loss\n-0.3333333", 
            "title": "CosineProximityCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#meansquaredlogarithmiccriterion", 
            "text": "Scala:  val criterion = MeanSquaredLogarithmicCriterion()  Python:  criterion = MeanSquaredLogarithmicCriterion()  compute mean squared logarithmic error for input and target  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.MeanSquaredLogarithmicCriterion\nimport com.intel.analytics.bigdl.utils.T\n\nval criterion = MeanSquaredLogarithmicCriterion()\nval input = Tensor[Float](2, 3).range(1, 6, 1)\nval target = Tensor[Float](2, 3).range(2, 13, 2)\nval loss = criterion.forward(input, target)  loss\nloss: Float = 0.30576965  Python example:  import numpy as np\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ncriterion = MeanSquaredLogarithmicCriterion()\n\ninput = np.arange(1, 7, 1).astype( float32 )\ninput = input.reshape(2, 3)\ntarget = np.arange(2, 13, 2).astype( float32 )\ntarget = target.reshape(2, 3)\n\nloss = criterion.forward(input, target)  loss\n0.30576965", 
            "title": "MeanSquaredLogarithmicCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#meanabsolutepercentagecriterion", 
            "text": "Scala:  val criterion = MeanAbsolutePercentageCriterion()  Python:  criterion = MeanAbsolutePercentageCriterion()  compute mean absolute percentage error for intput and target  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.MeanAbsolutePercentageCriterion\nimport com.intel.analytics.bigdl.utils.T\n\nval criterion = MeanAbsolutePercentageCriterion()\n\nval input = Tensor[Float](2, 3).range(1, 6, 1)\nval target = Tensor[Float](2, 3).range(2, 13, 2)\nval loss = criterion.forward(input, target)  loss\nloss: Float = 50.0  Python example:  import numpy as np\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ncriterion = MeanAbsolutePercentageCriterion()\n\ninput = np.arange(1, 7, 1).astype( float32 )\ninput = input.reshape(2, 3)\ntarget = np.arange(2, 13, 2).astype( float32 )\ntarget = target.reshape(2, 3)\n\nloss = criterion.forward(input, target)  loss\n50.0", 
            "title": "MeanAbsolutePercentageCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#kullbackleiblerdivergencecriterion", 
            "text": "Scala:  val criterion = KullbackLeiblerDivergenceCriterion()  Python:  criterion = KullbackLeiblerDivergenceCriterion()  compute Kullback Leibler Divergence Criterion error for intput and target  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.KullbackLeiblerDivergenceCriterion\nimport com.intel.analytics.bigdl.utils.T\n\nval criterion = KullbackLeiblerDivergenceCriterion[Float]()\nval input = Tensor[Float](Array(0.1f, 0.2f, 0.3f, 0.4f, 0.5f, 0.6f), Array(2, 3))\nval target = Tensor[Float](Array(0.6f, 0.5f, 0.4f, 0.3f, 0.2f, 0.1f), Array(2, 3))\nval loss = criterion.forward(input, target)  loss\nloss: Float = 0.59976757  Python example:  import numpy as np\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ncriterion = KullbackLeiblerDivergenceCriterion()\n\ny_pred = np.matrix('0.1 0.2 0.3; 0.4 0.5 0.6')\ny_true = np.matrix('0.6 0.5 0.4; 0.3 0.2 0.1')\n\nloss = criterion.forward(y_pred, y_true)  loss\n0.59976757", 
            "title": "KullbackLeiblerDivergenceCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#poissoncriterion", 
            "text": "Scala:  val criterion = PoissonCriterion()  Python:  criterion = PoissonCriterion()  compute Poisson error for intput and target  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.PoissonCriterion\nimport com.intel.analytics.bigdl.utils.T\n\nval criterion = PoissonCriterion()\nval input = Tensor[Float](2, 3).range(1, 6, 1)\nval target = Tensor[Float](2, 3).range(2, 13, 2)\nval loss = criterion.forward(input, target)  loss\nloss = -6.1750183  Python example:  import numpy as np\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ncriterion = PoissonCriterion()\ninput = np.arange(1, 7, 1).astype( float32 )\ninput = input.reshape(2, 3)\ntarget = np.arange(2, 13, 2).astype( float32 )\ntarget = target.reshape(2, 3)\n\nloss = criterion.forward(input, target)  loss\n-6.1750183", 
            "title": "PoissonCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#transformercriterion", 
            "text": "Scala:  val criterion = TransformerCriterion(criterion, Some(inputTransformer), Some(targetTransformer))  Python:  criterion = TransformerCriterion(criterion, input_transformer, targetTransformer)  The criterion that takes two modules (optional) to transform input and target, and take\none criterion to compute the loss with the transformed input and target.  This criterion can be used to construct complex criterion. For example, the inputTransformer  and  targetTransformer  can be pre-trained CNN networks,\nand we can use the networks' output to compute the high-level feature\nreconstruction loss, which is commonly used in areas like neural style transfer\n(https://arxiv.org/abs/1508.06576), texture synthesis (https://arxiv.org/abs/1505.07376),\n.etc.  Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.TransformerCriterion\nimport com.intel.analytics.bigdl.utils.T\n\nval criterion = MSECriterion()\nval input = Tensor[Float](2, 3).range(1, 6, 1)\nval target = Tensor[Float](2, 3).range(2, 13, 2)\nval inputTransformer = Identity()\nval targetTransformer = Identity()\nval transCriterion = TransformerCriterion(criterion,\n     Some(inputTransformer), Some(targetTransformer))\nval loss = transCriterion.forward(input, target)  loss\n15.166667  Python example:  import numpy as np\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ncriterion = MSECriterion()\ninput = np.arange(1, 7, 1).astype( float32 )\ninput = input.reshape(2, 3)\ntarget = np.arange(2, 13, 2).astype( float32 )\ntarget = target.reshape(2, 3)\n\ninputTransformer = Identity()\ntargetTransformer = Identity()\ntransCriterion = TransformerCriterion(criterion, inputTransformer, targetTransformer)\nloss = transCriterion.forward(input, target)  loss\n15.166667", 
            "title": "TransformerCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#dotproductcriterion", 
            "text": "Scala:  val criterion = DotProductCriterion(sizeAverage=false)  Python:  criterion = DotProductCriterion(sizeAverage=False)  Compute the dot product of input and target tensor.\nInput and target are required to have the same size.   sizeAverage:  whether to average over each observations in the same batch   Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = DotProductCriterion()\nval input = Tensor[Float](2, 3).range(1, 6, 1)\nval target = Tensor[Float](2, 3).range(2, 13, 2)\n\nval loss = criterion.forward(input, target)  loss\n182.0  Python example:  import numpy as np\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ncriterion = DotProductCriterion()\ninput = np.arange(1, 7, 1).astype( float32 )\ninput = input.reshape(2, 3)\ntarget = np.arange(2, 13, 2).astype( float32 )\ntarget = target.reshape(2, 3)\n\nloss = criterion.forward(input, target)  loss\n182.0", 
            "title": "DotProductCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#pgcriterion", 
            "text": "Scala:  val criterion = PGCriterion(sizeAverage=false)  Python:  criterion = PGCriterion(sizeAverage=False)  The Criterion to compute the negative policy gradient given a\nmultinomial distribution and the sampled action and reward.  The input to this criterion should be a 2-D tensor representing\na batch of multinomial distribution, the target should also be\na 2-D tensor with the same size of input, representing the sampled\naction and reward/advantage with the index of non-zero element in the vector\nrepresents the sampled action and the non-zero element itself represents\nthe reward. If the action is space is large, you should consider using\nSparseTensor for target.  The loss computed is simple the standard policy gradient,  loss = - 1/n * sum(R_{n} dot_product log(P_{n}))  where R_{n} is the reward vector, and P_{n} is the input distribution.   sizeAverage:  whether to average over each observations in the same batch   Scala example:  import com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval criterion = PGCriterion()\nval input = Tensor[Float](2, 3).range(1, 6, 1)\nval target = Tensor[Float](2, 3).range(2, 13, 2)\n\nval loss = criterion.forward(input, target)  loss\n-58.05011  Python example:  import numpy as np\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ncriterion = PGCriterion()\ninput = np.arange(1, 7, 1).astype( float32 )\ninput = input.reshape(2, 3)\ntarget = np.arange(2, 13, 2).astype( float32 )\ntarget = target.reshape(2, 3)\n\nloss = criterion.forward(input, target)  loss\n-58.05011", 
            "title": "PGCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#cosinedistancecriterion", 
            "text": "Scala:  val criterion = CosineDistanceCriterion()  Python:  criterion = CosineDistanceCriterion(size_average = True)  This loss function measures the Cosine Distance between the target and the output   loss(o, t) = 1 - cos(o, t)  By default, the losses are averaged for each mini-batch over observations as well as over\n dimensions. However, if the field sizeAverage is set to false, the losses are instead summed.  Scala example:  import com.intel.analytics.bigdl.numeric.NumericFloat\n\nval criterion = CosineDistanceCriterion()\nval input = Tensor(1, 5).rand\nval target = Tensor(1, 5).rand\nval loss = criterion.forward(input, target)  println(target)\ntarget: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.95363826  0.3175587   0.90366143  0.10316128  0.05317958\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5]  println(input)\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.5895327   0.20547494  0.43118918  0.28824696  0.032088008\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5]  println(loss)\nloss: Float = 0.048458755  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ncriterion = CosineDistanceCriterion(size_average = True)\ninput = np.random.uniform(0, 1, (1, 5)).astype( float32 )\ntarget = np.random.uniform(0, 1, (1, 5)).astype( float32 )\nloss = criterion.forward(input, target)  input\narray([[ 0.34291017,  0.95894575,  0.23869193,  0.42518589,  0.73902631]], dtype=float32)  target \narray([[ 0.00489056,  0.7253111 ,  0.94344038,  0.69811821,  0.45532107]], dtype=float32)  loss\n0.20651573", 
            "title": "CosineDistanceCriterion"
        }, 
        {
            "location": "/APIGuide/Losses/#categoricalcrossentropy", 
            "text": "Scala:  val criterion = CategoricalCrossEntropy()  Python:  criterion = CategoricalCrossEntropy()  This is same with cross entropy criterion, except the target tensor is a\none-hot tensor.  Scala example:  import com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval criterion = CategoricalCrossEntropy()\nval input = Tensor(1, 5).rand()\nval target = Tensor(1, 5).zero().setValue(1, 3, 1)\nval loss = criterion.forward(input, target)  println(target)\ntarget: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.0     0.0     1.0     0.0     0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5]  println(input)\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.95245546      0.8304343       0.8296352       0.13989972      0.17466335\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x5]  println(loss)\nloss: Float = 1.2607772  Python example:  import numpy as np\nfrom bigdl.nn.criterion import *\n\ncriterion = CategoricalCrossEntropy()\ninput = np.random.uniform(0, 1, (1, 5)).astype( float32 )\ntarget = np.zeros((1, 5)).astype( float32 )\ntarget[0, 2] = 1\nloss = criterion.forward(input, target)  input\narray([[ 0.31309742,  0.75959802,  0.01649681,  0.65792692,  0.21528937]], dtype=float32)  target \narray([[ 0.,  0.,  1.,  0.,  0.]], dtype=float32)  loss\n4.7787604", 
            "title": "CategoricalCrossEntropy"
        }, 
        {
            "location": "/APIGuide/Initializers/", 
            "text": "Zeros\n\n\nScala:\n\n\nval initMethod = Zeros\n\n\n\n\n\nPython:\n\n\ninit_method = Zeros()\n\n\n\n\nInitialization method that set tensor to zeros.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval weightInitMethod = Zeros\nval biasInitMethod = Zeros\nval model = Linear(3, 2).setName(\nlinear1\n)\nmodel.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(model.getParametersTable().get(\nlinear1\n).get)\n\n\n\n\n\n {\n    weight: 0.0 0.0 0.0 \n            0.0 0.0 0.0 \n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    bias: 0.0\n          0.0\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradBias: 0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradWeight: 0.0 0.0 0.0 \n                0.0 0.0 0.0 \n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n }\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.initialization_method import *\nweight_init = Zeros()\nbias_init = Zeros()\nmodel = Linear(3, 2)\nmodel.set_init_method(weight_init, bias_init)\nprint(\nweight:\n)\nprint(model.get_weights()[0])\nprint(\nbias: \n)\nprint(model.get_weights()[1])\n\n\n\n\ncreating: createZeros\ncreating: createZeros\ncreating: createLinear\nweight:\n[[ 0.  0.  0.]\n [ 0.  0.  0.]]\nbias: \n[ 0.  0.]\n\n\n\n\n\n\nOnes\n\n\nScala:\n\n\nval initMethod = Ones\n\n\n\n\n\nPython:\n\n\ninit_method = Ones()\n\n\n\n\nInitialization method that set tensor to be ones.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval weightInitMethod = Ones\nval biasInitMethod = Ones\nval model = Linear(3, 2).setName(\nlinear1\n)\nmodel.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(model.getParametersTable().get(\nlinear1\n).get)\n\n\n\n\n {\n    weight: 1.0 1.0 1.0 \n            1.0 1.0 1.0 \n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    bias: 1.0\n          1.0\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradBias: 0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradWeight: 0.0 0.0 0.0 \n                0.0 0.0 0.0 \n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n }\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.initialization_method import *\nweight_init = Ones()\nbias_init = Ones()\nmodel = Linear(3, 2)\nmodel.set_init_method(weight_init, bias_init)\nprint(\nweight:\n)\nprint(model.get_weights()[0])\nprint(\nbias: \n)\nprint(model.get_weights()[1])\n\n\n\n\ncreating: createOnes\ncreating: createOnes\ncreating: createLinear\nweight:\n[[ 1.  1.  1.]\n [ 1.  1.  1.]]\nbias: \n[ 1.  1.]\n\n\n\n\n\nConstInitMethod\n\n\nScala:\n\n\nval initMethod = ConstInitMethod(value: Double)\n\n\n\n\n\nPython:\n\n\ninit_method = ConstInitMethod(value)\n\n\n\n\nInitialization method that set tensor to the specified constant value.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\n\nval weightInitMethod = ConstInitMethod(0.2)\nval biasInitMethod = ConstInitMethod(0.2)\nval linear = Linear(3, 2).setName(\nlinear1\n)\nlinear.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(linear.getParametersTable().get(\nlinear1\n).get)\n\n\n\n\n {\n    weight: 0.2 0.2 0.2\n            0.2 0.2 0.2\n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    bias: 0.2\n          0.2\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradBias: 0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradWeight: 0.0 0.0 0.0\n                0.0 0.0 0.0\n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n }\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.initialization_method import *\nweight_init = ConstInitMethod(0.2)\nbias_init = ConstInitMethod(0.2)\nlinear = Linear(3, 2)\nlinear.set_init_method(weight_init, bias_init)\nprint(\nweight:\n)\nprint(linear.get_weights()[0])\nprint(\nbias: \n)\nprint(linear.get_weights()[1])\n\n\n\n\ncreating: createConstInitMethod\ncreating: createConstInitMethod\ncreating: createLinear\nweight:\n[[ 0.2  0.2  0.2]\n [ 0.2  0.2  0.2]]\nbias:\n[ 0.2  0.2]\n\n\n\n\n\nXavier\n\n\nScala:\n\n\nval initMethod = Xavier\n\n\n\n\n\nPython:\n\n\ninit_method = Xavier()\n\n\n\n\nThe Xavier initialization method draws samples from a uniform distribution\nbounded by [-limit, limit) where limit = sqrt(6.0/(fanIn+fanOut)). The rationale\nbehind this formula can be found in the paper\n\nUnderstanding the difficulty of training deep feedforward neural networks\n.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval weightInitMethod = Xavier\nval biasInitMethod = Xavier\nval model = Linear(3, 2).setName(\nlinear1\n)\nmodel.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(model.getParametersTable().get(\nlinear1\n).get)\n\n\n\n\n {\n    weight: -0.78095555 -0.09939616 0.12034761  \n            -0.3019594  0.11734331  0.80369484  \n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    bias: 1.0727772\n          -0.6703765\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradBias: 0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradWeight: 0.0 0.0 0.0 \n                0.0 0.0 0.0 \n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n }\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.initialization_method import *\nweight_init = Xavier()\nbias_init = Xavier()\nmodel = Linear(3, 2)\nmodel.set_init_method(weight_init, bias_init)\nprint(\nweight:\n)\nprint(model.get_weights()[0])\nprint(\nbias: \n)\nprint(model.get_weights()[1])\n\n\n\n\ncreating: createXavier\ncreating: createXavier\ncreating: createLinear\nweight:\n[[ 0.00580597 -0.73662472  0.13767919]\n [ 0.16802482 -0.49394709 -0.74967551]]\nbias: \n[-1.12355328  0.0779365 ]\n\n\n\n\nBilinearFiller\n\n\nScala:\n\n\nval initMethod = BilinearFiller\n\n\n\n\n\nPython:\n\n\ninit_method = BilinearFiller()\n\n\n\n\nInitialize the weight with coefficients for bilinear interpolation. A common use case is with the DeconvolutionLayer acting as upsampling. This initialization method can only be used in the weight initialization of SpatialFullConvolution.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval weightInitMethod = BilinearFiller\nval biasInitMethod - Zeros\nval model = SpatialFullConvolution(2, 3, 2, 2).setName(\nsfconv\n)\nmodel.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(model.getParametersTable().get(\nsfconv\n).get)\n\n\n\n\n{\n    weight: (1,1,1,.,.) =\n            1.0 0.0 \n            0.0 0.0 \n\n            (1,1,2,.,.) =\n            1.0 0.0 \n            0.0 0.0 \n\n            (1,1,3,.,.) =\n            1.0 0.0 \n            0.0 0.0 \n\n            (1,2,1,.,.) =\n            1.0 0.0 \n            0.0 0.0 \n\n            (1,2,2,.,.) =\n            1.0 0.0 \n            0.0 0.0 \n\n            (1,2,3,.,.) =\n            1.0 0.0 \n            0.0 0.0 \n\n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x3x2x2]\n    bias: 0.0\n          0.0\n          0.0\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n    gradBias: 0.0\n              0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n    gradWeight: (1,1,1,.,.) =\n                0.0 0.0 \n                0.0 0.0 \n\n                (1,1,2,.,.) =\n                0.0 0.0 \n                0.0 0.0 \n\n                (1,1,3,.,.) =\n                0.0 0.0 \n                0.0 0.0 \n\n                (1,2,1,.,.) =\n                0.0 0.0 \n                0.0 0.0 \n\n                (1,2,2,.,.) =\n                0.0 0.0 \n                0.0 0.0 \n\n                (1,2,3,.,.) =\n                0.0 0.0 \n                0.0 0.0 \n\n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x3x2x2]\n }\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.initialization_method import *\nweight_init = BilinearFiller()\nbias_init = Zeros()\nmodel =  SpatialFullConvolution(2, 3, 2, 2)\nmodel.set_init_method(weight_init, bias_init)\nprint(\nweight:\n)\nprint(model.get_weights()[0])\nprint(\nbias: \n)\nprint(model.get_weights()[1])\n\n\n\n\ncreating: createBilinearFiller\ncreating: createZeros\ncreating: createSpatialFullConvolution\nweight:\n[[[[[ 1.  0.]\n    [ 0.  0.]]\n\n   [[ 1.  0.]\n    [ 0.  0.]]\n\n   [[ 1.  0.]\n    [ 0.  0.]]]\n\n\n  [[[ 1.  0.]\n    [ 0.  0.]]\n\n   [[ 1.  0.]\n    [ 0.  0.]]\n\n   [[ 1.  0.]\n    [ 0.  0.]]]]]\nbias: \n[ 0.  0.  0.]\n\n\n\n\n\n\nRandomNormal\n\n\nScala:\n\n\nval initMethod = RandomNormal(mean, stdv)\n\n\n\n\n\nPython:\n\n\ninit_method = RandomNormal(mean, stdv)\n\n\n\n\nThis initialization method draws samples from a normal distribution.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval weightInitMethod = RandomNormal(0, 1)\nval biasInitMethod = RandomNormal(0, 1)\nval linear = Linear(3, 2).setName(\nlinear1\n)\nlinear.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(linear.getParametersTable().get(\nlinear1\n).get)\n\n\n\n\n {\n    weight: -0.5908564  0.32844943  -0.845019   \n            0.21550806  1.2037253   0.6807024   \n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    bias: 0.5345903\n          -0.76420456\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradBias: 0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradWeight: 0.0 0.0 0.0 \n                0.0 0.0 0.0 \n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n  }\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.initialization_method import *\nfrom bigdl.nn.layer import *\n\nweight_init = RandomNormal(0, 1)\nbias_init = RandomNormal(0, 1)\nlinear= Linear(3, 2)\nlinear.set_init_method(weight_init, bias_init)\nprint(\nweight:\n)\nprint(linear.get_weights()[0])\nprint(\nbias: \n)\nprint(linear.get_weights()[1])\n\n\n\n\ncreating: createRandomNormal\ncreating: createRandomNormal\ncreating: createLinear\nweight:\n[[-0.00784962  0.77845585 -1.16250944]\n [ 0.03195094 -0.15211993  0.6254822 ]]\nbias: \n[-0.37883148 -0.81106091]\n\n\n\n\n\nRandomUniform\n\n\nScala:\n\n\nval initMethod = RandomUniform(lower, upper)\n\n\n\n\n\nPython:\n\n\ninit_method = RandomUniform(upper=None, lower=None)\n\n\n\n\nThis initialization method draws samples from a uniform distribution. If the lower bound and upper bound of this uniform distribution is not specified, it will be set to [-limit, limit) where limit = 1/sqrt(fanIn).\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval weightInitMethod = RandomUniform\nval biasInitMethod = RandomUniform(0, 1)\nval model = Linear(3, 2).setName(\nlinear1\n)\nmodel.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(model.getParametersTable().get(\nlinear1\n).get)\n\n\n\n\n {\n    weight: -0.572536   0.13046022  -0.040449623    \n            -0.547542   0.19093458  0.5632484   \n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    bias: 0.785292\n          0.63280666\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradBias: 0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradWeight: 0.0 0.0 0.0 \n                0.0 0.0 0.0 \n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n }\n\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.initialization_method import *\nweight_init = RandomUniform()\nbias_init = RandomUniform()\nmodel = Linear(3, 2)\nmodel.set_init_method(weight_init, bias_init)\nprint(\nweight:\n)\nprint(model.get_weights()[0])\nprint(\nbias: \n)\nprint(model.get_weights()[1])\n\n\n\n\ncreating: createRandomUniform\ncreating: createRandomUniform\ncreating: createLinear\nweight:\n[[ 0.53153235  0.53016287  0.32831791]\n [-0.45736417 -0.16206641  0.21758588]]\nbias: \n[ 0.32058391  0.26307678]\n\n\n\n\n\nDefine your own Initializer\n\n\nAll customizedInitializer should implement the \nInitializationMethod\n trait\n\n\n/**\n * Initialization method to initialize bias and weight.\n * The init method will be called in Module.reset()\n */\n\ntrait InitializationMethod {\n\n  type Shape = Array[Int]\n\n  /**\n   * Initialize the given variable\n   *\n   * @param variable    the variable to initialize\n   * @param dataFormat  describe the meaning of each dimension of the variable\n   */\n  def init[T](variable: Tensor[T], dataFormat: VariableFormat)\n             (implicit ev: TensorNumeric[T]): Unit\n}\n\n\n\n\nThe \nRandomUniform\n\ncode should give you a good sense of how to implement this trait.\n\n\n_\nPython\n\nCustom initialization method in python is not supported right now.", 
            "title": "Initalizers"
        }, 
        {
            "location": "/APIGuide/Initializers/#zeros", 
            "text": "Scala:  val initMethod = Zeros  Python:  init_method = Zeros()  Initialization method that set tensor to zeros.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval weightInitMethod = Zeros\nval biasInitMethod = Zeros\nval model = Linear(3, 2).setName( linear1 )\nmodel.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(model.getParametersTable().get( linear1 ).get)  \n {\n    weight: 0.0 0.0 0.0 \n            0.0 0.0 0.0 \n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    bias: 0.0\n          0.0\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradBias: 0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradWeight: 0.0 0.0 0.0 \n                0.0 0.0 0.0 \n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n }  Python example:  from bigdl.nn.initialization_method import *\nweight_init = Zeros()\nbias_init = Zeros()\nmodel = Linear(3, 2)\nmodel.set_init_method(weight_init, bias_init)\nprint( weight: )\nprint(model.get_weights()[0])\nprint( bias:  )\nprint(model.get_weights()[1])  creating: createZeros\ncreating: createZeros\ncreating: createLinear\nweight:\n[[ 0.  0.  0.]\n [ 0.  0.  0.]]\nbias: \n[ 0.  0.]", 
            "title": "Zeros"
        }, 
        {
            "location": "/APIGuide/Initializers/#ones", 
            "text": "Scala:  val initMethod = Ones  Python:  init_method = Ones()  Initialization method that set tensor to be ones.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval weightInitMethod = Ones\nval biasInitMethod = Ones\nval model = Linear(3, 2).setName( linear1 )\nmodel.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(model.getParametersTable().get( linear1 ).get)   {\n    weight: 1.0 1.0 1.0 \n            1.0 1.0 1.0 \n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    bias: 1.0\n          1.0\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradBias: 0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradWeight: 0.0 0.0 0.0 \n                0.0 0.0 0.0 \n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n }  Python example:  from bigdl.nn.initialization_method import *\nweight_init = Ones()\nbias_init = Ones()\nmodel = Linear(3, 2)\nmodel.set_init_method(weight_init, bias_init)\nprint( weight: )\nprint(model.get_weights()[0])\nprint( bias:  )\nprint(model.get_weights()[1])  creating: createOnes\ncreating: createOnes\ncreating: createLinear\nweight:\n[[ 1.  1.  1.]\n [ 1.  1.  1.]]\nbias: \n[ 1.  1.]", 
            "title": "Ones"
        }, 
        {
            "location": "/APIGuide/Initializers/#constinitmethod", 
            "text": "Scala:  val initMethod = ConstInitMethod(value: Double)  Python:  init_method = ConstInitMethod(value)  Initialization method that set tensor to the specified constant value.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\n\nval weightInitMethod = ConstInitMethod(0.2)\nval biasInitMethod = ConstInitMethod(0.2)\nval linear = Linear(3, 2).setName( linear1 )\nlinear.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(linear.getParametersTable().get( linear1 ).get)   {\n    weight: 0.2 0.2 0.2\n            0.2 0.2 0.2\n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    bias: 0.2\n          0.2\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradBias: 0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradWeight: 0.0 0.0 0.0\n                0.0 0.0 0.0\n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n }  Python example:  from bigdl.nn.initialization_method import *\nweight_init = ConstInitMethod(0.2)\nbias_init = ConstInitMethod(0.2)\nlinear = Linear(3, 2)\nlinear.set_init_method(weight_init, bias_init)\nprint( weight: )\nprint(linear.get_weights()[0])\nprint( bias:  )\nprint(linear.get_weights()[1])  creating: createConstInitMethod\ncreating: createConstInitMethod\ncreating: createLinear\nweight:\n[[ 0.2  0.2  0.2]\n [ 0.2  0.2  0.2]]\nbias:\n[ 0.2  0.2]", 
            "title": "ConstInitMethod"
        }, 
        {
            "location": "/APIGuide/Initializers/#xavier", 
            "text": "Scala:  val initMethod = Xavier  Python:  init_method = Xavier()  The Xavier initialization method draws samples from a uniform distribution\nbounded by [-limit, limit) where limit = sqrt(6.0/(fanIn+fanOut)). The rationale\nbehind this formula can be found in the paper Understanding the difficulty of training deep feedforward neural networks .  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval weightInitMethod = Xavier\nval biasInitMethod = Xavier\nval model = Linear(3, 2).setName( linear1 )\nmodel.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(model.getParametersTable().get( linear1 ).get)   {\n    weight: -0.78095555 -0.09939616 0.12034761  \n            -0.3019594  0.11734331  0.80369484  \n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    bias: 1.0727772\n          -0.6703765\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradBias: 0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradWeight: 0.0 0.0 0.0 \n                0.0 0.0 0.0 \n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n }  Python example:  from bigdl.nn.initialization_method import *\nweight_init = Xavier()\nbias_init = Xavier()\nmodel = Linear(3, 2)\nmodel.set_init_method(weight_init, bias_init)\nprint( weight: )\nprint(model.get_weights()[0])\nprint( bias:  )\nprint(model.get_weights()[1])  creating: createXavier\ncreating: createXavier\ncreating: createLinear\nweight:\n[[ 0.00580597 -0.73662472  0.13767919]\n [ 0.16802482 -0.49394709 -0.74967551]]\nbias: \n[-1.12355328  0.0779365 ]", 
            "title": "Xavier"
        }, 
        {
            "location": "/APIGuide/Initializers/#bilinearfiller", 
            "text": "Scala:  val initMethod = BilinearFiller  Python:  init_method = BilinearFiller()  Initialize the weight with coefficients for bilinear interpolation. A common use case is with the DeconvolutionLayer acting as upsampling. This initialization method can only be used in the weight initialization of SpatialFullConvolution.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval weightInitMethod = BilinearFiller\nval biasInitMethod - Zeros\nval model = SpatialFullConvolution(2, 3, 2, 2).setName( sfconv )\nmodel.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(model.getParametersTable().get( sfconv ).get)  {\n    weight: (1,1,1,.,.) =\n            1.0 0.0 \n            0.0 0.0 \n\n            (1,1,2,.,.) =\n            1.0 0.0 \n            0.0 0.0 \n\n            (1,1,3,.,.) =\n            1.0 0.0 \n            0.0 0.0 \n\n            (1,2,1,.,.) =\n            1.0 0.0 \n            0.0 0.0 \n\n            (1,2,2,.,.) =\n            1.0 0.0 \n            0.0 0.0 \n\n            (1,2,3,.,.) =\n            1.0 0.0 \n            0.0 0.0 \n\n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x3x2x2]\n    bias: 0.0\n          0.0\n          0.0\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n    gradBias: 0.0\n              0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 3]\n    gradWeight: (1,1,1,.,.) =\n                0.0 0.0 \n                0.0 0.0 \n\n                (1,1,2,.,.) =\n                0.0 0.0 \n                0.0 0.0 \n\n                (1,1,3,.,.) =\n                0.0 0.0 \n                0.0 0.0 \n\n                (1,2,1,.,.) =\n                0.0 0.0 \n                0.0 0.0 \n\n                (1,2,2,.,.) =\n                0.0 0.0 \n                0.0 0.0 \n\n                (1,2,3,.,.) =\n                0.0 0.0 \n                0.0 0.0 \n\n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x3x2x2]\n }  Python example:  from bigdl.nn.initialization_method import *\nweight_init = BilinearFiller()\nbias_init = Zeros()\nmodel =  SpatialFullConvolution(2, 3, 2, 2)\nmodel.set_init_method(weight_init, bias_init)\nprint( weight: )\nprint(model.get_weights()[0])\nprint( bias:  )\nprint(model.get_weights()[1])  creating: createBilinearFiller\ncreating: createZeros\ncreating: createSpatialFullConvolution\nweight:\n[[[[[ 1.  0.]\n    [ 0.  0.]]\n\n   [[ 1.  0.]\n    [ 0.  0.]]\n\n   [[ 1.  0.]\n    [ 0.  0.]]]\n\n\n  [[[ 1.  0.]\n    [ 0.  0.]]\n\n   [[ 1.  0.]\n    [ 0.  0.]]\n\n   [[ 1.  0.]\n    [ 0.  0.]]]]]\nbias: \n[ 0.  0.  0.]", 
            "title": "BilinearFiller"
        }, 
        {
            "location": "/APIGuide/Initializers/#randomnormal", 
            "text": "Scala:  val initMethod = RandomNormal(mean, stdv)  Python:  init_method = RandomNormal(mean, stdv)  This initialization method draws samples from a normal distribution.  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval weightInitMethod = RandomNormal(0, 1)\nval biasInitMethod = RandomNormal(0, 1)\nval linear = Linear(3, 2).setName( linear1 )\nlinear.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(linear.getParametersTable().get( linear1 ).get)   {\n    weight: -0.5908564  0.32844943  -0.845019   \n            0.21550806  1.2037253   0.6807024   \n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    bias: 0.5345903\n          -0.76420456\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradBias: 0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradWeight: 0.0 0.0 0.0 \n                0.0 0.0 0.0 \n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n  }  Python example:  from bigdl.nn.initialization_method import *\nfrom bigdl.nn.layer import *\n\nweight_init = RandomNormal(0, 1)\nbias_init = RandomNormal(0, 1)\nlinear= Linear(3, 2)\nlinear.set_init_method(weight_init, bias_init)\nprint( weight: )\nprint(linear.get_weights()[0])\nprint( bias:  )\nprint(linear.get_weights()[1])  creating: createRandomNormal\ncreating: createRandomNormal\ncreating: createLinear\nweight:\n[[-0.00784962  0.77845585 -1.16250944]\n [ 0.03195094 -0.15211993  0.6254822 ]]\nbias: \n[-0.37883148 -0.81106091]", 
            "title": "RandomNormal"
        }, 
        {
            "location": "/APIGuide/Initializers/#randomuniform", 
            "text": "Scala:  val initMethod = RandomUniform(lower, upper)  Python:  init_method = RandomUniform(upper=None, lower=None)  This initialization method draws samples from a uniform distribution. If the lower bound and upper bound of this uniform distribution is not specified, it will be set to [-limit, limit) where limit = 1/sqrt(fanIn).  Scala example:  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\n\nval weightInitMethod = RandomUniform\nval biasInitMethod = RandomUniform(0, 1)\nval model = Linear(3, 2).setName( linear1 )\nmodel.setInitMethod(weightInitMethod, biasInitMethod)\nprintln(model.getParametersTable().get( linear1 ).get)   {\n    weight: -0.572536   0.13046022  -0.040449623    \n            -0.547542   0.19093458  0.5632484   \n            [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n    bias: 0.785292\n          0.63280666\n          [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradBias: 0.0\n              0.0\n              [com.intel.analytics.bigdl.tensor.DenseTensor of size 2]\n    gradWeight: 0.0 0.0 0.0 \n                0.0 0.0 0.0 \n                [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n }  Python example:  from bigdl.nn.initialization_method import *\nweight_init = RandomUniform()\nbias_init = RandomUniform()\nmodel = Linear(3, 2)\nmodel.set_init_method(weight_init, bias_init)\nprint( weight: )\nprint(model.get_weights()[0])\nprint( bias:  )\nprint(model.get_weights()[1])  creating: createRandomUniform\ncreating: createRandomUniform\ncreating: createLinear\nweight:\n[[ 0.53153235  0.53016287  0.32831791]\n [-0.45736417 -0.16206641  0.21758588]]\nbias: \n[ 0.32058391  0.26307678]", 
            "title": "RandomUniform"
        }, 
        {
            "location": "/APIGuide/Initializers/#define-your-own-initializer", 
            "text": "All customizedInitializer should implement the  InitializationMethod  trait  /**\n * Initialization method to initialize bias and weight.\n * The init method will be called in Module.reset()\n */\n\ntrait InitializationMethod {\n\n  type Shape = Array[Int]\n\n  /**\n   * Initialize the given variable\n   *\n   * @param variable    the variable to initialize\n   * @param dataFormat  describe the meaning of each dimension of the variable\n   */\n  def init[T](variable: Tensor[T], dataFormat: VariableFormat)\n             (implicit ev: TensorNumeric[T]): Unit\n}  The  RandomUniform \ncode should give you a good sense of how to implement this trait.  _ Python \nCustom initialization method in python is not supported right now.", 
            "title": "Define your own Initializer"
        }, 
        {
            "location": "/APIGuide/Regularizers/", 
            "text": "L1 Regularizer\n\n\nScala:\n\n\nval l1Regularizer = L1Regularizer(rate)\n\n\n\n\nPython:\n\n\nregularizerl1 = L1Regularizer(rate)\n\n\n\n\nL1 regularizer is used to add penalty to the gradWeight to avoid overfitting.\n\n\nIn our code implementation, gradWeight = gradWeight + alpha * abs(weight)\n\n\nFor more details, please refer to \nwiki\n.\n\n\nScala example:\n\n\n\nimport com.intel.analytics.bigdl.utils.RandomGenerator.RNG\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\n\nRNG.setSeed(100)\n\nval input = Tensor(3, 5).rand\nval gradOutput = Tensor(3, 5).rand\nval linear = Linear(5, 5, wRegularizer = L1Regularizer(0.2), bRegularizer = L1Regularizer(0.2))\n\nval output = linear.forward(input)\nval gradInput = linear.backward(input, gradOutput)\n\nscala\n input\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.54340494      0.67115563      0.2783694       0.4120464       0.4245176\n0.52638245      0.84477615      0.14860484      0.004718862     0.15671109\n0.12156912      0.18646719      0.67074907      0.21010774      0.82585275\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x5]\n\nscala\n gradOutput\ngradOutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.4527399       0.13670659      0.87014264      0.5750933       0.063681036\n0.89132196      0.62431186      0.20920213      0.52334774      0.18532822\n0.5622963       0.10837689      0.0058171963    0.21969749      0.3074232\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x5]\n\nscala\n linear.gradWeight\nres2: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.9835552       1.3616763       0.83564335      0.108898684     0.59625006\n0.21608911      0.8393639       0.0035243928    -0.11795368     0.4453743\n0.38366735      0.9618148       0.47721142      0.5607486       0.6069793\n0.81469804      0.6690552       0.18522228      0.08559488      0.7075894\n-0.030468717    0.056625083     0.051471338     0.2917061       0.109963015\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5x5]\n\n\n\n\n\nPython example:\n\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ninput = np.random.uniform(0, 1, (3, 5)).astype(\nfloat32\n)\ngradOutput = np.random.uniform(0, 1, (3, 5)).astype(\nfloat32\n)\nlinear = Linear(5, 5, wRegularizer = L1Regularizer(0.2), bRegularizer = L1Regularizer(0.2))\noutput = linear.forward(input)\ngradInput = linear.backward(input, gradOutput)\n\n\n linear.parameters()\n{u'Linear@596d857b': {u'bias': array([ 0.3185505 , -0.02004393,  0.34620118, -0.09206461,  0.40776938], dtype=float32),\n  u'gradBias': array([ 2.14087653,  1.82181644,  1.90674937,  1.37307787,  0.81534696], dtype=float32),\n  u'gradWeight': array([[ 0.34909648,  0.85083449,  1.44904375,  0.90150446,  0.57136625],\n         [ 0.3745544 ,  0.42218602,  1.53656614,  1.1836741 ,  1.00702667],\n         [ 0.30529332,  0.26813674,  0.85559171,  0.61224306,  0.34721529],\n         [ 0.22859855,  0.8535381 ,  1.19809723,  1.37248564,  0.50041491],\n         [ 0.36197871,  0.03069445,  0.64837945,  0.12765063,  0.12872688]], dtype=float32),\n  u'weight': array([[-0.12423037,  0.35694697,  0.39038274, -0.34970999, -0.08283543],\n         [-0.4186025 , -0.33235055,  0.34948507,  0.39953214,  0.16294235],\n         [-0.25171402, -0.28955361, -0.32243955, -0.19771226, -0.29320192],\n         [-0.39263198,  0.37766701,  0.14673658,  0.24882999, -0.0779015 ],\n         [ 0.0323218 , -0.31266898,  0.31543773, -0.0898933 , -0.33485892]], dtype=float32)}}\n\n\n\n\nL2 Regularizer\n\n\nScala:\n\n\nval l2Regularizer = L2Regularizer(rate)\n\n\n\n\nPython:\n\n\nregularizerl2 = L2Regularizer(rate)\n\n\n\n\nL2 regularizer is used to add penalty to the gradWeight to avoid overfitting.\n\n\nIn our code implementation, gradWeight = gradWeight + alpha * weight * weight\n\n\nFor more details, please refer to \nwiki\n.\n\n\nScala example:\n\n\n\nimport com.intel.analytics.bigdl.utils.RandomGenerator.RNG\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\n\nRNG.setSeed(100)linear.updateParameters\n\nval input = Tensor(3, 5).rand\nval gradOutput = Tensor(3, 5).rand\nval linear = Linear(5, 5, wRegularizer = L2Regularizer(0.2), bRegularizer = L2Regularizer(0.2))\n\nval output = linear.forward(input)\nval gradInput = linear.backward(input, gradOutput)\n\nscala\n input\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.54340494      0.67115563      0.2783694       0.4120464       0.4245176\n0.52638245      0.84477615      0.14860484      0.004718862     0.15671109\n0.12156912      0.18646719      0.67074907      0.21010774      0.82585275\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x5]\n\nscala\n gradOutput\ngradOutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.4527399       0.13670659      0.87014264      0.5750933       0.063681036\n0.89132196      0.62431186      0.20920213      0.52334774      0.18532822\n0.5622963       0.10837689      0.0058171963    0.21969749      0.3074232\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x5]\n\nscala\n linear.gradWeight\nres0: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0329735       0.047239657     0.8979603       0.53614384      1.2781229\n0.5621818       0.29772854      0.69706535      0.30559152      0.8352279\n1.3044653       0.43065858      0.9896795       0.7435816       1.6003494\n0.94218314      0.6793372       0.97101355      0.62892824      1.3458569\n0.73134506      0.5975239       0.9109101       0.59374434      1.1656629\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5x5]\n\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ninput = np.random.uniform(0, 1, (3, 5)).astype(\nfloat32\n)\ngradOutput = np.random.uniform(0, 1, (3, 5)).astype(\nfloat32\n)\nlinear = Linear(5, 5, wRegularizer = L2Regularizer(0.2), bRegularizer = L2Regularizer(0.2))\noutput = linear.forward(input)\ngradInput = linear.backward(input, gradOutput)\n\n\n linear.parameters()\n{u'Linear@787aab5e': {u'bias': array([-0.43960261, -0.12444571,  0.22857292, -0.43216187,  0.27770036], dtype=float32),\n  u'gradBias': array([ 0.51726723,  1.32883406,  0.57567948,  1.7791357 ,  1.2887038 ], dtype=float32),\n  u'gradWeight': array([[ 0.45477036,  0.22262168,  0.21923628,  0.26152173,  0.19836383],\n         [ 1.12261093,  0.72921795,  0.08405925,  0.78192139,  0.48798928],\n         [ 0.34581488,  0.21195598,  0.26357424,  0.18987852,  0.2465664 ],\n         [ 1.18659711,  1.11271608,  0.72589797,  1.19098675,  0.33769298],\n         [ 0.82314551,  0.71177536,  0.4428404 ,  0.764337  ,  0.3500182 ]], dtype=float32),\n  u'weight': array([[ 0.03727285, -0.39697152,  0.42733836, -0.34291714, -0.13833708],\n         [ 0.09232076, -0.09720675, -0.33625153,  0.06477787, -0.34739712],\n         [ 0.17145753,  0.10128133,  0.16679128, -0.33541158,  0.40437087],\n         [-0.03005157, -0.36412898,  0.0629965 ,  0.13443278, -0.38414535],\n         [-0.16630849,  0.06934392,  0.40328237,  0.22299488, -0.1178569 ]], dtype=float32)}}\n\n\n\n\nL1L2 Regularizer\n\n\nScala:\n\n\nval l1l2Regularizer = L1L2Regularizer(l1rate, l2rate)\n\n\n\n\nPython:\n\n\nregularizerl1l2 = L1L2Regularizer(l1rate, l2rate)\n\n\n\n\nL1L2 regularizer is used to add penalty to the gradWeight to avoid overfitting.\n\n\nIn our code implementation, we will apply L1regularizer and L2regularizer sequentially.\n\n\nFor more details, please refer to \nwiki\n.\n\n\nScala example:\n\n\n\nimport com.intel.analytics.bigdl.utils.RandomGenerator.RNG\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\n\nRNG.setSeed(100)\n\nval input = Tensor(3, 5).rand\nval gradOutput = Tensor(3, 5).rand\nval linear = Linear(5, 5, wRegularizer = L1L2Regularizer(0.2, 0.2), bRegularizer = L1L2Regularizer(0.2, 0.2))\n\nval output = linear.forward(input)\nval gradInput = linear.backward(input, gradOutput)\n\nscala\n input\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.54340494      0.67115563      0.2783694       0.4120464       0.4245176\n0.52638245      0.84477615      0.14860484      0.004718862     0.15671109\n0.12156912      0.18646719      0.67074907      0.21010774      0.82585275\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x5]\n\nscala\n gradOutput\ngradOutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.4527399       0.13670659      0.87014264      0.5750933       0.063681036\n0.89132196      0.62431186      0.20920213      0.52334774      0.18532822\n0.5622963       0.10837689      0.0058171963    0.21969749      0.3074232\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x5]\n\nscala\n linear.gradWeight\nres1: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.069174        1.4422078       0.8913989       0.042112567     0.53756505\n0.14077617      0.8959319       -0.030221784    -0.1583686      0.4690558\n0.37145022      0.99747723      0.5559263       0.58614403      0.66380215\n0.88983417      0.639738        0.14924419      0.027530536     0.71988696\n-0.053217214    -8.643427E-4    -0.036953792    0.29753304      0.06567569\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5x5]\n\n\n\n\nPython example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ninput = np.random.uniform(0, 1, (3, 5)).astype(\nfloat32\n)\ngradOutput = np.random.uniform(0, 1, (3, 5)).astype(\nfloat32\n)\nlinear = Linear(5, 5, wRegularizer = L1L2Regularizer(0.2, 0.2), bRegularizer = L1L2Regularizer(0.2, 0.2))\noutput = linear.forward(input)\ngradInput = linear.backward(input, gradOutput)\n\n\n linear.parameters()\n{u'Linear@1356aa91': {u'bias': array([-0.05799473, -0.0548001 ,  0.00408955, -0.22004321, -0.07143869], dtype=float32),\n  u'gradBias': array([ 0.89119786,  1.09953558,  1.03394508,  1.19511735,  2.02241182], dtype=float32),\n  u'gradWeight': array([[ 0.89061081,  0.58810186, -0.10087357,  0.19108151,  0.60029608],\n         [ 0.95275503,  0.2333075 ,  0.46897018,  0.74429053,  1.16038764],\n         [ 0.22894514,  0.60031962,  0.3836292 ,  0.15895618,  0.83136207],\n         [ 0.49079862,  0.80913013,  0.55491877,  0.69608945,  0.80458677],\n         [ 0.98890561,  0.49226439,  0.14861123,  1.37666655,  1.47615671]], dtype=float32),\n  u'weight': array([[ 0.44654208,  0.16320795, -0.36029238, -0.25365737, -0.41974261],\n         [ 0.18809238, -0.28065765,  0.27677274, -0.29904234,  0.41338971],\n         [-0.03731538,  0.22493915,  0.10021331, -0.19495697,  0.25470355],\n         [-0.30836752,  0.12083009,  0.3773002 ,  0.24059358, -0.40325543],\n         [-0.13601269, -0.39310011, -0.05292636,  0.20001481, -0.08444868]], dtype=float32)}}", 
            "title": "Regularizers"
        }, 
        {
            "location": "/APIGuide/Regularizers/#l1-regularizer", 
            "text": "Scala:  val l1Regularizer = L1Regularizer(rate)  Python:  regularizerl1 = L1Regularizer(rate)  L1 regularizer is used to add penalty to the gradWeight to avoid overfitting.  In our code implementation, gradWeight = gradWeight + alpha * abs(weight)  For more details, please refer to  wiki .  Scala example:  \nimport com.intel.analytics.bigdl.utils.RandomGenerator.RNG\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\n\nRNG.setSeed(100)\n\nval input = Tensor(3, 5).rand\nval gradOutput = Tensor(3, 5).rand\nval linear = Linear(5, 5, wRegularizer = L1Regularizer(0.2), bRegularizer = L1Regularizer(0.2))\n\nval output = linear.forward(input)\nval gradInput = linear.backward(input, gradOutput)\n\nscala  input\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.54340494      0.67115563      0.2783694       0.4120464       0.4245176\n0.52638245      0.84477615      0.14860484      0.004718862     0.15671109\n0.12156912      0.18646719      0.67074907      0.21010774      0.82585275\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x5]\n\nscala  gradOutput\ngradOutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.4527399       0.13670659      0.87014264      0.5750933       0.063681036\n0.89132196      0.62431186      0.20920213      0.52334774      0.18532822\n0.5622963       0.10837689      0.0058171963    0.21969749      0.3074232\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x5]\n\nscala  linear.gradWeight\nres2: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.9835552       1.3616763       0.83564335      0.108898684     0.59625006\n0.21608911      0.8393639       0.0035243928    -0.11795368     0.4453743\n0.38366735      0.9618148       0.47721142      0.5607486       0.6069793\n0.81469804      0.6690552       0.18522228      0.08559488      0.7075894\n-0.030468717    0.056625083     0.051471338     0.2917061       0.109963015\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5x5]  Python example:  \nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ninput = np.random.uniform(0, 1, (3, 5)).astype( float32 )\ngradOutput = np.random.uniform(0, 1, (3, 5)).astype( float32 )\nlinear = Linear(5, 5, wRegularizer = L1Regularizer(0.2), bRegularizer = L1Regularizer(0.2))\noutput = linear.forward(input)\ngradInput = linear.backward(input, gradOutput)  linear.parameters()\n{u'Linear@596d857b': {u'bias': array([ 0.3185505 , -0.02004393,  0.34620118, -0.09206461,  0.40776938], dtype=float32),\n  u'gradBias': array([ 2.14087653,  1.82181644,  1.90674937,  1.37307787,  0.81534696], dtype=float32),\n  u'gradWeight': array([[ 0.34909648,  0.85083449,  1.44904375,  0.90150446,  0.57136625],\n         [ 0.3745544 ,  0.42218602,  1.53656614,  1.1836741 ,  1.00702667],\n         [ 0.30529332,  0.26813674,  0.85559171,  0.61224306,  0.34721529],\n         [ 0.22859855,  0.8535381 ,  1.19809723,  1.37248564,  0.50041491],\n         [ 0.36197871,  0.03069445,  0.64837945,  0.12765063,  0.12872688]], dtype=float32),\n  u'weight': array([[-0.12423037,  0.35694697,  0.39038274, -0.34970999, -0.08283543],\n         [-0.4186025 , -0.33235055,  0.34948507,  0.39953214,  0.16294235],\n         [-0.25171402, -0.28955361, -0.32243955, -0.19771226, -0.29320192],\n         [-0.39263198,  0.37766701,  0.14673658,  0.24882999, -0.0779015 ],\n         [ 0.0323218 , -0.31266898,  0.31543773, -0.0898933 , -0.33485892]], dtype=float32)}}", 
            "title": "L1 Regularizer"
        }, 
        {
            "location": "/APIGuide/Regularizers/#l2-regularizer", 
            "text": "Scala:  val l2Regularizer = L2Regularizer(rate)  Python:  regularizerl2 = L2Regularizer(rate)  L2 regularizer is used to add penalty to the gradWeight to avoid overfitting.  In our code implementation, gradWeight = gradWeight + alpha * weight * weight  For more details, please refer to  wiki .  Scala example:  \nimport com.intel.analytics.bigdl.utils.RandomGenerator.RNG\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\n\nRNG.setSeed(100)linear.updateParameters\n\nval input = Tensor(3, 5).rand\nval gradOutput = Tensor(3, 5).rand\nval linear = Linear(5, 5, wRegularizer = L2Regularizer(0.2), bRegularizer = L2Regularizer(0.2))\n\nval output = linear.forward(input)\nval gradInput = linear.backward(input, gradOutput)\n\nscala  input\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.54340494      0.67115563      0.2783694       0.4120464       0.4245176\n0.52638245      0.84477615      0.14860484      0.004718862     0.15671109\n0.12156912      0.18646719      0.67074907      0.21010774      0.82585275\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x5]\n\nscala  gradOutput\ngradOutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.4527399       0.13670659      0.87014264      0.5750933       0.063681036\n0.89132196      0.62431186      0.20920213      0.52334774      0.18532822\n0.5622963       0.10837689      0.0058171963    0.21969749      0.3074232\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x5]\n\nscala  linear.gradWeight\nres0: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0329735       0.047239657     0.8979603       0.53614384      1.2781229\n0.5621818       0.29772854      0.69706535      0.30559152      0.8352279\n1.3044653       0.43065858      0.9896795       0.7435816       1.6003494\n0.94218314      0.6793372       0.97101355      0.62892824      1.3458569\n0.73134506      0.5975239       0.9109101       0.59374434      1.1656629\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5x5]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ninput = np.random.uniform(0, 1, (3, 5)).astype( float32 )\ngradOutput = np.random.uniform(0, 1, (3, 5)).astype( float32 )\nlinear = Linear(5, 5, wRegularizer = L2Regularizer(0.2), bRegularizer = L2Regularizer(0.2))\noutput = linear.forward(input)\ngradInput = linear.backward(input, gradOutput)  linear.parameters()\n{u'Linear@787aab5e': {u'bias': array([-0.43960261, -0.12444571,  0.22857292, -0.43216187,  0.27770036], dtype=float32),\n  u'gradBias': array([ 0.51726723,  1.32883406,  0.57567948,  1.7791357 ,  1.2887038 ], dtype=float32),\n  u'gradWeight': array([[ 0.45477036,  0.22262168,  0.21923628,  0.26152173,  0.19836383],\n         [ 1.12261093,  0.72921795,  0.08405925,  0.78192139,  0.48798928],\n         [ 0.34581488,  0.21195598,  0.26357424,  0.18987852,  0.2465664 ],\n         [ 1.18659711,  1.11271608,  0.72589797,  1.19098675,  0.33769298],\n         [ 0.82314551,  0.71177536,  0.4428404 ,  0.764337  ,  0.3500182 ]], dtype=float32),\n  u'weight': array([[ 0.03727285, -0.39697152,  0.42733836, -0.34291714, -0.13833708],\n         [ 0.09232076, -0.09720675, -0.33625153,  0.06477787, -0.34739712],\n         [ 0.17145753,  0.10128133,  0.16679128, -0.33541158,  0.40437087],\n         [-0.03005157, -0.36412898,  0.0629965 ,  0.13443278, -0.38414535],\n         [-0.16630849,  0.06934392,  0.40328237,  0.22299488, -0.1178569 ]], dtype=float32)}}", 
            "title": "L2 Regularizer"
        }, 
        {
            "location": "/APIGuide/Regularizers/#l1l2-regularizer", 
            "text": "Scala:  val l1l2Regularizer = L1L2Regularizer(l1rate, l2rate)  Python:  regularizerl1l2 = L1L2Regularizer(l1rate, l2rate)  L1L2 regularizer is used to add penalty to the gradWeight to avoid overfitting.  In our code implementation, we will apply L1regularizer and L2regularizer sequentially.  For more details, please refer to  wiki .  Scala example:  \nimport com.intel.analytics.bigdl.utils.RandomGenerator.RNG\nimport com.intel.analytics.bigdl.tensor._\nimport com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.nn._\n\nRNG.setSeed(100)\n\nval input = Tensor(3, 5).rand\nval gradOutput = Tensor(3, 5).rand\nval linear = Linear(5, 5, wRegularizer = L1L2Regularizer(0.2, 0.2), bRegularizer = L1L2Regularizer(0.2, 0.2))\n\nval output = linear.forward(input)\nval gradInput = linear.backward(input, gradOutput)\n\nscala  input\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.54340494      0.67115563      0.2783694       0.4120464       0.4245176\n0.52638245      0.84477615      0.14860484      0.004718862     0.15671109\n0.12156912      0.18646719      0.67074907      0.21010774      0.82585275\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x5]\n\nscala  gradOutput\ngradOutput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.4527399       0.13670659      0.87014264      0.5750933       0.063681036\n0.89132196      0.62431186      0.20920213      0.52334774      0.18532822\n0.5622963       0.10837689      0.0058171963    0.21969749      0.3074232\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 3x5]\n\nscala  linear.gradWeight\nres1: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.069174        1.4422078       0.8913989       0.042112567     0.53756505\n0.14077617      0.8959319       -0.030221784    -0.1583686      0.4690558\n0.37145022      0.99747723      0.5559263       0.58614403      0.66380215\n0.88983417      0.639738        0.14924419      0.027530536     0.71988696\n-0.053217214    -8.643427E-4    -0.036953792    0.29753304      0.06567569\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 5x5]  Python example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.optim.optimizer import *\nfrom bigdl.util.common import *\n\ninput = np.random.uniform(0, 1, (3, 5)).astype( float32 )\ngradOutput = np.random.uniform(0, 1, (3, 5)).astype( float32 )\nlinear = Linear(5, 5, wRegularizer = L1L2Regularizer(0.2, 0.2), bRegularizer = L1L2Regularizer(0.2, 0.2))\noutput = linear.forward(input)\ngradInput = linear.backward(input, gradOutput)  linear.parameters()\n{u'Linear@1356aa91': {u'bias': array([-0.05799473, -0.0548001 ,  0.00408955, -0.22004321, -0.07143869], dtype=float32),\n  u'gradBias': array([ 0.89119786,  1.09953558,  1.03394508,  1.19511735,  2.02241182], dtype=float32),\n  u'gradWeight': array([[ 0.89061081,  0.58810186, -0.10087357,  0.19108151,  0.60029608],\n         [ 0.95275503,  0.2333075 ,  0.46897018,  0.74429053,  1.16038764],\n         [ 0.22894514,  0.60031962,  0.3836292 ,  0.15895618,  0.83136207],\n         [ 0.49079862,  0.80913013,  0.55491877,  0.69608945,  0.80458677],\n         [ 0.98890561,  0.49226439,  0.14861123,  1.37666655,  1.47615671]], dtype=float32),\n  u'weight': array([[ 0.44654208,  0.16320795, -0.36029238, -0.25365737, -0.41974261],\n         [ 0.18809238, -0.28065765,  0.27677274, -0.29904234,  0.41338971],\n         [-0.03731538,  0.22493915,  0.10021331, -0.19495697,  0.25470355],\n         [-0.30836752,  0.12083009,  0.3773002 ,  0.24059358, -0.40325543],\n         [-0.13601269, -0.39310011, -0.05292636,  0.20001481, -0.08444868]], dtype=float32)}}", 
            "title": "L1L2 Regularizer"
        }, 
        {
            "location": "/APIGuide/Optimizers/Optimizer/", 
            "text": "Optimizer\n\n\nAn optimizer is in general to minimize any function with respect to a set of parameters. In case of training a neural network, an optimizer tries to minimize the loss of the neural net with respect to its weights/biases, over the training set.\n\n\nScala API\n\n\nFactory method\n\n\nIn summary, you need to supply 3 kinds of paramters to create an optimizer:\n1) train data: You could supply \n   a) a sampleRDD and batchSize (with optional featurePadding and labelPadding), or \n   b) a sampleRDD and batchSize and a customized implemenation of trait MiniBatch, or\n   c) a DataSet - the type of optimizer created will be dermined by the type of Dataset. \n2) a model\n3) a criterion (i.e. loss)\nas shown in below interfaces:\n\n\nval optimizer = Opimizer[T: ClassTag, D](\n      model: Module[T],\n      sampleRDD: RDD[Sample[T]],\n      criterion: Criterion[T],\n      batchSize: Int,\n      featurePaddingParam: PaddingParam[T]=null,\n      labelPaddingParam: PaddingParam[T]=null)\n\n\n\n\nThe meaning of parameters are as below:\n\nmodel\n: model will be optimized.\n\nsampleRDD\n: training Samples.\n\ncriterion\n: loss function.\n\nbatchSize\n: mini batch size.\n\nfeaturePaddingParam\n(optional): feature padding strategy.\n\nlabelPaddingParam\n(optional): label padding strategy.\n \n\n\nval optimizer = Opimizer[T: ClassTag, D](\n  model: Module[T],\n  dataset: DataSet[D],\n  criterion: Criterion[T])\n\n\n\n\nT\n: the numeric type(Float/Double).\n\n\nD\n: should be a kind of MiniBatch.\n\n\nmodel\n: the model will be optimized.\n\n\ndataset\n: the training DataSet.\n\n\ncriterion\n: the Loss function.\n \n\n\nval optimizer = Opimizer[T: ClassTag, D](\n      model: Module[T],\n      sampleRDD: RDD[Sample[T]],\n      criterion: Criterion[T],\n      batchSize: Int,\n      miniBatch: MiniBatch[T])\n\n\n\n\nApply an optimizer with User-Defined \nMiniBatch\n.\n\n\nmodel\n: model will be optimized.\n\n\nsampleRDD\n: training Samples.\n\n\ncriterion\n: loss function.\n\n\nbatchSize\n: mini batch size.\n\n\nminiBatch\n: An User-Defined MiniBatch implementation.\n \n\n\nValidation\n\n\nFunction setValidation is to set a validate evaluation in the \noptimizer\n.\n\n\noptimizer.setValidation(\n  trigger: Trigger,\n  dataset: DataSet[MiniBatch[T]],\n  vMethods : Array[ValidationMethod[T])\n\n\n\n\ntrigger\n: how often to evaluation validation set.\n\n\ndataset\n: validate data set in type of DataSet[MiniBatch].\n\n\nvMethods\n: a set of ValidationMethod.\n\n \n\n\noptimizer.setValidation(\n  trigger: Trigger,\n  sampleRDD: RDD[Sample[T]],\n  vMethods: Array[ValidationMethod[T]],\n  batchSize: Int)\n\n\n\n\ntrigger\n: how often to evaluation validation set.\n\n\nsampleRDD\n: validate data set in type of RDD[Sample].\n\n\nvMethods\n: a set of ValidationMethod.\n\n\nbatchSize\n: size of mini batch.\n \n\n\nCheckpoint\n\n\noptimizer.setCheckpoint(path: String, trigger: Trigger)\n\n\n\n\nFunction setCheckPoint is used to set a check point saved at \npath\n triggered by \ntrigger\n.\n\n\npath\n: a local/HDFS directory to save checkpoint.\n\n\ntrigger\n: how often to save the check point.\n\n \n\n\nval path = optimizer.getCheckpointPath()\n\n\n\n\nFunction getCheckpointPath is used to get the directory of saving checkpoint.\n\n \n\n\noptimizer.overWriteCheckpoint()\n\n\n\n\nFunction overWriteCheckpoint is enable overwrite saving checkpoint.  \n\n\nSummary\n\n\noptimizer.setTrainSummary(trainSummary: TrainSummary)\n\n\n\n\nFunction setTrainSummary is used to enable train summary in this optimizer.\n\n\ntrainSummary\n: an instance of TrainSummary.\n\n \n\n\noptimizer.setValidationSummary(validationSummary: ValidationSummary)\n\n\n\n\nFunction setValidationSummary is used to enable validation summary in this optimizer.\n\n\nvalidationSummary\n: an instance of ValidationSummary.  \n\n\nOther important API\n\n\nval trainedModel = optimizer.optimize()\n\n\n\n\nFunction optimize will start the training.\n\n \n\n\noptimizer.setModel(newModel: Module[T])\n\n\n\n\nFunction setModel will set a new model to the optimizer.\n\n\nnewModel\n: a model will replace the old model in optimizer.\n\n \n\n\n\noptimizer.setTrainData(sampleRDD: RDD[Sample[T]],\n                 batchSize: Int,\n                 miniBatch: MiniBatch[T])\n\noptimizer.setTrainData(sampleRDD: RDD[Sample[T]],\n                 batchSize: Int,\n                 featurePaddingParam: PaddingParam[T]=null,\n                 labelPaddingParam: PaddingParam[T])=null\n\n\n\n\n\nthe overloaded set of methods \nsetTrainData\n allows user to replace the training data. Each time setTrainData is called, the dataset is replaced and the following call to optimize() will use the new dataset. The meaning of arguments are the same as in the Factory methods:\n\nsampleRDD\n: training Samples.\n\nbatchSize\n: mini batch size.\n\nfeaturePaddingParam\n: feature padding strategy.\n\nlabelPaddingParam\n: label padding strategy.\n\nminiBatch\n: An User-Defined MiniBatch implemenation.\n \n\n\noptimizer.setCriterion(newCriterion: Criterion[T])\n\n\n\n\nsetCriterion\n allows user to set a new criterion to replace the old one. \n\nnewCriterion\n: the new Criterion.\n \n\n\noptimizer.setState(state: Table)\n\n\n\n\nFunction setState is used to set a state(learning rate, epochs...) to the \noptimizer\n.\n\n\nstate\n: the state to be saved.\n\n \n\n\noptimizer.setOptimMethod(method : OptimMethod[T])\n\n\n\n\nFunction setOptimMethod is used to set an optimization method in this \noptimizer\n.\n\n\nmethod\n: the method the optimize the model in this \noptimizer\n.\n\n \n\n\noptimizer.setEndWhen(endWhen: Trigger)\n\n\n\n\nFunction setEndWhen is used to declare when to stop the training invoked by \noptimize()\n.\n\n\nendWhen\n: a trigger to stop the training.\n\n\nScala example\n\n\nHere is an example to new an Optimizer with SGD for optimizing LeNet5 model.\n\n\nval trainingRDD = ...\nval valRDD = ...\nval batchSize = 12\n// Create an optimizer\nval optimizer = Optimizer(\n  model = LeNet5(classNum = 10),\n  sampleRDD = trainingRDD,\n  criterion = ClassNLLCriterion(),\n  batchSize = batchSize\n).setValidation(Trigger.everyEpoch, valRDD, Array(new Top1Accuracy), batchSize) // set validation method\n  .setEndWhen(Trigger.maxEpoch(15)) // set end trigger\n  .setOptimMethod(new SGD(learningRate = 0.05)) // set optimize method, Since 0.2.0. Older version should use optimizer.setOptimMethod(new SGD()).setState(T(\nlearningRate\n -\n 0.05))\n\nval trainedModel = optimizer.optimize()\n\n\n\n\nPython API\n\n\nFactory method\n\n\noptimizer =  Optimizer(model,\n                 training_rdd,\n                 criterion,\n                 end_trigger,\n                 batch_size,\n                 optim_method=None,\n                 bigdl_type=\nfloat\n)\n\n\n\n\nmodel\n: the model will be optimized.\n\n\ntraining_rdd\n: the training dataset.\n\n\ncriterion\n: the Loss function.\n\n\nend_trigger\n: when to end the optimization.\n\n\nbatch_size\n: size of minibatch.\n\n\noptim_method\n:  the algorithm to use for optimization, e.g. SGD, Adagrad, etc. If optim_method is None, the default algorithm is SGD.\n\n\nbigdl_type\n: the numeric type(Float/Double).  \n\n\nValidation\n\n\nFunction setValidation is to set a validate evaluation in the \noptimizer\n.\n\n\noptimizer.set_validation(batch_size, val_rdd, trigger, val_method=[\nTop1Accuracy\n])\n\n\n\n\ntrigger\n: how often to evaluation validation set.\n\n\nval_rdd\n: validate data set in type of RDD[Sample].\n\n\nval_method\n: a list of ValidationMethod, e.g. \"Top1Accuracy\", \"Top5Accuracy\", \"Loss\".\n\n\nbatch_size\n: size of mini batch.\n\n\nCheckpoint\n\n\noptimizer.set_checkpoint(checkpoint_trigger,\n                      checkpoint_path, isOverWrite=True)\n\n\n\n\nFunction setCheckPoint is used to set a check point saved at \npath\n triggered by \ntrigger\n.\n\n\ncheckpoint_trigger\n: how often to save the check point.\n\ncheckpoint_path\n: a local/HDFS directory to save checkpoint.\n\n\nisOverWrite\n: whether to overwrite existing snapshots in path.default is True\n\n\nSummary\n\n\noptimizer.set_train_summary(summary)\n\n\n\n\nSet train summary. A TrainSummary object contains information necessary for the optimizer to know how often the logs are recorded, where to store the logs and how to retrieve them, etc. For details, refer to the docs of TrainSummary.\n\nsummary\n: an instance of TrainSummary.\n\n\noptimizer.set_validation_summary(summary)\n\n\n\n\nFunction setValidationSummary is used to set validation summary. A ValidationSummary object contains information necessary for the optimizer to know how often the logs are recorded, where to store the logs and how to retrieve them, etc. For details, refer to the docs of ValidationSummary.\n\nsummary\n: an instance of ValidationSummary.\n\n\nStart Training\n\n\ntrained_model = optimizer.optimize()\n\n\n\n\nFunction optimize will start the training.\n\n\nSet Model\n\n\noptimizer.set_model(model)\n\n\n\n\nFunction setModel will set a new model to the optimizer.\n\n\nmodel\n: a model will replace the old model in optimizer.\n\n\nSet Train Data\n\n\noptimizer.set_traindata(sample_rdd, batch_size)\n\n\n\n\nset_traindata allows user to replace the train data (for optimizer reuse)\n\n\nSet Criterion\n\n\noptimizer.set_criterion(criterion)\n\n\n\n\nset_criterion allows user to replace the criterion (for optimizer reuse)\n\n\nPython example\n\n\nHere is an example to new an Optimizer with SGD for optimizing LeNet5 model.\n\n\ntrain_data = ...\ntest_data = ...\nbatch_size = 12\n# Create an Optimizer, Since 0.2.0\noptimizer = Optimizer(\n  model=lenet_model,\n  training_rdd=train_data,\n  criterion=ClassNLLCriterion(),\n  optim_method=SGD(learningrate=0.01, learningrate_decay=0.0002), # set optim method\n  end_trigger=MaxEpoch(15),\n  batch_size=batch_size)\n\n# Older version, before 0.2.0, use following code: \n# optimizer = Optimizer(\n#   model=model,\n#   training_rdd=train_data,\n#   criterion=ClassNLLCriterion(),\n#   optim_method=\nSGD\n,\n#   state={\nlearningRate\n: 0.05},\n#   end_trigger=MaxEpoch(training_epochs),\n#   batch_size=batch_size)\n\noptimizer.set_validation(\n    batch_size=2048,\n    val_rdd=test_data,\n    trigger=EveryEpoch(),\n    val_method=[Top1Accuracy()]\n)\n\n# Older version, before 0.2.0, use following code: \n#optimizer.set_validation(\n#    batch_size=2048,\n#    val_rdd=test_data,\n#    trigger=EveryEpoch(),\n#    val_method=[\nTop1Accuracy\n]\n#)\n\ntrained_model = optimizer.optimize()\n\n\n\n\n\nHow BigDL train models in a distributed cluster?\n\n\nBigDL distributed training is data parallelism. The training data is split among workers and cached in memory. A complete model is also cached on each worker. The model only uses the data of the same worker in the training.\n\n\nBigDL employs a synchronous distributed training. In each iteration, each worker will sync the latest weights, calculate gradients with local data and local model, sync the gradients and update the weights with a given optimization method(e.g. SGD, Adagrad).\n\n\nIn gradients and weights sync, BigDL doesn't use the RDD APIs like(broadcast, reduce, aggregate, treeAggregate). The problem of these methods is every worker needs to communicate with driver, so the driver will become the bottleneck if the parameter is too large or the workers are too many. Instead, BigDL implement a P2P algorithm for parameter sync to remove the bottleneck. For detail of the algorithm, please see the \ncode", 
            "title": "Optimizer"
        }, 
        {
            "location": "/APIGuide/Optimizers/Optimizer/#optimizer", 
            "text": "An optimizer is in general to minimize any function with respect to a set of parameters. In case of training a neural network, an optimizer tries to minimize the loss of the neural net with respect to its weights/biases, over the training set.", 
            "title": "Optimizer"
        }, 
        {
            "location": "/APIGuide/Optimizers/Optimizer/#scala-api", 
            "text": "Factory method  In summary, you need to supply 3 kinds of paramters to create an optimizer:\n1) train data: You could supply \n   a) a sampleRDD and batchSize (with optional featurePadding and labelPadding), or \n   b) a sampleRDD and batchSize and a customized implemenation of trait MiniBatch, or\n   c) a DataSet - the type of optimizer created will be dermined by the type of Dataset. \n2) a model\n3) a criterion (i.e. loss)\nas shown in below interfaces:  val optimizer = Opimizer[T: ClassTag, D](\n      model: Module[T],\n      sampleRDD: RDD[Sample[T]],\n      criterion: Criterion[T],\n      batchSize: Int,\n      featurePaddingParam: PaddingParam[T]=null,\n      labelPaddingParam: PaddingParam[T]=null)  The meaning of parameters are as below: model : model will be optimized. sampleRDD : training Samples. criterion : loss function. batchSize : mini batch size. featurePaddingParam (optional): feature padding strategy. labelPaddingParam (optional): label padding strategy.\n   val optimizer = Opimizer[T: ClassTag, D](\n  model: Module[T],\n  dataset: DataSet[D],\n  criterion: Criterion[T])  T : the numeric type(Float/Double).  D : should be a kind of MiniBatch.  model : the model will be optimized.  dataset : the training DataSet.  criterion : the Loss function.\n   val optimizer = Opimizer[T: ClassTag, D](\n      model: Module[T],\n      sampleRDD: RDD[Sample[T]],\n      criterion: Criterion[T],\n      batchSize: Int,\n      miniBatch: MiniBatch[T])  Apply an optimizer with User-Defined  MiniBatch .  model : model will be optimized.  sampleRDD : training Samples.  criterion : loss function.  batchSize : mini batch size.  miniBatch : An User-Defined MiniBatch implementation.\n   Validation  Function setValidation is to set a validate evaluation in the  optimizer .  optimizer.setValidation(\n  trigger: Trigger,\n  dataset: DataSet[MiniBatch[T]],\n  vMethods : Array[ValidationMethod[T])  trigger : how often to evaluation validation set.  dataset : validate data set in type of DataSet[MiniBatch].  vMethods : a set of ValidationMethod. \n   optimizer.setValidation(\n  trigger: Trigger,\n  sampleRDD: RDD[Sample[T]],\n  vMethods: Array[ValidationMethod[T]],\n  batchSize: Int)  trigger : how often to evaluation validation set.  sampleRDD : validate data set in type of RDD[Sample].  vMethods : a set of ValidationMethod.  batchSize : size of mini batch.\n   Checkpoint  optimizer.setCheckpoint(path: String, trigger: Trigger)  Function setCheckPoint is used to set a check point saved at  path  triggered by  trigger .  path : a local/HDFS directory to save checkpoint.  trigger : how often to save the check point. \n   val path = optimizer.getCheckpointPath()  Function getCheckpointPath is used to get the directory of saving checkpoint. \n   optimizer.overWriteCheckpoint()  Function overWriteCheckpoint is enable overwrite saving checkpoint.    Summary  optimizer.setTrainSummary(trainSummary: TrainSummary)  Function setTrainSummary is used to enable train summary in this optimizer.  trainSummary : an instance of TrainSummary. \n   optimizer.setValidationSummary(validationSummary: ValidationSummary)  Function setValidationSummary is used to enable validation summary in this optimizer.  validationSummary : an instance of ValidationSummary.    Other important API  val trainedModel = optimizer.optimize()  Function optimize will start the training. \n   optimizer.setModel(newModel: Module[T])  Function setModel will set a new model to the optimizer.  newModel : a model will replace the old model in optimizer. \n   \noptimizer.setTrainData(sampleRDD: RDD[Sample[T]],\n                 batchSize: Int,\n                 miniBatch: MiniBatch[T])\n\noptimizer.setTrainData(sampleRDD: RDD[Sample[T]],\n                 batchSize: Int,\n                 featurePaddingParam: PaddingParam[T]=null,\n                 labelPaddingParam: PaddingParam[T])=null  the overloaded set of methods  setTrainData  allows user to replace the training data. Each time setTrainData is called, the dataset is replaced and the following call to optimize() will use the new dataset. The meaning of arguments are the same as in the Factory methods: sampleRDD : training Samples. batchSize : mini batch size. featurePaddingParam : feature padding strategy. labelPaddingParam : label padding strategy. miniBatch : An User-Defined MiniBatch implemenation.\n   optimizer.setCriterion(newCriterion: Criterion[T])  setCriterion  allows user to set a new criterion to replace the old one.  newCriterion : the new Criterion.\n   optimizer.setState(state: Table)  Function setState is used to set a state(learning rate, epochs...) to the  optimizer .  state : the state to be saved. \n   optimizer.setOptimMethod(method : OptimMethod[T])  Function setOptimMethod is used to set an optimization method in this  optimizer .  method : the method the optimize the model in this  optimizer . \n   optimizer.setEndWhen(endWhen: Trigger)  Function setEndWhen is used to declare when to stop the training invoked by  optimize() .  endWhen : a trigger to stop the training.", 
            "title": "Scala API"
        }, 
        {
            "location": "/APIGuide/Optimizers/Optimizer/#scala-example", 
            "text": "Here is an example to new an Optimizer with SGD for optimizing LeNet5 model.  val trainingRDD = ...\nval valRDD = ...\nval batchSize = 12\n// Create an optimizer\nval optimizer = Optimizer(\n  model = LeNet5(classNum = 10),\n  sampleRDD = trainingRDD,\n  criterion = ClassNLLCriterion(),\n  batchSize = batchSize\n).setValidation(Trigger.everyEpoch, valRDD, Array(new Top1Accuracy), batchSize) // set validation method\n  .setEndWhen(Trigger.maxEpoch(15)) // set end trigger\n  .setOptimMethod(new SGD(learningRate = 0.05)) // set optimize method, Since 0.2.0. Older version should use optimizer.setOptimMethod(new SGD()).setState(T( learningRate  -  0.05))\n\nval trainedModel = optimizer.optimize()", 
            "title": "Scala example"
        }, 
        {
            "location": "/APIGuide/Optimizers/Optimizer/#python-api", 
            "text": "Factory method  optimizer =  Optimizer(model,\n                 training_rdd,\n                 criterion,\n                 end_trigger,\n                 batch_size,\n                 optim_method=None,\n                 bigdl_type= float )  model : the model will be optimized.  training_rdd : the training dataset.  criterion : the Loss function.  end_trigger : when to end the optimization.  batch_size : size of minibatch.  optim_method :  the algorithm to use for optimization, e.g. SGD, Adagrad, etc. If optim_method is None, the default algorithm is SGD.  bigdl_type : the numeric type(Float/Double).    Validation  Function setValidation is to set a validate evaluation in the  optimizer .  optimizer.set_validation(batch_size, val_rdd, trigger, val_method=[ Top1Accuracy ])  trigger : how often to evaluation validation set.  val_rdd : validate data set in type of RDD[Sample].  val_method : a list of ValidationMethod, e.g. \"Top1Accuracy\", \"Top5Accuracy\", \"Loss\".  batch_size : size of mini batch.  Checkpoint  optimizer.set_checkpoint(checkpoint_trigger,\n                      checkpoint_path, isOverWrite=True)  Function setCheckPoint is used to set a check point saved at  path  triggered by  trigger .  checkpoint_trigger : how often to save the check point. checkpoint_path : a local/HDFS directory to save checkpoint.  isOverWrite : whether to overwrite existing snapshots in path.default is True  Summary  optimizer.set_train_summary(summary)  Set train summary. A TrainSummary object contains information necessary for the optimizer to know how often the logs are recorded, where to store the logs and how to retrieve them, etc. For details, refer to the docs of TrainSummary. summary : an instance of TrainSummary.  optimizer.set_validation_summary(summary)  Function setValidationSummary is used to set validation summary. A ValidationSummary object contains information necessary for the optimizer to know how often the logs are recorded, where to store the logs and how to retrieve them, etc. For details, refer to the docs of ValidationSummary. summary : an instance of ValidationSummary.  Start Training  trained_model = optimizer.optimize()  Function optimize will start the training.  Set Model  optimizer.set_model(model)  Function setModel will set a new model to the optimizer.  model : a model will replace the old model in optimizer.  Set Train Data  optimizer.set_traindata(sample_rdd, batch_size)  set_traindata allows user to replace the train data (for optimizer reuse)  Set Criterion  optimizer.set_criterion(criterion)  set_criterion allows user to replace the criterion (for optimizer reuse)", 
            "title": "Python API"
        }, 
        {
            "location": "/APIGuide/Optimizers/Optimizer/#python-example", 
            "text": "Here is an example to new an Optimizer with SGD for optimizing LeNet5 model.  train_data = ...\ntest_data = ...\nbatch_size = 12\n# Create an Optimizer, Since 0.2.0\noptimizer = Optimizer(\n  model=lenet_model,\n  training_rdd=train_data,\n  criterion=ClassNLLCriterion(),\n  optim_method=SGD(learningrate=0.01, learningrate_decay=0.0002), # set optim method\n  end_trigger=MaxEpoch(15),\n  batch_size=batch_size)\n\n# Older version, before 0.2.0, use following code: \n# optimizer = Optimizer(\n#   model=model,\n#   training_rdd=train_data,\n#   criterion=ClassNLLCriterion(),\n#   optim_method= SGD ,\n#   state={ learningRate : 0.05},\n#   end_trigger=MaxEpoch(training_epochs),\n#   batch_size=batch_size)\n\noptimizer.set_validation(\n    batch_size=2048,\n    val_rdd=test_data,\n    trigger=EveryEpoch(),\n    val_method=[Top1Accuracy()]\n)\n\n# Older version, before 0.2.0, use following code: \n#optimizer.set_validation(\n#    batch_size=2048,\n#    val_rdd=test_data,\n#    trigger=EveryEpoch(),\n#    val_method=[ Top1Accuracy ]\n#)\n\ntrained_model = optimizer.optimize()", 
            "title": "Python example"
        }, 
        {
            "location": "/APIGuide/Optimizers/Optimizer/#how-bigdl-train-models-in-a-distributed-cluster", 
            "text": "BigDL distributed training is data parallelism. The training data is split among workers and cached in memory. A complete model is also cached on each worker. The model only uses the data of the same worker in the training.  BigDL employs a synchronous distributed training. In each iteration, each worker will sync the latest weights, calculate gradients with local data and local model, sync the gradients and update the weights with a given optimization method(e.g. SGD, Adagrad).  In gradients and weights sync, BigDL doesn't use the RDD APIs like(broadcast, reduce, aggregate, treeAggregate). The problem of these methods is every worker needs to communicate with driver, so the driver will become the bottleneck if the parameter is too large or the workers are too many. Instead, BigDL implement a P2P algorithm for parameter sync to remove the bottleneck. For detail of the algorithm, please see the  code", 
            "title": "How BigDL train models in a distributed cluster?"
        }, 
        {
            "location": "/APIGuide/Optimizers/OptimMethod/", 
            "text": "OptimMethod\n\n\nOptimMethod is used to update model gradient parameters.We have defined SGD method, Adagrad method, etc.\nDetails about those optim methods, you can refer to \nOptim-Methods\n.\nNow, method construct parameters(e.g.\"learningRate\") and internal training parameters(e.g.\"epoch\") store in optim method instead of state(since version 0.2.0)\nHere is mainly to describe how to use those methods when training\n\n\nSet method\n\n\nscala\n\n\noptimizer.setOptimMethod(method : OptimMethod[T])\n\n\n\n\npython\n\n\noptimizer = Optimizer(\n    model,\n    training_rdd,\n    criterion,\n    optim_method,\n    end_trigger,\n    batch_size)\n\n\n\n\nin python, you can set optim method when creating an optimizer\n\n\nSave method\n\n\nmethod.save(path: String, overWrite: Boolean = false)\n\n\n\n\nT\n: path to save method\n\n\noverWrite\n: whether to overwrite or not\n\n\nWhen training, you can use optimizer.setCheckPoint(for scala) or optimizer.set_checkpoint(for python) to save methods at regular intervals.\n\n\nLoad method\n\n\nscala\n\n\nval method = OptimMethod.load(path : String)\n\n\n\n\npath\n: file of optim method path\n\n\npython\n\n\noptimizer = OptimMethod.load(path, bigdl_type=\nfloat\n)\n\n\n\n\nbigdl_type\n: type of optim method, default is \"float\"\n\n\nScala example\n\n\nHere is an example to train LeNet5 model with a loading method.\n\n\nval trainingRDD = ...\nval valRDD = ...\nval batchSize = 12\nval methodPath = ...\n// Load optim method\nval method = OptimMethod.load(methodPath)\n// Create an optimizer\nval optimizer = Optimizer(\n  model = LeNet5(classNum = 10),\n  sampleRDD = trainingRDD,\n  criterion = ClassNLLCriterion(),\n  batchSize = batchSize\n).setValidation(Trigger.everyEpoch, valRDD, Array(new Top1Accuracy), batchSize)\n  .setEndWhen(Trigger.maxEpoch(15))\n\noptimizer.setOptimMethod(method) // set optim method\n\noptimizer.setCheckpoint(param.checkpoint.get, checkpointTrigger) // set checkpoint to save model and optim method\n\nval trainedModel = optimizer.optimize()\n\n\n\n\nPython example\n\n\nHere is an example to train LeNet5 model with SGD method.\n\n\ntrain_data = ...\ntest_data = ...\nbatch_size = 12\noptimizer = Optimizer(\n  model=lenet_model,\n  training_rdd=train_data,\n  criterion=ClassNLLCriterion(),\n  optim_method=SGD(learningrate=0.01, learningrate_decay=0.0002), # set optim method\n  end_trigger=MaxEpoch(15),\n  batch_size=batch_size)\n\noptimizer.set_validation(\n    batch_size=32,\n    val_rdd=test_data,\n    trigger=EveryEpoch(),\n    val_method=[Top1Accuracy()]\n)\n\noptimizer.set_checkpoint(EveryEpoch(), checkpointPath) # set checkpoint to save model and optim method\n\ntrained_model = optimizer.optimize()", 
            "title": "OptimMethod"
        }, 
        {
            "location": "/APIGuide/Optimizers/OptimMethod/#optimmethod", 
            "text": "OptimMethod is used to update model gradient parameters.We have defined SGD method, Adagrad method, etc.\nDetails about those optim methods, you can refer to  Optim-Methods .\nNow, method construct parameters(e.g.\"learningRate\") and internal training parameters(e.g.\"epoch\") store in optim method instead of state(since version 0.2.0)\nHere is mainly to describe how to use those methods when training", 
            "title": "OptimMethod"
        }, 
        {
            "location": "/APIGuide/Optimizers/OptimMethod/#set-method", 
            "text": "scala  optimizer.setOptimMethod(method : OptimMethod[T])  python  optimizer = Optimizer(\n    model,\n    training_rdd,\n    criterion,\n    optim_method,\n    end_trigger,\n    batch_size)  in python, you can set optim method when creating an optimizer", 
            "title": "Set method"
        }, 
        {
            "location": "/APIGuide/Optimizers/OptimMethod/#save-method", 
            "text": "method.save(path: String, overWrite: Boolean = false)  T : path to save method  overWrite : whether to overwrite or not  When training, you can use optimizer.setCheckPoint(for scala) or optimizer.set_checkpoint(for python) to save methods at regular intervals.", 
            "title": "Save method"
        }, 
        {
            "location": "/APIGuide/Optimizers/OptimMethod/#load-method", 
            "text": "scala  val method = OptimMethod.load(path : String)  path : file of optim method path  python  optimizer = OptimMethod.load(path, bigdl_type= float )  bigdl_type : type of optim method, default is \"float\"", 
            "title": "Load method"
        }, 
        {
            "location": "/APIGuide/Optimizers/OptimMethod/#scala-example", 
            "text": "Here is an example to train LeNet5 model with a loading method.  val trainingRDD = ...\nval valRDD = ...\nval batchSize = 12\nval methodPath = ...\n// Load optim method\nval method = OptimMethod.load(methodPath)\n// Create an optimizer\nval optimizer = Optimizer(\n  model = LeNet5(classNum = 10),\n  sampleRDD = trainingRDD,\n  criterion = ClassNLLCriterion(),\n  batchSize = batchSize\n).setValidation(Trigger.everyEpoch, valRDD, Array(new Top1Accuracy), batchSize)\n  .setEndWhen(Trigger.maxEpoch(15))\n\noptimizer.setOptimMethod(method) // set optim method\n\noptimizer.setCheckpoint(param.checkpoint.get, checkpointTrigger) // set checkpoint to save model and optim method\n\nval trainedModel = optimizer.optimize()", 
            "title": "Scala example"
        }, 
        {
            "location": "/APIGuide/Optimizers/OptimMethod/#python-example", 
            "text": "Here is an example to train LeNet5 model with SGD method.  train_data = ...\ntest_data = ...\nbatch_size = 12\noptimizer = Optimizer(\n  model=lenet_model,\n  training_rdd=train_data,\n  criterion=ClassNLLCriterion(),\n  optim_method=SGD(learningrate=0.01, learningrate_decay=0.0002), # set optim method\n  end_trigger=MaxEpoch(15),\n  batch_size=batch_size)\n\noptimizer.set_validation(\n    batch_size=32,\n    val_rdd=test_data,\n    trigger=EveryEpoch(),\n    val_method=[Top1Accuracy()]\n)\n\noptimizer.set_checkpoint(EveryEpoch(), checkpointPath) # set checkpoint to save model and optim method\n\ntrained_model = optimizer.optimize()", 
            "title": "Python example"
        }, 
        {
            "location": "/APIGuide/Optimizers/Optim-Methods/", 
            "text": "Adam\n\n\nScala:\n\n\nval optim = new Adam(learningRate=1e-3, learningRateDecay=0.0, beta1=0.9, beta2=0.999, Epsilon=1e-8)\n\n\n\n\nPython:\n\n\noptim = Adam(learningRate=1e-3, learningRateDecay-0.0, beta1=0.9, beta2=0.999, Epsilon=1e-8, bigdl_type=\nfloat\n)\n\n\n\n\nAn implementation of Adam optimization, first-order gradient-based optimization of stochastic  objective  functions. http://arxiv.org/pdf/1412.6980.pdf\n\n\nlearningRate\n learning rate. Default value is 1e-3. \n\n\nlearningRateDecay\n learning rate decay. Default value is 0.0.\n\n\nbeta1\n first moment coefficient. Default value is 0.9.\n\n\nbeta2\n second moment coefficient. Default value is 0.999.\n\n\nEpsilon\n for numerical stability. Default value is 1e-8.\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval optm = new Adam(learningRate=0.002)\ndef rosenBrock(x: Tensor[Float]): (Float, Tensor[Float]) = {\n    // (1) compute f(x)\n    val d = x.size(1)\n\n    // x1 = x(i)\n    val x1 = Tensor[Float](d - 1).copy(x.narrow(1, 1, d - 1))\n    // x(i + 1) - x(i)^2\n    x1.cmul(x1).mul(-1).add(x.narrow(1, 2, d - 1))\n    // 100 * (x(i + 1) - x(i)^2)^2\n    x1.cmul(x1).mul(100)\n\n    // x0 = x(i)\n    val x0 = Tensor[Float](d - 1).copy(x.narrow(1, 1, d - 1))\n    // 1-x(i)\n    x0.mul(-1).add(1)\n    x0.cmul(x0)\n    // 100*(x(i+1) - x(i)^2)^2 + (1-x(i))^2\n    x1.add(x0)\n\n    val fout = x1.sum()\n\n    // (2) compute f(x)/dx\n    val dxout = Tensor[Float]().resizeAs(x).zero()\n    // df(1:D-1) = - 400*x(1:D-1).*(x(2:D)-x(1:D-1).^2) - 2*(1-x(1:D-1));\n    x1.copy(x.narrow(1, 1, d - 1))\n    x1.cmul(x1).mul(-1).add(x.narrow(1, 2, d - 1)).cmul(x.narrow(1, 1, d - 1)).mul(-400)\n    x0.copy(x.narrow(1, 1, d - 1)).mul(-1).add(1).mul(-2)\n    x1.add(x0)\n    dxout.narrow(1, 1, d - 1).copy(x1)\n\n    // df(2:D) = df(2:D) + 200*(x(2:D)-x(1:D-1).^2);\n    x0.copy(x.narrow(1, 1, d - 1))\n    x0.cmul(x0).mul(-1).add(x.narrow(1, 2, d - 1)).mul(200)\n    dxout.narrow(1, 2, d - 1).add(x0)\n\n    (fout, dxout)\n  }  \nval x = Tensor(2).fill(0)\n\n print(optm.optimize(rosenBrock, x))\n(0.0019999996\n0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcD$sp of size 2],[D@302d88d8)\n\n\n\n\nPython example:\n\n\noptim_method = Adam(learningrate=0.002)\n\noptimizer = Optimizer(\n    model=mlp_model,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=optim_method,\n    end_trigger=MaxEpoch(20),\n    batch_size=32)\n\n\n\n\n\nSGD\n\n\nScala:\n\n\nval optimMethod = SGD(learningRate= 1e-3,learningRateDecay=0.0,\n                      weightDecay=0.0,momentum=0.0,dampening=Double.MaxValue,\n                      nesterov=false,learningRateSchedule=Default(),\n                      learningRates=null,weightDecays=null)\n\n\n\n\nPython:\n\n\noptim_method = SGD(learningrate=1e-3,learningrate_decay=0.0,weightdecay=0.0,\n                   momentum=0.0,dampening=DOUBLEMAX,nesterov=False,\n                   leaningrate_schedule=None,learningrates=None,\n                   weightdecays=None,bigdl_type=\nfloat\n)\n\n\n\n\nA plain implementation of SGD which provides optimize method. After setting \noptimization method when create Optimize, Optimize will call optimization method at the end of \neach iteration.\n\n\nScala example:\n\n\nval optimMethod = new SGD[Float](learningRate= 1e-3,learningRateDecay=0.0,\n                               weightDecay=0.0,momentum=0.0,dampening=Double.MaxValue,\n                               nesterov=false,learningRateSchedule=Default(),\n                               learningRates=null,weightDecays=null)\noptimizer.setOptimMethod(optimMethod)\n\n\n\n\nPython example:\n\n\noptim_method = SGD(learningrate=1e-3,learningrate_decay=0.0,weightdecay=0.0,\n                  momentum=0.0,dampening=DOUBLEMAX,nesterov=False,\n                  leaningrate_schedule=None,learningrates=None,\n                  weightdecays=None,bigdl_type=\nfloat\n)\n\noptimizer = Optimizer(\n    model=mlp_model,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=optim_method,\n    end_trigger=MaxEpoch(20),\n    batch_size=32)\n\n\n\n\nAdadelta\n\n\nAdaDelta\n implementation for \nSGD\n \nIt has been proposed in \nADADELTA: An Adaptive Learning Rate Method\n.\nhttp://arxiv.org/abs/1212.5701.\n\n\nScala:\n\n\nval optimMethod = Adadelta(decayRate = 0.9, Epsilon = 1e-10)\n\n\n\n\nPython:\n\n\noptim_method = AdaDelta(decayrate = 0.9, epsilon = 1e-10)\n\n\n\n\nScala example:\n\n\noptimizer.setOptimMethod(new Adadelta(0.9, 1e-10))\n\n\n\n\n\nPython example:\n\n\noptimizer = Optimizer(\n    model=mlp_model,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=Adadelta(0.9, 0.00001),\n    end_trigger=MaxEpoch(20),\n    batch_size=32)\n\n\n\n\nRMSprop\n\n\nAn implementation of RMSprop (Reference: http://arxiv.org/pdf/1308.0850v5.pdf, Sec 4.2)\n\n\n\n\nlearningRate : learning rate\n\n\nlearningRateDecay : learning rate decay\n\n\ndecayRate : decayRate, also called rho\n\n\nEpsilone : for numerical stability\n\n\n\n\nAdamax\n\n\nAn implementation of Adamax http://arxiv.org/pdf/1412.6980.pdf\n\n\nArguments:\n\n\n\n\nlearningRate : learning rate\n\n\nbeta1 : first moment coefficient\n\n\nbeta2 : second moment coefficient\n\n\nEpsilon : for numerical stability\n\n\n\n\nReturns:\n\n\nthe new x vector and the function list {fx}, evaluated before the update\n\n\nAdagrad\n\n\nScala:\n\n\nval adagrad = new Adagrad(learningRate = 1e-3,\n                          learningRateDecay = 0.0,\n                          weightDecay = 0.0)\n\n\n\n\n\nAn implementation of Adagrad. See the original paper:\n \nhttp://jmlr.org/papers/volume12/duchi11a/duchi11a.pdf\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.tensor._\nval adagrad = Adagrad(0.01, 0.0, 0.0)\n    def feval(x: Tensor[Float]): (Float, Tensor[Float]) = {\n      // (1) compute f(x)\n      val d = x.size(1)\n      // x1 = x(i)\n      val x1 = Tensor[Float](d - 1).copy(x.narrow(1, 1, d - 1))\n      // x(i + 1) - x(i)^2\n      x1.cmul(x1).mul(-1).add(x.narrow(1, 2, d - 1))\n      // 100 * (x(i + 1) - x(i)^2)^2\n      x1.cmul(x1).mul(100)\n      // x0 = x(i)\n      val x0 = Tensor[Float](d - 1).copy(x.narrow(1, 1, d - 1))\n      // 1-x(i)\n      x0.mul(-1).add(1)\n      x0.cmul(x0)\n      // 100*(x(i+1) - x(i)^2)^2 + (1-x(i))^2\n      x1.add(x0)\n      val fout = x1.sum()\n      // (2) compute f(x)/dx\n      val dxout = Tensor[Float]().resizeAs(x).zero()\n      // df(1:D-1) = - 400*x(1:D-1).*(x(2:D)-x(1:D-1).^2) - 2*(1-x(1:D-1));\n      x1.copy(x.narrow(1, 1, d - 1))\n      x1.cmul(x1).mul(-1).add(x.narrow(1, 2, d - 1)).cmul(x.narrow(1, 1, d - 1)).mul(-400)\n      x0.copy(x.narrow(1, 1, d - 1)).mul(-1).add(1).mul(-2)\n      x1.add(x0)\n      dxout.narrow(1, 1, d - 1).copy(x1)\n      // df(2:D) = df(2:D) + 200*(x(2:D)-x(1:D-1).^2);\n      x0.copy(x.narrow(1, 1, d - 1))\n      x0.cmul(x0).mul(-1).add(x.narrow(1, 2, d - 1)).mul(200)\n      dxout.narrow(1, 2, d - 1).add(x0)\n      (fout, dxout)\n    }\nval x = Tensor(2).fill(0)\nval config = T(\nlearningRate\n -\n 1e-1)\nfor (i \n- 1 to 10) {\n  adagrad.optimize(feval, x, config, config)\n}\nx after optimize: 0.27779138\n0.07226955\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2]\n\n\n\n\nScala:\n\n\nval optimMethod = new LBFGS(maxIter=20, maxEval=Double.MaxValue,\n                            tolFun=1e-5, tolX=1e-9, nCorrection=100,\n                            learningRate=1.0, lineSearch=None, lineSearchOptions=None)\n\n\n\n\nPython:\n\n\noptim_method = LBFGS(max_iter=20, max_eval=Double.MaxValue, \\\n                 tol_fun=1e-5, tol_x=1e-9, n_correction=100, \\\n                 learning_rate=1.0, line_search=None, line_search_options=None)\n\n\n\n\nThis implementation of L-BFGS relies on a user-provided line search function\n(state.lineSearch). If this function is not provided, then a simple learningRate\nis used to produce fixed size steps. Fixed size steps are much less costly than line\nsearches, and can be useful for stochastic problems.\n\n\nThe learning rate is used even when a line search is provided.This is also useful for\nlarge-scale stochastic problems, where opfunc is a noisy approximation of f(x). In that\ncase, the learning rate allows a reduction of confidence in the step size.\n\n\nParameters:\n\n\n\n\nmaxIter - Maximum number of iterations allowed. Default: 20\n\n\nmaxEval - Maximum number of function evaluations. Default: Double.MaxValue\n\n\ntolFun - Termination tolerance on the first-order optimality. Default: 1e-5\n\n\ntolX - Termination tol on progress in terms of func/param changes. Default: 1e-9\n\n\nlearningRate - the learning rate. Default: 1.0\n\n\nlineSearch - A line search function. Default: None\n\n\nlineSearchOptions - If no line search provided, then a fixed step size is used. Default: None\n\n\n\n\nScala example:\n\n\nval optimMethod = new LBFGS(maxIter=20, maxEval=Double.MaxValue,\n                            tolFun=1e-5, tolX=1e-9, nCorrection=100,\n                            learningRate=1.0, lineSearch=None, lineSearchOptions=None)\noptimizer.setOptimMethod(optimMethod)\n\n\n\n\nPython example:\n\n\noptim_method = LBFGS(max_iter=20, max_eval=DOUBLEMAX, \\\n                 tol_fun=1e-5, tol_x=1e-9, n_correction=100, \\\n                 learning_rate=1.0, line_search=None, line_search_options=None)\n\noptimizer = Optimizer(\n    model=mlp_model,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=optim_method,\n    end_trigger=MaxEpoch(20),\n    batch_size=32)", 
            "title": "Optimization Algorithms"
        }, 
        {
            "location": "/APIGuide/Optimizers/Optim-Methods/#adam", 
            "text": "Scala:  val optim = new Adam(learningRate=1e-3, learningRateDecay=0.0, beta1=0.9, beta2=0.999, Epsilon=1e-8)  Python:  optim = Adam(learningRate=1e-3, learningRateDecay-0.0, beta1=0.9, beta2=0.999, Epsilon=1e-8, bigdl_type= float )  An implementation of Adam optimization, first-order gradient-based optimization of stochastic  objective  functions. http://arxiv.org/pdf/1412.6980.pdf  learningRate  learning rate. Default value is 1e-3.   learningRateDecay  learning rate decay. Default value is 0.0.  beta1  first moment coefficient. Default value is 0.9.  beta2  second moment coefficient. Default value is 0.999.  Epsilon  for numerical stability. Default value is 1e-8.  Scala example:  import com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval optm = new Adam(learningRate=0.002)\ndef rosenBrock(x: Tensor[Float]): (Float, Tensor[Float]) = {\n    // (1) compute f(x)\n    val d = x.size(1)\n\n    // x1 = x(i)\n    val x1 = Tensor[Float](d - 1).copy(x.narrow(1, 1, d - 1))\n    // x(i + 1) - x(i)^2\n    x1.cmul(x1).mul(-1).add(x.narrow(1, 2, d - 1))\n    // 100 * (x(i + 1) - x(i)^2)^2\n    x1.cmul(x1).mul(100)\n\n    // x0 = x(i)\n    val x0 = Tensor[Float](d - 1).copy(x.narrow(1, 1, d - 1))\n    // 1-x(i)\n    x0.mul(-1).add(1)\n    x0.cmul(x0)\n    // 100*(x(i+1) - x(i)^2)^2 + (1-x(i))^2\n    x1.add(x0)\n\n    val fout = x1.sum()\n\n    // (2) compute f(x)/dx\n    val dxout = Tensor[Float]().resizeAs(x).zero()\n    // df(1:D-1) = - 400*x(1:D-1).*(x(2:D)-x(1:D-1).^2) - 2*(1-x(1:D-1));\n    x1.copy(x.narrow(1, 1, d - 1))\n    x1.cmul(x1).mul(-1).add(x.narrow(1, 2, d - 1)).cmul(x.narrow(1, 1, d - 1)).mul(-400)\n    x0.copy(x.narrow(1, 1, d - 1)).mul(-1).add(1).mul(-2)\n    x1.add(x0)\n    dxout.narrow(1, 1, d - 1).copy(x1)\n\n    // df(2:D) = df(2:D) + 200*(x(2:D)-x(1:D-1).^2);\n    x0.copy(x.narrow(1, 1, d - 1))\n    x0.cmul(x0).mul(-1).add(x.narrow(1, 2, d - 1)).mul(200)\n    dxout.narrow(1, 2, d - 1).add(x0)\n\n    (fout, dxout)\n  }  \nval x = Tensor(2).fill(0)  print(optm.optimize(rosenBrock, x))\n(0.0019999996\n0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcD$sp of size 2],[D@302d88d8)  Python example:  optim_method = Adam(learningrate=0.002)\n\noptimizer = Optimizer(\n    model=mlp_model,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=optim_method,\n    end_trigger=MaxEpoch(20),\n    batch_size=32)", 
            "title": "Adam"
        }, 
        {
            "location": "/APIGuide/Optimizers/Optim-Methods/#sgd", 
            "text": "Scala:  val optimMethod = SGD(learningRate= 1e-3,learningRateDecay=0.0,\n                      weightDecay=0.0,momentum=0.0,dampening=Double.MaxValue,\n                      nesterov=false,learningRateSchedule=Default(),\n                      learningRates=null,weightDecays=null)  Python:  optim_method = SGD(learningrate=1e-3,learningrate_decay=0.0,weightdecay=0.0,\n                   momentum=0.0,dampening=DOUBLEMAX,nesterov=False,\n                   leaningrate_schedule=None,learningrates=None,\n                   weightdecays=None,bigdl_type= float )  A plain implementation of SGD which provides optimize method. After setting \noptimization method when create Optimize, Optimize will call optimization method at the end of \neach iteration.  Scala example:  val optimMethod = new SGD[Float](learningRate= 1e-3,learningRateDecay=0.0,\n                               weightDecay=0.0,momentum=0.0,dampening=Double.MaxValue,\n                               nesterov=false,learningRateSchedule=Default(),\n                               learningRates=null,weightDecays=null)\noptimizer.setOptimMethod(optimMethod)  Python example:  optim_method = SGD(learningrate=1e-3,learningrate_decay=0.0,weightdecay=0.0,\n                  momentum=0.0,dampening=DOUBLEMAX,nesterov=False,\n                  leaningrate_schedule=None,learningrates=None,\n                  weightdecays=None,bigdl_type= float )\n\noptimizer = Optimizer(\n    model=mlp_model,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=optim_method,\n    end_trigger=MaxEpoch(20),\n    batch_size=32)", 
            "title": "SGD"
        }, 
        {
            "location": "/APIGuide/Optimizers/Optim-Methods/#adadelta", 
            "text": "AdaDelta  implementation for  SGD  \nIt has been proposed in  ADADELTA: An Adaptive Learning Rate Method .\nhttp://arxiv.org/abs/1212.5701.  Scala:  val optimMethod = Adadelta(decayRate = 0.9, Epsilon = 1e-10)  Python:  optim_method = AdaDelta(decayrate = 0.9, epsilon = 1e-10)  Scala example:  optimizer.setOptimMethod(new Adadelta(0.9, 1e-10))  Python example:  optimizer = Optimizer(\n    model=mlp_model,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=Adadelta(0.9, 0.00001),\n    end_trigger=MaxEpoch(20),\n    batch_size=32)", 
            "title": "Adadelta"
        }, 
        {
            "location": "/APIGuide/Optimizers/Optim-Methods/#rmsprop", 
            "text": "An implementation of RMSprop (Reference: http://arxiv.org/pdf/1308.0850v5.pdf, Sec 4.2)   learningRate : learning rate  learningRateDecay : learning rate decay  decayRate : decayRate, also called rho  Epsilone : for numerical stability", 
            "title": "RMSprop"
        }, 
        {
            "location": "/APIGuide/Optimizers/Optim-Methods/#adamax", 
            "text": "An implementation of Adamax http://arxiv.org/pdf/1412.6980.pdf  Arguments:   learningRate : learning rate  beta1 : first moment coefficient  beta2 : second moment coefficient  Epsilon : for numerical stability   Returns:  the new x vector and the function list {fx}, evaluated before the update", 
            "title": "Adamax"
        }, 
        {
            "location": "/APIGuide/Optimizers/Optim-Methods/#adagrad", 
            "text": "Scala:  val adagrad = new Adagrad(learningRate = 1e-3,\n                          learningRateDecay = 0.0,\n                          weightDecay = 0.0)  An implementation of Adagrad. See the original paper:\n  http://jmlr.org/papers/volume12/duchi11a/duchi11a.pdf  Scala example:  import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.tensor._\nval adagrad = Adagrad(0.01, 0.0, 0.0)\n    def feval(x: Tensor[Float]): (Float, Tensor[Float]) = {\n      // (1) compute f(x)\n      val d = x.size(1)\n      // x1 = x(i)\n      val x1 = Tensor[Float](d - 1).copy(x.narrow(1, 1, d - 1))\n      // x(i + 1) - x(i)^2\n      x1.cmul(x1).mul(-1).add(x.narrow(1, 2, d - 1))\n      // 100 * (x(i + 1) - x(i)^2)^2\n      x1.cmul(x1).mul(100)\n      // x0 = x(i)\n      val x0 = Tensor[Float](d - 1).copy(x.narrow(1, 1, d - 1))\n      // 1-x(i)\n      x0.mul(-1).add(1)\n      x0.cmul(x0)\n      // 100*(x(i+1) - x(i)^2)^2 + (1-x(i))^2\n      x1.add(x0)\n      val fout = x1.sum()\n      // (2) compute f(x)/dx\n      val dxout = Tensor[Float]().resizeAs(x).zero()\n      // df(1:D-1) = - 400*x(1:D-1).*(x(2:D)-x(1:D-1).^2) - 2*(1-x(1:D-1));\n      x1.copy(x.narrow(1, 1, d - 1))\n      x1.cmul(x1).mul(-1).add(x.narrow(1, 2, d - 1)).cmul(x.narrow(1, 1, d - 1)).mul(-400)\n      x0.copy(x.narrow(1, 1, d - 1)).mul(-1).add(1).mul(-2)\n      x1.add(x0)\n      dxout.narrow(1, 1, d - 1).copy(x1)\n      // df(2:D) = df(2:D) + 200*(x(2:D)-x(1:D-1).^2);\n      x0.copy(x.narrow(1, 1, d - 1))\n      x0.cmul(x0).mul(-1).add(x.narrow(1, 2, d - 1)).mul(200)\n      dxout.narrow(1, 2, d - 1).add(x0)\n      (fout, dxout)\n    }\nval x = Tensor(2).fill(0)\nval config = T( learningRate  -  1e-1)\nfor (i  - 1 to 10) {\n  adagrad.optimize(feval, x, config, config)\n}\nx after optimize: 0.27779138\n0.07226955\n[com.intel.analytics.bigdl.tensor.DenseTensor$mcF$sp of size 2]  Scala:  val optimMethod = new LBFGS(maxIter=20, maxEval=Double.MaxValue,\n                            tolFun=1e-5, tolX=1e-9, nCorrection=100,\n                            learningRate=1.0, lineSearch=None, lineSearchOptions=None)  Python:  optim_method = LBFGS(max_iter=20, max_eval=Double.MaxValue, \\\n                 tol_fun=1e-5, tol_x=1e-9, n_correction=100, \\\n                 learning_rate=1.0, line_search=None, line_search_options=None)  This implementation of L-BFGS relies on a user-provided line search function\n(state.lineSearch). If this function is not provided, then a simple learningRate\nis used to produce fixed size steps. Fixed size steps are much less costly than line\nsearches, and can be useful for stochastic problems.  The learning rate is used even when a line search is provided.This is also useful for\nlarge-scale stochastic problems, where opfunc is a noisy approximation of f(x). In that\ncase, the learning rate allows a reduction of confidence in the step size.  Parameters:   maxIter - Maximum number of iterations allowed. Default: 20  maxEval - Maximum number of function evaluations. Default: Double.MaxValue  tolFun - Termination tolerance on the first-order optimality. Default: 1e-5  tolX - Termination tol on progress in terms of func/param changes. Default: 1e-9  learningRate - the learning rate. Default: 1.0  lineSearch - A line search function. Default: None  lineSearchOptions - If no line search provided, then a fixed step size is used. Default: None   Scala example:  val optimMethod = new LBFGS(maxIter=20, maxEval=Double.MaxValue,\n                            tolFun=1e-5, tolX=1e-9, nCorrection=100,\n                            learningRate=1.0, lineSearch=None, lineSearchOptions=None)\noptimizer.setOptimMethod(optimMethod)  Python example:  optim_method = LBFGS(max_iter=20, max_eval=DOUBLEMAX, \\\n                 tol_fun=1e-5, tol_x=1e-9, n_correction=100, \\\n                 learning_rate=1.0, line_search=None, line_search_options=None)\n\noptimizer = Optimizer(\n    model=mlp_model,\n    training_rdd=train_data,\n    criterion=ClassNLLCriterion(),\n    optim_method=optim_method,\n    end_trigger=MaxEpoch(20),\n    batch_size=32)", 
            "title": "Adagrad"
        }, 
        {
            "location": "/APIGuide/Optimizers/Learningrate-Scheduler/", 
            "text": "Poly\n\n\nScala:\n\n\nval lrScheduler = Poly(power=0.5, maxIteration=1000)\n\n\n\n\nPython:\n\n\nlr_scheduler = Poly(power=0.5, max_iteration=1000, bigdl_type=\nfloat\n)\n\n\n\n\nA learning rate decay policy, where the effective learning rate follows a polynomial decay, to be zero by the max_iteration. Calculation: base_lr (1 - iter/maxIteration) \n^\n (power)\n\n\npower\n coeffient of decay, refer to calculation formula\n\n\nmaxIteration\n max iteration when lr becomes zero\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval optimMethod = new SGD[Double](0.1)\noptimMethod.learningRateSchedule = Poly(3, 100)\ndef feval(x: Tensor[Double]): (Double, Tensor[Double]) = {\n  return (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))\n}\nval x = Tensor[Double](Storage(Array(10.0, 10.0)))\noptimMethod.optimize(feval, x)\n\n print(optimMethod.learningRateSchedule.currentRate)\n-0.1\noptimMethod.optimize(feval, x)\n\n print(optimMethod.learningRateSchedule.currentRate)\n-0.0970299\n\n\n\n\nPython example:\n\n\noptim_method = SGD(0.1)\noptimMethod.learningRateSchedule = Poly(3, 100)\n\n\n\n\nDefault\n\n\nIt is the default learning rate schedule. For each iteration, the learning rate would update with the following formula:\n l_{n + 1} = l / (1 + n * learning_rate_decay) where \nl\n is the initial learning rate\n\n\nScala:\n\n\nval lrScheduler = Default()\n\n\n\n\nPython:\n\n\nlr_scheduler = Default()\n\n\n\n\nScala example:\n\n\nval optimMethod = new SGD[Double](0.1, 0.1)\ndef feval(x: Tensor[Double]): (Double, Tensor[Double]) = {\n  return (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))\n}\nval x = Tensor[Double](Storage(Array(10.0, 10.0)))\noptimMethod.optimize(feval, x)\n\n print(optimMethod.learningRateSchedule.currentRate)\n-0.1\noptimMethod.optimize(feval, x)\n\n print(optimMethod.learningRateSchedule.currentRate)\n-0.09090909090909091\noptimMethod.optimize(feval, x)\n\n print(optimMethod.learningRateSchedule.currentRate)\n-0.08333333333333334\n\n\n\n\nPython example:\n\n\noptimMethod = SGD(leaningrate_schedule=Default())\n\n\n\n\nNaturalExp\n\n\nA learning rate schedule, which rescale the learning rate by exp ( -decay_rate * iter / decay_step ) referring to tensorflow's learning rate decay # natural_exp_decay\n\n\ndecay_step\n how often to apply decay\n\n\ngamma\n the decay rate. e.g. 0.96\n\n\nScala:\n\n\nval learningRateScheduler = NaturalExp(1, 1)\n\n\n\n\nScala example:\n\n\nval optimMethod = new SGD[Double](0.1)\noptimMethod.learningRateSchedule = NaturalExp(1, 1)\ndef feval(x: Tensor[Double]): (Double, Tensor[Double]) = {\n  (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))\n}\nval x = Tensor[Double](Storage(Array(10.0, 10.0)))\nval state = T(\nepoch\n -\n 0, \nevalCounter\n -\n 0)\noptimMethod.state = state\noptimMethod.optimize(feval, x)\n\n print(optimMethod.learningRateSchedule.currentRate)\n-0.1\n\noptimMethod.optimize(feval, x)\n\n print(optimMethod.learningRateSchedule.currentRate)\n-0.036787944117144235\n\noptimMethod.optimize(feval, x)\n\n print(optimMethod.learningRateSchedule.currentRate)\n-0.013533528323661271\n\n\n\n\nExponential\n\n\nA learning rate schedule, which rescale the learning rate by lr_{n + 1} = lr * decayRate \n^\n (iter / decayStep)\n\n\ndecayStep\n the inteval for lr decay\n\n\ndecayRate\n decay rate\n\n\nstairCase\n if true, iter / decayStep is an integer division and the decayed learning rate follows a staircase function.\n\n\nScala:\n\n\nval learningRateSchedule = Exponential(10, 0.96)\n\n\n\n\nPython:\n\n\nexponential = Exponential(100, 0.1)\n\n\n\n\nScala example:\n\n\nval optimMethod = new SGD[Double](0.05)\noptimMethod.learningRateSchedule = Exponential(10, 0.96)\ndef feval(x: Tensor[Double]): (Double, Tensor[Double]) = {\n  (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))\n}\nval x = Tensor[Double](Storage(Array(10.0, 10.0)))\nval state = T(\nepoch\n -\n 0, \nevalCounter\n -\n 0)\noptimMethod.state = state\noptimMethod.optimize(feval, x)\n\n print(optimMethod.learningRateSchedule.currentRate)\n-0.05\n\noptimMethod.optimize(feval, x)\n\n print(optimMethod.learningRateSchedule.currentRate)\n-0.049796306069892535\n\n\n\n\nPython example:\n\n\noptimMethod = SGD(leaningrate_schedule=Exponential(100, 0.1))\n\n\n\n\nPlateau\n\n\nPlateau is the learning rate schedule when a metric has stopped improving. Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. It monitors a quantity and if no improvement is seen for a 'patience' number of epochs, the learning rate is reduced.\n\n\nmonitor\n quantity to be monitored, can be Loss or score\n\n\nfactor\n factor by which the learning rate will be reduced. new_lr = lr * factor\n\n\npatience\n number of epochs with no improvement after which learning rate will be reduced.\n\n\nmode\n one of {min, max}. In min mode, lr will be reduced when the quantity monitored has stopped decreasing;\n in max mode it will be reduced when the quantity monitored has stopped increasing\n\n\nepsilon\n threshold for measuring the new optimum, to only focus on significant changes.\n\n\ncooldown\n number of epochs to wait before resuming normal operation after lr has been reduced.\n\n\nminLr\n lower bound on the learning rate.\n\n\nScala:\n\n\nval learningRateSchedule = Plateau(monitor=\nscore\n, factor=0.1, patience=10, mode=\nmin\n, epsilon=1e-4f, cooldown=0, minLr=0)\n\n\n\n\nPython:\n\n\nplateau = Plateau(\nscore\n, factor=0.1, patience=10, mode=\nmin\n, epsilon=1e-4, cooldown=0, minLr=0)\n\n\n\n\nScala example:\n\n\nval optimMethod = new SGD[Double](0.05)\noptimMethod.learningRateSchedule = Plateau(monitor=\nscore\n, factor=0.1, patience=10, mode=\nmin\n, epsilon=1e-4f, cooldown=0, minLr=0)\ndef feval(x: Tensor[Double]): (Double, Tensor[Double]) = {\n  (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))\n}\nval x = Tensor[Double](Storage(Array(10.0, 10.0)))\nval state = T(\nepoch\n -\n 0, \nevalCounter\n -\n 0)\noptimMethod.state = state\noptimMethod.optimize(feval, x)\n\n print(optimMethod.learningRateSchedule.currentRate)\n\n\noptimMethod.optimize(feval, x)\n\n print(optimMethod.learningRateSchedule.currentRate)\n\n\n\n\n\nPython example:\n\n\noptimMethod = SGD(leaningrate_schedule=Plateau(\nscore\n))\n\n\n\n\nWarmup\n\n\nA learning rate gradual increase policy, where the effective learning rate increase delta after each iteration. Calculation: base_lr + delta * iteration\n\n\ndelta\n increase amount after each iteration\n\n\nScala:\n\n\nval learningRateSchedule = Warmup(delta = 0.05)\n\n\n\n\nPython:\n\n\nwarmup = Warmup(delta=0.05)\n\n\n\n\nScala example:\n\n\nval lrSchedules = new SequentialSchedule(100)\nlrSchedules.add(Warmup(0.3), 3).add(Poly(3, 100), 100)\nval optimMethod = new SGD[Double](learningRate = 0.1, learningRateSchedule = lrSchedules)\n\ndef feval(x: Tensor[Double]): (Double, Tensor[Double]) = {\n  return (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))\n}\nval x = Tensor[Double](Storage(Array(10.0, 10.0)))\noptimMethod.optimize(feval, x)\n\n print(optimMethod.learningRateSchedule.currentRate)\n-0.1\n\noptimMethod.optimize(feval, x)\n\n print(optimMethod.learningRateSchedule.currentRate)\n-0.4\n\n\n\n\nPython example:\n\n\noptimMethod = SGD(leaningrate_schedule=Warmup(0.05))\n\n\n\n\nSequentialSchedule\n\n\nA learning rate scheduler which can stack several learning rate schedulers.\n\n\niterationPerEpoch\n iteration numbers per epoch\n\n\nScala:\n\n\nval learningRateSchedule = SequentialSchedule(iterationPerEpoch=100)\n\n\n\n\nPython:\n\n\nsequentialSchedule = SequentialSchedule(iteration_per_epoch=5)\n\n\n\n\nScala example:\n\n\nval lrSchedules = new SequentialSchedule(100)\nlrSchedules.add(Warmup(0.3), 3).add(Poly(3, 100), 100)\nval optimMethod = new SGD[Double](learningRate = 0.1, learningRateSchedule = lrSchedules)\n\ndef feval(x: Tensor[Double]): (Double, Tensor[Double]) = {\n  return (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))\n}\nval x = Tensor[Double](Storage(Array(10.0, 10.0)))\noptimMethod.optimize(feval, x)\n\n print(optimMethod.learningRateSchedule.currentRate)\n-0.1\n\noptimMethod.optimize(feval, x)\n\n print(optimMethod.learningRateSchedule.currentRate)\n-0.4\n\noptimMethod.optimize(feval, x)\n\n print(optimMethod.learningRateSchedule.currentRate)\n-0.7\n\noptimMethod.optimize(feval, x)\n\n print(optimMethod.learningRateSchedule.currentRate)\n-1.0\n\noptimMethod.optimize(feval, x)\n\n print(optimMethod.learningRateSchedule.currentRate)\n-0.9702989999999999\n\n\n\n\nPython example:\n\n\nsequentialSchedule = SequentialSchedule(5)\npoly = Poly(0.5, 2)\nsequentialSchedule.add(poly, 5)\n\n\n\n\nEpochDecay\n\n\nScala:\n\n\ndef decay(epoch: Int): Double =\n  if (epoch \n= 1) 2.0 else if (epoch \n= 2) 1.0 else 0.0\n\nval learningRateSchedule = EpochDecay(decay)\n\n\n\n\nIt is an epoch decay learning rate schedule. The learning rate decays through a function argument on number of run epochs l_{n + 1} = l_{n} * 0.1 \n^\n decayType(epoch)\n\n\ndecayType\n is a function with number of run epochs as the argument\n\n\nScala example:\n\n\ndef decay(epoch: Int): Double =\n  if (epoch == 1) 2.0 else if (epoch == 2) 1.0 else 0.0\n\nval optimMethod = new SGD[Double](1000)\noptimMethod.learningRateSchedule = EpochDecay(decay)\ndef feval(x: Tensor[Double]): (Double, Tensor[Double]) = {\n  return (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))\n}\nval x = Tensor[Double](Storage(Array(10.0, 10.0)))\nval state = T(\nepoch\n -\n 0)\nfor(e \n- 1 to 3) {\n  state(\nepoch\n) = e\n  optimMethod.state = state\n  optimMethod.optimize(feval, x)\n  if(e \n= 1) {\n    assert(optimMethod.learningRateSchedule.currentRate==10)\n  } else if (e \n= 2) {\n    assert(optimMethod.learningRateSchedule.currentRate==100)\n  } else {\n    assert(optimMethod.learningRateSchedule.currentRate==1000)\n  }\n}\n\n\n\n\nRegime\n\n\nA structure to specify hyper parameters by start epoch and end epoch. Usually work with [[EpochSchedule]].\n\n\nstartEpoch\n start epoch\n\n\nendEpoch\n end epoch\n\n\nconfig\n config table contains hyper parameters\n\n\nEpochSchedule\n\n\nA learning rate schedule which configure the learning rate according to some pre-defined [[Regime]]. If the running epoch is within the interval of a regime \nr\n [r.startEpoch, r.endEpoch], then the learning\n rate will take the \"learningRate\" in r.config.\n\n\nregimes\n an array of pre-defined [[Regime]].\n\n\nScala:\n\n\nval regimes: Array[Regime] = Array(\n  Regime(1, 3, T(\nlearningRate\n -\n 1e-2, \nweightDecay\n -\n 2e-4)),\n  Regime(4, 7, T(\nlearningRate\n -\n 5e-3, \nweightDecay\n -\n 2e-4)),\n  Regime(8, 10, T(\nlearningRate\n -\n 1e-3, \nweightDecay\n -\n 0.0))\n)\nval learningRateScheduler = EpochSchedule(regimes)\n\n\n\n\nScala example:\n\n\nval regimes: Array[Regime] = Array(\n  Regime(1, 3, T(\nlearningRate\n -\n 1e-2, \nweightDecay\n -\n 2e-4)),\n  Regime(4, 7, T(\nlearningRate\n -\n 5e-3, \nweightDecay\n -\n 2e-4)),\n  Regime(8, 10, T(\nlearningRate\n -\n 1e-3, \nweightDecay\n -\n 0.0))\n)\n\nval state = T(\nepoch\n -\n 0)\nval optimMethod = new SGD[Double](0.1)\noptimMethod.learningRateSchedule = EpochSchedule(regimes)\ndef feval(x: Tensor[Double]): (Double, Tensor[Double]) = {\n  return (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))\n}\nval x = Tensor[Double](Storage(Array(10.0, 10.0)))\nfor(e \n- 1 to 10) {\n  state(\nepoch\n) = e\n  optimMethod.state = state\n  optimMethod.optimize(feval, x)\n  if(e \n= 3) {\n    assert(optimMethod.learningRateSchedule.currentRate==-1e-2)\n    assert(optimMethod.weightDecay==2e-4)\n  } else if (e \n= 7) {\n    assert(optimMethod.learningRateSchedule.currentRate==-5e-3)\n    assert(optimMethod.weightDecay==2e-4)\n  } else if (e \n= 10) {\n    assert(optimMethod.learningRateSchedule.currentRate==-1e-3)\n    assert(optimMethod.weightDecay==0.0)\n  }\n}\n\n\n\n\nEpochStep\n\n\nA learning rate schedule which rescale the learning rate by \ngamma\n for each \nstepSize\n epochs.\n\n\nstepSize\n For how many epochs to update the learning rate once\n\n\ngamma\n the rescale factor\n\n\nScala:\n\n \nscala\n val learningRateScheduler = EpochStep(1, 0.5)\n\n\nScala example:\n\n \nscala\n val optimMethod = new SGD[Double](0.1)\n optimMethod.learningRateSchedule = EpochStep(1, 0.5)\n def feval(x: Tensor[Double]): (Double, Tensor[Double]) = {\n   (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))\n }\n val x = Tensor[Double](Storage(Array(10.0, 10.0)))\n val state = T(\"epoch\" -\n 0)\n for(e \n- 1 to 10) {\n   state(\"epoch\") = e\n   optimMethod.state = state\n   optimMethod.optimize(feval, x)\n   assert(optimMethod.learningRateSchedule.currentRate==(-0.1 * Math.pow(0.5, e)))\n }", 
            "title": "LearningRate Scheduler"
        }, 
        {
            "location": "/APIGuide/Optimizers/Learningrate-Scheduler/#poly", 
            "text": "Scala:  val lrScheduler = Poly(power=0.5, maxIteration=1000)  Python:  lr_scheduler = Poly(power=0.5, max_iteration=1000, bigdl_type= float )  A learning rate decay policy, where the effective learning rate follows a polynomial decay, to be zero by the max_iteration. Calculation: base_lr (1 - iter/maxIteration)  ^  (power)  power  coeffient of decay, refer to calculation formula  maxIteration  max iteration when lr becomes zero  Scala example:  import com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.T\n\nval optimMethod = new SGD[Double](0.1)\noptimMethod.learningRateSchedule = Poly(3, 100)\ndef feval(x: Tensor[Double]): (Double, Tensor[Double]) = {\n  return (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))\n}\nval x = Tensor[Double](Storage(Array(10.0, 10.0)))\noptimMethod.optimize(feval, x)  print(optimMethod.learningRateSchedule.currentRate)\n-0.1\noptimMethod.optimize(feval, x)  print(optimMethod.learningRateSchedule.currentRate)\n-0.0970299  Python example:  optim_method = SGD(0.1)\noptimMethod.learningRateSchedule = Poly(3, 100)", 
            "title": "Poly"
        }, 
        {
            "location": "/APIGuide/Optimizers/Learningrate-Scheduler/#default", 
            "text": "It is the default learning rate schedule. For each iteration, the learning rate would update with the following formula:\n l_{n + 1} = l / (1 + n * learning_rate_decay) where  l  is the initial learning rate  Scala:  val lrScheduler = Default()  Python:  lr_scheduler = Default()  Scala example:  val optimMethod = new SGD[Double](0.1, 0.1)\ndef feval(x: Tensor[Double]): (Double, Tensor[Double]) = {\n  return (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))\n}\nval x = Tensor[Double](Storage(Array(10.0, 10.0)))\noptimMethod.optimize(feval, x)  print(optimMethod.learningRateSchedule.currentRate)\n-0.1\noptimMethod.optimize(feval, x)  print(optimMethod.learningRateSchedule.currentRate)\n-0.09090909090909091\noptimMethod.optimize(feval, x)  print(optimMethod.learningRateSchedule.currentRate)\n-0.08333333333333334  Python example:  optimMethod = SGD(leaningrate_schedule=Default())", 
            "title": "Default"
        }, 
        {
            "location": "/APIGuide/Optimizers/Learningrate-Scheduler/#naturalexp", 
            "text": "A learning rate schedule, which rescale the learning rate by exp ( -decay_rate * iter / decay_step ) referring to tensorflow's learning rate decay # natural_exp_decay  decay_step  how often to apply decay  gamma  the decay rate. e.g. 0.96  Scala:  val learningRateScheduler = NaturalExp(1, 1)  Scala example:  val optimMethod = new SGD[Double](0.1)\noptimMethod.learningRateSchedule = NaturalExp(1, 1)\ndef feval(x: Tensor[Double]): (Double, Tensor[Double]) = {\n  (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))\n}\nval x = Tensor[Double](Storage(Array(10.0, 10.0)))\nval state = T( epoch  -  0,  evalCounter  -  0)\noptimMethod.state = state\noptimMethod.optimize(feval, x)  print(optimMethod.learningRateSchedule.currentRate)\n-0.1\n\noptimMethod.optimize(feval, x)  print(optimMethod.learningRateSchedule.currentRate)\n-0.036787944117144235\n\noptimMethod.optimize(feval, x)  print(optimMethod.learningRateSchedule.currentRate)\n-0.013533528323661271", 
            "title": "NaturalExp"
        }, 
        {
            "location": "/APIGuide/Optimizers/Learningrate-Scheduler/#exponential", 
            "text": "A learning rate schedule, which rescale the learning rate by lr_{n + 1} = lr * decayRate  ^  (iter / decayStep)  decayStep  the inteval for lr decay  decayRate  decay rate  stairCase  if true, iter / decayStep is an integer division and the decayed learning rate follows a staircase function.  Scala:  val learningRateSchedule = Exponential(10, 0.96)  Python:  exponential = Exponential(100, 0.1)  Scala example:  val optimMethod = new SGD[Double](0.05)\noptimMethod.learningRateSchedule = Exponential(10, 0.96)\ndef feval(x: Tensor[Double]): (Double, Tensor[Double]) = {\n  (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))\n}\nval x = Tensor[Double](Storage(Array(10.0, 10.0)))\nval state = T( epoch  -  0,  evalCounter  -  0)\noptimMethod.state = state\noptimMethod.optimize(feval, x)  print(optimMethod.learningRateSchedule.currentRate)\n-0.05\n\noptimMethod.optimize(feval, x)  print(optimMethod.learningRateSchedule.currentRate)\n-0.049796306069892535  Python example:  optimMethod = SGD(leaningrate_schedule=Exponential(100, 0.1))", 
            "title": "Exponential"
        }, 
        {
            "location": "/APIGuide/Optimizers/Learningrate-Scheduler/#plateau", 
            "text": "Plateau is the learning rate schedule when a metric has stopped improving. Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. It monitors a quantity and if no improvement is seen for a 'patience' number of epochs, the learning rate is reduced.  monitor  quantity to be monitored, can be Loss or score  factor  factor by which the learning rate will be reduced. new_lr = lr * factor  patience  number of epochs with no improvement after which learning rate will be reduced.  mode  one of {min, max}. In min mode, lr will be reduced when the quantity monitored has stopped decreasing;\n in max mode it will be reduced when the quantity monitored has stopped increasing  epsilon  threshold for measuring the new optimum, to only focus on significant changes.  cooldown  number of epochs to wait before resuming normal operation after lr has been reduced.  minLr  lower bound on the learning rate.  Scala:  val learningRateSchedule = Plateau(monitor= score , factor=0.1, patience=10, mode= min , epsilon=1e-4f, cooldown=0, minLr=0)  Python:  plateau = Plateau( score , factor=0.1, patience=10, mode= min , epsilon=1e-4, cooldown=0, minLr=0)  Scala example:  val optimMethod = new SGD[Double](0.05)\noptimMethod.learningRateSchedule = Plateau(monitor= score , factor=0.1, patience=10, mode= min , epsilon=1e-4f, cooldown=0, minLr=0)\ndef feval(x: Tensor[Double]): (Double, Tensor[Double]) = {\n  (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))\n}\nval x = Tensor[Double](Storage(Array(10.0, 10.0)))\nval state = T( epoch  -  0,  evalCounter  -  0)\noptimMethod.state = state\noptimMethod.optimize(feval, x)  print(optimMethod.learningRateSchedule.currentRate)\n\n\noptimMethod.optimize(feval, x)  print(optimMethod.learningRateSchedule.currentRate)  Python example:  optimMethod = SGD(leaningrate_schedule=Plateau( score ))", 
            "title": "Plateau"
        }, 
        {
            "location": "/APIGuide/Optimizers/Learningrate-Scheduler/#warmup", 
            "text": "A learning rate gradual increase policy, where the effective learning rate increase delta after each iteration. Calculation: base_lr + delta * iteration  delta  increase amount after each iteration  Scala:  val learningRateSchedule = Warmup(delta = 0.05)  Python:  warmup = Warmup(delta=0.05)  Scala example:  val lrSchedules = new SequentialSchedule(100)\nlrSchedules.add(Warmup(0.3), 3).add(Poly(3, 100), 100)\nval optimMethod = new SGD[Double](learningRate = 0.1, learningRateSchedule = lrSchedules)\n\ndef feval(x: Tensor[Double]): (Double, Tensor[Double]) = {\n  return (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))\n}\nval x = Tensor[Double](Storage(Array(10.0, 10.0)))\noptimMethod.optimize(feval, x)  print(optimMethod.learningRateSchedule.currentRate)\n-0.1\n\noptimMethod.optimize(feval, x)  print(optimMethod.learningRateSchedule.currentRate)\n-0.4  Python example:  optimMethod = SGD(leaningrate_schedule=Warmup(0.05))", 
            "title": "Warmup"
        }, 
        {
            "location": "/APIGuide/Optimizers/Learningrate-Scheduler/#sequentialschedule", 
            "text": "A learning rate scheduler which can stack several learning rate schedulers.  iterationPerEpoch  iteration numbers per epoch  Scala:  val learningRateSchedule = SequentialSchedule(iterationPerEpoch=100)  Python:  sequentialSchedule = SequentialSchedule(iteration_per_epoch=5)  Scala example:  val lrSchedules = new SequentialSchedule(100)\nlrSchedules.add(Warmup(0.3), 3).add(Poly(3, 100), 100)\nval optimMethod = new SGD[Double](learningRate = 0.1, learningRateSchedule = lrSchedules)\n\ndef feval(x: Tensor[Double]): (Double, Tensor[Double]) = {\n  return (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))\n}\nval x = Tensor[Double](Storage(Array(10.0, 10.0)))\noptimMethod.optimize(feval, x)  print(optimMethod.learningRateSchedule.currentRate)\n-0.1\n\noptimMethod.optimize(feval, x)  print(optimMethod.learningRateSchedule.currentRate)\n-0.4\n\noptimMethod.optimize(feval, x)  print(optimMethod.learningRateSchedule.currentRate)\n-0.7\n\noptimMethod.optimize(feval, x)  print(optimMethod.learningRateSchedule.currentRate)\n-1.0\n\noptimMethod.optimize(feval, x)  print(optimMethod.learningRateSchedule.currentRate)\n-0.9702989999999999  Python example:  sequentialSchedule = SequentialSchedule(5)\npoly = Poly(0.5, 2)\nsequentialSchedule.add(poly, 5)", 
            "title": "SequentialSchedule"
        }, 
        {
            "location": "/APIGuide/Optimizers/Learningrate-Scheduler/#epochdecay", 
            "text": "Scala:  def decay(epoch: Int): Double =\n  if (epoch  = 1) 2.0 else if (epoch  = 2) 1.0 else 0.0\n\nval learningRateSchedule = EpochDecay(decay)  It is an epoch decay learning rate schedule. The learning rate decays through a function argument on number of run epochs l_{n + 1} = l_{n} * 0.1  ^  decayType(epoch)  decayType  is a function with number of run epochs as the argument  Scala example:  def decay(epoch: Int): Double =\n  if (epoch == 1) 2.0 else if (epoch == 2) 1.0 else 0.0\n\nval optimMethod = new SGD[Double](1000)\noptimMethod.learningRateSchedule = EpochDecay(decay)\ndef feval(x: Tensor[Double]): (Double, Tensor[Double]) = {\n  return (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))\n}\nval x = Tensor[Double](Storage(Array(10.0, 10.0)))\nval state = T( epoch  -  0)\nfor(e  - 1 to 3) {\n  state( epoch ) = e\n  optimMethod.state = state\n  optimMethod.optimize(feval, x)\n  if(e  = 1) {\n    assert(optimMethod.learningRateSchedule.currentRate==10)\n  } else if (e  = 2) {\n    assert(optimMethod.learningRateSchedule.currentRate==100)\n  } else {\n    assert(optimMethod.learningRateSchedule.currentRate==1000)\n  }\n}", 
            "title": "EpochDecay"
        }, 
        {
            "location": "/APIGuide/Optimizers/Learningrate-Scheduler/#regime", 
            "text": "A structure to specify hyper parameters by start epoch and end epoch. Usually work with [[EpochSchedule]].  startEpoch  start epoch  endEpoch  end epoch  config  config table contains hyper parameters", 
            "title": "Regime"
        }, 
        {
            "location": "/APIGuide/Optimizers/Learningrate-Scheduler/#epochschedule", 
            "text": "A learning rate schedule which configure the learning rate according to some pre-defined [[Regime]]. If the running epoch is within the interval of a regime  r  [r.startEpoch, r.endEpoch], then the learning\n rate will take the \"learningRate\" in r.config.  regimes  an array of pre-defined [[Regime]].  Scala:  val regimes: Array[Regime] = Array(\n  Regime(1, 3, T( learningRate  -  1e-2,  weightDecay  -  2e-4)),\n  Regime(4, 7, T( learningRate  -  5e-3,  weightDecay  -  2e-4)),\n  Regime(8, 10, T( learningRate  -  1e-3,  weightDecay  -  0.0))\n)\nval learningRateScheduler = EpochSchedule(regimes)  Scala example:  val regimes: Array[Regime] = Array(\n  Regime(1, 3, T( learningRate  -  1e-2,  weightDecay  -  2e-4)),\n  Regime(4, 7, T( learningRate  -  5e-3,  weightDecay  -  2e-4)),\n  Regime(8, 10, T( learningRate  -  1e-3,  weightDecay  -  0.0))\n)\n\nval state = T( epoch  -  0)\nval optimMethod = new SGD[Double](0.1)\noptimMethod.learningRateSchedule = EpochSchedule(regimes)\ndef feval(x: Tensor[Double]): (Double, Tensor[Double]) = {\n  return (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))\n}\nval x = Tensor[Double](Storage(Array(10.0, 10.0)))\nfor(e  - 1 to 10) {\n  state( epoch ) = e\n  optimMethod.state = state\n  optimMethod.optimize(feval, x)\n  if(e  = 3) {\n    assert(optimMethod.learningRateSchedule.currentRate==-1e-2)\n    assert(optimMethod.weightDecay==2e-4)\n  } else if (e  = 7) {\n    assert(optimMethod.learningRateSchedule.currentRate==-5e-3)\n    assert(optimMethod.weightDecay==2e-4)\n  } else if (e  = 10) {\n    assert(optimMethod.learningRateSchedule.currentRate==-1e-3)\n    assert(optimMethod.weightDecay==0.0)\n  }\n}", 
            "title": "EpochSchedule"
        }, 
        {
            "location": "/APIGuide/Optimizers/Learningrate-Scheduler/#epochstep", 
            "text": "A learning rate schedule which rescale the learning rate by  gamma  for each  stepSize  epochs.  stepSize  For how many epochs to update the learning rate once  gamma  the rescale factor  Scala: \n  scala\n val learningRateScheduler = EpochStep(1, 0.5)  Scala example: \n  scala\n val optimMethod = new SGD[Double](0.1)\n optimMethod.learningRateSchedule = EpochStep(1, 0.5)\n def feval(x: Tensor[Double]): (Double, Tensor[Double]) = {\n   (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))\n }\n val x = Tensor[Double](Storage(Array(10.0, 10.0)))\n val state = T(\"epoch\" -  0)\n for(e  - 1 to 10) {\n   state(\"epoch\") = e\n   optimMethod.state = state\n   optimMethod.optimize(feval, x)\n   assert(optimMethod.learningRateSchedule.currentRate==(-0.1 * Math.pow(0.5, e)))\n }", 
            "title": "EpochStep"
        }, 
        {
            "location": "/APIGuide/Triggers/", 
            "text": "A trigger specifies a timespot or several timespots during training,\nand a corresponding action will be taken when the timespot(s)\ns reached.\n\n\n\n\nEvery Epoch\n\n\nScala:\n\n\n val trigger = Trigger.everyEpoch\n\n\n\n\nPython:\n\n\n trigger = EveryEpoch()\n\n\n\n\nA trigger that triggers an action when each epoch finishes.\n   Could be used as trigger in \nsetValidation\n and \nsetCheckpoint\n\n   in Optimizer, and also in \nTrainSummary.setSummaryTrigger\n.\n\n\n\n\nSeveral Iteration\n\n\nScala:\n\n\n val trigger = Trigger.severalIteration(n)\n\n\n\n\nPython:\n\n\n trigger = SeveralIteration(n)\n\n\n\n\nA trigger that triggers an action every \nn\n iterations.\n Could be used as trigger in \nsetValidation\n and \nsetCheckpoint\n \n in Optimizer, and also in \nTrainSummary.setSummaryTrigger\n.\n\n\n\n\nMax Epoch\n\n\nScala:\n\n\n val trigger = Trigger.maxEpoch(max)\n\n\n\n\nPython:\n\n\n trigger = MaxEpoch(max)\n\n\n\n\nA trigger that triggers an action when training reaches\n  the number of epochs specified by \"max\".\n  Usually used in \nOptimizer.setEndWhen\n.\n\n\n\n\nMax Iteration\n\n\nScala:\n\n\n val trigger = Trigger.maxIteration(max)\n\n\n\n\nPython:\n\n\n trigger = MaxIteration(max)\n\n\n\n\nA trigger that triggers an action when training reaches\n  the number of iterations specified by \"max\".\n  Usually used in \nOptimizer.setEndWhen\n.\n\n\n\n\nMax Score\n\n\nScala:\n\n\n val trigger = Trigger.maxScore(max)\n\n\n\n\nPython:\n\n\n trigger = MaxScore(max)\n\n\n\n\nA trigger that triggers an action when validation score\n larger than \"max\" score\n\n\n\n\nMin Loss\n\n\nScala:\n\n\n val trigger = Trigger.minLoss(min)\n\n\n\n\nPython:\n\n\n trigger = MinLoss(min)\n\n\n\n\nA trigger that triggers an action when training loss\n less than \"min\" loss", 
            "title": "Triggers"
        }, 
        {
            "location": "/APIGuide/Triggers/#every-epoch", 
            "text": "Scala:   val trigger = Trigger.everyEpoch  Python:   trigger = EveryEpoch()  A trigger that triggers an action when each epoch finishes.\n   Could be used as trigger in  setValidation  and  setCheckpoint \n   in Optimizer, and also in  TrainSummary.setSummaryTrigger .", 
            "title": "Every Epoch"
        }, 
        {
            "location": "/APIGuide/Triggers/#several-iteration", 
            "text": "Scala:   val trigger = Trigger.severalIteration(n)  Python:   trigger = SeveralIteration(n)  A trigger that triggers an action every  n  iterations.\n Could be used as trigger in  setValidation  and  setCheckpoint  \n in Optimizer, and also in  TrainSummary.setSummaryTrigger .", 
            "title": "Several Iteration"
        }, 
        {
            "location": "/APIGuide/Triggers/#max-epoch", 
            "text": "Scala:   val trigger = Trigger.maxEpoch(max)  Python:   trigger = MaxEpoch(max)  A trigger that triggers an action when training reaches\n  the number of epochs specified by \"max\".\n  Usually used in  Optimizer.setEndWhen .", 
            "title": "Max Epoch"
        }, 
        {
            "location": "/APIGuide/Triggers/#max-iteration", 
            "text": "Scala:   val trigger = Trigger.maxIteration(max)  Python:   trigger = MaxIteration(max)  A trigger that triggers an action when training reaches\n  the number of iterations specified by \"max\".\n  Usually used in  Optimizer.setEndWhen .", 
            "title": "Max Iteration"
        }, 
        {
            "location": "/APIGuide/Triggers/#max-score", 
            "text": "Scala:   val trigger = Trigger.maxScore(max)  Python:   trigger = MaxScore(max)  A trigger that triggers an action when validation score\n larger than \"max\" score", 
            "title": "Max Score"
        }, 
        {
            "location": "/APIGuide/Triggers/#min-loss", 
            "text": "Scala:   val trigger = Trigger.minLoss(min)  Python:   trigger = MinLoss(min)  A trigger that triggers an action when training loss\n less than \"min\" loss", 
            "title": "Min Loss"
        }, 
        {
            "location": "/APIGuide/Metrics/", 
            "text": "ValidationMethod is a method to validate the model during model training or evaluation.\nThe trait can be extended by user-defined method. Now we have defined Top1Accuracy, Top5Accuracy, Loss.\nYou can use those methods to evaluate model, please refer to \nModule\n for details.\n\n\n\n\nLoss\n\n\nCalculate loss of output and target with criterion. The default criterion is ClassNLLCriterion.\n\n\nScala:\n\n\nval loss = new Loss(criterion)\n\n\n\n\nexample\n\n\nimport com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.utils.Engine\nimport org.apache.spark.SparkContext\nimport com.intel.analytics.bigdl.dataset.Sample\nimport com.intel.analytics.bigdl.models.lenet.LeNet5\n\nval conf = Engine.createSparkConf()\nval sc = new SparkContext(conf)\nEngine.init\n\nval data = new Array[Sample[Float]](10)\nvar i = 0\nwhile (i \n data.length) {\n  val input = Tensor[Float](28, 28).fill(0.8f)\n  val label = Tensor[Float](1).fill(1.0f)\n  data(i) = Sample(input, label)\n  i += 1\n}\nval model = LeNet5(classNum = 10)\nval dataSet = sc.parallelize(data, 4)\n\nval result = model.evaluate(dataSet, Array(new Loss[Float]().asInstanceOf[ValidationMethod[Float]]))\n\nscala\n result\nres12: Array[(com.intel.analytics.bigdl.optim.ValidationResult, com.intel.analytics.bigdl.optim.ValidationMethod[Float])] = Array(((Loss: 9.339776, count: 4, Average Loss: 2.334944),Loss))\n\n\n\n\nPython:\n\n\nloss = Loss(cri)\n\n\n\n\nexample\n\n\nfrom pyspark import SparkContext\nfrom bigdl.util.common import *\nfrom bigdl.nn.layer import *\nfrom bigdl.optim.optimizer import *\n\nsc = get_spark_context(conf=create_spark_conf())\ninit_engine()\n\ndata_len = 10\nbatch_size = 8\nFEATURES_DIM = 4\n\ndef gen_rand_sample():\n    features = np.random.uniform(0, 1, (FEATURES_DIM))\n    label = features.sum() + 0.4\n    return Sample.from_ndarray(features, label)\n\ntrainingData = sc.parallelize(range(0, data_len)).map(\n    lambda i: gen_rand_sample())\n\nmodel = Sequential()\nmodel.add(Linear(4, 5))\ntest_results = model.evaluate(trainingData, batch_size, [Loss()])\n\n\n print test_results[0]\nTest result: 0.116546951234, total_num: 10, method: Loss\n\n\n\n\n\n\nTop1Accuracy\n\n\nCaculate the percentage that output's max probability index equals target.\n\n\nScala:\n\n\nval top1accuracy = new Top1Accuracy()\n\n\n\n\nset validation method as Top1Accuracy\n\n\nval result = model.evaluate(dataSet, Array(new Top1Accuracy[Float]().asInstanceOf[ValidationMethod[Float]]))\n\nscala\n result\nres13: Array[(com.intel.analytics.bigdl.optim.ValidationResult, com.intel.analytics.bigdl.optim.ValidationMethod[Float])] = Array((Accuracy(correct: 0, count: 10, accuracy: 0.0),Top1Accuracy))\n\n\n\n\nPython:\n\n\ntop1accuracy = Top1Accuracy()\n\n\n\n\ntest_results = model.evaluate(trainingData, batch_size, [Top1Accuracy()])\n\n\n print test_results[0]\nTest result: 0.0, total_num: 10, method: Top1Accuracy\n\n\n\n\n\n\nTop5Accuracy\n\n\nCaculate the percentage that target in output's top5 probability indexes.\n\n\nScala:\n\n\nval top5accuracy = new Top5Accuracy()\n\n\n\n\nset validation method as Top5Accuracy\n\n\nval result = model.evaluate(dataSet, Array(new Top5Accuracy[Float]().asInstanceOf[ValidationMethod[Float]]))\n\nscala\n result\nres18: Array[(com.intel.analytics.bigdl.optim.ValidationResult, com.intel.analytics.bigdl.optim.ValidationMethod[Float])] = Array((Accuracy(correct: 10, count: 10, accuracy: 1.0),Top5Accuracy))\n\n\n\n\nPython:\n\n\ntop5accuracy = Top5Accuracy()\n\n\n\n\ntest_results = model.evaluate(trainingData, batch_size, [Top5Accuracy()])\n\n\n print test_results[0]\nTest result: 0.0, total_num: 10, method: Top5Accuracy", 
            "title": "Metrics"
        }, 
        {
            "location": "/APIGuide/Metrics/#loss", 
            "text": "Calculate loss of output and target with criterion. The default criterion is ClassNLLCriterion.  Scala:  val loss = new Loss(criterion)  example  import com.intel.analytics.bigdl.nn._\nimport com.intel.analytics.bigdl.tensor.Tensor\nimport com.intel.analytics.bigdl.optim._\nimport com.intel.analytics.bigdl.utils.Engine\nimport org.apache.spark.SparkContext\nimport com.intel.analytics.bigdl.dataset.Sample\nimport com.intel.analytics.bigdl.models.lenet.LeNet5\n\nval conf = Engine.createSparkConf()\nval sc = new SparkContext(conf)\nEngine.init\n\nval data = new Array[Sample[Float]](10)\nvar i = 0\nwhile (i   data.length) {\n  val input = Tensor[Float](28, 28).fill(0.8f)\n  val label = Tensor[Float](1).fill(1.0f)\n  data(i) = Sample(input, label)\n  i += 1\n}\nval model = LeNet5(classNum = 10)\nval dataSet = sc.parallelize(data, 4)\n\nval result = model.evaluate(dataSet, Array(new Loss[Float]().asInstanceOf[ValidationMethod[Float]]))\n\nscala  result\nres12: Array[(com.intel.analytics.bigdl.optim.ValidationResult, com.intel.analytics.bigdl.optim.ValidationMethod[Float])] = Array(((Loss: 9.339776, count: 4, Average Loss: 2.334944),Loss))  Python:  loss = Loss(cri)  example  from pyspark import SparkContext\nfrom bigdl.util.common import *\nfrom bigdl.nn.layer import *\nfrom bigdl.optim.optimizer import *\n\nsc = get_spark_context(conf=create_spark_conf())\ninit_engine()\n\ndata_len = 10\nbatch_size = 8\nFEATURES_DIM = 4\n\ndef gen_rand_sample():\n    features = np.random.uniform(0, 1, (FEATURES_DIM))\n    label = features.sum() + 0.4\n    return Sample.from_ndarray(features, label)\n\ntrainingData = sc.parallelize(range(0, data_len)).map(\n    lambda i: gen_rand_sample())\n\nmodel = Sequential()\nmodel.add(Linear(4, 5))\ntest_results = model.evaluate(trainingData, batch_size, [Loss()])  print test_results[0]\nTest result: 0.116546951234, total_num: 10, method: Loss", 
            "title": "Loss"
        }, 
        {
            "location": "/APIGuide/Metrics/#top1accuracy", 
            "text": "Caculate the percentage that output's max probability index equals target.  Scala:  val top1accuracy = new Top1Accuracy()  set validation method as Top1Accuracy  val result = model.evaluate(dataSet, Array(new Top1Accuracy[Float]().asInstanceOf[ValidationMethod[Float]]))\n\nscala  result\nres13: Array[(com.intel.analytics.bigdl.optim.ValidationResult, com.intel.analytics.bigdl.optim.ValidationMethod[Float])] = Array((Accuracy(correct: 0, count: 10, accuracy: 0.0),Top1Accuracy))  Python:  top1accuracy = Top1Accuracy()  test_results = model.evaluate(trainingData, batch_size, [Top1Accuracy()])  print test_results[0]\nTest result: 0.0, total_num: 10, method: Top1Accuracy", 
            "title": "Top1Accuracy"
        }, 
        {
            "location": "/APIGuide/Metrics/#top5accuracy", 
            "text": "Caculate the percentage that target in output's top5 probability indexes.  Scala:  val top5accuracy = new Top5Accuracy()  set validation method as Top5Accuracy  val result = model.evaluate(dataSet, Array(new Top5Accuracy[Float]().asInstanceOf[ValidationMethod[Float]]))\n\nscala  result\nres18: Array[(com.intel.analytics.bigdl.optim.ValidationResult, com.intel.analytics.bigdl.optim.ValidationMethod[Float])] = Array((Accuracy(correct: 10, count: 10, accuracy: 1.0),Top5Accuracy))  Python:  top5accuracy = Top5Accuracy()  test_results = model.evaluate(trainingData, batch_size, [Top5Accuracy()])  print test_results[0]\nTest result: 0.0, total_num: 10, method: Top5Accuracy", 
            "title": "Top5Accuracy"
        }, 
        {
            "location": "/APIGuide/DLFrames/DLEstimator_DLClassifier/", 
            "text": "DLModel\n\n\nScala:\n\n\nval dlModel = new DLModel[T](model: Module[T], featureSize: Array[Int])\n\n\n\n\nPython:\n\n\ndl_model = DLModel(model, feature_size)\n\n\n\n\nDLModel is designed to wrap the BigDL Module as a Spark's ML \nTransformer\n which is compatible \nwith both spark 1.5-plus and 2.0. It greatly improves the \nexperience of Spark users because now you can \nwrap a pre-trained BigDL Model into a DlModel, \nand use it \nas a transformer in your Spark ML pipeline to predict the results\n.\n\n\nDLModel supports feature data in the format of \nArray[Double], Array[Float], org.apache.spark.mllib.linalg.{Vector, VectorUDT} for Spark 1.5, 1.6 \nand org.apache.spark.ml.linalg.{Vector, VectorUDT} for Spark 2.0+. Internally [[DLModel]] use \nfeatures column as storage of the feature data, and create Tensors according to the constructor \nparameter featureSize.\n\n\n\n\nmodel\n fitted BigDL module to use in prediction\n\n\nfeatureSize\n The size (Tensor dimensions) of the feature data. \n(e.g. an image may be with featureSize = 28 * 28)\n\n\n\n\n\n\n\n\nDLEstimator\n\n\nScala:\n\n\nval estimator = new DLEstimator(model: Module[T], criterion: Criterion[T], val featureSize: Array[Int], val labelSize: Array[Int])\n\n\n\n\nPython:\n\n\nestimator = DLEstimator(model, criterion, feature_size, label_size)\n\n\n\n\nDLEstimator is used to take the user-presumed model and criterion with specification on feature and \nlabel dimension to prepare for the training. Within its class definition, it implements a method \nfit()\n, \nwhich accepts dataset to start training and produce a optimized DLModel with more accurate prediction.\n\n\nDLEstimator extends Spark's ML \nEsitmator\n API (\norg.apache.spark.ml.Estimator\n) and supports model training from Apache Spark \nDataFrame/Dataset. Different from many algorithms in Spark MLlib, DLEstimator supports more data \ntypes for the label column. In many deep learning applications, the label data could be a sequence \nor other data collection. DLEstimator supports feature and label data in the format of \nArray[Double]\n, \n\nArray[Float]\n, \norg.apache.spark.mllib.linalg.Vector\n (for Apache Spark 1.5, 1.6) and \n\norg.apache.spark.ml.linalg.Vector\n (for Apache Spark 2.0+). Also label data can be of \nDouble\n type.\nUser should specify the feature data dimensions and label data dimensions via the constructor parameters \nfeatureSize and labelSize respectively. Internally the feature and label data are converted to BigDL \ntensors, to further train a BigDL model efficiently.\n\n\n\n\nmodel\n BigDL module to be optimized in the fit() method\n\n\ncriterion\n the criterion used to compute the loss and the gradient\n\n\nfeatureSize\n The size (Tensor dimensions) of the feature data.\n\n\nlabelSize\n The size (Tensor dimensions) of the label data\n\n\n\n\nScala Example:\n\n\n/**\n *  Multi-label regression with BigDL layers and DLEstimator\n */\nobject DLEstimatorMultiLabelLR {\n\n  def main(args: Array[String]): Unit = {\n    val conf = Engine.createSparkConf()\n      .setAppName(\nDLEstimatorMultiLabelLR\n)\n      .setMaster(\nlocal[1]\n)\n    val sc = new SparkContext(conf)\n    val sqlContext = SQLContext.getOrCreate(sc)\n    Engine.init\n\n    val model = Sequential().add(Linear(2, 2))\n    val criterion = MSECriterion()\n    val estimator = new DLEstimator(model, criterion, Array(2), Array(2))\n      .setBatchSize(4)\n      .setMaxEpoch(10)\n    val data = sc.parallelize(Seq(\n      (Array(2.0, 1.0), Array(1.0, 2.0)),\n      (Array(1.0, 2.0), Array(2.0, 1.0)),\n      (Array(2.0, 1.0), Array(1.0, 2.0)),\n      (Array(1.0, 2.0), Array(2.0, 1.0))))\n    val df = sqlContext.createDataFrame(data).toDF(\nfeatures\n, \nlabel\n)\n    val dlModel = estimator.fit(df)\n    dlModel.transform(df).show(false)\n  }\n}\n\n\n\n\n\nPython Example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.util.common import *\nfrom bigdl.dlframes.dl_classifier import *\nfrom pyspark.sql.types import *\nfrom pyspark.context import SparkContext\n\n#Multi-label regression with BigDL layers and DLEstimator\nsc = SparkContext(appName=\nDLEstimatorMultiLabelLR\n, conf=create_spark_conf().setMaster(\nlocal[1]\n))\nsqlContext = SQLContext(sc)\ninit_engine()\nmodel = Sequential().add(Linear(2, 2))\ncriterion = MSECriterion()\nestimator = DLEstimator(model, criterion, [2], [2]).setBatchSize(4).setMaxEpoch(10)\ndata = sc.parallelize([\n    ((2.0, 1.0), (1.0, 2.0)),\n    ((1.0, 2.0), (2.0, 1.0)),\n    ((2.0, 1.0), (1.0, 2.0)),\n    ((1.0, 2.0), (2.0, 1.0))])\n\nschema = StructType([\n    StructField(\nfeatures\n, ArrayType(DoubleType(), False), False),\n    StructField(\nlabel\n, ArrayType(DoubleType(), False), False)])\ndf = sqlContext.createDataFrame(data, schema)\ndlModel = estimator.fit(df)\ndlModel.transform(df).show(False)\nsc.stop()\n\n\n\n\nOutput is\n\n\n\n\n\n\n\n\nfeatures\n\n\nlabel\n\n\nprediction\n\n\n\n\n\n\n\n\n\n\n[2.0, 1.0]\n\n\n[1.0, 2.0]\n\n\n[1.0034767389297485, 2.006068706512451]\n\n\n\n\n\n\n[1.0, 2.0]\n\n\n[2.0, 1.0]\n\n\n[2.006953001022339, 1.0039551258087158]\n\n\n\n\n\n\n[2.0, 1.0]\n\n\n[1.0, 2.0]\n\n\n[1.0034767389297485, 2.006068706512451]\n\n\n\n\n\n\n[1.0, 2.0]\n\n\n[2.0, 1.0]\n\n\n[2.006953001022339, 1.0039551258087158]\n\n\n\n\n\n\n\n\n\n\n\n\nDLClassifierModel\n\n\nScala:\n\n\nval dlClassifierModel = new DLClassifierModel[T](model: Module[T], featureSize: Array[Int])\n\n\n\n\nPython:\n\n\ndl_classifier_model = DLClassifierModel(model, feature_size)\n\n\n\n\nDLClassifierModel extends DLModel, which is a specialized DLModel for classification tasks.\nThe prediction column will have the datatype of Double.\n\n \nmodel\n fitted BigDL module to use in prediction\n\n \nfeatureSize\n The size (Tensor dimensions) of the feature data. (e.g. an image may be with\nfeatureSize = 28 * 28)\n\n\n\n\n\n\nDLClassifier\n\n\nval classifer = new DLClassifer(model: Module[T], criterion: Criterion[T], val featureSize: Array[Int])\n\n\n\n\nPython:\n\n\nclassifier = DLClassifer(model, criterion, feature_size)\n\n\n\n\nDLClassifier\n is a specialized \nDLEstimator\n that simplifies the data format for\nclassification tasks where the label space is discrete. It only supports label column of DoubleType,\nand the fitted\n\nDLClassifierModel\n will have the prediction column of DoubleType.\n\n\n\n\nmodel\n BigDL module to be optimized in the fit() method\n\n\ncriterion\n the criterion used to compute the loss and the gradient\n\n\nfeatureSize\n The size (Tensor dimensions) of the feature data.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.dlframes.DLClassifier\nimport com.intel.analytics.bigdl.nn.{ClassNLLCriterion, Linear, LogSoftMax, Sequential}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.Engine\nimport org.apache.spark.SparkContext\nimport org.apache.spark.sql.SQLContext\n\n/**\n * Logistic Regression with BigDL layers and DLClassifier\n */\nobject DLClassifierLogisticRegression {\n\n  def main(args: Array[String]): Unit = {\n    val conf = Engine.createSparkConf()\n      .setAppName(\nDLClassifierLogisticRegression\n)\n      .setMaster(\nlocal[1]\n)\n    val sc = new SparkContext(conf)\n    val sqlContext = SQLContext.getOrCreate(sc)\n    Engine.init\n\n    val model = Sequential().add(Linear(2, 2)).add(LogSoftMax())\n    val criterion = ClassNLLCriterion()\n    val estimator = new DLClassifier(model, criterion, Array(2))\n      .setBatchSize(4)\n      .setMaxEpoch(10)\n    val data = sc.parallelize(Seq(\n      (Array(0.0, 1.0), 1.0),\n      (Array(1.0, 0.0), 2.0),\n      (Array(0.0, 1.0), 1.0),\n      (Array(1.0, 0.0), 2.0)))\n    val df = sqlContext.createDataFrame(data).toDF(\nfeatures\n, \nlabel\n)\n    val dlModel = estimator.fit(df)\n    dlModel.transform(df).show(false)\n  }\n}\n\n\n\n\nPython Example:\n\n\nfrom bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.util.common import *\nfrom bigdl.dlframes.dl_classifier import *\nfrom pyspark.sql.types import *\nfrom pyspark.context import SparkContext\n\n#Logistic Regression with BigDL layers and DLClassifier\nsc = SparkContext(appName=\nDLClassifierLogisticRegression\n, conf=create_spark_conf().setMaster(\nlocal[1]\n))\nsqlContext = SQLContext(sc)\ninit_engine()\nmodel = Sequential().add(Linear(2, 2)).add(LogSoftMax())\ncriterion = ClassNLLCriterion()\nestimator = DLClassifier(model, criterion, [2]).setBatchSize(4).setMaxEpoch(10)\ndata = sc.parallelize([\n    ((0.0, 1.0), [1.0]),\n    ((1.0, 0.0), [2.0]),\n    ((0.0, 1.0), [1.0]),\n    ((1.0, 0.0), [2.0])])\n\nschema = StructType([\n    StructField(\nfeatures\n, ArrayType(DoubleType(), False), False),\n    StructField(\nlabel\n, ArrayType(DoubleType(), False), False)])\ndf = sqlContext.createDataFrame(data, schema)\ndlModel = estimator.fit(df)\ndlModel.transform(df).show(False)\nsc.stop()\n\n\n\n\nOutput is\n\n\n\n\n\n\n\n\nfeatures\n\n\nlabel\n\n\nprediction\n\n\n\n\n\n\n\n\n\n\n[0.0, 1.0]\n\n\n1.0\n\n\n1.0\n\n\n\n\n\n\n[1.0, 0.0]\n\n\n2.0\n\n\n2.0\n\n\n\n\n\n\n[0.0, 1.0]\n\n\n1.0\n\n\n1.0\n\n\n\n\n\n\n[1.0, 0.0]\n\n\n2.0\n\n\n2.0", 
            "title": "ML Pipeline"
        }, 
        {
            "location": "/APIGuide/DLFrames/DLEstimator_DLClassifier/#dlmodel", 
            "text": "Scala:  val dlModel = new DLModel[T](model: Module[T], featureSize: Array[Int])  Python:  dl_model = DLModel(model, feature_size)  DLModel is designed to wrap the BigDL Module as a Spark's ML  Transformer  which is compatible \nwith both spark 1.5-plus and 2.0. It greatly improves the \nexperience of Spark users because now you can  wrap a pre-trained BigDL Model into a DlModel, \nand use it \nas a transformer in your Spark ML pipeline to predict the results .  DLModel supports feature data in the format of \nArray[Double], Array[Float], org.apache.spark.mllib.linalg.{Vector, VectorUDT} for Spark 1.5, 1.6 \nand org.apache.spark.ml.linalg.{Vector, VectorUDT} for Spark 2.0+. Internally [[DLModel]] use \nfeatures column as storage of the feature data, and create Tensors according to the constructor \nparameter featureSize.   model  fitted BigDL module to use in prediction  featureSize  The size (Tensor dimensions) of the feature data. \n(e.g. an image may be with featureSize = 28 * 28)", 
            "title": "DLModel"
        }, 
        {
            "location": "/APIGuide/DLFrames/DLEstimator_DLClassifier/#dlestimator", 
            "text": "Scala:  val estimator = new DLEstimator(model: Module[T], criterion: Criterion[T], val featureSize: Array[Int], val labelSize: Array[Int])  Python:  estimator = DLEstimator(model, criterion, feature_size, label_size)  DLEstimator is used to take the user-presumed model and criterion with specification on feature and \nlabel dimension to prepare for the training. Within its class definition, it implements a method  fit() , \nwhich accepts dataset to start training and produce a optimized DLModel with more accurate prediction.  DLEstimator extends Spark's ML  Esitmator  API ( org.apache.spark.ml.Estimator ) and supports model training from Apache Spark \nDataFrame/Dataset. Different from many algorithms in Spark MLlib, DLEstimator supports more data \ntypes for the label column. In many deep learning applications, the label data could be a sequence \nor other data collection. DLEstimator supports feature and label data in the format of  Array[Double] ,  Array[Float] ,  org.apache.spark.mllib.linalg.Vector  (for Apache Spark 1.5, 1.6) and  org.apache.spark.ml.linalg.Vector  (for Apache Spark 2.0+). Also label data can be of  Double  type.\nUser should specify the feature data dimensions and label data dimensions via the constructor parameters \nfeatureSize and labelSize respectively. Internally the feature and label data are converted to BigDL \ntensors, to further train a BigDL model efficiently.   model  BigDL module to be optimized in the fit() method  criterion  the criterion used to compute the loss and the gradient  featureSize  The size (Tensor dimensions) of the feature data.  labelSize  The size (Tensor dimensions) of the label data   Scala Example:  /**\n *  Multi-label regression with BigDL layers and DLEstimator\n */\nobject DLEstimatorMultiLabelLR {\n\n  def main(args: Array[String]): Unit = {\n    val conf = Engine.createSparkConf()\n      .setAppName( DLEstimatorMultiLabelLR )\n      .setMaster( local[1] )\n    val sc = new SparkContext(conf)\n    val sqlContext = SQLContext.getOrCreate(sc)\n    Engine.init\n\n    val model = Sequential().add(Linear(2, 2))\n    val criterion = MSECriterion()\n    val estimator = new DLEstimator(model, criterion, Array(2), Array(2))\n      .setBatchSize(4)\n      .setMaxEpoch(10)\n    val data = sc.parallelize(Seq(\n      (Array(2.0, 1.0), Array(1.0, 2.0)),\n      (Array(1.0, 2.0), Array(2.0, 1.0)),\n      (Array(2.0, 1.0), Array(1.0, 2.0)),\n      (Array(1.0, 2.0), Array(2.0, 1.0))))\n    val df = sqlContext.createDataFrame(data).toDF( features ,  label )\n    val dlModel = estimator.fit(df)\n    dlModel.transform(df).show(false)\n  }\n}  Python Example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.util.common import *\nfrom bigdl.dlframes.dl_classifier import *\nfrom pyspark.sql.types import *\nfrom pyspark.context import SparkContext\n\n#Multi-label regression with BigDL layers and DLEstimator\nsc = SparkContext(appName= DLEstimatorMultiLabelLR , conf=create_spark_conf().setMaster( local[1] ))\nsqlContext = SQLContext(sc)\ninit_engine()\nmodel = Sequential().add(Linear(2, 2))\ncriterion = MSECriterion()\nestimator = DLEstimator(model, criterion, [2], [2]).setBatchSize(4).setMaxEpoch(10)\ndata = sc.parallelize([\n    ((2.0, 1.0), (1.0, 2.0)),\n    ((1.0, 2.0), (2.0, 1.0)),\n    ((2.0, 1.0), (1.0, 2.0)),\n    ((1.0, 2.0), (2.0, 1.0))])\n\nschema = StructType([\n    StructField( features , ArrayType(DoubleType(), False), False),\n    StructField( label , ArrayType(DoubleType(), False), False)])\ndf = sqlContext.createDataFrame(data, schema)\ndlModel = estimator.fit(df)\ndlModel.transform(df).show(False)\nsc.stop()  Output is     features  label  prediction      [2.0, 1.0]  [1.0, 2.0]  [1.0034767389297485, 2.006068706512451]    [1.0, 2.0]  [2.0, 1.0]  [2.006953001022339, 1.0039551258087158]    [2.0, 1.0]  [1.0, 2.0]  [1.0034767389297485, 2.006068706512451]    [1.0, 2.0]  [2.0, 1.0]  [2.006953001022339, 1.0039551258087158]", 
            "title": "DLEstimator"
        }, 
        {
            "location": "/APIGuide/DLFrames/DLEstimator_DLClassifier/#dlclassifiermodel", 
            "text": "Scala:  val dlClassifierModel = new DLClassifierModel[T](model: Module[T], featureSize: Array[Int])  Python:  dl_classifier_model = DLClassifierModel(model, feature_size)  DLClassifierModel extends DLModel, which is a specialized DLModel for classification tasks.\nThe prediction column will have the datatype of Double.   model  fitted BigDL module to use in prediction   featureSize  The size (Tensor dimensions) of the feature data. (e.g. an image may be with\nfeatureSize = 28 * 28)", 
            "title": "DLClassifierModel"
        }, 
        {
            "location": "/APIGuide/DLFrames/DLEstimator_DLClassifier/#dlclassifier", 
            "text": "val classifer = new DLClassifer(model: Module[T], criterion: Criterion[T], val featureSize: Array[Int])  Python:  classifier = DLClassifer(model, criterion, feature_size)  DLClassifier  is a specialized  DLEstimator  that simplifies the data format for\nclassification tasks where the label space is discrete. It only supports label column of DoubleType,\nand the fitted DLClassifierModel  will have the prediction column of DoubleType.   model  BigDL module to be optimized in the fit() method  criterion  the criterion used to compute the loss and the gradient  featureSize  The size (Tensor dimensions) of the feature data.   Scala example:  import com.intel.analytics.bigdl.dlframes.DLClassifier\nimport com.intel.analytics.bigdl.nn.{ClassNLLCriterion, Linear, LogSoftMax, Sequential}\nimport com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat\nimport com.intel.analytics.bigdl.utils.Engine\nimport org.apache.spark.SparkContext\nimport org.apache.spark.sql.SQLContext\n\n/**\n * Logistic Regression with BigDL layers and DLClassifier\n */\nobject DLClassifierLogisticRegression {\n\n  def main(args: Array[String]): Unit = {\n    val conf = Engine.createSparkConf()\n      .setAppName( DLClassifierLogisticRegression )\n      .setMaster( local[1] )\n    val sc = new SparkContext(conf)\n    val sqlContext = SQLContext.getOrCreate(sc)\n    Engine.init\n\n    val model = Sequential().add(Linear(2, 2)).add(LogSoftMax())\n    val criterion = ClassNLLCriterion()\n    val estimator = new DLClassifier(model, criterion, Array(2))\n      .setBatchSize(4)\n      .setMaxEpoch(10)\n    val data = sc.parallelize(Seq(\n      (Array(0.0, 1.0), 1.0),\n      (Array(1.0, 0.0), 2.0),\n      (Array(0.0, 1.0), 1.0),\n      (Array(1.0, 0.0), 2.0)))\n    val df = sqlContext.createDataFrame(data).toDF( features ,  label )\n    val dlModel = estimator.fit(df)\n    dlModel.transform(df).show(false)\n  }\n}  Python Example:  from bigdl.nn.layer import *\nfrom bigdl.nn.criterion import *\nfrom bigdl.util.common import *\nfrom bigdl.dlframes.dl_classifier import *\nfrom pyspark.sql.types import *\nfrom pyspark.context import SparkContext\n\n#Logistic Regression with BigDL layers and DLClassifier\nsc = SparkContext(appName= DLClassifierLogisticRegression , conf=create_spark_conf().setMaster( local[1] ))\nsqlContext = SQLContext(sc)\ninit_engine()\nmodel = Sequential().add(Linear(2, 2)).add(LogSoftMax())\ncriterion = ClassNLLCriterion()\nestimator = DLClassifier(model, criterion, [2]).setBatchSize(4).setMaxEpoch(10)\ndata = sc.parallelize([\n    ((0.0, 1.0), [1.0]),\n    ((1.0, 0.0), [2.0]),\n    ((0.0, 1.0), [1.0]),\n    ((1.0, 0.0), [2.0])])\n\nschema = StructType([\n    StructField( features , ArrayType(DoubleType(), False), False),\n    StructField( label , ArrayType(DoubleType(), False), False)])\ndf = sqlContext.createDataFrame(data, schema)\ndlModel = estimator.fit(df)\ndlModel.transform(df).show(False)\nsc.stop()  Output is     features  label  prediction      [0.0, 1.0]  1.0  1.0    [1.0, 0.0]  2.0  2.0    [0.0, 1.0]  1.0  1.0    [1.0, 0.0]  2.0  2.0", 
            "title": "DLClassifier"
        }, 
        {
            "location": "/APIGuide/caffe_layer_list/", 
            "text": "AbsVal\n\n\nBatchNorm\n\n\nBias\n\n\nConcat\n\n\nConvolution\n\n\nDeconvolution\n\n\nDropout\n\n\nEltwise\n\n\nElu\n\n\nExp\n\n\nFlatten\n\n\nInnerProduct\n\n\nLog\n\n\nLrn\n\n\nPooling\n\n\nPower\n\n\nPrelu\n\n\nRelu\n\n\nReshape\n\n\nScale\n\n\nSigmoid\n\n\nSlice\n\n\nSoftmax\n\n\nTanh\n\n\nThreshold\n\n\nTile", 
            "title": "Supported Caffe Layers"
        }, 
        {
            "location": "/APIGuide/tensorflow_ops_list/", 
            "text": "Abs\n\n\nAdapter\n\n\nAdd\n\n\nAddN\n\n\nAll\n\n\nAny\n\n\nApproximateEqual\n\n\nArgMax\n\n\nAssert\n\n\nAvgPool\n\n\nAvgPoolGrad\n\n\nBatchMatMul\n\n\nBiasAdd\n\n\nBiasAddGrad\n\n\nBiasAddV1\n\n\nBroadcastGradientArgs\n\n\nCast\n\n\nCeil\n\n\nConcatOffset\n\n\nConcatV2\n\n\nConst\n\n\nControlTrigger\n\n\nConv2D\n\n\nConv2DBackpropFilter\n\n\nConv2DBackpropInput\n\n\nConv3D\n\n\nConv3DBackpropFilter\n\n\nConv3DBackpropFilterV2\n\n\nConv3DBackpropInput\n\n\nConv3DBackpropInputV2\n\n\nDecodeGif\n\n\nDecodeJpeg\n\n\nDecodePng\n\n\nDecodeRaw\n\n\nDependencyNode\n\n\nDepthwiseConv2dNative\n\n\nDepthwiseConv2dNativeBackpropFilter\n\n\nDepthwiseConv2dNativeBackpropInput\n\n\nDigamma\n\n\nDilation2D\n\n\nDilation2DBackpropFilter\n\n\nDilation2DBackpropInput\n\n\nDiv\n\n\nElu\n\n\nEluGrad\n\n\nEnter\n\n\nEqual\n\n\nErf\n\n\nErfc\n\n\nExit\n\n\nExp\n\n\nExpandDims\n\n\nExpm1\n\n\nFill\n\n\nFloor\n\n\nFloorDiv\n\n\nFloorMod\n\n\nFusedBatchNorm\n\n\nFusedBatchNormGrad\n\n\nFusedBatchNormGradV2\n\n\nFusedBatchNormV2\n\n\nGreater\n\n\nGreaterEqual\n\n\nIdentity\n\n\nInTopK\n\n\nInv\n\n\nInvertPermutation\n\n\nInvGrad\n\n\nIsFinite\n\n\nIsInf\n\n\nIsNan\n\n\nL2Loss\n\n\nLRN\n\n\nLRNGrad\n\n\nLess\n\n\nLessEqual\n\n\nLgamma\n\n\nLog\n\n\nLog1p\n\n\nLogSoftmax\n\n\nLogicalAnd\n\n\nLogicalNot\n\n\nLogicalOr\n\n\nLoopCond\n\n\nMatMul\n\n\nMaxPool\n\n\nMaxPoolGrad\n\n\nMaximum\n\n\nMean\n\n\nMerge\n\n\nMinimum\n\n\nMod\n\n\nMul\n\n\nNeg\n\n\nNextIteration\n\n\nNoOp\n\n\nNotEqual\n\n\nOneHot\n\n\nPack\n\n\nPad\n\n\nParseExample\n\n\nPlaceholder\n\n\nPow\n\n\nProd\n\n\nQueueDequeueManyV2\n\n\nQueueDequeueV2\n\n\nQueueEnqueueManyV2\n\n\nQueueEnqueueV2\n\n\nRandomShuffle\n\n\nRandomUniform\n\n\nRange\n\n\nRank\n\n\nReaderReadV2\n\n\nRealDiv\n\n\nReciprocal\n\n\nReciprocalGrad\n\n\nRefEnter\n\n\nRelu\n\n\nRelu6\n\n\nRelu6Grad\n\n\nReluGrad\n\n\nReshape\n\n\nResizeBilinear\n\n\nRint\n\n\nRound\n\n\nRsqrt\n\n\nRsqrtGrad\n\n\nSegmentSum\n\n\nSelect\n\n\nShape\n\n\nSigmoid\n\n\nSigmoidGrad\n\n\nSign\n\n\nSlice\n\n\nSoftmax\n\n\nSoftmaxCrossEntropyWithLogits\n\n\nSoftplus\n\n\nSoftplusGrad\n\n\nSoftsign\n\n\nSoftsignGrad\n\n\nSplit\n\n\nSqrt\n\n\nSqrtGrad\n\n\nSquare\n\n\nSquaredDifference\n\n\nSqueeze\n\n\nStack\n\n\nStackPopV2\n\n\nStackPop\n\n\nStackPush\n\n\nStackPushV2\n\n\nStackV2\n\n\nStridedSlice\n\n\nSub\n\n\nSubstr\n\n\nSum\n\n\nSwitch\n\n\nTanh\n\n\nTanhGrad\n\n\nTensorArrayConcatV3\n\n\nTensorArrayGatherV3\n\n\nTensorArrayGradV3\n\n\nTensorArrayReadV3\n\n\nTensorArrayScatterV3\n\n\nTensorArraySizeV3\n\n\nTensorArraySplitV3\n\n\nTensorArrayV3\n\n\nTensorArrayWriteV3\n\n\nTensorflowOpsLoader\n\n\nTile\n\n\nTopK\n\n\nTopKV2\n\n\nTranspose\n\n\nTruncateDiv\n\n\nTruncateMod\n\n\nUnpack\n\n\nUtils\n\n\nVariableV2", 
            "title": "Supported Tensorflow Operations"
        }, 
        {
            "location": "/APIGuide/keras-issues/", 
            "text": "Up to now, we have generally supported \nALL\n the layers of \nKeras 1.2.2\n to be loaded into BigDL.\n\n\nSelf-defined Keras layers or \nLambda\n layers are not supported for now. Weight sharing is not supported for now.\n\n\nThis page lists the so-far unsupported arguments for specific layers and some known issues.\n\n\nUnsupported Layer Arguments\n\n\nFor the following arguments, currently only the default values are expected and supported.\n\n\n\n\nFor \ninitializations\n, \nlecun_uniform\n, \northogonal\n, \nglorot_normal\n, \nhe_normal\n and \nhe_uniform\n are not supported for all layers. For those unsupported initialization methods, we will default values from BigDL instead. Thus in this case, you are \nstrongly recommended\n to load the weights from Keras together with its model definition.\n\n\nConstraints (\nW_constraint\n, \nb_constraint\n, etc.) are not supported for all layers.\n\n\nactivity_regularizer\n is not supported for all layers.\n\n\nFor \nDropout\n, \nnoise_shape\n is not supported.\n\n\nFor \nMerge\n layers, \nnode_indices\n, \ntensor_indices\n, \noutput_mask\n are not supported. \nLambda/function\n as merge mode is not supported.\n\n\nFor \nMerge\n layers with mode \n'dot'\n or \n'cosine'\n, only \n2D\n input with \ndot_axes=1\n is supported.\n\n\nFor \nAtrousConvolution1D\n, only \nbias=True\n is supported.\n\n\nFor \nAtrousConvolution2D\n, only \ndim_ordering='th'\n and \nbias=True\n are supported.\n\n\nFor \nDeConvolution2D\n, only \ndim_ordering='th'\n is supported. For \nborder_mode='same'\n, only symmetric padding on both sides is supported.\n\n\nFor \nConvolution3D\n, only \ndim_ordering='th'\n is supported.\n\n\nFor \nUpSampling3D\n, only \ndim_ordering='th'\n is supported.\n\n\nFor \nMaxPooling3D\n, only \ndim_ordering='th'\n and \nborder_mode='valid'\n are supported.\n\n\nFor \nAveragePooling3D\n, only \ndim_ordering='th'\n and \nborder_mode='valid'\n are supported.\n\n\nFor \nGlobalMaxPooling3D\n, only \ndim_ordering='th'\n is supported.\n\n\nFor \nGlobalAveragePooling3D\n, only \ndim_ordering='th'\n is supported.\n\n\nFor all \nRecurrent\n layers (\nSimpleRNN\n, \nGRU\n, \nLSTM\n and \nConvLSTM2D\n), \nstateful\n, \nconsume_less\n, \ndropout_W\n and \ndropout_U\n are not supported.\nIf RNNs are wrapped with \nBidirectional\n, only \nreturn_sequences=True\n is supported.\n\n\nFor \nConvLSTM2D\n, only \nborder_mode='valid'\n, \nnb_row==nb_col\n(square kernel) and \nsubsample[0]==subsample[1]\n(equal strides) are supported.\n\n\nFor \nEmbedding\n, \nmask_zero\n and \ndropout\n are not supported.\n\n\nFor \nPReLU\n, \ninit\n, \nweights\n and \nshared_axes\n are not supported.\n\n\nFor \nParametricSoftplus\n, \nweights\n and \nshared_axes\n are not supported. Only \nalpha_init = 1/beta_init\n is supported.\n\n\nFor \nBatchNormalization\n, only 4D input with \nmode=0\n is supported. Only \nchannel_first\n (\ndim_ordering='th'\n with \naxis=1\n) and \nchannel_last\n (\ndim_ordering='tf'\n with \naxis=-1\n) is supported. \ngamma_regularizer\n and \nbeta_regularizer\n are not supported.\n\n\n\n\nKnown Issues\n\n\n\n\nFor some layers such as \nZeroPadding2D\n, \nZeroPadding3D\n, \nCropping2D\n, \nCropping3D\n, etc., Keras doesn't save \ndim_ordering\n into config. In this case, the default \ndim_ordering\n found in \n~/.keras/keras.json\n will be used instead.\n\n\nFor \nConvLSTM2D\n, Keras doesn't save \nW_regularizer\n, \nU_regularizer\n and \nb_regularizer\n into config. In this case, the default \nNone\n will be used instead.", 
            "title": "Keras Issues"
        }, 
        {
            "location": "/APIGuide/keras-issues/#unsupported-layer-arguments", 
            "text": "For the following arguments, currently only the default values are expected and supported.   For  initializations ,  lecun_uniform ,  orthogonal ,  glorot_normal ,  he_normal  and  he_uniform  are not supported for all layers. For those unsupported initialization methods, we will default values from BigDL instead. Thus in this case, you are  strongly recommended  to load the weights from Keras together with its model definition.  Constraints ( W_constraint ,  b_constraint , etc.) are not supported for all layers.  activity_regularizer  is not supported for all layers.  For  Dropout ,  noise_shape  is not supported.  For  Merge  layers,  node_indices ,  tensor_indices ,  output_mask  are not supported.  Lambda/function  as merge mode is not supported.  For  Merge  layers with mode  'dot'  or  'cosine' , only  2D  input with  dot_axes=1  is supported.  For  AtrousConvolution1D , only  bias=True  is supported.  For  AtrousConvolution2D , only  dim_ordering='th'  and  bias=True  are supported.  For  DeConvolution2D , only  dim_ordering='th'  is supported. For  border_mode='same' , only symmetric padding on both sides is supported.  For  Convolution3D , only  dim_ordering='th'  is supported.  For  UpSampling3D , only  dim_ordering='th'  is supported.  For  MaxPooling3D , only  dim_ordering='th'  and  border_mode='valid'  are supported.  For  AveragePooling3D , only  dim_ordering='th'  and  border_mode='valid'  are supported.  For  GlobalMaxPooling3D , only  dim_ordering='th'  is supported.  For  GlobalAveragePooling3D , only  dim_ordering='th'  is supported.  For all  Recurrent  layers ( SimpleRNN ,  GRU ,  LSTM  and  ConvLSTM2D ),  stateful ,  consume_less ,  dropout_W  and  dropout_U  are not supported.\nIf RNNs are wrapped with  Bidirectional , only  return_sequences=True  is supported.  For  ConvLSTM2D , only  border_mode='valid' ,  nb_row==nb_col (square kernel) and  subsample[0]==subsample[1] (equal strides) are supported.  For  Embedding ,  mask_zero  and  dropout  are not supported.  For  PReLU ,  init ,  weights  and  shared_axes  are not supported.  For  ParametricSoftplus ,  weights  and  shared_axes  are not supported. Only  alpha_init = 1/beta_init  is supported.  For  BatchNormalization , only 4D input with  mode=0  is supported. Only  channel_first  ( dim_ordering='th'  with  axis=1 ) and  channel_last  ( dim_ordering='tf'  with  axis=-1 ) is supported.  gamma_regularizer  and  beta_regularizer  are not supported.", 
            "title": "Unsupported Layer Arguments"
        }, 
        {
            "location": "/APIGuide/keras-issues/#known-issues", 
            "text": "For some layers such as  ZeroPadding2D ,  ZeroPadding3D ,  Cropping2D ,  Cropping3D , etc., Keras doesn't save  dim_ordering  into config. In this case, the default  dim_ordering  found in  ~/.keras/keras.json  will be used instead.  For  ConvLSTM2D , Keras doesn't save  W_regularizer ,  U_regularizer  and  b_regularizer  into config. In this case, the default  None  will be used instead.", 
            "title": "Known Issues"
        }, 
        {
            "location": "/APIGuide/scaladoc/", 
            "text": "javadoc", 
            "title": "Scala Docs"
        }, 
        {
            "location": "/APIGuide/scaladoc/#javadoc", 
            "text": "", 
            "title": "javadoc"
        }, 
        {
            "location": "/APIGuide/python-api-doc/", 
            "text": "pythonapidoc", 
            "title": "Python API Docs"
        }, 
        {
            "location": "/APIGuide/python-api-doc/#pythonapidoc", 
            "text": "", 
            "title": "pythonapidoc"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-python/", 
            "text": "Introduction\n\n\nWe hereby introduce a new set of \nKeras-Style API\n based on \nKeras 1.2.2\n in BigDL for the sake of user-friendliness. Users, especially those familiar with Keras, are recommended to use the new API to create a BigDL model and train, evaluate or tune it in a distributed fashion.\n\n\nTo define a model in Python using the Keras-Style API, now one just need to import the following packages:\n\n\nfrom bigdl.nn.keras.topology import *\nfrom bigdl.nn.keras.layer import *\n\n\n\n\nOne of the highlighted features with regard to the new API is \nshape inference\n. Users only need to specify the input shape (a shape tuple \nexcluding\n batch dimension, for example, \ninput_shape=(3, 4)\n for 3D input) for the first layer of a model and for the remaining layers, the input dimension will be automatically inferred.\n\n\n\n\nDefine a model\n\n\nYou can define a model either using \nSequential API\n or \nFunctional API\n. Remember to specify the input shape for the first layer.\n\n\nAfter creating a model, you can call the following \nmethods\n:\n\n\nget_input_shape()\n\n\n\n\nget_output_shape()\n\n\n\n\n\n\nReturn the input or output shape of a model, which is a shape tuple. The first entry is \nNone\n representing the batch dimension. For a model with multiple inputs or outputs, a list of shape tuples will be returned.\n\n\n\n\nset_name(name)\n\n\n\n\n\n\nSet the name of the model. Can alternatively specify the argument \nname\n in the constructor when creating a model.\n\n\n\n\nSee \nhere\n on how to train, predict or evaluate a defined model.\n\n\n\n\nSequential API\n\n\nThe model is described as a linear stack of layers in the Sequential API. Layers can be added into the \nSequential\n container one by one and the order of the layers in the model will be the same as the insertion order.\n\n\nTo create a sequential container:\n\n\nSequential()\n\n\n\n\nExample code to create a sequential model:\n\n\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Dense, Activation\n\nmodel = Sequential()\nmodel.add(Dense(32, input_shape=(128, )))\nmodel.add(Activation(\nrelu\n))\n\n\n\n\n\n\nFunctional API\n\n\nThe model is described as a graph in the Functional API. It is more convenient than the Sequential API when defining some complex model (for example, a model with multiple outputs).\n\n\nTo create an input node:\n\n\nInput(shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nshape\n: A shape tuple indicating the shape of the input node, not including batch.\n\n\nname\n: String to set the name of the input node. If not specified, its name will by default to be a generated string.\n\n\n\n\nTo create a graph container:\n\n\nModel(input, output)\n\n\n\n\nParameters:\n\n\n\n\ninput\n: An input node or a list of input nodes.\n\n\noutput\n: An output node or a list of output nodes.\n\n\n\n\nTo merge a list of input \nnodes\n (\nNOT\n layers), following some merge mode in the Functional API:\n\n\nmerge(inputs, mode=\nsum\n, concat_axis=-1) # This will return an output NODE.\n\n\n\n\nParameters:\n\n\n\n\ninputs\n: A list of node instances. Must be more than one node.\n\n\nmode\n: Merge mode. String, must be one of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'. Default is 'sum'.\n\n\nconcat_axis\n: Int, axis to use when concatenating nodes. Only specify this when merge mode is 'concat'. Default is -1, meaning the last axis of the input.\n\n\n\n\nExample code to create a graph model:\n\n\nfrom bigdl.nn.keras.topology import Model\nfrom bigdl.nn.keras.layer import Input, Dense, merge\n\n# instantiate input nodes\ninput1 = Input(shape=(8, )) \ninput2 = Input(shape=(6, ))\n# pass an input node into a layer and get an output node\ndense1 = Dense(10)(input1)\ndense2 = Dense(10)(input2)\n# merge two nodes following some merge mode\noutput = merge([dense1, dense2], mode=\nsum\n)\n# create a graph container\nmodel = Model([input1, input2], output)\n\n\n\n\n\n\nLayers\n\n\nSee \nhere\n for all the available layers for the new set of Keras-Style API.\n\n\nTo set the name of a layer, you can either call \nset_name(name)\n or alternatively specify the argument \nname\n in the constructor when creating a layer.\n\n\n\n\nLeNet Example\n\n\nHere we adopt our Keras-Style API to define a LeNet CNN model to be trained on the MNIST dataset:\n\n\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import *\n\nmodel = Sequential()\nmodel.add(Reshape((1, 28, 28), input_shape=(28, 28, 1)))\nmodel.add(Convolution2D(6, 5, 5, activation=\ntanh\n, name=\nconv1_5x5\n))\nmodel.add(MaxPooling2D())\nmodel.add(Convolution2D(12, 5, 5, activation=\ntanh\n, name=\nconv2_5x5\n))\nmodel.add(MaxPooling2D())\nmodel.add(Flatten())\nmodel.add(Dense(100, activation=\ntanh\n, name=\nfc1\n))\nmodel.add(Dense(10, activation=\nsoftmax\n, name=\nfc2\n))\n\nmodel.get_input_shape() # (None, 28, 28, 1)\nmodel.get_output_shape() # (None, 10)\n\n\n\n\nSee \nhere\n for detailed introduction of LeNet, the full example code and running instructions.\n\n\n\n\nKeras Code Support\n\n\nIf you have an existing piece of Keras code for a model definition, without installing Keras, you can directly migrate the code to construct a BigDL model by just replacing Keras import lines with:\n\n\nfrom bigdl.nn.keras.topology import *\nfrom bigdl.nn.keras.layer import *\n\n\n\n\nand making modifications subject to the following limitations:\n\n\n\n\n\n\nThe Keras version we support and test is \nKeras 1.2.2\n with TensorFlow backend.\n\n\n\n\n\n\nThere exist some arguments supported in Keras layers but not supported in BigDL for now. See \nhere\n for the full list of unsupported layer arguments. Also, currently we haven't supported self-defined Keras layers or \nLambda\n layers.\n\n\n\n\n\n\nThe default dim_ordering in BigDL is \nth\n (Channel First, channel_axis=1).\n\n\n\n\n\n\nKeras \nbackend\n related code needs to be deleted or refactored appropriately.\n\n\n\n\n\n\nCode involving Keras utility functions or loading weights from HDF5 files should be removed.\n\n\n\n\n\n\nRemark:\n We have tested for migrating Keras code definition of \nVGG16\n, \nVGG19\n, \nResNet50\n and \nInceptionV3\n into BigDL.", 
            "title": "Python Guide"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-python/#introduction", 
            "text": "We hereby introduce a new set of  Keras-Style API  based on  Keras 1.2.2  in BigDL for the sake of user-friendliness. Users, especially those familiar with Keras, are recommended to use the new API to create a BigDL model and train, evaluate or tune it in a distributed fashion.  To define a model in Python using the Keras-Style API, now one just need to import the following packages:  from bigdl.nn.keras.topology import *\nfrom bigdl.nn.keras.layer import *  One of the highlighted features with regard to the new API is  shape inference . Users only need to specify the input shape (a shape tuple  excluding  batch dimension, for example,  input_shape=(3, 4)  for 3D input) for the first layer of a model and for the remaining layers, the input dimension will be automatically inferred.", 
            "title": "Introduction"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-python/#define-a-model", 
            "text": "You can define a model either using  Sequential API  or  Functional API . Remember to specify the input shape for the first layer.  After creating a model, you can call the following  methods :  get_input_shape()  get_output_shape()   Return the input or output shape of a model, which is a shape tuple. The first entry is  None  representing the batch dimension. For a model with multiple inputs or outputs, a list of shape tuples will be returned.   set_name(name)   Set the name of the model. Can alternatively specify the argument  name  in the constructor when creating a model.   See  here  on how to train, predict or evaluate a defined model.", 
            "title": "Define a model"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-python/#sequential-api", 
            "text": "The model is described as a linear stack of layers in the Sequential API. Layers can be added into the  Sequential  container one by one and the order of the layers in the model will be the same as the insertion order.  To create a sequential container:  Sequential()  Example code to create a sequential model:  from bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Dense, Activation\n\nmodel = Sequential()\nmodel.add(Dense(32, input_shape=(128, )))\nmodel.add(Activation( relu ))", 
            "title": "Sequential API"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-python/#functional-api", 
            "text": "The model is described as a graph in the Functional API. It is more convenient than the Sequential API when defining some complex model (for example, a model with multiple outputs).  To create an input node:  Input(shape=None, name=None)  Parameters:   shape : A shape tuple indicating the shape of the input node, not including batch.  name : String to set the name of the input node. If not specified, its name will by default to be a generated string.   To create a graph container:  Model(input, output)  Parameters:   input : An input node or a list of input nodes.  output : An output node or a list of output nodes.   To merge a list of input  nodes  ( NOT  layers), following some merge mode in the Functional API:  merge(inputs, mode= sum , concat_axis=-1) # This will return an output NODE.  Parameters:   inputs : A list of node instances. Must be more than one node.  mode : Merge mode. String, must be one of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'. Default is 'sum'.  concat_axis : Int, axis to use when concatenating nodes. Only specify this when merge mode is 'concat'. Default is -1, meaning the last axis of the input.   Example code to create a graph model:  from bigdl.nn.keras.topology import Model\nfrom bigdl.nn.keras.layer import Input, Dense, merge\n\n# instantiate input nodes\ninput1 = Input(shape=(8, )) \ninput2 = Input(shape=(6, ))\n# pass an input node into a layer and get an output node\ndense1 = Dense(10)(input1)\ndense2 = Dense(10)(input2)\n# merge two nodes following some merge mode\noutput = merge([dense1, dense2], mode= sum )\n# create a graph container\nmodel = Model([input1, input2], output)", 
            "title": "Functional API"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-python/#layers", 
            "text": "See  here  for all the available layers for the new set of Keras-Style API.  To set the name of a layer, you can either call  set_name(name)  or alternatively specify the argument  name  in the constructor when creating a layer.", 
            "title": "Layers"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-python/#lenet-example", 
            "text": "Here we adopt our Keras-Style API to define a LeNet CNN model to be trained on the MNIST dataset:  from bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import *\n\nmodel = Sequential()\nmodel.add(Reshape((1, 28, 28), input_shape=(28, 28, 1)))\nmodel.add(Convolution2D(6, 5, 5, activation= tanh , name= conv1_5x5 ))\nmodel.add(MaxPooling2D())\nmodel.add(Convolution2D(12, 5, 5, activation= tanh , name= conv2_5x5 ))\nmodel.add(MaxPooling2D())\nmodel.add(Flatten())\nmodel.add(Dense(100, activation= tanh , name= fc1 ))\nmodel.add(Dense(10, activation= softmax , name= fc2 ))\n\nmodel.get_input_shape() # (None, 28, 28, 1)\nmodel.get_output_shape() # (None, 10)  See  here  for detailed introduction of LeNet, the full example code and running instructions.", 
            "title": "LeNet Example"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-python/#keras-code-support", 
            "text": "If you have an existing piece of Keras code for a model definition, without installing Keras, you can directly migrate the code to construct a BigDL model by just replacing Keras import lines with:  from bigdl.nn.keras.topology import *\nfrom bigdl.nn.keras.layer import *  and making modifications subject to the following limitations:    The Keras version we support and test is  Keras 1.2.2  with TensorFlow backend.    There exist some arguments supported in Keras layers but not supported in BigDL for now. See  here  for the full list of unsupported layer arguments. Also, currently we haven't supported self-defined Keras layers or  Lambda  layers.    The default dim_ordering in BigDL is  th  (Channel First, channel_axis=1).    Keras  backend  related code needs to be deleted or refactored appropriately.    Code involving Keras utility functions or loading weights from HDF5 files should be removed.    Remark:  We have tested for migrating Keras code definition of  VGG16 ,  VGG19 ,  ResNet50  and  InceptionV3  into BigDL.", 
            "title": "Keras Code Support"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-scala/", 
            "text": "Introduction\n\n\nWe hereby introduce a new set of \nKeras-Style API\n based on \nKeras 1.2.2\n in BigDL for the sake of user-friendliness. Users, especially those familiar with Keras, are recommended to use the new API to create a BigDL model and train, evaluate or tune it in a distributed fashion.\n\n\nTo define a model in Scala using the Keras-Style API, now one just need to import the following packages:\n\n\nimport com.intel.analytics.bigdl.nn.keras._\nimport com.intel.analytics.bigdl.utils.Shape\n\n\n\n\nOne of the highlighted features with regard to the new API is \nshape inference\n. Users only need to specify the input shape (a \nShape\n object \nexcluding\n batch dimension, for example, \ninputShape=Shape(3, 4)\n for 3D input) for the first layer of a model and for the remaining layers, the input dimension will be automatically inferred.\n\n\n\n\nShape\n\n\nInput and output shapes of a model in the Keras-Style API are described by the \nShape\n object in Scala, which can be classified into \nSingleShape\n and \nMultiShape\n.\n\n\nSingleShape\n is just a list of Int indicating shape dimensions while \nMultiShape\n is essentially a list of \nShape\n.\n\n\nExample code to create a shape:\n\n\n// create a SingleShape\nval shape1 = Shape(3, 4)\n// create a MultiShape consisting of two SingleShape\nval shape2 = Shape(List(Shape(1, 2, 3), Shape(4, 5, 6)))\n\n\n\n\nYou can use method \ntoSingle()\n to cast a \nShape\n to a \nSingleShape\n. Similarly, use \ntoMulti()\n to cast a \nShape\n to a \nMultiShape\n.\n\n\n\n\nDefine a model\n\n\nYou can define a model either using \nSequential API\n or \nFunctional API\n. Remember to specify the input shape for the first layer.\n\n\nAfter creating a model, you can call the following \nmethods\n:\n\n\ngetInputShape()\n\n\n\n\ngetOutputShape()\n\n\n\n\n\n\nReturn the input or output shape of a model, which is a \nShape\n object. For \nSingleShape\n, the first entry is \n-1\n representing the batch dimension. For a model with multiple inputs or outputs, it will return a \nMultiShape\n.\n\n\n\n\nsetName(name)\n\n\n\n\n\n\nSet the name of the model.\n\n\n\n\nSee \nhere\n on how to train, predict or evaluate a defined model.\n\n\n\n\nSequential API\n\n\nThe model is described as a linear stack of layers in the Sequential API. Layers can be added into the \nSequential\n container one by one and the order of the layers in the model will be the same as the insertion order.\n\n\nTo create a sequential container:\n\n\nSequential()\n\n\n\n\nExample code to create a sequential model:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, Dense, Activation}\nimport com.intel.analytics.bigdl.utils.Shape\n\nval model = Sequential[Float]()\nmodel.add(Dense(32, inputShape = Shape(128)))\nmodel.add(Activation(\nrelu\n))\n\n\n\n\n\n\nFunctional API\n\n\nThe model is described as a graph in the Functional API. It is more convenient than the Sequential API when defining some complex model (for example, a model with multiple outputs).\n\n\nTo create an input node:\n\n\nInput(inputShape = null, name = null)\n\n\n\n\nParameters:\n\n\n\n\ninputShape\n: A \nShape\n object indicating the shape of the input node, not including batch.\n\n\nname\n: String to set the name of the input node. If not specified, its name will by default to be a generated string.\n\n\n\n\nTo create a graph container:\n\n\nModel(input, output)\n\n\n\n\nParameters:\n\n\n\n\ninput\n: An input node or an array of input nodes.\n\n\noutput\n: An output node or an array of output nodes.\n\n\n\n\nTo merge a list of input \nnodes\n (\nNOT\n layers), following some merge mode in the Functional API:\n\n\nimport com.intel.analytics.bigdl.nn.keras.Merge.merge\n\nmerge(inputs, mode = \nsum\n, concatAxis = -1) // This will return an output NODE.\n\n\n\n\nParameters:\n\n\n\n\ninputs\n: A list of node instances. Must be more than one node.\n\n\nmode\n: Merge mode. String, must be one of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'. Default is 'sum'.\n\n\nconcatAxis\n: Int, axis to use when concatenating nodes. Only specify this when merge mode is 'concat'. Default is -1, meaning the last axis of the input.\n\n\n\n\nExample code to create a graph model:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Input, Dense, Model}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.nn.keras.Merge.merge\n\n// instantiate input nodes\nval input1 = Input[Float](inputShape = Shape(8))\nval input2 = Input[Float](inputShape = Shape(6))\n// call inputs() with an input node and get an output node\nval dense1 = Dense[Float](10).inputs(input1)\nval dense2 = Dense[Float](10).inputs(input2)\n// merge two nodes following some merge mode\nval output = merge(inputs = List(dense1, dense2), mode = \nsum\n)\n// create a graph container\nval model = Model[Float](Array(input1, input2), output)\n\n\n\n\n\n\nLayers\n\n\nSee \nhere\n for all the available layers for the new set of Keras-Style API.\n\n\nTo set the name of a layer, call the method \nsetName(name)\n of the layer.\n\n\n\n\nLeNet Example\n\n\nHere we adopt our Keras-Style API to define a LeNet CNN model to be trained on the MNIST dataset:\n\n\nimport com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.keras._\nimport com.intel.analytics.bigdl.utils.Shape\n\nval model = Sequential()\nmodel.add(Reshape(Array(1, 28, 28), inputShape = Shape(28, 28, 1)))\nmodel.add(Convolution2D(6, 5, 5, activation = \ntanh\n).setName(\nconv1_5x5\n))\nmodel.add(MaxPooling2D())\nmodel.add(Convolution2D(12, 5, 5, activation = \ntanh\n).setName(\nconv2_5x5\n))\nmodel.add(MaxPooling2D())\nmodel.add(Flatten())\nmodel.add(Dense(100, activation = \ntanh\n).setName(\nfc1\n))\nmodel.add(Dense(10, activation = \nsoftmax\n).setName(\nfc2\n))\n\nmodel.getInputShape().toSingle().toArray // Array(-1, 28, 28, 1)\nmodel.getOutputShape().toSingle().toArray // Array(-1, 10)\n\n\n\n\nSee \nhere\n for detailed introduction of LeNet, the full example code and running instructions.", 
            "title": "Scala Guide"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-scala/#introduction", 
            "text": "We hereby introduce a new set of  Keras-Style API  based on  Keras 1.2.2  in BigDL for the sake of user-friendliness. Users, especially those familiar with Keras, are recommended to use the new API to create a BigDL model and train, evaluate or tune it in a distributed fashion.  To define a model in Scala using the Keras-Style API, now one just need to import the following packages:  import com.intel.analytics.bigdl.nn.keras._\nimport com.intel.analytics.bigdl.utils.Shape  One of the highlighted features with regard to the new API is  shape inference . Users only need to specify the input shape (a  Shape  object  excluding  batch dimension, for example,  inputShape=Shape(3, 4)  for 3D input) for the first layer of a model and for the remaining layers, the input dimension will be automatically inferred.", 
            "title": "Introduction"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-scala/#shape", 
            "text": "Input and output shapes of a model in the Keras-Style API are described by the  Shape  object in Scala, which can be classified into  SingleShape  and  MultiShape .  SingleShape  is just a list of Int indicating shape dimensions while  MultiShape  is essentially a list of  Shape .  Example code to create a shape:  // create a SingleShape\nval shape1 = Shape(3, 4)\n// create a MultiShape consisting of two SingleShape\nval shape2 = Shape(List(Shape(1, 2, 3), Shape(4, 5, 6)))  You can use method  toSingle()  to cast a  Shape  to a  SingleShape . Similarly, use  toMulti()  to cast a  Shape  to a  MultiShape .", 
            "title": "Shape"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-scala/#define-a-model", 
            "text": "You can define a model either using  Sequential API  or  Functional API . Remember to specify the input shape for the first layer.  After creating a model, you can call the following  methods :  getInputShape()  getOutputShape()   Return the input or output shape of a model, which is a  Shape  object. For  SingleShape , the first entry is  -1  representing the batch dimension. For a model with multiple inputs or outputs, it will return a  MultiShape .   setName(name)   Set the name of the model.   See  here  on how to train, predict or evaluate a defined model.", 
            "title": "Define a model"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-scala/#sequential-api", 
            "text": "The model is described as a linear stack of layers in the Sequential API. Layers can be added into the  Sequential  container one by one and the order of the layers in the model will be the same as the insertion order.  To create a sequential container:  Sequential()  Example code to create a sequential model:  import com.intel.analytics.bigdl.nn.keras.{Sequential, Dense, Activation}\nimport com.intel.analytics.bigdl.utils.Shape\n\nval model = Sequential[Float]()\nmodel.add(Dense(32, inputShape = Shape(128)))\nmodel.add(Activation( relu ))", 
            "title": "Sequential API"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-scala/#functional-api", 
            "text": "The model is described as a graph in the Functional API. It is more convenient than the Sequential API when defining some complex model (for example, a model with multiple outputs).  To create an input node:  Input(inputShape = null, name = null)  Parameters:   inputShape : A  Shape  object indicating the shape of the input node, not including batch.  name : String to set the name of the input node. If not specified, its name will by default to be a generated string.   To create a graph container:  Model(input, output)  Parameters:   input : An input node or an array of input nodes.  output : An output node or an array of output nodes.   To merge a list of input  nodes  ( NOT  layers), following some merge mode in the Functional API:  import com.intel.analytics.bigdl.nn.keras.Merge.merge\n\nmerge(inputs, mode =  sum , concatAxis = -1) // This will return an output NODE.  Parameters:   inputs : A list of node instances. Must be more than one node.  mode : Merge mode. String, must be one of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'. Default is 'sum'.  concatAxis : Int, axis to use when concatenating nodes. Only specify this when merge mode is 'concat'. Default is -1, meaning the last axis of the input.   Example code to create a graph model:  import com.intel.analytics.bigdl.nn.keras.{Input, Dense, Model}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.nn.keras.Merge.merge\n\n// instantiate input nodes\nval input1 = Input[Float](inputShape = Shape(8))\nval input2 = Input[Float](inputShape = Shape(6))\n// call inputs() with an input node and get an output node\nval dense1 = Dense[Float](10).inputs(input1)\nval dense2 = Dense[Float](10).inputs(input2)\n// merge two nodes following some merge mode\nval output = merge(inputs = List(dense1, dense2), mode =  sum )\n// create a graph container\nval model = Model[Float](Array(input1, input2), output)", 
            "title": "Functional API"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-scala/#layers", 
            "text": "See  here  for all the available layers for the new set of Keras-Style API.  To set the name of a layer, call the method  setName(name)  of the layer.", 
            "title": "Layers"
        }, 
        {
            "location": "/KerasStyleAPIGuide/keras-api-scala/#lenet-example", 
            "text": "Here we adopt our Keras-Style API to define a LeNet CNN model to be trained on the MNIST dataset:  import com.intel.analytics.bigdl.numeric.NumericFloat\nimport com.intel.analytics.bigdl.nn.keras._\nimport com.intel.analytics.bigdl.utils.Shape\n\nval model = Sequential()\nmodel.add(Reshape(Array(1, 28, 28), inputShape = Shape(28, 28, 1)))\nmodel.add(Convolution2D(6, 5, 5, activation =  tanh ).setName( conv1_5x5 ))\nmodel.add(MaxPooling2D())\nmodel.add(Convolution2D(12, 5, 5, activation =  tanh ).setName( conv2_5x5 ))\nmodel.add(MaxPooling2D())\nmodel.add(Flatten())\nmodel.add(Dense(100, activation =  tanh ).setName( fc1 ))\nmodel.add(Dense(10, activation =  softmax ).setName( fc2 ))\n\nmodel.getInputShape().toSingle().toArray // Array(-1, 28, 28, 1)\nmodel.getOutputShape().toSingle().toArray // Array(-1, 10)  See  here  for detailed introduction of LeNet, the full example code and running instructions.", 
            "title": "LeNet Example"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/activation/", 
            "text": "Activation\n\n\nSimple activation function to be applied to the output.\n\n\nScala:\n\n\nActivation(activation, inputShape = null)\n\n\n\n\nPython:\n\n\nActivation(activation, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nactivation\n: Name of the activation function as string. See \nhere\n for available activation strings.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, Activation}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Activation(\ntanh\n, inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n2.1659365   0.28006053  -0.20148286\n0.9146865    3.4301455    1.0930616\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.9740552    0.2729611    -0.1988\n 0.723374   0.99790496  0.7979928\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Activation\n\nmodel = Sequential()\nmodel.add(Activation(\ntanh\n, input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[ 0.26202468  0.15868397  0.27812652]\n [ 0.45931689  0.32100054  0.51839282]]\n\n\n\n\nOutput is\n\n\n[[ 0.2561883   0.15736534  0.27117023]\n [ 0.42952728  0.31041133  0.47645861]]\n\n\n\n\nNote that the following two pieces of code will be equivalent:\n\n\nmodel.add(Dense(32))\nmodel.add(Activation('relu'))\n\n\n\n\nmodel.add(Dense(32, activation=\nrelu\n))\n\n\n\n\n\n\nAvailable Activations\n\n\n\n\nrelu\n\n\ntanh\n\n\nsigmoid\n\n\nhard_sigmoid\n\n\nsoftmax\n\n\nsoftplus\n\n\nsoftsign", 
            "title": "Activation"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/activation/#activation", 
            "text": "Simple activation function to be applied to the output.  Scala:  Activation(activation, inputShape = null)  Python:  Activation(activation, input_shape=None, name=None)  Parameters:   activation : Name of the activation function as string. See  here  for available activation strings.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, Activation}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Activation( tanh , inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n2.1659365   0.28006053  -0.20148286\n0.9146865    3.4301455    1.0930616\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.9740552    0.2729611    -0.1988\n 0.723374   0.99790496  0.7979928\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Activation\n\nmodel = Sequential()\nmodel.add(Activation( tanh , input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  [[ 0.26202468  0.15868397  0.27812652]\n [ 0.45931689  0.32100054  0.51839282]]  Output is  [[ 0.2561883   0.15736534  0.27117023]\n [ 0.42952728  0.31041133  0.47645861]]  Note that the following two pieces of code will be equivalent:  model.add(Dense(32))\nmodel.add(Activation('relu'))  model.add(Dense(32, activation= relu ))", 
            "title": "Activation"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/activation/#available-activations", 
            "text": "relu  tanh  sigmoid  hard_sigmoid  softmax  softplus  softsign", 
            "title": "Available Activations"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/initialization/", 
            "text": "Initialization methods initialize weights for layers. String representations of initialization methods can be passed into the layer argument \ninit\n to take effect.\n\n\n\n\nAvailable Initialization Methods\n\n\n\n\nzero\n\n\none\n\n\nuniform\n\n\nnormal\n\n\nglorot_uniform (a.k.a \nXavier\n)", 
            "title": "Initialization"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/initialization/#available-initialization-methods", 
            "text": "zero  one  uniform  normal  glorot_uniform (a.k.a  Xavier )", 
            "title": "Available Initialization Methods"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/", 
            "text": "InputLayer\n\n\nCan be used as an entry point into a model.\n\n\nScala:\n\n\nInputLayer(inputShape = null, name = null)\n\n\n\n\nPython:\n\n\nInputLayer(input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ninputShape\n: For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\nname\n: String to set the name of the input node. If not specified, its name will by default to be a generated string.\n\n\n\n\n\n\nDense\n\n\nA densely-connected NN layer.\n\n\nThe most common input is 2D.\n\n\nScala:\n\n\nDense(outputDim, init = \nglorot_uniform\n, activation = null, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nDense(output_dim, init=\nglorot_uniform\n, activation=None, W_regularizer=None, b_regularizer=None, bias=True, input_dim=None, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\noutputDim\n: The size of the output dimension.\n\n\ninit\n: String representation of the initialization method for the weights of the layer. See \nhere\n for available initialization strings. Default is 'glorot_uniform'.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is null.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, Dense}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Dense(5, activation = \nrelu\n, inputShape = Shape(4)))\nval input = Tensor[Float](2, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n 1.8646977  -0.059090078  0.091468036   0.6387431\n-0.4485392  1.5150243     -0.60176533   -0.6811443\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n1.0648216  0.0         0.0  0.0  0.0\n0.0        0.20690927  0.0  0.0  0.34191078\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Dense\n\nmodel = Sequential()\nmodel.add(Dense(5, activation=\nrelu\n, input_shape=(4, )))\ninput = np.random.random([2, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[ 0.26202468  0.15868397  0.27812652  0.45931689]\n [ 0.32100054  0.51839282  0.26194293  0.97608528]]\n\n\n\n\nOutput is\n\n\n[[ 0.0   0.0     0.0     0.02094215  0.38839486]\n [ 0.0   0.0     0.0     0.24498197  0.38024583]]\n\n\n\n\n\n\nFlatten\n\n\nFlattens the input without affecting the batch size.\n\n\nScala:\n\n\nFlatten(inputShape = null)\n\n\n\n\nPython:\n\n\nFlatten(input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, Flatten}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Flatten(inputShape = Shape(2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n1.2196734   -0.37271047 -0.31215316\n-0.68951845 -0.20356052 -0.85899264\n\n(1,2,.,.) =\n-1.7452804  -0.1138052  -0.9124519\n-0.94204897 0.28943604  -0.71905166\n\n(2,1,.,.) =\n0.7228912   -0.51781553 -0.5869045\n-0.82529205 0.26846665  -0.6199292\n\n(2,2,.,.) =\n-0.4529333  -0.57688874 0.9097755\n0.7112487   -0.6711465  1.3074298\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n1.2196734   -0.37271047 -0.31215316 -0.68951845 -0.20356052 -0.85899264 -1.7452804  -0.1138052  -0.9124519  -0.94204897 0.28943604  -0.71905166\n0.7228912   -0.51781553 -0.5869045  -0.82529205 0.26846665  -0.6199292  -0.4529333  -0.57688874 0.9097755   0.7112487   -0.6711465  1.3074298\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x12]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Flatten\n\nmodel = Sequential()\nmodel.add(Flatten(input_shape=(2, 2, 3)))\ninput = np.random.random([2, 2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.86901694 0.18961039 0.40317114]\n   [0.03546013 0.44338256 0.14267447]]\n  [[0.08971508 0.04943281 0.47568212]\n   [0.21874466 0.54040762 0.19513549]]]\n\n [[[0.89994454 0.10154699 0.19762439]\n   [0.90341835 0.44006613 0.08758557]]\n  [[0.51165122 0.15523108 0.47434121]\n   [0.24526962 0.79663289 0.52078471]]]]\n\n\n\n\nOutput is\n\n\n[[0.86901695 0.18961039 0.40317115 0.03546013 0.44338256 0.14267448\n  0.08971508 0.04943281 0.4756821  0.21874467 0.5404076  0.19513549]\n [0.89994454 0.10154699 0.1976244  0.90341836 0.44006613 0.08758558\n  0.5116512  0.15523107 0.4743412  0.24526963 0.7966329  0.52078474]]\n\n\n\n\n\n\nReshape\n\n\nReshapes an output to a certain shape.\n\n\nSupports shape inference by allowing one -1 in the target shape. For example, if input shape is (2, 3, 4), target shape is (3, -1), then output shape will be (3, 8).\n\n\nScala:\n\n\nReshape(targetShape, inputShape = null)\n\n\n\n\nPython:\n\n\nReshape(target_shape, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ntargetShape\n: The target shape that you desire to have. Batch dimension should be excluded.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, Reshape}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Reshape(Array(3, 8), inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-1.7092276  -1.3941092  -0.6348466  0.71309644\n0.3605411   0.025597548 0.4287048   -0.548675\n0.4623341   -2.3912702  0.22030865  -0.058272455\n\n(1,2,.,.) =\n-1.5049093  -1.8828062  0.8230564   -0.020209199\n-0.3415721  1.1219939   1.1089007   -0.74697906\n-1.503861   -1.616539   0.048006497 1.1613717\n\n(2,1,.,.) =\n0.21216023  1.0107462   0.8586909   -0.05644316\n-0.31436008 1.6892323   -0.9961186  -0.08169463\n0.3559391   0.010261055 -0.70408463 -1.2480727\n\n(2,2,.,.) =\n1.7663039   0.07122444  0.073556066 -0.7847014\n0.17604464  -0.99110585 -1.0302067  -0.39024687\n-0.0260166  -0.43142694 0.28443158  0.72679126\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-1.7092276  -1.3941092  -0.6348466  0.71309644      0.3605411   0.025597548 0.4287048   -0.548675\n0.4623341   -2.3912702  0.22030865  -0.058272455    -1.5049093  -1.8828062  0.8230564   -0.020209199\n-0.3415721  1.1219939   1.1089007   -0.74697906     -1.503861   -1.616539   0.048006497 1.1613717\n\n(2,.,.) =\n0.21216023  1.0107462   0.8586909   -0.05644316     -0.31436008 1.6892323   -0.9961186  -0.08169463\n0.3559391   0.010261055 -0.70408463 -1.2480727      1.7663039   0.07122444  0.073556066 -0.7847014\n0.17604464  -0.99110585 -1.0302067  -0.39024687     -0.0260166  -0.43142694 0.28443158  0.72679126\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x8]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Reshape\n\nmodel = Sequential()\nmodel.add(Reshape(target_shape=(3, 8), input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.39260304 0.10383185 0.87490319 0.89167328]\n   [0.61649117 0.43285247 0.86851582 0.97743004]\n   [0.90018969 0.04303951 0.74263493 0.14208656]]\n  [[0.66193405 0.93432157 0.76160537 0.70437459]\n   [0.99953431 0.23016734 0.42293405 0.66078049]\n   [0.03357645 0.9695145  0.30111138 0.67109948]]]\n\n [[[0.39640201 0.92930203 0.86027666 0.13958544]\n   [0.34584767 0.14743425 0.93804016 0.38053062]\n   [0.55068792 0.77375329 0.84161166 0.48131356]]\n  [[0.90116368 0.53253689 0.03332962 0.58278686]\n   [0.34935685 0.32599554 0.97641892 0.57696434]\n   [0.53974677 0.90682861 0.20027319 0.05962118]]]]\n\n\n\n\nOutput is\n\n\n[[[0.39260304 0.10383185 0.8749032  0.89167327 0.6164912  0.43285248 0.86851585 0.97743005]\n  [0.9001897  0.04303951 0.74263495 0.14208655 0.661934   0.9343216  0.7616054  0.7043746 ]\n  [0.9995343  0.23016734 0.42293406 0.6607805  0.03357645 0.9695145  0.30111137 0.6710995 ]]\n\n [[0.396402   0.92930204 0.86027664 0.13958544 0.34584767 0.14743425 0.93804014 0.38053063]\n  [0.5506879  0.7737533  0.8416117  0.48131356 0.9011637  0.53253686 0.03332962 0.58278686]\n  [0.34935686 0.32599553 0.9764189  0.5769643  0.53974676 0.9068286  0.20027319 0.05962119]]]\n\n\n\n\n\n\nPermute\n\n\nPermutes the dimensions of the input according to a given pattern.\n\n\nUseful for connecting RNNs and convnets together.\n\n\nScala:\n\n\nPermute(dims, inputShape = null)\n\n\n\n\nPython:\n\n\nPermute(dims, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ndims\n: Permutation pattern, does not include the batch dimension. Indexing starts at 1.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, Permute}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Permute(Array(2, 3, 1), inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-1.1030567  -1.4624393  0.6139582   0.21287616\n-2.2278674  -2.5211496  1.9219213   0.85134244\n0.32953477  -2.1209111  -0.82459116 -0.82447577\n\n(1,2,.,.) =\n1.0540756   2.2638302   0.19139263  -0.9037997\n-0.20562297 -0.07835103 0.3883783   0.20750551\n-0.56583923 0.9617757   -0.5792387  0.9008493\n\n(2,1,.,.) =\n-0.54270995 -1.9089237     0.9289245    0.27833897\n-1.4734148  -0.9408616     -0.40362656  -1.1730295\n0.9813707   -0.0040280274  -1.5321463   -1.4322052\n\n(2,2,.,.) =\n-0.056844145   2.2309854    2.1172705     0.10043324\n1.121064       0.16069101   -0.51750094   -1.9682871\n0.9011646      0.47903928   -0.54172426   -0.6604068\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n-1.1030567  1.0540756\n-1.4624393  2.2638302\n0.6139582   0.19139263\n0.21287616  -0.9037997\n\n(1,2,.,.) =\n-2.2278674  -0.20562297\n-2.5211496  -0.07835103\n1.9219213   0.3883783\n0.85134244  0.20750551\n\n(1,3,.,.) =\n0.32953477  -0.56583923\n-2.1209111  0.9617757\n-0.82459116 -0.5792387\n-0.82447577 0.9008493\n\n(2,1,.,.) =\n-0.54270995 -0.056844145\n-1.9089237  2.2309854\n0.9289245   2.1172705\n0.27833897  0.10043324\n\n(2,2,.,.) =\n-1.4734148  1.121064\n-0.9408616  0.16069101\n-0.40362656 -0.51750094\n-1.1730295  -1.9682871\n\n(2,3,.,.) =\n0.9813707      0.9011646\n-0.0040280274  0.47903928\n-1.5321463     -0.54172426\n-1.4322052     -0.6604068\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4x2]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Permute\n\nmodel = Sequential()\nmodel.add(Permute(dims=(2, 3, 1), input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.47372355 0.18103412 0.07076151 0.51208742]\n   [0.3830121  0.2036672  0.24978515 0.3458438 ]\n   [0.34180976 0.54635229 0.90048856 0.89178666]]\n  [[0.15893009 0.62223068 0.1060953  0.26898095]\n   [0.97659789 0.72022333 0.12613522 0.66538681]\n   [0.79589927 0.32906473 0.27806256 0.99698214]]]\n\n [[[0.14608597 0.96667223 0.17876087 0.37672275]\n   [0.89726934 0.09588159 0.19987136 0.99728596]\n   [0.592439   0.40126537 0.18349086 0.88102044]]\n  [[0.29313258 0.94066727 0.57244849 0.79352687]\n   [0.31302252 0.65390325 0.54829736 0.63749209]\n   [0.76679177 0.43937809 0.06966902 0.27204878]]]]\n\n\n\n\nOutput is\n\n\n[[[[0.47372353 0.1589301 ]\n   [0.18103412 0.6222307 ]\n   [0.07076152 0.1060953 ]\n   [0.5120874  0.26898095]]\n  [[0.38301212 0.9765979 ]\n   [0.2036672  0.7202233 ]\n   [0.24978516 0.12613523]\n   [0.3458438  0.6653868 ]]\n  [[0.34180975 0.7958993 ]\n   [0.54635227 0.32906473]\n   [0.90048856 0.27806255]\n   [0.89178663 0.99698216]]]\n\n [[[0.14608598 0.29313257]\n   [0.96667224 0.9406673 ]\n   [0.17876087 0.5724485 ]\n   [0.37672275 0.7935269 ]]\n\n  [[0.8972693  0.31302252]\n   [0.09588159 0.65390325]\n   [0.19987136 0.54829735]\n   [0.99728596 0.63749206]]\n\n  [[0.592439   0.76679176]\n   [0.40126538 0.43937808]\n   [0.18349086 0.06966902]\n   [0.8810204  0.27204877]]]]\n\n\n\n\n\n\nRepeatVector\n\n\nRepeats the input n times.\n\n\nThe input of this layer should be 2D.\n\n\nScala:\n\n\nRepeatVector(n, inputShape = null)\n\n\n\n\nPython:\n\n\nRepeatVector(n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nn\n: Repetition factor. Integer.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, RepeatVector}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(RepeatVector(4, inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.4182444   2.858577    1.3975657\n-0.19606766 0.8585809   0.3027246\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n1.4182444   2.858577    1.3975657\n1.4182444   2.858577    1.3975657\n1.4182444   2.858577    1.3975657\n1.4182444   2.858577    1.3975657\n\n(2,.,.) =\n-0.19606766 0.8585809   0.3027246\n-0.19606766 0.8585809   0.3027246\n-0.19606766 0.8585809   0.3027246\n-0.19606766 0.8585809   0.3027246\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import RepeatVector\n\nmodel = Sequential()\nmodel.add(RepeatVector(4, input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[0.51416513 0.87768557 0.48015041]\n [0.66598164 0.58916225 0.03983186]]\n\n\n\n\nOutput is\n\n\n[[[0.5141651  0.87768555 0.4801504 ]\n  [0.5141651  0.87768555 0.4801504 ]\n  [0.5141651  0.87768555 0.4801504 ]\n  [0.5141651  0.87768555 0.4801504 ]]\n\n [[0.66598165 0.58916223 0.03983186]\n  [0.66598165 0.58916223 0.03983186]\n  [0.66598165 0.58916223 0.03983186]\n  [0.66598165 0.58916223 0.03983186]]]\n\n\n\n\n\n\nMerge\n\n\nUsed to merge a list of inputs into a single output, following some merge mode.\n\n\nMerge must have at least two input layers.\n\n\nScala:\n\n\nMerge(layers = null, mode = \nsum\n, concatAxis = -1, inputShape = null)\n\n\n\n\nPython:\n\n\nMerge(layers=None, mode=\nsum\n, concat_axis=-1, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nlayers\n: A list of layer instances. Must be more than one layer.\n\n\nmode\n: Merge mode. String, must be one of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'. Default is 'sum'.\n\n\nconcatAxis\n: Integer, axis to use when concatenating layers. Only specify this when merge mode is 'concat'. Default is -1, meaning the last axis of the input.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, Merge, InputLayer}\nimport com.intel.analytics.bigdl.utils.{Shape, T}\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nval l1 = InputLayer[Float](inputShape = Shape(2, 3))\nval l2 = InputLayer[Float](inputShape = Shape(2, 3))\nval layer = Merge[Float](layers = List(l1, l2), mode = \nsum\n)\nmodel.add(layer)\nval input1 = Tensor[Float](2, 2, 3).rand(0, 1)\nval input2 = Tensor[Float](2, 2, 3).rand(0, 1)\nval input = T(1 -\n input1, 2 -\n input2)\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.utils.Table =\n {\n    2: (1,.,.) =\n       0.87815475   0.15025006  0.34412447\n       0.07909282   0.008027249 0.111715704\n\n       (2,.,.) =\n       0.52245367   0.2547527   0.35857987\n       0.7718501    0.26783863  0.8642062\n\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n    1: (1,.,.) =\n       0.5377018    0.28364193  0.3424284\n       0.0075349305 0.9018168   0.9435114\n\n       (2,.,.) =\n       0.09112563   0.88585275  0.3100201\n       0.7910178    0.57497376  0.39764535\n\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n }\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n1.4158566   0.433892    0.6865529\n0.08662775  0.90984404  1.0552272\n\n(2,.,.) =\n0.6135793   1.1406054   0.66859996\n1.5628679   0.8428124   1.2618515\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Merge, InputLayer\n\nmodel = Sequential()\nl1 = InputLayer(input_shape=(3, 4))\nl2 = InputLayer(input_shape=(3, 4))\nmodel.add(Merge(layers=[l1, l2], mode='sum'))\ninput = [np.random.random([2, 3, 4]), np.random.random([2, 3, 4])]\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[array([[[0.28764351, 0.0236015 , 0.78927442, 0.52646492],\n        [0.63922826, 0.45101604, 0.4555552 , 0.70105653],\n        [0.75790798, 0.78551523, 0.00686686, 0.61290369]],\n\n       [[0.00430865, 0.3303661 , 0.59915782, 0.90362298],\n        [0.26230717, 0.99383052, 0.50630521, 0.99119486],\n        [0.56138318, 0.68165639, 0.10644523, 0.51860127]]]),\n\n array([[[0.84365767, 0.8854741 , 0.84183673, 0.96322321],\n        [0.49354248, 0.97936826, 0.2266097 , 0.88083622],\n        [0.11011776, 0.65762034, 0.17446099, 0.76658969]],\n\n       [[0.58266689, 0.86322199, 0.87122999, 0.19031255],\n        [0.42275118, 0.76379413, 0.21355413, 0.81132937],\n        [0.97294728, 0.68601731, 0.39871792, 0.63172344]]])]\n\n\n\n\nOutput is\n\n\n[[[1.1313012  0.90907556 1.6311111  1.4896882 ]\n  [1.1327708  1.4303843  0.6821649  1.5818927 ]\n  [0.8680257  1.4431355  0.18132785 1.3794935 ]]\n\n [[0.5869755  1.1935881  1.4703878  1.0939355 ]\n  [0.68505836 1.7576246  0.71985936 1.8025242 ]\n  [1.5343305  1.3676738  0.50516313 1.1503248 ]]]\n\n\n\n\n\n\nMasking\n\n\nUse a mask value to skip timesteps for a sequence.\n\n\nScala:\n\n\nMasking(maskValue = 0.0, inputShape = null)\n\n\n\n\nPython:\n\n\nMasking(mask_value=0.0, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nmaskValue\n: Mask value. For each timestep in the input (the second dimension), if all the values in the input at that timestep are equal to 'maskValue', then the timestep will masked (skipped) in all downstream layers.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, Masking}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Masking(inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.00938185  -1.1461893  -1.0204586\n0.24702129  -2.2756217  0.010394359\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.00938185  -1.1461893  -1.0204586\n0.24702129  -2.2756217  0.010394359\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Masking\n\nmodel = Sequential()\nmodel.add(Masking(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[0.59540156 0.24933489 0.04434161]\n [0.89243422 0.68499562 0.36788333]]\n\n\n\n\nOutput is\n\n\n[[0.5954016  0.24933489 0.04434161]\n [0.89243424 0.68499565 0.36788332]]\n\n\n\n\n\n\nMaxoutDense\n\n\nA dense maxout layer that takes the element-wise maximum of linear layers.\n\n\nThis allows the layer to learn a convex, piecewise linear activation function over the inputs.\n\n\nThe input of this layer should be 2D.\n\n\nScala:\n\n\nMaxoutDense(outputDim, nbFeature = 4, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nMaxoutDense(output_dim, nb_feature=4, W_regularizer=None, b_regularizer=None, bias=True, input_dim=None, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\noutputDim\n: The size of output dimension.\n\n\nnbFeature\n: Number of Dense layers to use internally. Integer. Default is 4.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, MaxoutDense}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(MaxoutDense(2, inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-1.3550005  -1.1668127  -1.2882779\n0.83600295  -1.94683    1.323666\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.71675766  1.2987505\n0.9871184   0.6634239\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import MaxoutDense\n\nmodel = Sequential()\nmodel.add(MaxoutDense(2, input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[0.15996114 0.8391686  0.81922903]\n [0.52929427 0.35061754 0.88167693]]\n\n\n\n\nOutput is\n\n\n[[0.4479192  0.4842512]\n [0.16833156 0.521764 ]]", 
            "title": "Core Layers"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#inputlayer", 
            "text": "Can be used as an entry point into a model.  Scala:  InputLayer(inputShape = null, name = null)  Python:  InputLayer(input_shape=None, name=None)  Parameters:   inputShape : For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.  name : String to set the name of the input node. If not specified, its name will by default to be a generated string.", 
            "title": "InputLayer"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#dense", 
            "text": "A densely-connected NN layer.  The most common input is 2D.  Scala:  Dense(outputDim, init =  glorot_uniform , activation = null, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)  Python:  Dense(output_dim, init= glorot_uniform , activation=None, W_regularizer=None, b_regularizer=None, bias=True, input_dim=None, input_shape=None, name=None)  Parameters:   outputDim : The size of the output dimension.  init : String representation of the initialization method for the weights of the layer. See  here  for available initialization strings. Default is 'glorot_uniform'.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is null.  wRegularizer : An instance of  Regularizer , applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, Dense}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Dense(5, activation =  relu , inputShape = Shape(4)))\nval input = Tensor[Float](2, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n 1.8646977  -0.059090078  0.091468036   0.6387431\n-0.4485392  1.5150243     -0.60176533   -0.6811443\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n1.0648216  0.0         0.0  0.0  0.0\n0.0        0.20690927  0.0  0.0  0.34191078\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Dense\n\nmodel = Sequential()\nmodel.add(Dense(5, activation= relu , input_shape=(4, )))\ninput = np.random.random([2, 4])\noutput = model.forward(input)  Input is:  [[ 0.26202468  0.15868397  0.27812652  0.45931689]\n [ 0.32100054  0.51839282  0.26194293  0.97608528]]  Output is  [[ 0.0   0.0     0.0     0.02094215  0.38839486]\n [ 0.0   0.0     0.0     0.24498197  0.38024583]]", 
            "title": "Dense"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#flatten", 
            "text": "Flattens the input without affecting the batch size.  Scala:  Flatten(inputShape = null)  Python:  Flatten(input_shape=None, name=None)  Parameters:   inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, Flatten}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Flatten(inputShape = Shape(2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n1.2196734   -0.37271047 -0.31215316\n-0.68951845 -0.20356052 -0.85899264\n\n(1,2,.,.) =\n-1.7452804  -0.1138052  -0.9124519\n-0.94204897 0.28943604  -0.71905166\n\n(2,1,.,.) =\n0.7228912   -0.51781553 -0.5869045\n-0.82529205 0.26846665  -0.6199292\n\n(2,2,.,.) =\n-0.4529333  -0.57688874 0.9097755\n0.7112487   -0.6711465  1.3074298\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n1.2196734   -0.37271047 -0.31215316 -0.68951845 -0.20356052 -0.85899264 -1.7452804  -0.1138052  -0.9124519  -0.94204897 0.28943604  -0.71905166\n0.7228912   -0.51781553 -0.5869045  -0.82529205 0.26846665  -0.6199292  -0.4529333  -0.57688874 0.9097755   0.7112487   -0.6711465  1.3074298\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x12]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Flatten\n\nmodel = Sequential()\nmodel.add(Flatten(input_shape=(2, 2, 3)))\ninput = np.random.random([2, 2, 2, 3])\noutput = model.forward(input)  Input is:  [[[[0.86901694 0.18961039 0.40317114]\n   [0.03546013 0.44338256 0.14267447]]\n  [[0.08971508 0.04943281 0.47568212]\n   [0.21874466 0.54040762 0.19513549]]]\n\n [[[0.89994454 0.10154699 0.19762439]\n   [0.90341835 0.44006613 0.08758557]]\n  [[0.51165122 0.15523108 0.47434121]\n   [0.24526962 0.79663289 0.52078471]]]]  Output is  [[0.86901695 0.18961039 0.40317115 0.03546013 0.44338256 0.14267448\n  0.08971508 0.04943281 0.4756821  0.21874467 0.5404076  0.19513549]\n [0.89994454 0.10154699 0.1976244  0.90341836 0.44006613 0.08758558\n  0.5116512  0.15523107 0.4743412  0.24526963 0.7966329  0.52078474]]", 
            "title": "Flatten"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#reshape", 
            "text": "Reshapes an output to a certain shape.  Supports shape inference by allowing one -1 in the target shape. For example, if input shape is (2, 3, 4), target shape is (3, -1), then output shape will be (3, 8).  Scala:  Reshape(targetShape, inputShape = null)  Python:  Reshape(target_shape, input_shape=None, name=None)  Parameters:   targetShape : The target shape that you desire to have. Batch dimension should be excluded.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, Reshape}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Reshape(Array(3, 8), inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-1.7092276  -1.3941092  -0.6348466  0.71309644\n0.3605411   0.025597548 0.4287048   -0.548675\n0.4623341   -2.3912702  0.22030865  -0.058272455\n\n(1,2,.,.) =\n-1.5049093  -1.8828062  0.8230564   -0.020209199\n-0.3415721  1.1219939   1.1089007   -0.74697906\n-1.503861   -1.616539   0.048006497 1.1613717\n\n(2,1,.,.) =\n0.21216023  1.0107462   0.8586909   -0.05644316\n-0.31436008 1.6892323   -0.9961186  -0.08169463\n0.3559391   0.010261055 -0.70408463 -1.2480727\n\n(2,2,.,.) =\n1.7663039   0.07122444  0.073556066 -0.7847014\n0.17604464  -0.99110585 -1.0302067  -0.39024687\n-0.0260166  -0.43142694 0.28443158  0.72679126\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-1.7092276  -1.3941092  -0.6348466  0.71309644      0.3605411   0.025597548 0.4287048   -0.548675\n0.4623341   -2.3912702  0.22030865  -0.058272455    -1.5049093  -1.8828062  0.8230564   -0.020209199\n-0.3415721  1.1219939   1.1089007   -0.74697906     -1.503861   -1.616539   0.048006497 1.1613717\n\n(2,.,.) =\n0.21216023  1.0107462   0.8586909   -0.05644316     -0.31436008 1.6892323   -0.9961186  -0.08169463\n0.3559391   0.010261055 -0.70408463 -1.2480727      1.7663039   0.07122444  0.073556066 -0.7847014\n0.17604464  -0.99110585 -1.0302067  -0.39024687     -0.0260166  -0.43142694 0.28443158  0.72679126\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x8]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Reshape\n\nmodel = Sequential()\nmodel.add(Reshape(target_shape=(3, 8), input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.39260304 0.10383185 0.87490319 0.89167328]\n   [0.61649117 0.43285247 0.86851582 0.97743004]\n   [0.90018969 0.04303951 0.74263493 0.14208656]]\n  [[0.66193405 0.93432157 0.76160537 0.70437459]\n   [0.99953431 0.23016734 0.42293405 0.66078049]\n   [0.03357645 0.9695145  0.30111138 0.67109948]]]\n\n [[[0.39640201 0.92930203 0.86027666 0.13958544]\n   [0.34584767 0.14743425 0.93804016 0.38053062]\n   [0.55068792 0.77375329 0.84161166 0.48131356]]\n  [[0.90116368 0.53253689 0.03332962 0.58278686]\n   [0.34935685 0.32599554 0.97641892 0.57696434]\n   [0.53974677 0.90682861 0.20027319 0.05962118]]]]  Output is  [[[0.39260304 0.10383185 0.8749032  0.89167327 0.6164912  0.43285248 0.86851585 0.97743005]\n  [0.9001897  0.04303951 0.74263495 0.14208655 0.661934   0.9343216  0.7616054  0.7043746 ]\n  [0.9995343  0.23016734 0.42293406 0.6607805  0.03357645 0.9695145  0.30111137 0.6710995 ]]\n\n [[0.396402   0.92930204 0.86027664 0.13958544 0.34584767 0.14743425 0.93804014 0.38053063]\n  [0.5506879  0.7737533  0.8416117  0.48131356 0.9011637  0.53253686 0.03332962 0.58278686]\n  [0.34935686 0.32599553 0.9764189  0.5769643  0.53974676 0.9068286  0.20027319 0.05962119]]]", 
            "title": "Reshape"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#permute", 
            "text": "Permutes the dimensions of the input according to a given pattern.  Useful for connecting RNNs and convnets together.  Scala:  Permute(dims, inputShape = null)  Python:  Permute(dims, input_shape=None, name=None)  Parameters:   dims : Permutation pattern, does not include the batch dimension. Indexing starts at 1.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, Permute}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Permute(Array(2, 3, 1), inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-1.1030567  -1.4624393  0.6139582   0.21287616\n-2.2278674  -2.5211496  1.9219213   0.85134244\n0.32953477  -2.1209111  -0.82459116 -0.82447577\n\n(1,2,.,.) =\n1.0540756   2.2638302   0.19139263  -0.9037997\n-0.20562297 -0.07835103 0.3883783   0.20750551\n-0.56583923 0.9617757   -0.5792387  0.9008493\n\n(2,1,.,.) =\n-0.54270995 -1.9089237     0.9289245    0.27833897\n-1.4734148  -0.9408616     -0.40362656  -1.1730295\n0.9813707   -0.0040280274  -1.5321463   -1.4322052\n\n(2,2,.,.) =\n-0.056844145   2.2309854    2.1172705     0.10043324\n1.121064       0.16069101   -0.51750094   -1.9682871\n0.9011646      0.47903928   -0.54172426   -0.6604068\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n-1.1030567  1.0540756\n-1.4624393  2.2638302\n0.6139582   0.19139263\n0.21287616  -0.9037997\n\n(1,2,.,.) =\n-2.2278674  -0.20562297\n-2.5211496  -0.07835103\n1.9219213   0.3883783\n0.85134244  0.20750551\n\n(1,3,.,.) =\n0.32953477  -0.56583923\n-2.1209111  0.9617757\n-0.82459116 -0.5792387\n-0.82447577 0.9008493\n\n(2,1,.,.) =\n-0.54270995 -0.056844145\n-1.9089237  2.2309854\n0.9289245   2.1172705\n0.27833897  0.10043324\n\n(2,2,.,.) =\n-1.4734148  1.121064\n-0.9408616  0.16069101\n-0.40362656 -0.51750094\n-1.1730295  -1.9682871\n\n(2,3,.,.) =\n0.9813707      0.9011646\n-0.0040280274  0.47903928\n-1.5321463     -0.54172426\n-1.4322052     -0.6604068\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4x2]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Permute\n\nmodel = Sequential()\nmodel.add(Permute(dims=(2, 3, 1), input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.47372355 0.18103412 0.07076151 0.51208742]\n   [0.3830121  0.2036672  0.24978515 0.3458438 ]\n   [0.34180976 0.54635229 0.90048856 0.89178666]]\n  [[0.15893009 0.62223068 0.1060953  0.26898095]\n   [0.97659789 0.72022333 0.12613522 0.66538681]\n   [0.79589927 0.32906473 0.27806256 0.99698214]]]\n\n [[[0.14608597 0.96667223 0.17876087 0.37672275]\n   [0.89726934 0.09588159 0.19987136 0.99728596]\n   [0.592439   0.40126537 0.18349086 0.88102044]]\n  [[0.29313258 0.94066727 0.57244849 0.79352687]\n   [0.31302252 0.65390325 0.54829736 0.63749209]\n   [0.76679177 0.43937809 0.06966902 0.27204878]]]]  Output is  [[[[0.47372353 0.1589301 ]\n   [0.18103412 0.6222307 ]\n   [0.07076152 0.1060953 ]\n   [0.5120874  0.26898095]]\n  [[0.38301212 0.9765979 ]\n   [0.2036672  0.7202233 ]\n   [0.24978516 0.12613523]\n   [0.3458438  0.6653868 ]]\n  [[0.34180975 0.7958993 ]\n   [0.54635227 0.32906473]\n   [0.90048856 0.27806255]\n   [0.89178663 0.99698216]]]\n\n [[[0.14608598 0.29313257]\n   [0.96667224 0.9406673 ]\n   [0.17876087 0.5724485 ]\n   [0.37672275 0.7935269 ]]\n\n  [[0.8972693  0.31302252]\n   [0.09588159 0.65390325]\n   [0.19987136 0.54829735]\n   [0.99728596 0.63749206]]\n\n  [[0.592439   0.76679176]\n   [0.40126538 0.43937808]\n   [0.18349086 0.06966902]\n   [0.8810204  0.27204877]]]]", 
            "title": "Permute"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#repeatvector", 
            "text": "Repeats the input n times.  The input of this layer should be 2D.  Scala:  RepeatVector(n, inputShape = null)  Python:  RepeatVector(n, input_shape=None, name=None)  Parameters:   n : Repetition factor. Integer.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, RepeatVector}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(RepeatVector(4, inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.4182444   2.858577    1.3975657\n-0.19606766 0.8585809   0.3027246\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n1.4182444   2.858577    1.3975657\n1.4182444   2.858577    1.3975657\n1.4182444   2.858577    1.3975657\n1.4182444   2.858577    1.3975657\n\n(2,.,.) =\n-0.19606766 0.8585809   0.3027246\n-0.19606766 0.8585809   0.3027246\n-0.19606766 0.8585809   0.3027246\n-0.19606766 0.8585809   0.3027246\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x3]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import RepeatVector\n\nmodel = Sequential()\nmodel.add(RepeatVector(4, input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  [[0.51416513 0.87768557 0.48015041]\n [0.66598164 0.58916225 0.03983186]]  Output is  [[[0.5141651  0.87768555 0.4801504 ]\n  [0.5141651  0.87768555 0.4801504 ]\n  [0.5141651  0.87768555 0.4801504 ]\n  [0.5141651  0.87768555 0.4801504 ]]\n\n [[0.66598165 0.58916223 0.03983186]\n  [0.66598165 0.58916223 0.03983186]\n  [0.66598165 0.58916223 0.03983186]\n  [0.66598165 0.58916223 0.03983186]]]", 
            "title": "RepeatVector"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#merge", 
            "text": "Used to merge a list of inputs into a single output, following some merge mode.  Merge must have at least two input layers.  Scala:  Merge(layers = null, mode =  sum , concatAxis = -1, inputShape = null)  Python:  Merge(layers=None, mode= sum , concat_axis=-1, input_shape=None, name=None)  Parameters:   layers : A list of layer instances. Must be more than one layer.  mode : Merge mode. String, must be one of: 'sum', 'mul', 'concat', 'ave', 'cos', 'dot', 'max'. Default is 'sum'.  concatAxis : Integer, axis to use when concatenating layers. Only specify this when merge mode is 'concat'. Default is -1, meaning the last axis of the input.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, Merge, InputLayer}\nimport com.intel.analytics.bigdl.utils.{Shape, T}\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nval l1 = InputLayer[Float](inputShape = Shape(2, 3))\nval l2 = InputLayer[Float](inputShape = Shape(2, 3))\nval layer = Merge[Float](layers = List(l1, l2), mode =  sum )\nmodel.add(layer)\nval input1 = Tensor[Float](2, 2, 3).rand(0, 1)\nval input2 = Tensor[Float](2, 2, 3).rand(0, 1)\nval input = T(1 -  input1, 2 -  input2)\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.utils.Table =\n {\n    2: (1,.,.) =\n       0.87815475   0.15025006  0.34412447\n       0.07909282   0.008027249 0.111715704\n\n       (2,.,.) =\n       0.52245367   0.2547527   0.35857987\n       0.7718501    0.26783863  0.8642062\n\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n    1: (1,.,.) =\n       0.5377018    0.28364193  0.3424284\n       0.0075349305 0.9018168   0.9435114\n\n       (2,.,.) =\n       0.09112563   0.88585275  0.3100201\n       0.7910178    0.57497376  0.39764535\n\n       [com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n }  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n1.4158566   0.433892    0.6865529\n0.08662775  0.90984404  1.0552272\n\n(2,.,.) =\n0.6135793   1.1406054   0.66859996\n1.5628679   0.8428124   1.2618515\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Merge, InputLayer\n\nmodel = Sequential()\nl1 = InputLayer(input_shape=(3, 4))\nl2 = InputLayer(input_shape=(3, 4))\nmodel.add(Merge(layers=[l1, l2], mode='sum'))\ninput = [np.random.random([2, 3, 4]), np.random.random([2, 3, 4])]\noutput = model.forward(input)  Input is:  [array([[[0.28764351, 0.0236015 , 0.78927442, 0.52646492],\n        [0.63922826, 0.45101604, 0.4555552 , 0.70105653],\n        [0.75790798, 0.78551523, 0.00686686, 0.61290369]],\n\n       [[0.00430865, 0.3303661 , 0.59915782, 0.90362298],\n        [0.26230717, 0.99383052, 0.50630521, 0.99119486],\n        [0.56138318, 0.68165639, 0.10644523, 0.51860127]]]),\n\n array([[[0.84365767, 0.8854741 , 0.84183673, 0.96322321],\n        [0.49354248, 0.97936826, 0.2266097 , 0.88083622],\n        [0.11011776, 0.65762034, 0.17446099, 0.76658969]],\n\n       [[0.58266689, 0.86322199, 0.87122999, 0.19031255],\n        [0.42275118, 0.76379413, 0.21355413, 0.81132937],\n        [0.97294728, 0.68601731, 0.39871792, 0.63172344]]])]  Output is  [[[1.1313012  0.90907556 1.6311111  1.4896882 ]\n  [1.1327708  1.4303843  0.6821649  1.5818927 ]\n  [0.8680257  1.4431355  0.18132785 1.3794935 ]]\n\n [[0.5869755  1.1935881  1.4703878  1.0939355 ]\n  [0.68505836 1.7576246  0.71985936 1.8025242 ]\n  [1.5343305  1.3676738  0.50516313 1.1503248 ]]]", 
            "title": "Merge"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#masking", 
            "text": "Use a mask value to skip timesteps for a sequence.  Scala:  Masking(maskValue = 0.0, inputShape = null)  Python:  Masking(mask_value=0.0, input_shape=None, name=None)  Parameters:   maskValue : Mask value. For each timestep in the input (the second dimension), if all the values in the input at that timestep are equal to 'maskValue', then the timestep will masked (skipped) in all downstream layers.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, Masking}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Masking(inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.00938185  -1.1461893  -1.0204586\n0.24702129  -2.2756217  0.010394359\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.00938185  -1.1461893  -1.0204586\n0.24702129  -2.2756217  0.010394359\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Masking\n\nmodel = Sequential()\nmodel.add(Masking(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  [[0.59540156 0.24933489 0.04434161]\n [0.89243422 0.68499562 0.36788333]]  Output is  [[0.5954016  0.24933489 0.04434161]\n [0.89243424 0.68499565 0.36788332]]", 
            "title": "Masking"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/core/#maxoutdense", 
            "text": "A dense maxout layer that takes the element-wise maximum of linear layers.  This allows the layer to learn a convex, piecewise linear activation function over the inputs.  The input of this layer should be 2D.  Scala:  MaxoutDense(outputDim, nbFeature = 4, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)  Python:  MaxoutDense(output_dim, nb_feature=4, W_regularizer=None, b_regularizer=None, bias=True, input_dim=None, input_shape=None, name=None)  Parameters:   outputDim : The size of output dimension.  nbFeature : Number of Dense layers to use internally. Integer. Default is 4.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, MaxoutDense}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(MaxoutDense(2, inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-1.3550005  -1.1668127  -1.2882779\n0.83600295  -1.94683    1.323666\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.71675766  1.2987505\n0.9871184   0.6634239\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import MaxoutDense\n\nmodel = Sequential()\nmodel.add(MaxoutDense(2, input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  [[0.15996114 0.8391686  0.81922903]\n [0.52929427 0.35061754 0.88167693]]  Output is  [[0.4479192  0.4842512]\n [0.16833156 0.521764 ]]", 
            "title": "MaxoutDense"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/", 
            "text": "Convolution1D\n\n\nApplies convolution operator for filtering neighborhoods of 1-D inputs.\n\n\nYou can also use \nConv1D\n as an alias of this layer.\n\n\nThe input of this layer should be 3D.\n\n\nScala:\n\n\nConvolution1D(nbFilter, filterLength, init = \nglorot_uniform\n, activation = null, borderMode = \nvalid\n, subsampleLength = 1, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nConvolution1D(nb_filter, filter_length, init=\nglorot_uniform\n, activation=None, border_mode=\nvalid\n, subsample_length=1, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nnbFilter\n: Number of convolution filters to use.\n\n\nfilterLength\n: The extension (spatial or temporal) of each filter.\n\n\ninit\n: String representation of the initialization method for the weights of the layer. See \nhere\n for available initialization strings. Default is 'glorot_uniform'.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is null.\n\n\nborderMode\n: Either 'valid' or 'same'. Default is 'valid'.\n\n\nsubsampleLength\n: Factor by which to subsample output. Integer. Default is 1.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, Convolution1D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Convolution1D(8, 3, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-1.4253887  -0.044403594    -1.1169672  -0.19499049\n0.85463065  0.6665206       0.21340805  0.56255895\n1.1126599   -0.3423326      0.09643264  -0.34345046\n\n(2,.,.) =\n-0.04046587 -0.2710401      0.10183265  1.4503858\n1.0639644   1.5317003       -0.18313104 -0.7098296\n0.612399    1.7357533       0.4641411   0.13530721\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.22175728  0.76192796  1.7907748   1.1534728   -1.5304534  0.07466106  -0.18292685 0.6038852\n\n(2,.,.) =\n0.85337734  0.43939286  -0.16770163 -0.8380078  0.7825804   -0.3485601  0.3017909   0.5823619\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x8]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Convolution1D\n\nmodel = Sequential()\nmodel.add(Convolution1D(8, 3, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.06092268 0.0508438  0.47256153 0.80004565]\n  [0.48706905 0.65704781 0.04297214 0.42288264]\n  [0.92286158 0.85394381 0.46423248 0.87896669]]\n\n [[0.216527   0.13880484 0.93482372 0.44812419]\n  [0.95553331 0.27084259 0.58913626 0.01879454]\n  [0.6656435  0.1985877  0.94133745 0.57504128]]]\n\n\n\n\nOutput is\n\n\n[[[ 0.7461933  -2.3189526  -1.454972   -0.7323345   1.5272427  -0.87963724  0.6278059  -0.23403725]]\n\n [[ 1.2397771  -0.9249111  -1.1432207  -0.92868984  0.53766745 -1.0271561  -0.9593589  -0.4768026 ]]]\n\n\n\n\n\n\nConvolution2D\n\n\nApplies a 2D convolution over an input image composed of several input planes.\n\n\nYou can also use \nConv2D\n as an alias of this layer.\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nConvolution2D(nbFilter, nbRow, nbCol, init = \nglorot_uniform\n, activation = null, borderMode = \nvalid\n, subsample = (1, 1), dimOrdering = \nth\n, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nConvolution2D(nb_filter, nb_row, nb_col, init=\nglorot_uniform\n, activation=None, border_mode=\nvalid\n, subsample=(1, 1), dim_ordering=\nth\n, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nnbFilter\n: Number of convolution filters to use.\n\n\nnbRow\n: Number of rows in the convolution kernel.\n\n\nnbCol\n: Number of columns in the convolution kernel.\n\n\ninit\n: String representation of the initialization method for the weights of the layer. See \nhere\n for available initialization strings. Default is 'glorot_uniform'.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is null.\n\n\nborderMode\n: Either 'valid' or 'same'. Default is 'valid'.\n\n\nsubsample\n: Length 2 corresponding to the step of the convolution in the height and width dimension. Also called strides elsewhere. Default is (1, 1).\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, Convolution2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Convolution2D(4, 2, 2, activation = \nrelu\n, inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-1.6687597  1.3452173   -1.9608531  -0.30892205\n1.7459077   -0.443617   0.25789636  0.44496542\n-1.5395774  -0.37713575 -0.9973955  0.16208267\n\n(1,2,.,.) =\n0.593965    1.0544858   -1.0765858  0.22257836\n0.69452614  1.3700147   -0.886259   0.013910895\n-1.9819669  0.32151425  1.8303248   0.24231844\n\n(2,1,.,.) =\n-2.150859   -1.5894475  0.7543173   0.7713991\n-0.17536041 0.89053404  0.50489277  -0.098128\n0.11551995  1.3663125   0.76734704  0.28318745\n\n(2,2,.,.) =\n-0.9801306  0.39797616  -0.6403248  1.0090133\n-0.16866015 -1.426308   -2.4097774  0.26011375\n-2.5700948  1.0486397   -0.4585798  -0.94231766\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.0         0.6800046   0.0\n1.0366663   0.235024    0.0\n\n(1,2,.,.) =\n0.0         0.84696645  0.0\n0.9099177   0.0         0.0\n\n(1,3,.,.) =\n0.122891426 0.0         0.86579126\n0.0         0.0         0.0\n\n(1,4,.,.) =\n0.0         0.7185988   0.0\n1.0967548   0.48376864  0.0\n\n(2,1,.,.) =\n0.0         0.0         0.29164955\n0.06815311  0.0         0.0\n\n(2,2,.,.) =\n0.36370438  0.42393038  0.26948324\n1.1676859   0.5698308   0.44842285\n\n(2,3,.,.) =\n1.0797265   1.2410768   0.18289843\n0.0         0.0         0.18757495\n\n(2,4,.,.) =\n0.0         0.35713753  0.0\n0.0         0.0         0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Convolution2D\n\nmodel = Sequential()\nmodel.add(Convolution2D(4, 2, 2, input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.05182015 0.91971256 0.81030852 0.64093699]\n   [0.60282957 0.16269049 0.79136121 0.05202386]\n   [0.62560999 0.00174107 0.75762976 0.93589574]]\n  [[0.13728558 0.85812609 0.39695457 0.81678788]\n   [0.7569393  0.61161632 0.60750583 0.6222684 ]\n   [0.53094821 0.38715199 0.0087283  0.05758945]]]\n\n [[[0.50030948 0.40179766 0.54900785 0.60950401]\n   [0.17464329 0.01506322 0.55273153 0.21567461]\n   [0.09037649 0.58831638 0.818708   0.96642448]]\n  [[0.77126628 0.58039509 0.91612417 0.12578268]\n   [0.6095838  0.15802154 0.78099004 0.63619778]\n   [0.70632951 0.91378968 0.84851605 0.7242516 ]]]]\n\n\n\n\nOutput is\n\n\n[[[[-0.45239753  0.2432243  -0.02717562]\n   [ 0.2698849  -0.09664132  0.92311716]]\n  [[ 0.9092748   0.7945191   0.8834159 ]\n   [ 0.4853364   0.6511425   0.52513427]]\n  [[ 0.5550465   0.8177169   0.43213058]\n   [ 0.4209347   0.7514105   0.27255327]]\n  [[-0.22105691  0.02853963  0.01092601]\n   [ 0.1258291  -0.41649136 -0.18953061]]]\n\n [[[-0.12111888  0.06418754  0.26331317]\n   [ 0.41674113  0.04221775  0.7313505 ]]\n  [[ 0.49442202  0.6964868   0.558412  ]\n   [ 0.25196168  0.8145504   0.69307953]]\n  [[ 0.5885831   0.59289575  0.71726865]\n   [ 0.46759683  0.520353    0.59305453]]\n  [[ 0.00594708  0.09721318  0.07852311]\n   [ 0.49868047  0.02704304  0.14635414]]]]\n\n\n\n\n\n\nConvolution3D\n\n\nApplies convolution operator for filtering windows of three-dimensional inputs.\n\n\nYou can also use \nConv3D\n as an alias of this layer.\n\n\nData format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').\n\n\nThe input of this layer should be 5D.\n\n\nScala:\n\n\nConvolution3D(nbFilter, kernelDim1, kernelDim2, kernelDim3, init = \nglorot_uniform\n, activation = null, borderMode = \nvalid\n, subsample = (1, 1, 1), dimOrdering = \nth\n, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nConvolution3D(nb_filter, kernel_dim1, kernel_dim2, kernel_dim3, init=\nglorot_uniform\n, activation=None, border_mode=\nvalid\n, subsample=(1, 1, 1), dim_ordering=\nth\n, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nnbFilter\n: Number of convolution filters to use.\n\n\nkernelDim1\n: Length of the first dimension in the convolution kernel.\n\n\nkernelDim2\n: Length of the second dimension in the convolution kernel.\n\n\nkernelDim3\n: Length of the third dimension in the convolution kernel.\n\n\ninit\n: String representation of the initialization method for the weights of the layer. See \nhere\n for available initialization strings. Default is 'glorot_uniform'.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is null.\n\n\nborderMode\n: Either 'valid' or 'same'. Default is 'valid'.\n\n\nsubsample\n: Length 3. Factor by which to subsample output. Also called strides elsewhere. Default is (1, 1, 1).\n\n\ndimOrdering\n: Format of input data. Only 'th' (Channel First) is supported for now.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, Convolution3D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Convolution3D(4, 2, 2, 2, inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n0.64140224  -1.4049392  0.4935015\n0.33096266  1.2768826   -0.57567996\n\n(1,1,2,.,.) =\n0.49570087  -2.0367618    -0.0032108661\n-0.24242361 -0.092683665  1.1579652\n\n(1,2,1,.,.) =\n-0.6730608  0.9149566   -1.7478822\n-0.1763675  -0.90117735 0.38452747\n\n(1,2,2,.,.) =\n0.5314353   1.4802488   -1.196325\n0.43506134  -0.56575996 -1.5489199\n\n(2,1,1,.,.) =\n0.074545994 -1.4092928  -0.57647055\n1.9998664   -0.19424418 -0.9296713\n\n(2,1,2,.,.) =\n-0.42966184 0.9247804   -0.21713361\n0.2723336   -1.3024703  1.278154\n\n(2,2,1,.,.) =\n1.1240695   1.1061385   -2.4662287\n-0.36022148 0.1620907   -1.1525819\n\n(2,2,2,.,.) =\n0.9885768   -0.526637   -0.40684605\n0.37813842  0.53998697  1.0001947\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.36078936  -0.6334647\n\n(1,2,1,.,.) =\n-0.19685572 0.4559337\n\n(1,3,1,.,.) =\n1.3750207   -2.4377227\n\n(1,4,1,.,.) =\n-0.82853335 -0.74145436\n\n(2,1,1,.,.) =\n-0.17973013 1.2930126\n\n(2,2,1,.,.) =\n0.69144577  0.44385013\n\n(2,3,1,.,.) =\n-0.5597819  0.5965629\n\n(2,4,1,.,.) =\n0.89755684  -0.6737796\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x1x1x2]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Convolution3D\n\nmodel = Sequential()\nmodel.add(Convolution3D(4, 2, 2, 2, input_shape=(2, 2, 2, 3)))\ninput = np.random.random([2, 2, 2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[[0.36798873 0.92635561 0.31834968]\n    [0.09001392 0.66762381 0.64477164]]\n   [[0.09760993 0.38067132 0.15069965]\n    [0.39052699 0.0223722  0.04786307]]]\n  [[[0.2867726  0.3674255  0.11852931]\n    [0.96436629 0.8012903  0.3211012 ]]\n   [[0.81738622 0.80606827 0.4060485 ]\n    [0.68010177 0.0934071  0.98479026]]]]\n\n [[[[0.71624597 0.37754442 0.07367964]\n    [0.60742428 0.38549046 0.78880978]]\n   [[0.97844361 0.11426373 0.55479659]\n    [0.06395313 0.86007246 0.34004405]]]\n  [[[0.94149643 0.8027673  0.19478027]\n    [0.17437108 0.754479   0.51055297]]\n   [[0.81933677 0.09040694 0.33775061]\n    [0.02582059 0.40027544 0.91809986]]]]]\n\n\n\n\n\nOutput is\n\n\n[[[[[ 1.6276866  -4.4106215]]]\n  [[[ 6.6988254  1.1409638]]]\n  [[[-5.7734865  -5.2575850]]]\n  [[[-1.8073934  -4.4056013]]]]\n\n [[[[-4.8580116  9.4352424]]]\n  [[[ 7.8890514  6.6063654]]]\n  [[[-7.3165756  -1.0116580]]]\n  [[[-1.3100024  1.0475740]]]]]\n\n\n\n\n\n\nAtrousConvolution1D\n\n\nApplies an atrous convolution operator for filtering neighborhoods of 1-D inputs.\n\n\nA.k.a dilated convolution or convolution with holes.\n\n\nBias will be included in this layer.\n\n\nBorder mode currently supported for this layer is 'valid'.\n\n\nYou can also use \nAtrousConv1D\n as an alias of this layer.\n\n\nThe input of this layer should be 3D.\n\n\nScala:\n\n\nAtrousConvolution1D(nbFilter, filterLength, init = \nglorot_uniform\n, activation = null, subsampleLength = 1, atrousRate = 1, wRegularizer = null, bRegularizer = null, inputShape = null)\n\n\n\n\nPython:\n\n\nAtrousConvolution1D(nb_filter, filter_length, init=\nglorot_uniform\n, activation=None, border_mode='valid', subsample_length=1, atrous_rate=1, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nnbFilter\n: Number of convolution kernels to use.\n\n\nfilterLength\n: The extension (spatial or temporal) of each filter.\n\n\ninit\n: String representation of the initialization method for the weights of the layer. See \nhere\n for available initialization strings. Default is 'glorot_uniform'.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is null.\n\n\nsubsampleLength\n: Factor by which to subsample output. Integer. Default is 1.\n\n\natrousRate\n: Factor for kernel dilation. Also called filter_dilation elsewhere. Integer. Default is 1.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, AtrousConvolution1D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AtrousConvolution1D(8, 3, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.18167362 2.1452308   -0.39164552 -0.19750737\n-0.16184713 -1.3867316  -1.3447738  -0.6431075\n-0.42635638 -0.20490816 -2.5391808  -0.05881459\n\n(2,.,.) =\n-0.83197606 1.1706954   -0.80197126 -1.0663458\n0.36859998  -0.45194706 -1.2959619  -0.521925\n-1.133602   0.7700087   -1.2523394  1.1293458\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.1675637   0.9712032   -0.5615059  0.065867506 0.6681816   1.2097323   -1.0912716  0.8040266\n\n(2,.,.) =\n0.5009172   1.4765333   -0.14173388 0.060548827 0.752389    1.2912648   -1.0077878  0.06344204\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x8]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import AtrousConvolution1D\n\nmodel = Sequential()\nmodel.add(AtrousConvolution1D(8, 3, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.96952262 0.15211776 0.63026888 0.50572335]\n  [0.13218867 0.18807126 0.33509675 0.43385223]\n  [0.48027981 0.82222524 0.9630902  0.78855421]]\n\n [[0.49106312 0.16875464 0.54099084 0.2892753 ]\n  [0.03776569 0.51324722 0.95359981 0.52863015]\n  [0.69851295 0.29676433 0.59404524 0.90078511]]]\n\n\n\n\nOutput is\n\n\n[[[-0.62304074  0.6667814  -0.07074605 -0.03640915  0.11369559  0.3451041  -0.44238544  0.618591  ]]\n\n [[-0.5048915   0.9070808  -0.03285386  0.26761323 -0.08491824  0.36105093 -0.15240929  0.6145356 ]]]\n\n\n\n\n\n\nAtrousConvolution2D\n\n\nApplies an atrous convolution operator for filtering windows of 2-D inputs.\n\n\nA.k.a dilated convolution or convolution with holes.\n\n\nBias will be included in this layer.\n\n\nData format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').\n\n\nBorder mode currently supported for this layer is 'valid'.\n\n\nYou can also use \nAtrousConv2D\n as an alias of this layer.\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nAtrousConvolution2D(nbFilter, nbRow, nbCol, init = \nglorot_uniform\n, activation = null, subsample = (1, 1), atrousRate= (1, 1), dimOrdering = \nth\n, wRegularizer = null, bRegularizer = null, inputShape = null)\n\n\n\n\nPython:\n\n\nAtrousConvolution2D(nb_filter, nb_row, nb_col, init=\nglorot_uniform\n, activation=None, border_mode=\nvalid\n, subsample=(1, 1), atrous_rate=(1, 1), dim_ordering=\nth\n, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nnbFilter\n: Number of convolution filters to use.\n\n\nnbRow\n: Number of rows in the convolution kernel.\n\n\nnbCol\n: Number of columns in the convolution kernel.\n\n\ninit\n: String representation of the initialization method for the weights of the layer. See \nhere\n for available initialization strings. Default is 'glorot_uniform'.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is null.\n\n\nsubsample\n: Length 2 . Factor by which to subsample output. Also called strides elsewhere. Default is (1, 1).\n\n\natrousRate\n: Length 2. Factor for kernel dilation. Also called filter_dilation elsewhere. Default is (1, 1).\n\n\ndimOrdering\n: Format of input data. Only 'th' (Channel First) is supported for now.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, AtrousConvolution2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AtrousConvolution2D(4, 2, 2, activation = \nrelu\n, inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.57626903     -0.56916714     0.46516004      -1.189643\n-0.117406875    -1.1139084      1.115328        0.23275337\n1.452733        -0.30968842     -0.6693723      -0.22098665\n\n(1,2,.,.) =\n0.06541251      -0.7000564      -0.460471       -0.5291468\n-0.6625642      0.6460361       -0.556095       1.6327276\n1.1914377       -0.69054496     -0.7461783      -1.0129389\n\n(2,1,.,.) =\n-0.19123174     0.06803144      -0.010993495    -0.79966563\n-0.010654963    2.0806832       1.972848        -1.8525643\n-0.84387285     1.2974458       -0.42781293     0.3540522\n\n(2,2,.,.) =\n1.6231914       0.52689505      0.47506556      -1.030227\n0.5143046       -0.9930063      -2.2869735      0.03994834\n-1.5566326      -1.0937842      0.82693833      -0.08408405\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.11401264  0.0         1.1396459\n0.0         0.0         0.88493514\n\n(1,2,.,.) =\n0.0         8.398667    1.1495202\n0.0         0.0         0.1630742\n\n(1,3,.,.) =\n0.0         0.92470163  0.0\n0.0         0.6321572   0.0\n\n(1,4,.,.) =\n0.0         1.1912066   0.0\n0.0         1.27647     0.13422263\n\n(2,1,.,.) =\n0.0         0.0         0.51365596\n0.0         0.4207713   1.1226959\n\n(2,2,.,.) =\n0.0         0.67600054  0.63635653\n0.40892223  2.0596464   1.7690754\n\n(2,3,.,.) =\n1.1899394   0.0         0.0\n1.7185769   0.39178902  0.0\n\n(2,4,.,.) =\n0.44333076  0.73385376  0.0\n2.516453    0.36223468  0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import AtrousConvolution2D\n\nmodel = Sequential()\nmodel.add(AtrousConvolution2D(4, 2, 2, input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.52102612 0.30683086 0.38543426 0.0026452 ]\n   [0.66805249 0.60656045 0.94601998 0.46574414]\n   [0.49391338 0.14274225 0.70473703 0.30427041]]\n  [[0.89066007 0.51782675 0.7063052  0.53440807]\n   [0.67377917 0.51541465 0.02137767 0.63357007]\n   [0.6614106  0.15849977 0.94459604 0.46852022]]]\n\n [[[0.79639026 0.94468413 0.73165819 0.54531867]\n   [0.97741046 0.64477619 0.52373183 0.06861999]\n   [0.37278645 0.53198045 0.95098245 0.86249644]]\n  [[0.47186038 0.81694951 0.78009033 0.20925898]\n   [0.69942883 0.37150324 0.58907364 0.88754231]\n   [0.64083971 0.4480097  0.91716521 0.66808943]]]]\n\n\n\n\nOutput is\n\n\n[[[[-0.32139003  -0.34667802 -0.35534883]\n   [-0.09653517  -0.35052428 -0.09859636]]\n  [[-0.3138999   -0.5563417  -0.6694119 ]\n   [-0.03151364  0.35521197  0.31497604]]\n  [[-0.34939283  -0.7537081  -0.3939833 ]\n   [-0.25708836  0.06015673  -0.16755156]]\n  [[-0.04791902  0.02060626  -0.5639752 ]\n   [ 0.16054101  0.22528952  -0.02460545]]]\n\n [[[-0.13129832  -0.5262137   -0.12281597]\n   [-0.36988598  -0.5532047   -0.43338764]]\n  [[-0.21627764  -0.17562683  0.23560521]\n   [ 0.23035726  -0.03152001  -0.46413773]]\n  [[-0.63740283  -0.33359224  0.15731882]\n   [-0.12795202  -0.25798583  -0.5261132 ]]\n  [[-0.01759483  -0.07666921  -0.00890112]\n   [ 0.27595833  -0.14117064  -0.3357542 ]]]]\n\n\n\n\n\n\nDeconvolution2D\n\n\nTransposed convolution operator for filtering windows of 2-D inputs.\n\n\nThe need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has\nthe shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution.\n\n\nData format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').\n\n\nBorder mode currently supported for this layer is 'valid'.\n\n\nYou can also use \nDeconv2D\n as an alias of this layer.\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nDeconvolution2D(nbFilter, nbRow, nbCol, init = \nglorot_uniform\n, activation = null, subsample = (1, 1), dimOrdering = \nth\n, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nDeconvolution2D(nb_filter, nb_row, nb_col, output_shape, init=\nglorot_uniform\n, activation=None, border_mode=\nvalid\n, subsample=(1, 1), dim_ordering=\nth\n, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nnbFilter\n: Number of transposed convolution filters to use.\n\n\nnbRow\n: Number of rows in the transposed convolution kernel.\n\n\nnbCol\n: Number of columns in the transposed convolution kernel.\n\n\ninit\n: String representation of the initialization method for the weights of the layer. See \nhere\n for available initialization strings. Default is 'glorot_uniform'.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is null.\n\n\nsubsample\n: Length 2 . The step of the convolution in the height and width dimension. Also called strides elsewhere. Default is (1, 1).\n\n\ndimOrdering\n: Format of input data. Only 'th' (Channel First) is supported for now.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, Deconvolution2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Deconvolution2D(2, 2, 2, activation = \nrelu\n, inputShape = Shape(2, 2, 3)))\nval input = Tensor[Float](1, 2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-1.1157457  -0.8626509  -0.7326707\n1.8340882   -1.1647098  -1.0159439\n\n(1,2,.,.) =\n-0.13360074 0.4507607   -0.5922559\n0.15494606  0.16541296  1.6870573\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.0         0.0         0.0     0.020009547\n0.0         0.0         0.0     0.0\n0.9656998   0.0         0.0     0.5543601\n\n(1,2,.,.) =\n0.0         0.0         0.0     0.07773054\n1.4971795   0.029338006 0.0     0.0\n0.0         0.45826393  0.0     0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Deconvolution2D\n\nmodel = Sequential()\nmodel.add(Deconvolution2D(2, 2, 2, (2, 3, 4), input_shape=(2, 2, 3)))\ninput = np.random.random([1, 2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.65315139 0.21904901 0.57943617]\n   [0.35141043 0.14628658 0.81862311]]\n\n  [[0.60094717 0.84649884 0.08338504]\n   [0.26753695 0.83676038 0.87466877]]]]\n\n\n\n\nOutput is\n\n\n[[[[-0.35380065  0.22048733  0.3084591   0.23341973]\n   [-0.11611718  0.5349988  -0.26301163  1.0291481 ]\n   [ 0.00479569  0.48814884  0.00127316  0.2546792 ]]\n\n  [[-0.02683929 -0.21759698 -0.8542665  -0.25376737]\n   [ 0.04426606  0.05486238 -0.9282576  -1.1576774 ]\n   [ 0.01637976  0.1838439  -0.01419228 -0.60704494]]]]\n\n\n\n\n\n\nSeparableConvolution2D\n\n\nApplies separable convolution operator for 2D inputs.\n\n\nSeparable convolutions consist in first performing a depthwise spatial convolution (which acts on each input channel separately) followed by a pointwise convolution which mixes together the resulting output channels. The depthMultiplier argument controls how many output channels are generated per input channel in the depthwise step.\n\n\nYou can also use \nSeparableConv2D\n as an alias of this layer.\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nSeparableConvolution2D(nbFilter, nbRow, nbCol, init = \nglorot_uniform\n, activation = null, borderMode = \nvalid\n, subsample = (1, 1), depthMultiplier = 1, dimOrdering = \nth\n, depthwiseRegularizer = null, pointwiseRegularizer= null, bRegularizer = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nSeparableConvolution2D(nb_filter, nb_row, nb_col, init=\nglorot_uniform\n, activation=None, border_mode=\nvalid\n, subsample=(1, 1), depth_multiplier=1, dim_ordering=\nth\n, depthwise_regularizer=None, pointwise_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nnbFilter\n: Number of convolution filters to use.\n\n\nnbRow\n: Number of rows in the convolution kernel.\n\n\nnbCol\n: Number of columns in the convolution kernel.\n\n\ninit\n: String representation of the initialization method for the weights of the layer. See \nhere\n for available initialization strings. Default is 'glorot_uniform'.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is null.\n\n\nborderMode\n: Either 'valid' or 'same'. Default is 'valid'.\n\n\nsubsample\n: Length 2 corresponding to the step of the convolution in the height and width dimension. Also called strides elsewhere. Default is (1, 1).\n\n\ndepthMultiplier\n: How many output channel to use per input channel for the depthwise convolution step. Integer. Default is 1.\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ndepthwiseRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the depthwise weights matrices. Default is null.\n\n\npointwiseRegularizer\n: An instance of \nRegularizer\n, applied to the pointwise weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, SeparableConvolution2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SeparableConvolution2D(2, 2, 2, activation = \nrelu\n, inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.61846036  0.13724488     1.9047198    0.8788536\n0.74383116  -0.7590018     0.17210509   1.8095028\n-0.21476124 -0.010768774   0.5437478    0.97470677\n\n(1,2,.,.) =\n-0.22464052 -1.7141389     1.8457758    0.81563693\n-0.17250067 -1.2183974     -2.5329974   -1.3014348\n0.43760046  0.32672745     -0.6059157   0.31439257\n\n(2,1,.,.) =\n-0.32413644 -0.1871411     -0.13821407  -0.16577224\n-0.02138366 1.2260025      -0.48404458  -1.0251912\n-1.8844653  0.6796752      -0.5881143   2.1656246\n\n(2,2,.,.) =\n0.17234507  -0.6455974     1.9615031    0.6552883\n-0.05861185 1.8847446      -0.857622    -0.5949971\n-0.41135395 -0.92089206    0.13154007   -0.9326055\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.0         0.0         0.0\n0.029595211 0.0         0.34002993\n\n(1,2,.,.) =\n0.0         0.0         0.0\n0.073145226 0.0         0.5542682\n\n(2,1,.,.) =\n0.4973382   0.36478913  0.0\n0.0         0.0         0.0\n\n(2,2,.,.) =\n0.9668598   0.7102739   0.0\n0.0         0.0         0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import SeparableConvolution2D\n\nmodel = Sequential()\nmodel.add(SeparableConvolution2D(2, 2, 2, input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.39277921 0.36904141 0.16768533 0.41712068]\n   [0.62416696 0.19334139 0.83341541 0.16486488]\n   [0.57287259 0.47809379 0.11103843 0.01746644]]\n  [[0.24945342 0.05728102 0.19076369 0.70498077]\n   [0.39147172 0.08100018 0.74426575 0.74251056]\n   [0.61840056 0.00771785 0.65170218 0.04492181]]]\n\n [[[0.08337509 0.19320791 0.66757918 0.38905916]\n   [0.50237454 0.0996316  0.3981495  0.32274897]\n   [0.01598124 0.52896577 0.76068351 0.10099803]]\n  [[0.20396797 0.48682425 0.11302674 0.57491998]\n   [0.71529612 0.11720466 0.57783092 0.45790133]\n   [0.41573101 0.60269287 0.613528   0.32717263]]]]\n\n\n\n\nOutput is\n\n\n[[[[0.15971108 0.12109925 0.17461367]\n   [0.20024002 0.13661252 0.1871847 ]]\n  [[0.47139192 0.36838844 0.45902973]\n   [0.57752806 0.41371965 0.5079273 ]]]\n\n [[[0.11111417 0.10702941 0.2030398 ]\n   [0.13108528 0.15029006 0.18544158]]\n  [[0.27002305 0.31479427 0.57750916]\n   [0.3573216  0.40100253 0.5122235 ]]]]\n\n\n\n\n\n\nLocallyConnected1D\n\n\nLocally-connected layer for 1D inputs which works similarly to the TemporalConvolution layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.\n\n\nBorder mode currently supported for this layer is 'valid'.\n\n\nThe input of this layer should be 3D.\n\n\nScala:\n\n\nLocallyConnected1D(nbFilter, filterLength, activation = null, subsampleLength = 1, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nLocallyConnected1D(nb_filter, filter_length, activation=None, border_mode=\nvalid\n, subsample_length=1, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nnbFilter\n: Dimensionality of the output.\n\n\nfilterLength\n: The extension (spatial or temporal) of each filter.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is null.\n\n\nsubsampleLength\n: Integer. Factor by which to subsample output.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, LocallyConnected1D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(LocallyConnected1D(6, 3, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.6755046   0.47923228  -0.41470557 -1.4644535\n-1.580751   -0.36924785 -1.1507624  0.20131736\n-0.4983051  -2.0898817  0.1623063   0.8118141\n\n(2,.,.) =\n1.5955191   -1.1017833  1.6614468   1.7959124\n1.1084127   0.528379    -1.114553   -1.030853\n0.37758648  -2.5828059  1.0172523   -1.6773314\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.20011228 0.7842446   -0.57892114 0.2405633   -0.35126245 -0.5116563\n\n(2,.,.) =\n-0.33687726 0.7863857   0.30202985  0.33251244  -0.7414977  0.14271683\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x6]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import LocallyConnected1D\n\nmodel = Sequential()\nmodel.add(LocallyConnected1D(6, 3, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.67992353 0.88287213 0.98861104 0.17401607]\n  [0.23660068 0.02779148 0.52982599 0.19876749]\n  [0.38880073 0.6498778  0.81532701 0.91719509]]\n\n [[0.30532677 0.1574227  0.40535271 0.03174637]\n  [0.37303714 0.27821415 0.02314422 0.64516966]\n  [0.74813923 0.9884225  0.40667151 0.21894944]]]\n\n\n\n\nOutput is\n\n\n[[[ 0.66351205 -0.03819168 -0.48071918 -0.05209085 -0.07307816  0.94942856]]\n\n [[ 0.5890693   0.0179258  -0.31232932  0.4427027  -0.30954808  0.4486028 ]]]\n\n\n\n\n\n\nLocallyConnected2D\n\n\nLocally-connected layer for 2D inputs that works similarly to the SpatialConvolution layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nLocallyConnected2D(nbFilter, nbRow, nbCol, activation = null, borderMode = \nvalid\n, subsample = (1, 1), dimOrdering = \nth\n, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nLocallyConnected2D(nb_filter, nb_row, nb_col, activation=None, border_mode=\nvalid\n, subsample=(1, 1), dim_ordering=\nth\n, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nnbFilter\n: Number of convolution filters to use.\n\n\nnbRow\n: Number of rows in the convolution kernel.\n\n\nnbCol\n: Number of columns in the convolution kernel.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is null.\n\n\nborderMode\n: Either 'valid' or 'same'. Default is 'valid'.\n\n\nsubsample\n: Length 2 corresponding to the step of the convolution in the height and width dimension. Also called strides elsewhere. Default is (1, 1).\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, LocallyConnected2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(LocallyConnected2D(2, 2, 2, inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n1.3119988       -1.8982307      -0.13138956     1.0872058\n-0.11329581     -0.7087005      0.085274234     -0.94051\n1.04928         2.1579344       -1.4412278      -0.90965116\n\n(1,2,.,.) =\n-0.6119555      1.2226686       -0.10441754     -1.6240023\n0.5598073       -0.099059306    -1.543586       0.72533834\n-1.6674699      -1.0901593      -0.24129404     0.30954796\n\n(2,1,.,.) =\n-0.78856885     -0.5567014      -1.1273636      -0.98069143\n-0.40949664     0.92562497      -1.3729718      0.7423901\n-0.29498738     -0.044669412    1.0937366       0.90768206\n\n(2,2,.,.) =\n1.0948726       -0.23575573     -0.051821854    -0.58692485\n1.9133459       -1.0849183      2.1423934       0.6559134\n-0.8390565      -0.27111387     -0.8439365      -1.3939567\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n-0.42428172 0.25790718  -0.5227444\n0.6963143   -0.34605533 -0.35524538\n\n(1,2,.,.) =\n0.61758286  0.8430548   0.1378907\n0.24116383  0.15782532  0.16882366\n\n(2,1,.,.) =\n-0.5603108  0.5107949   -0.112701565\n0.62288725  0.6909297   -0.9253155\n\n(2,2,.,.) =\n-0.2443612  0.9310517   -0.2417406\n-0.82973266 -1.0886648  0.19112866\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import LocallyConnected2D\n\nmodel = Sequential()\nmodel.add(LocallyConnected2D(2, 2, 2, input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.57424593 0.49505236 0.63711108 0.43693806]\n   [0.34655799 0.0058394  0.69310344 0.70403367]\n   [0.4620432  0.58679338 0.64529398 0.78130808]]\n  [[0.49651564 0.32201482 0.02470762 0.80535793]\n   [0.94485185 0.07150504 0.58789497 0.4562848 ]\n   [0.63595033 0.04600271 0.89771801 0.95419454]]]\n\n [[[0.69641827 0.21785002 0.15815588 0.8317213 ]\n   [0.84192366 0.3939658  0.64309395 0.3858968 ]\n   [0.16545408 0.58533897 0.99486481 0.84651898]]\n  [[0.05144159 0.94930242 0.26842063 0.6341632 ]\n   [0.442836   0.38544902 0.04266468 0.22600452]\n   [0.2705393  0.07313841 0.24295287 0.9573069 ]]]]\n\n\n\n\nOutput is\n\n\n[[[[ 0.1600316   0.178018   -0.07472821]\n   [ 0.0570091  -0.19973318  0.44483435]]\n  [[-0.20258084 -0.37692443 -0.27103102]\n   [-0.624092   -0.09749079 -0.00799894]]]\n\n [[[ 0.58953685  0.35287908 -0.2203412 ]\n   [ 0.13649486 -0.29554832  0.16932982]]\n  [[-0.00787066 -0.06614903 -0.2027885 ]\n   [-0.33434835 -0.33458236 -0.15103136]]]]\n\n\n\n\n\n\nCropping1D\n\n\nCropping layer for 1D input (e.g. temporal sequence).\n\n\nThe input of this layer should be 3D.\n\n\nScala:\n\n\nCropping1D(cropping = (1, 1), inputShape = null)\n\n\n\n\nPython:\n\n\nCropping1D(cropping=(1, 1), input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ncropping\n: Length 2. How many units should be trimmed off at the beginning and end of the cropping dimension. Default is (1, 1).\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, Cropping1D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Cropping1D((1, 1), inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-1.0038188  -0.75265634 0.7417358   1.0674809\n-1.4702164  0.64112693  0.17750219  -0.21439286\n-0.93766433 -1.0809567  0.7706962   0.16380796\n\n(2,.,.) =\n0.45019576  -0.36689326 0.08852628  -0.21602148\n0.66039973  0.11638404  0.062985964 -1.0420738\n0.46727908  -0.85894865 1.9853845   0.059447426\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-1.4702164  0.64112693  0.17750219  -0.21439286\n\n(2,.,.) =\n0.66039973  0.11638404  0.062985964 -1.0420738\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Cropping1D\n\nmodel = Sequential()\nmodel.add(Cropping1D(input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.01030651 0.77603525 0.97263208 0.15933375]\n  [0.05135971 0.01139832 0.28809891 0.57260363]\n  [0.28128354 0.55290954 0.77011153 0.09879061]]\n\n [[0.75765909 0.55102462 0.42426818 0.14383546]\n  [0.85198966 0.3990277  0.13061313 0.10349525]\n  [0.69892804 0.30310119 0.2241441  0.05978997]]]\n\n\n\n\nOutput is\n\n\n[[[0.05135971 0.01139832 0.2880989  0.57260364]]\n\n [[0.8519896  0.3990277  0.13061313 0.10349525]]]\n\n\n\n\n\n\nCropping2D\n\n\nCropping layer for 2D input (e.g. picture).\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nCropping2D(cropping = ((0, 0), (0, 0)), dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nCropping2D(cropping=((0, 0), (0, 0)), dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ncropping\n: Int tuple of tuple of length 2. How many units should be trimmed off at the beginning and end of the 2 cropping dimensions (i.e. height and width). Default is ((0, 0), (0, 0)).\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, Cropping2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Cropping2D(((0, 1), (1, 0)), inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-1.3613406  -0.03520738  -0.008660733  2.1150143\n0.18087284  1.8787018    0.30097032   -2.5634677\n-1.9463011  -0.18772388  1.5215846    -0.8047026\n\n(1,2,.,.) =\n-0.50510925 -1.1193116   0.6901347   -0.2625669\n-0.24307655 -0.77917117  -0.566465   1.0432123\n0.4877474   0.49704018   -1.5550427  1.5772455\n\n(2,1,.,.) =\n-1.6180872  0.011832007  1.2762135   0.5600022\n1.9009352   -0.11096256  1.1500957   -0.26341736\n1.0153246   0.88008636   0.0560876   -1.0235065\n\n(2,2,.,.) =\n0.1036221   1.08527      -0.52559805   -0.5091204\n1.3085281   -0.96346164  -0.09713245   -1.1010116\n0.08505145  1.9413263    2.0237558     -0.5978173\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n-0.03520738 -0.008660733  2.1150143\n1.8787018   0.30097032    -2.5634677\n\n(1,2,.,.) =\n-1.1193116   0.6901347  -0.2625669\n-0.77917117  -0.566465  1.0432123\n\n(2,1,.,.) =\n0.011832007  1.2762135  0.5600022\n-0.11096256  1.1500957  -0.26341736\n\n(2,2,.,.) =\n1.08527      -0.52559805   -0.5091204\n-0.96346164  -0.09713245   -1.1010116\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Cropping2D\n\nmodel = Sequential()\nmodel.add(Cropping2D(((0, 1), (1, 0)), input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.03691489 0.60233732 0.96327319 0.99561146]\n   [0.85728883 0.77923287 0.41328434 0.87490199]\n   [0.3389653  0.94804499 0.72922732 0.21191413]]\n  [[0.28962322 0.30133445 0.58516862 0.22476588]\n   [0.95386045 0.72488497 0.12056255 0.01265548]\n   [0.48645173 0.34426033 0.09410422 0.86815053]]]\n\n [[[0.57444115 0.79141167 0.20755353 0.38616465]\n   [0.95793123 0.22366943 0.5080078  0.27193368]\n   [0.65402317 0.1023231  0.67207896 0.2229965 ]]\n  [[0.04160647 0.55577895 0.30907277 0.42227706]\n   [0.54489229 0.90423796 0.50782414 0.51441165]\n   [0.87544565 0.47791071 0.0341273  0.14728084]]]]\n\n\n\n\nOutput is\n\n\n[[[[0.6023373  0.96327317 0.9956115 ]\n   [0.77923286 0.41328433 0.874902  ]]\n  [[0.30133444 0.5851686  0.22476588]\n   [0.724885   0.12056255 0.01265548]]]\n\n [[[0.7914117  0.20755354 0.38616467]\n   [0.22366942 0.5080078  0.27193367]]\n\n  [[0.555779   0.30907276 0.42227706]\n   [0.904238   0.5078241  0.5144116 ]]]]\n\n\n\n\n\n\nCropping3D\n\n\nCropping layer for 3D data (e.g. spatial or spatio-temporal).\n\n\nThe input of this layer should be 5D.\n\n\nScala:\n\n\nCropping3D(cropping = ((1, 1), (1, 1), (1, 1)), dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nCropping3D(cropping=((1, 1), (1, 1), (1, 1)), dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ncropping\n: Int tuple of tuple of length 3. How many units should be trimmed off at the beginning and end of the 3 cropping dimensions (i.e. kernel_dim1, kernel_dim2 and kernel_dim3). Default is ((1, 1), (1, 1), (1, 1)).\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, Cropping3D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Cropping3D(((1, 1), (1, 1), (1, 1)), inputShape = Shape(2, 3, 4, 5)))\nval input = Tensor[Float](2, 2, 3, 4, 5).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n-0.12339484     0.25661087      0.04387503      -1.1047344      -1.1413815\n1.1830065       -0.07189157     -0.5418846      0.5576781       -0.5460917\n-0.5679186      -0.30854696     1.2614665       -0.6774269      -0.63295823\n0.5269464       -2.7981617      -0.056265026    -1.0814936      -1.0848739\n\n(1,1,2,.,.) =\n-1.9100302      0.461067        0.4014941       0.60723174      -0.40414023\n0.34300476      0.7107094       1.3142885       1.5696589       0.97591686\n0.38320687      0.07036536      -0.43628898     0.58050656      -0.57882625\n-0.43699506     -0.0094956765   0.15171598      0.038076796     -1.2433665\n\n(1,1,3,.,.) =\n0.39671394      0.880047        0.30971292      -0.3369089      0.13062176\n-0.27803114     -0.62177086     0.16659822      0.89428085      0.23684736\n1.6151237       -1.1479733      -0.2229254      1.1361892       0.79478127\n-1.8207864      1.6544164       0.07977915      -1.1316417      -0.25483203\n\n(1,2,1,.,.) =\n1.3165517       -0.9479057      -1.4662051      -0.3343554      -0.4522552\n-1.5829691      0.6378519       -0.16399206     1.4724066       1.2387054\n-1.1467208      -0.6325814      -1.2106491      -0.035734158    0.19871919\n2.285004        1.0482147       -2.0056705      -0.80917794     2.523167\n\n(1,2,2,.,.) =\n-0.57108706     -0.23606259     -0.45569882     -0.034214735    -1.9130942\n-0.2743481      1.61177         -0.7052599      0.17889105      -0.31241596\n0.22377247      1.5860337       -0.3226252      -0.1341058      0.9239994\n0.03615294      0.6233593       0.757827        -0.72271305     0.9429943\n\n(1,2,3,.,.) =\n-0.4409662      0.8867786       2.0036085       0.16242673      -0.3332395\n0.09082064      0.04958198      -0.27834833     1.8025815       -0.04848101\n0.2690667       -1.1263227      -0.95486647     0.09473259      0.98166656\n-0.9509363      -0.10084029     -0.35410827     0.29626986      0.97203517\n\n(2,1,1,.,.) =\n0.42096403      0.14016314      0.20216857      -0.678293       -1.0970931\n-0.4981112      0.12429344      1.7156922       -0.24384527     -0.010780937\n0.03672217      2.3021698       1.568247        -0.43173146     -0.5550057\n0.30469602      1.4772439       -0.21195345     0.04221814      -1.6883365\n\n(2,1,2,.,.) =\n0.22468264      0.72787744      -0.9597003      -0.28472963     -1.4575284\n1.0487963       0.4982454       -1.0186157      -1.9877508      -1.133779\n0.17539643      -0.35151628     -1.8955303      2.1854792       0.59556997\n0.6893949       -0.19556235     0.25862908      0.24450152      0.17786922\n\n(2,1,3,.,.) =\n1.147159        -0.8849993      0.9826487       0.95360875      -0.9210176\n1.3439047       0.6739913       0.06558858      0.91963255      -1.1758618\n1.747105        -0.7225308      -1.0160877      0.67554474      -0.7762811\n0.21184689      -0.43668815     -1.0738864      0.04661594      0.9613895\n\n(2,2,1,.,.) =\n-0.377159       -0.28094378     0.1081715       1.3683178       1.2572801\n0.47781375      0.4545212       0.55356956      1.0366637       -0.1962683\n-1.820227       -0.111765414    1.9194998       -1.6089902      -1.6960226\n0.14896627      0.9360371       0.49156702      0.08601956      -0.08815153\n\n(2,2,2,.,.) =\n0.056315728     -0.13061485     -0.49018836     -0.59103477     -1.6910721\n-0.023719765    -0.44977355     0.11218439      0.224829        1.400084\n0.31496882      -1.6386473      -0.6715097      0.14816228      0.3240011\n-0.80607724     -0.37951842     -0.2187672      1.1087769       0.43044603\n\n(2,2,3,.,.) =\n-1.6647842      -0.5720825      -1.5150099      0.42346838      1.495052\n-0.3567161      -1.4341534      -0.19422509     -1.2871891      -1.2758921\n-0.47077888     -0.42217267     0.67764246      1.2170314       0.8420698\n-0.4263702      1.2792329       0.38645822      -2.4653213      -1.512707\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4x5]\n\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.7107094   1.3142885   1.5696589\n0.07036536  -0.43628898 0.58050656\n\n(1,2,1,.,.) =\n1.61177     -0.7052599  0.17889105\n1.5860337   -0.3226252  -0.1341058\n\n(2,1,1,.,.) =\n0.4982454   -1.0186157  -1.9877508\n-0.35151628 -1.8955303  2.1854792\n\n(2,2,1,.,.) =\n-0.44977355 0.11218439  0.224829\n-1.6386473  -0.6715097  0.14816228\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Cropping3D\n\nmodel = Sequential()\nmodel.add(Cropping3D(((1, 1), (1, 1), (1, 1)), input_shape=(2, 3, 4, 5)))\ninput = np.random.random([2, 2, 3, 4, 5])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[[0.17398425 0.68189365 0.77769123 0.53108205 0.64715435]\n    [0.14553671 0.56312657 0.68612354 0.69176945 0.30109699]\n    [0.09732807 0.37460879 0.19945361 0.86471357 0.66225896]\n    [0.23071766 0.7940814  0.20828491 0.05256511 0.39059369]]\n   [[0.61604377 0.08752888 0.0373393  0.2074062  0.60620641]\n    [0.72873275 0.86871873 0.89248703 0.9407502  0.71830713]\n    [0.23277175 0.75968678 0.2160847  0.76278034 0.27796526]\n    [0.45593022 0.31406512 0.83030059 0.17528758 0.56134316]]\n   [[0.65576189 0.41055457 0.90979203 0.76003643 0.26369912]\n    [0.20767533 0.60489496 0.44996379 0.20016757 0.39282226]\n    [0.14055952 0.15767185 0.70149107 0.88403803 0.77345544]\n    [0.34344548 0.03721154 0.86204782 0.45349481 0.69348787]]]\n  [[[0.55441874 0.59949813 0.4450893  0.2103161  0.6300366 ]\n    [0.71573331 0.32423206 0.06302588 0.91902299 0.30852669]\n    [0.73540519 0.20697542 0.20543135 0.44461869 0.89286638]\n    [0.41614996 0.48155318 0.51663767 0.23681825 0.34780746]]\n   [[0.34529962 0.81156897 0.77911935 0.65392321 0.45178564]\n    [0.39702465 0.36180668 0.37867952 0.24818676 0.84365902]\n    [0.67836434 0.24043224 0.59870659 0.81976809 0.95442206]\n    [0.15342281 0.48607751 0.11420129 0.68621285 0.09892679]]\n   [[0.61122758 0.40359022 0.99805441 0.76764677 0.6281926 ]\n    [0.44867213 0.81206033 0.40117858 0.98967612 0.76897064]\n    [0.90603977 0.17299288 0.68803644 0.75164168 0.4161878 ]\n    [0.18996933 0.93317759 0.77711184 0.50760022 0.77439241]]]]\n\n [[[[0.49974828 0.74486599 0.12447392 0.15415173 0.36715309]\n    [0.49334423 0.66699219 0.22202136 0.52689596 0.15497081]\n    [0.4117844  0.21886979 0.13096058 0.82589121 0.00621519]\n    [0.38257617 0.60924058 0.53549974 0.64299846 0.66315369]]\n   [[0.78048895 0.20350694 0.16485496 0.71243727 0.4581091 ]\n    [0.554526   0.66891789 0.90082079 0.76729771 0.40647459]\n    [0.72809646 0.68164733 0.83008334 0.90941546 0.1441997 ]\n    [0.44580521 0.78015871 0.63982938 0.26813225 0.15588673]]\n   [[0.85294056 0.0928758  0.37056251 0.82930655 0.27178195]\n    [0.95953427 0.60170629 0.69156911 0.27902576 0.55613879]\n    [0.97101437 0.49876892 0.36313494 0.11233855 0.24221145]\n    [0.28739626 0.2990425  0.68940864 0.95621615 0.6922569 ]]]\n  [[[0.90283303 0.51320503 0.78356741 0.79301195 0.17681709]\n    [0.61624755 0.95418399 0.68118889 0.69241549 0.17943311]\n    [0.71129437 0.55478761 0.34121912 0.86018439 0.03652437]\n    [0.39098173 0.87916544 0.39647239 0.00104663 0.01377085]]\n   [[0.28875017 0.03733266 0.47260498 0.2896268  0.55976704]\n    [0.08723092 0.45523634 0.98463086 0.56950302 0.98261442]\n    [0.20716971 0.52744283 0.39455719 0.57384754 0.76698272]\n    [0.3079253  0.88143353 0.85897125 0.0969679  0.43760548]]\n   [[0.44239165 0.56141652 0.30344311 0.05425044 0.34003295]\n    [0.31417344 0.39485584 0.47300811 0.38006721 0.23185974]\n    [0.06158527 0.95330693 0.63043506 0.9480669  0.93758737]\n    [0.05340179 0.2064604  0.97254971 0.60841205 0.89738937]]]]]\n\n\n\n\nOutput is\n\n\n[[[[[0.86871874 0.89248705 0.9407502 ]\n    [0.75968677 0.2160847  0.7627803 ]]]\n  [[[0.3618067  0.3786795  0.24818675]\n    [0.24043223 0.5987066  0.8197681 ]]]]\n\n [[[[0.6689179  0.9008208  0.7672977 ]\n    [0.68164736 0.8300834  0.9094155 ]]]\n  [[[0.45523635 0.9846309  0.569503  ]\n    [0.5274428  0.39455718 0.57384753]]]]]\n\n\n\n\n\n\nZeroPadding1D\n\n\nZero-padding layer for 1D input (e.g. temporal sequence).\n\n\nThe input of this layer should be 3D.\n\n\nScala:\n\n\nZeroPadding1D(padding = 1, inputShape = null)\n\n\n\n\nPython:\n\n\nZeroPadding1D(padding=1, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npadding\n: How many zeros to add at the beginning and at the end of the padding dimension.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, ZeroPadding1D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ZeroPadding1D(1, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.7421485   -0.13270181 -0.12605186 -0.7442475\n0.36977226  -0.90300065 -0.34193754 -0.035565257\n-0.23300397 0.8183156   0.7023575   -0.16938858\n\n(2,.,.) =\n-0.7785278  0.36642975  -1.0542017  -0.29036212\n-0.22632122 0.46808097  -0.68293047 1.2529073\n-0.8619831  1.3846883   1.0762612   1.1351995\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.0         0.0         0.0         0.0\n0.7421485   -0.13270181 -0.12605186 -0.7442475\n0.36977226  -0.90300065 -0.34193754 -0.035565257\n-0.23300397 0.8183156   0.7023575   -0.16938858\n0.0         0.0         0.0         0.0\n\n(2,.,.) =\n0.0         0.0         0.0         0.0\n-0.7785278  0.36642975  -1.0542017  -0.29036212\n-0.22632122 0.46808097  -0.68293047 1.2529073\n-0.8619831  1.3846883   1.0762612   1.1351995\n0.0         0.0         0.0         0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import ZeroPadding1D\n\nmodel = Sequential()\nmodel.add(ZeroPadding1D(1, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.74177145 0.75805981 0.2091588  0.46929227]\n  [0.46041743 0.13213793 0.51065024 0.36081853]\n  [0.60803218 0.27764702 0.31788482 0.65445294]]\n\n [[0.96255443 0.74692762 0.50050961 0.88456158]\n  [0.55492653 0.50850271 0.17788885 0.91569285]\n  [0.27356035 0.74622588 0.39690752 0.75229177]]]\n\n\n\n\nOutput is\n\n\n[[[0.0        0.0        0.0        0.0       ]\n  [0.74177146 0.7580598  0.2091588  0.46929225]\n  [0.46041742 0.13213794 0.5106502  0.36081854]\n  [0.60803217 0.27764702 0.31788483 0.6544529 ]\n  [0.0        0.0        0.0        0.0       ]]\n\n [[0.0        0.0        0.0        0.0       ]\n  [0.96255445 0.7469276  0.5005096  0.8845616 ]\n  [0.5549265  0.5085027  0.17788884 0.91569287]\n  [0.27356035 0.7462259  0.39690754 0.75229174]\n  [0.0        0.0        0.0        0.0       ]]]\n\n\n\n\n\n\nZeroPadding2D\n\n\nZero-padding layer for 2D input (e.g. picture).\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nZeroPadding2D(padding = (1, 1), dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nZeroPadding2D(padding=(1, 1), dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npadding\n: How many zeros to add at the beginning and at the end of the 2 padding dimensions (rows and cols).\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, ZeroPadding2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ZeroPadding2D((1, 1), inputShape = Shape(2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n1.7201442   -1.0197405  1.3163399\n-0.23921064 0.7732504   -0.069928266\n\n(1,2,.,.) =\n0.46323594  -1.3043984  -0.67622787\n-1.610615   -0.39253974 -0.89652705\n\n(2,1,.,.) =\n-0.3784847  -0.6738694  0.30479854\n-0.49577644 1.0704983   0.6288544\n\n(2,2,.,.) =\n0.2821439   0.790223    0.34665197\n0.24190207  0.10775433  0.46225727\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.0     0.0         0.0         0.0             0.0\n0.0     1.7201442   -1.0197405  1.3163399       0.0\n0.0     -0.23921064 0.7732504   -0.069928266    0.0\n0.0     0.0         0.0         0.0             0.0\n\n(1,2,.,.) =\n0.0     0.0         0.0         0.0             0.0\n0.0     0.46323594  -1.3043984  -0.67622787     0.0\n0.0     -1.610615   -0.39253974 -0.89652705     0.0\n0.0     0.0         0.0         0.0             0.0\n\n(2,1,.,.) =\n0.0     0.0         0.0         0.0             0.0\n0.0     -0.3784847  -0.6738694  0.30479854      0.0\n0.0     -0.49577644 1.0704983   0.6288544       0.0\n0.0     0.0         0.0         0.0             0.0\n\n(2,2,.,.) =\n0.0     0.0         0.0         0.0             0.0\n0.0     0.2821439   0.790223    0.34665197      0.0\n0.0     0.24190207  0.10775433  0.46225727      0.0\n0.0     0.0         0.0         0.0             0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x4x5]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import ZeroPadding2D\n\nmodel = Sequential()\nmodel.add(ZeroPadding2D(input_shape=(2, 2, 3)))\ninput = np.random.random([2, 2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.44048214 0.72494886 0.96654241]\n   [0.66254801 0.37409083 0.47681466]]\n\n  [[0.23204026 0.52762765 0.15072852]\n   [0.45052127 0.29016392 0.0133929 ]]]\n\n\n [[[0.09347565 0.4754528  0.63618458]\n   [0.08016674 0.21696158 0.83892852]]\n\n  [[0.81864575 0.90813398 0.08347963]\n   [0.57234761 0.76060611 0.65707858]]]]\n\n\n\n\nOutput is\n\n\n[[[[0.0   0.0        0.0        0.0        0.0 ]\n   [0.0   0.44048214 0.7249489  0.9665424  0.0 ]\n   [0.0   0.662548   0.37409082 0.47681466 0.0 ]\n   [0.0   0.0        0.0        0.0        0.0 ]]\n\n  [[0.0   0.0        0.0        0.0        0.0 ]\n   [0.0   0.23204026 0.52762765 0.15072852 0.0 ]\n   [0.0   0.45052126 0.29016393 0.0133929  0.0 ]\n   [0.0   0.0        0.0        0.0        0.0 ]]]\n\n\n [[[0.0   0.0        0.0        0.0        0.0 ]\n   [0.0   0.09347565 0.4754528  0.6361846  0.0 ]\n   [0.0   0.08016673 0.21696158 0.8389285  0.0 ]\n   [0.0   0.0        0.0        0.0        0.0 ]]\n\n  [[0.0   0.0        0.0        0.0        0.0 ]\n   [0.0   0.8186458  0.908134   0.08347963 0.0 ]\n   [0.0   0.5723476  0.7606061  0.65707856 0.0 ]\n   [0.0   0.0        0.0        0.0        0.0 ]]]]\n\n\n\n\n\n\nZeroPadding3D\n\n\nZero-padding layer for 3D data (spatial or spatio-temporal).\n\n\nThe input of this layer should be 5D.\n\n\nScala:\n\n\nZeroPadding3D(padding = (1, 1, 1), dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nZeroPadding3D(padding=(1, 1, 1), dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npadding\n: How many zeros to add at the beginning and end of the 3 padding dimensions. Symmetric padding will be applied to each dimension.\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, ZeroPadding3D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ZeroPadding3D((1, 1, 1), inputShape = Shape(1, 2, 2, 2)))\nval input = Tensor[Float](1, 1, 2, 2, 2).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n1.086798    2.162806\n-0.50501716 -0.17430544\n\n(1,1,2,.,.) =\n-1.7388326  0.27966997\n1.6211525   1.1713351\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x2x2]\n\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.0     0.0         0.0         0.0\n0.0     0.0         0.0         0.0\n0.0     0.0         0.0         0.0\n0.0     0.0         0.0         0.0\n\n(1,1,2,.,.) =\n0.0     0.0         0.0         0.0\n0.0     1.086798    2.162806    0.0\n0.0     -0.50501716 -0.17430544 0.0\n0.0     0.0         0.0         0.0\n\n(1,1,3,.,.) =\n0.0     0.0         0.0         0.0\n0.0     -1.7388326  0.27966997  0.0\n0.0     1.6211525   1.1713351   0.0\n0.0     0.0         0.0         0.0\n\n(1,1,4,.,.) =\n0.0     0.0         0.0         0.0\n0.0     0.0         0.0         0.0\n0.0     0.0         0.0         0.0\n0.0     0.0         0.0         0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x4x4x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import ZeroPadding3D\n\nmodel = Sequential()\nmodel.add(ZeroPadding3D((1, 1, 1), input_shape=(1, 2, 2, 2)))\ninput = np.random.random([1, 1, 2, 2, 2])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[[0.12432462 0.19244616]\n    [0.39039533 0.88140855]]\n\n   [[0.71426182 0.86085132]\n    [0.04443494 0.679125  ]]]]]\n\n\n\n\nOutput is\n\n\n[[[[[0.0   0.0        0.0        0.0 ]\n    [0.0   0.0        0.0        0.0 ]\n    [0.0   0.0        0.0        0.0 ]\n    [0.0   0.0        0.0        0.0 ]]\n   [[0.0   0.0        0.0        0.0 ]\n    [0.0   0.12432462 0.19244616 0.0 ]\n    [0.0   0.39039534 0.8814086  0.0 ]\n    [0.0   0.0        0.0        0.0 ]]\n   [[0.0   0.0        0.0        0.0 ]\n    [0.0   0.71426183 0.8608513  0.0 ]\n    [0.0   0.04443494 0.679125   0.0 ]\n    [0.0   0.0        0.0        0.0 ]]\n   [[0.0   0.0        0.0        0.0 ]\n    [0.0   0.0        0.0        0.0 ]\n    [0.0   0.0        0.0        0.0 ]\n    [0.0   0.0        0.0        0.0 ]]]]]\n\n\n\n\n\n\nUpSampling1D\n\n\nUpSampling layer for 1D inputs.\n\n\nRepeats each temporal step 'length' times along the time axis.\n\n\nThe input of this layer should be 3D.\n\n\nScala:\n\n\nUpSampling1D(length = 2, inputShape = null)\n\n\n\n\nPython:\n\n\nUpSampling1D(length=2, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nlength\n: Integer. UpSampling factor. Default is 2.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, UpSampling1D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(UpSampling1D(2, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.80225134  -0.9644977   -0.71038723    -1.5673652\n0.67224514  -0.24330814  -0.082499735   0.2807591\n-0.9299857  -1.8893008   -1.1062661     -1.1637908\n\n(2,.,.) =\n-0.1831344  -0.6621819   -0.667329      -0.26960346\n-0.6601015  1.0819869    1.0307902      1.1801233\n-0.18303517 0.2565441    -0.39598823    0.23400643\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.80225134  -0.9644977   -0.71038723     -1.5673652\n0.80225134  -0.9644977   -0.71038723     -1.5673652\n0.67224514  -0.24330814  -0.082499735    0.2807591\n0.67224514  -0.24330814  -0.082499735    0.2807591\n-0.9299857  -1.8893008   -1.1062661     -1.1637908\n-0.9299857  -1.8893008   -1.1062661     -1.1637908\n\n(2,.,.) =\n-0.1831344  -0.6621819   -0.667329      -0.26960346\n-0.1831344  -0.6621819   -0.667329      -0.26960346\n-0.6601015  1.0819869    1.0307902      1.1801233\n-0.6601015  1.0819869    1.0307902      1.1801233\n-0.18303517 0.2565441    -0.39598823    0.23400643\n-0.18303517 0.2565441    -0.39598823    0.23400643\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x6x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import UpSampling1D\n\nmodel = Sequential()\nmodel.add(UpSampling1D(2, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.66227662 0.00663032 0.49010329 0.26836567]\n  [0.34225774 0.26000732 0.27628499 0.49861887]\n  [0.11619066 0.28123766 0.60770962 0.80773197]]\n\n [[0.477639   0.88906297 0.38577295 0.99058504]\n  [0.50690837 0.38107999 0.05881034 0.96402145]\n  [0.42226283 0.77350512 0.54961295 0.55315271]]]\n\n\n\n\nOutput is\n\n\n[[[0.6622766  0.00663032 0.4901033  0.26836568]\n  [0.6622766  0.00663032 0.4901033  0.26836568]\n  [0.34225774 0.26000732 0.276285   0.49861887]\n  [0.34225774 0.26000732 0.276285   0.49861887]\n  [0.11619066 0.28123766 0.60770965 0.807732  ]\n  [0.11619066 0.28123766 0.60770965 0.807732  ]]\n\n [[0.477639   0.88906294 0.38577294 0.990585  ]\n  [0.477639   0.88906294 0.38577294 0.990585  ]\n  [0.50690836 0.38107997 0.05881034 0.96402144]\n  [0.50690836 0.38107997 0.05881034 0.96402144]\n  [0.42226282 0.7735051  0.54961294 0.5531527 ]\n  [0.42226282 0.7735051  0.54961294 0.5531527 ]]]\n\n\n\n\n\n\nUpSampling2D\n\n\nUpSampling layer for 2D inputs.\n\n\nRepeats the rows and columns of the data by the specified size.\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nUpSampling2D(size = (2, 2), dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nUpSampling2D(size=(2, 2), dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nsize\n: Length 2. UpSampling factors for rows and columns. Default is (2, 2).\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, UpSampling2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(UpSampling2D((2, 2), inputShape = Shape(2, 2, 2)))\nval input = Tensor[Float](1, 2, 2, 2).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.07563081 -1.921836\n-1.7368479  0.1043008\n\n(1,2,.,.) =\n-1.825055   -0.096810855\n-0.89331573 0.72812295\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x2]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n-0.07563081 -0.07563081  -1.921836   -1.921836\n-0.07563081 -0.07563081  -1.921836   -1.921836\n-1.7368479  -1.7368479   0.1043008   0.1043008\n-1.7368479  -1.7368479   0.1043008   0.1043008\n\n(1,2,.,.) =\n-1.825055    -1.825055    -0.096810855  -0.096810855\n-1.825055    -1.825055    -0.096810855  -0.096810855\n-0.89331573  -0.89331573  0.72812295    0.72812295\n-0.89331573  -0.89331573  0.72812295    0.72812295\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import UpSampling2D\n\nmodel = Sequential()\nmodel.add(UpSampling2D((2, 2), input_shape=(2, 2, 2)))\ninput = np.random.random([1, 2, 2, 2])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.55660253 0.21984387]\n   [0.36271854 0.57464162]]\n\n  [[0.55307278 0.33007518]\n   [0.31527167 0.87789644]]]]\n\n\n\n\nOutput is\n\n\n[[[[0.55660254 0.55660254 0.21984388 0.21984388]\n   [0.55660254 0.55660254 0.21984388 0.21984388]\n   [0.36271855 0.36271855 0.57464164 0.57464164]\n   [0.36271855 0.36271855 0.57464164 0.57464164]]\n\n  [[0.55307275 0.55307275 0.33007517 0.33007517]\n   [0.55307275 0.55307275 0.33007517 0.33007517]\n   [0.31527168 0.31527168 0.8778964  0.8778964 ]\n   [0.31527168 0.31527168 0.8778964  0.8778964 ]]]]\n\n\n\n\n\n\nUpSampling3D\n\n\nUpSampling layer for 3D inputs.\n\n\nRepeats the 1st, 2nd and 3rd dimensions of the data by the specified size.\n\n\nData format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').\n\n\nThe input of this layer should be 5D.\n\n\nScala:\n\n\nUpSampling3D(size = (2, 2, 2), dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nUpSampling3D(size=(2, 2, 2), dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nsize\n: Length 3. UpSampling factors for dim1, dim2 and dim3. Default is (2, 2, 2).\n\n\ndimOrdering\n: Format of input data. Only 'th' (Channel First) is supported for now.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, UpSampling3D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(UpSampling3D((2, 2, 2), inputShape = Shape(1, 1, 2, 2)))\nval input = Tensor[Float](1, 1, 1, 2, 2).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n0.9906968   -0.2451235\n1.5133694   -0.34076887\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1x2x2]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.9906968   0.9906968   -0.2451235  -0.2451235\n0.9906968   0.9906968   -0.2451235  -0.2451235\n1.5133694   1.5133694   -0.34076887 -0.34076887\n1.5133694   1.5133694   -0.34076887 -0.34076887\n\n(1,1,2,.,.) =\n0.9906968   0.9906968   -0.2451235  -0.2451235\n0.9906968   0.9906968   -0.2451235  -0.2451235\n1.5133694   1.5133694   -0.34076887 -0.34076887\n1.5133694   1.5133694   -0.34076887 -0.34076887\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x4x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import UpSampling3D\n\nmodel = Sequential()\nmodel.add(UpSampling3D((2, 2, 2), input_shape=(1, 1, 2, 2)))\ninput = np.random.random([1, 1, 1, 2, 2])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[[0.58361205 0.2096227 ]\n    [0.51686662 0.70260105]]]]]\n\n\n\n\nOutput is\n\n\n[[[[[0.583612  0.583612  0.2096227 0.2096227]\n    [0.583612  0.583612  0.2096227 0.2096227]\n    [0.5168666 0.5168666 0.7026011 0.7026011]\n    [0.5168666 0.5168666 0.7026011 0.7026011]]\n\n   [[0.583612  0.583612  0.2096227 0.2096227]\n    [0.583612  0.583612  0.2096227 0.2096227]\n    [0.5168666 0.5168666 0.7026011 0.7026011]\n    [0.5168666 0.5168666 0.7026011 0.7026011]]]]]", 
            "title": "Convolutional Layers"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#convolution1d", 
            "text": "Applies convolution operator for filtering neighborhoods of 1-D inputs.  You can also use  Conv1D  as an alias of this layer.  The input of this layer should be 3D.  Scala:  Convolution1D(nbFilter, filterLength, init =  glorot_uniform , activation = null, borderMode =  valid , subsampleLength = 1, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)  Python:  Convolution1D(nb_filter, filter_length, init= glorot_uniform , activation=None, border_mode= valid , subsample_length=1, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)  Parameters:   nbFilter : Number of convolution filters to use.  filterLength : The extension (spatial or temporal) of each filter.  init : String representation of the initialization method for the weights of the layer. See  here  for available initialization strings. Default is 'glorot_uniform'.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is null.  borderMode : Either 'valid' or 'same'. Default is 'valid'.  subsampleLength : Factor by which to subsample output. Integer. Default is 1.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, Convolution1D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Convolution1D(8, 3, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-1.4253887  -0.044403594    -1.1169672  -0.19499049\n0.85463065  0.6665206       0.21340805  0.56255895\n1.1126599   -0.3423326      0.09643264  -0.34345046\n\n(2,.,.) =\n-0.04046587 -0.2710401      0.10183265  1.4503858\n1.0639644   1.5317003       -0.18313104 -0.7098296\n0.612399    1.7357533       0.4641411   0.13530721\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.22175728  0.76192796  1.7907748   1.1534728   -1.5304534  0.07466106  -0.18292685 0.6038852\n\n(2,.,.) =\n0.85337734  0.43939286  -0.16770163 -0.8380078  0.7825804   -0.3485601  0.3017909   0.5823619\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x8]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Convolution1D\n\nmodel = Sequential()\nmodel.add(Convolution1D(8, 3, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  [[[0.06092268 0.0508438  0.47256153 0.80004565]\n  [0.48706905 0.65704781 0.04297214 0.42288264]\n  [0.92286158 0.85394381 0.46423248 0.87896669]]\n\n [[0.216527   0.13880484 0.93482372 0.44812419]\n  [0.95553331 0.27084259 0.58913626 0.01879454]\n  [0.6656435  0.1985877  0.94133745 0.57504128]]]  Output is  [[[ 0.7461933  -2.3189526  -1.454972   -0.7323345   1.5272427  -0.87963724  0.6278059  -0.23403725]]\n\n [[ 1.2397771  -0.9249111  -1.1432207  -0.92868984  0.53766745 -1.0271561  -0.9593589  -0.4768026 ]]]", 
            "title": "Convolution1D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#convolution2d", 
            "text": "Applies a 2D convolution over an input image composed of several input planes.  You can also use  Conv2D  as an alias of this layer.  The input of this layer should be 4D.  Scala:  Convolution2D(nbFilter, nbRow, nbCol, init =  glorot_uniform , activation = null, borderMode =  valid , subsample = (1, 1), dimOrdering =  th , wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)  Python:  Convolution2D(nb_filter, nb_row, nb_col, init= glorot_uniform , activation=None, border_mode= valid , subsample=(1, 1), dim_ordering= th , W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)  Parameters:   nbFilter : Number of convolution filters to use.  nbRow : Number of rows in the convolution kernel.  nbCol : Number of columns in the convolution kernel.  init : String representation of the initialization method for the weights of the layer. See  here  for available initialization strings. Default is 'glorot_uniform'.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is null.  borderMode : Either 'valid' or 'same'. Default is 'valid'.  subsample : Length 2 corresponding to the step of the convolution in the height and width dimension. Also called strides elsewhere. Default is (1, 1).  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, Convolution2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Convolution2D(4, 2, 2, activation =  relu , inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-1.6687597  1.3452173   -1.9608531  -0.30892205\n1.7459077   -0.443617   0.25789636  0.44496542\n-1.5395774  -0.37713575 -0.9973955  0.16208267\n\n(1,2,.,.) =\n0.593965    1.0544858   -1.0765858  0.22257836\n0.69452614  1.3700147   -0.886259   0.013910895\n-1.9819669  0.32151425  1.8303248   0.24231844\n\n(2,1,.,.) =\n-2.150859   -1.5894475  0.7543173   0.7713991\n-0.17536041 0.89053404  0.50489277  -0.098128\n0.11551995  1.3663125   0.76734704  0.28318745\n\n(2,2,.,.) =\n-0.9801306  0.39797616  -0.6403248  1.0090133\n-0.16866015 -1.426308   -2.4097774  0.26011375\n-2.5700948  1.0486397   -0.4585798  -0.94231766\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.0         0.6800046   0.0\n1.0366663   0.235024    0.0\n\n(1,2,.,.) =\n0.0         0.84696645  0.0\n0.9099177   0.0         0.0\n\n(1,3,.,.) =\n0.122891426 0.0         0.86579126\n0.0         0.0         0.0\n\n(1,4,.,.) =\n0.0         0.7185988   0.0\n1.0967548   0.48376864  0.0\n\n(2,1,.,.) =\n0.0         0.0         0.29164955\n0.06815311  0.0         0.0\n\n(2,2,.,.) =\n0.36370438  0.42393038  0.26948324\n1.1676859   0.5698308   0.44842285\n\n(2,3,.,.) =\n1.0797265   1.2410768   0.18289843\n0.0         0.0         0.18757495\n\n(2,4,.,.) =\n0.0         0.35713753  0.0\n0.0         0.0         0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x2x3]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Convolution2D\n\nmodel = Sequential()\nmodel.add(Convolution2D(4, 2, 2, input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.05182015 0.91971256 0.81030852 0.64093699]\n   [0.60282957 0.16269049 0.79136121 0.05202386]\n   [0.62560999 0.00174107 0.75762976 0.93589574]]\n  [[0.13728558 0.85812609 0.39695457 0.81678788]\n   [0.7569393  0.61161632 0.60750583 0.6222684 ]\n   [0.53094821 0.38715199 0.0087283  0.05758945]]]\n\n [[[0.50030948 0.40179766 0.54900785 0.60950401]\n   [0.17464329 0.01506322 0.55273153 0.21567461]\n   [0.09037649 0.58831638 0.818708   0.96642448]]\n  [[0.77126628 0.58039509 0.91612417 0.12578268]\n   [0.6095838  0.15802154 0.78099004 0.63619778]\n   [0.70632951 0.91378968 0.84851605 0.7242516 ]]]]  Output is  [[[[-0.45239753  0.2432243  -0.02717562]\n   [ 0.2698849  -0.09664132  0.92311716]]\n  [[ 0.9092748   0.7945191   0.8834159 ]\n   [ 0.4853364   0.6511425   0.52513427]]\n  [[ 0.5550465   0.8177169   0.43213058]\n   [ 0.4209347   0.7514105   0.27255327]]\n  [[-0.22105691  0.02853963  0.01092601]\n   [ 0.1258291  -0.41649136 -0.18953061]]]\n\n [[[-0.12111888  0.06418754  0.26331317]\n   [ 0.41674113  0.04221775  0.7313505 ]]\n  [[ 0.49442202  0.6964868   0.558412  ]\n   [ 0.25196168  0.8145504   0.69307953]]\n  [[ 0.5885831   0.59289575  0.71726865]\n   [ 0.46759683  0.520353    0.59305453]]\n  [[ 0.00594708  0.09721318  0.07852311]\n   [ 0.49868047  0.02704304  0.14635414]]]]", 
            "title": "Convolution2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#convolution3d", 
            "text": "Applies convolution operator for filtering windows of three-dimensional inputs.  You can also use  Conv3D  as an alias of this layer.  Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').  The input of this layer should be 5D.  Scala:  Convolution3D(nbFilter, kernelDim1, kernelDim2, kernelDim3, init =  glorot_uniform , activation = null, borderMode =  valid , subsample = (1, 1, 1), dimOrdering =  th , wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)  Python:  Convolution3D(nb_filter, kernel_dim1, kernel_dim2, kernel_dim3, init= glorot_uniform , activation=None, border_mode= valid , subsample=(1, 1, 1), dim_ordering= th , W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)  Parameters:   nbFilter : Number of convolution filters to use.  kernelDim1 : Length of the first dimension in the convolution kernel.  kernelDim2 : Length of the second dimension in the convolution kernel.  kernelDim3 : Length of the third dimension in the convolution kernel.  init : String representation of the initialization method for the weights of the layer. See  here  for available initialization strings. Default is 'glorot_uniform'.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is null.  borderMode : Either 'valid' or 'same'. Default is 'valid'.  subsample : Length 3. Factor by which to subsample output. Also called strides elsewhere. Default is (1, 1, 1).  dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, Convolution3D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Convolution3D(4, 2, 2, 2, inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n0.64140224  -1.4049392  0.4935015\n0.33096266  1.2768826   -0.57567996\n\n(1,1,2,.,.) =\n0.49570087  -2.0367618    -0.0032108661\n-0.24242361 -0.092683665  1.1579652\n\n(1,2,1,.,.) =\n-0.6730608  0.9149566   -1.7478822\n-0.1763675  -0.90117735 0.38452747\n\n(1,2,2,.,.) =\n0.5314353   1.4802488   -1.196325\n0.43506134  -0.56575996 -1.5489199\n\n(2,1,1,.,.) =\n0.074545994 -1.4092928  -0.57647055\n1.9998664   -0.19424418 -0.9296713\n\n(2,1,2,.,.) =\n-0.42966184 0.9247804   -0.21713361\n0.2723336   -1.3024703  1.278154\n\n(2,2,1,.,.) =\n1.1240695   1.1061385   -2.4662287\n-0.36022148 0.1620907   -1.1525819\n\n(2,2,2,.,.) =\n0.9885768   -0.526637   -0.40684605\n0.37813842  0.53998697  1.0001947\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.36078936  -0.6334647\n\n(1,2,1,.,.) =\n-0.19685572 0.4559337\n\n(1,3,1,.,.) =\n1.3750207   -2.4377227\n\n(1,4,1,.,.) =\n-0.82853335 -0.74145436\n\n(2,1,1,.,.) =\n-0.17973013 1.2930126\n\n(2,2,1,.,.) =\n0.69144577  0.44385013\n\n(2,3,1,.,.) =\n-0.5597819  0.5965629\n\n(2,4,1,.,.) =\n0.89755684  -0.6737796\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x1x1x2]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Convolution3D\n\nmodel = Sequential()\nmodel.add(Convolution3D(4, 2, 2, 2, input_shape=(2, 2, 2, 3)))\ninput = np.random.random([2, 2, 2, 2, 3])\noutput = model.forward(input)  Input is:  [[[[[0.36798873 0.92635561 0.31834968]\n    [0.09001392 0.66762381 0.64477164]]\n   [[0.09760993 0.38067132 0.15069965]\n    [0.39052699 0.0223722  0.04786307]]]\n  [[[0.2867726  0.3674255  0.11852931]\n    [0.96436629 0.8012903  0.3211012 ]]\n   [[0.81738622 0.80606827 0.4060485 ]\n    [0.68010177 0.0934071  0.98479026]]]]\n\n [[[[0.71624597 0.37754442 0.07367964]\n    [0.60742428 0.38549046 0.78880978]]\n   [[0.97844361 0.11426373 0.55479659]\n    [0.06395313 0.86007246 0.34004405]]]\n  [[[0.94149643 0.8027673  0.19478027]\n    [0.17437108 0.754479   0.51055297]]\n   [[0.81933677 0.09040694 0.33775061]\n    [0.02582059 0.40027544 0.91809986]]]]]  Output is  [[[[[ 1.6276866  -4.4106215]]]\n  [[[ 6.6988254  1.1409638]]]\n  [[[-5.7734865  -5.2575850]]]\n  [[[-1.8073934  -4.4056013]]]]\n\n [[[[-4.8580116  9.4352424]]]\n  [[[ 7.8890514  6.6063654]]]\n  [[[-7.3165756  -1.0116580]]]\n  [[[-1.3100024  1.0475740]]]]]", 
            "title": "Convolution3D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#atrousconvolution1d", 
            "text": "Applies an atrous convolution operator for filtering neighborhoods of 1-D inputs.  A.k.a dilated convolution or convolution with holes.  Bias will be included in this layer.  Border mode currently supported for this layer is 'valid'.  You can also use  AtrousConv1D  as an alias of this layer.  The input of this layer should be 3D.  Scala:  AtrousConvolution1D(nbFilter, filterLength, init =  glorot_uniform , activation = null, subsampleLength = 1, atrousRate = 1, wRegularizer = null, bRegularizer = null, inputShape = null)  Python:  AtrousConvolution1D(nb_filter, filter_length, init= glorot_uniform , activation=None, border_mode='valid', subsample_length=1, atrous_rate=1, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)  Parameters:   nbFilter : Number of convolution kernels to use.  filterLength : The extension (spatial or temporal) of each filter.  init : String representation of the initialization method for the weights of the layer. See  here  for available initialization strings. Default is 'glorot_uniform'.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is null.  subsampleLength : Factor by which to subsample output. Integer. Default is 1.  atrousRate : Factor for kernel dilation. Also called filter_dilation elsewhere. Integer. Default is 1.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, AtrousConvolution1D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AtrousConvolution1D(8, 3, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.18167362 2.1452308   -0.39164552 -0.19750737\n-0.16184713 -1.3867316  -1.3447738  -0.6431075\n-0.42635638 -0.20490816 -2.5391808  -0.05881459\n\n(2,.,.) =\n-0.83197606 1.1706954   -0.80197126 -1.0663458\n0.36859998  -0.45194706 -1.2959619  -0.521925\n-1.133602   0.7700087   -1.2523394  1.1293458\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.1675637   0.9712032   -0.5615059  0.065867506 0.6681816   1.2097323   -1.0912716  0.8040266\n\n(2,.,.) =\n0.5009172   1.4765333   -0.14173388 0.060548827 0.752389    1.2912648   -1.0077878  0.06344204\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x8]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import AtrousConvolution1D\n\nmodel = Sequential()\nmodel.add(AtrousConvolution1D(8, 3, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  [[[0.96952262 0.15211776 0.63026888 0.50572335]\n  [0.13218867 0.18807126 0.33509675 0.43385223]\n  [0.48027981 0.82222524 0.9630902  0.78855421]]\n\n [[0.49106312 0.16875464 0.54099084 0.2892753 ]\n  [0.03776569 0.51324722 0.95359981 0.52863015]\n  [0.69851295 0.29676433 0.59404524 0.90078511]]]  Output is  [[[-0.62304074  0.6667814  -0.07074605 -0.03640915  0.11369559  0.3451041  -0.44238544  0.618591  ]]\n\n [[-0.5048915   0.9070808  -0.03285386  0.26761323 -0.08491824  0.36105093 -0.15240929  0.6145356 ]]]", 
            "title": "AtrousConvolution1D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#atrousconvolution2d", 
            "text": "Applies an atrous convolution operator for filtering windows of 2-D inputs.  A.k.a dilated convolution or convolution with holes.  Bias will be included in this layer.  Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').  Border mode currently supported for this layer is 'valid'.  You can also use  AtrousConv2D  as an alias of this layer.  The input of this layer should be 4D.  Scala:  AtrousConvolution2D(nbFilter, nbRow, nbCol, init =  glorot_uniform , activation = null, subsample = (1, 1), atrousRate= (1, 1), dimOrdering =  th , wRegularizer = null, bRegularizer = null, inputShape = null)  Python:  AtrousConvolution2D(nb_filter, nb_row, nb_col, init= glorot_uniform , activation=None, border_mode= valid , subsample=(1, 1), atrous_rate=(1, 1), dim_ordering= th , W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)  Parameters:   nbFilter : Number of convolution filters to use.  nbRow : Number of rows in the convolution kernel.  nbCol : Number of columns in the convolution kernel.  init : String representation of the initialization method for the weights of the layer. See  here  for available initialization strings. Default is 'glorot_uniform'.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is null.  subsample : Length 2 . Factor by which to subsample output. Also called strides elsewhere. Default is (1, 1).  atrousRate : Length 2. Factor for kernel dilation. Also called filter_dilation elsewhere. Default is (1, 1).  dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, AtrousConvolution2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AtrousConvolution2D(4, 2, 2, activation =  relu , inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.57626903     -0.56916714     0.46516004      -1.189643\n-0.117406875    -1.1139084      1.115328        0.23275337\n1.452733        -0.30968842     -0.6693723      -0.22098665\n\n(1,2,.,.) =\n0.06541251      -0.7000564      -0.460471       -0.5291468\n-0.6625642      0.6460361       -0.556095       1.6327276\n1.1914377       -0.69054496     -0.7461783      -1.0129389\n\n(2,1,.,.) =\n-0.19123174     0.06803144      -0.010993495    -0.79966563\n-0.010654963    2.0806832       1.972848        -1.8525643\n-0.84387285     1.2974458       -0.42781293     0.3540522\n\n(2,2,.,.) =\n1.6231914       0.52689505      0.47506556      -1.030227\n0.5143046       -0.9930063      -2.2869735      0.03994834\n-1.5566326      -1.0937842      0.82693833      -0.08408405\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.11401264  0.0         1.1396459\n0.0         0.0         0.88493514\n\n(1,2,.,.) =\n0.0         8.398667    1.1495202\n0.0         0.0         0.1630742\n\n(1,3,.,.) =\n0.0         0.92470163  0.0\n0.0         0.6321572   0.0\n\n(1,4,.,.) =\n0.0         1.1912066   0.0\n0.0         1.27647     0.13422263\n\n(2,1,.,.) =\n0.0         0.0         0.51365596\n0.0         0.4207713   1.1226959\n\n(2,2,.,.) =\n0.0         0.67600054  0.63635653\n0.40892223  2.0596464   1.7690754\n\n(2,3,.,.) =\n1.1899394   0.0         0.0\n1.7185769   0.39178902  0.0\n\n(2,4,.,.) =\n0.44333076  0.73385376  0.0\n2.516453    0.36223468  0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x2x3]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import AtrousConvolution2D\n\nmodel = Sequential()\nmodel.add(AtrousConvolution2D(4, 2, 2, input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.52102612 0.30683086 0.38543426 0.0026452 ]\n   [0.66805249 0.60656045 0.94601998 0.46574414]\n   [0.49391338 0.14274225 0.70473703 0.30427041]]\n  [[0.89066007 0.51782675 0.7063052  0.53440807]\n   [0.67377917 0.51541465 0.02137767 0.63357007]\n   [0.6614106  0.15849977 0.94459604 0.46852022]]]\n\n [[[0.79639026 0.94468413 0.73165819 0.54531867]\n   [0.97741046 0.64477619 0.52373183 0.06861999]\n   [0.37278645 0.53198045 0.95098245 0.86249644]]\n  [[0.47186038 0.81694951 0.78009033 0.20925898]\n   [0.69942883 0.37150324 0.58907364 0.88754231]\n   [0.64083971 0.4480097  0.91716521 0.66808943]]]]  Output is  [[[[-0.32139003  -0.34667802 -0.35534883]\n   [-0.09653517  -0.35052428 -0.09859636]]\n  [[-0.3138999   -0.5563417  -0.6694119 ]\n   [-0.03151364  0.35521197  0.31497604]]\n  [[-0.34939283  -0.7537081  -0.3939833 ]\n   [-0.25708836  0.06015673  -0.16755156]]\n  [[-0.04791902  0.02060626  -0.5639752 ]\n   [ 0.16054101  0.22528952  -0.02460545]]]\n\n [[[-0.13129832  -0.5262137   -0.12281597]\n   [-0.36988598  -0.5532047   -0.43338764]]\n  [[-0.21627764  -0.17562683  0.23560521]\n   [ 0.23035726  -0.03152001  -0.46413773]]\n  [[-0.63740283  -0.33359224  0.15731882]\n   [-0.12795202  -0.25798583  -0.5261132 ]]\n  [[-0.01759483  -0.07666921  -0.00890112]\n   [ 0.27595833  -0.14117064  -0.3357542 ]]]]", 
            "title": "AtrousConvolution2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#deconvolution2d", 
            "text": "Transposed convolution operator for filtering windows of 2-D inputs.  The need for transposed convolutions generally arises from the desire to use a transformation going in the opposite direction of a normal convolution, i.e., from something that has\nthe shape of the output of some convolution to something that has the shape of its input while maintaining a connectivity pattern that is compatible with said convolution.  Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').  Border mode currently supported for this layer is 'valid'.  You can also use  Deconv2D  as an alias of this layer.  The input of this layer should be 4D.  Scala:  Deconvolution2D(nbFilter, nbRow, nbCol, init =  glorot_uniform , activation = null, subsample = (1, 1), dimOrdering =  th , wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)  Python:  Deconvolution2D(nb_filter, nb_row, nb_col, output_shape, init= glorot_uniform , activation=None, border_mode= valid , subsample=(1, 1), dim_ordering= th , W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)  Parameters:   nbFilter : Number of transposed convolution filters to use.  nbRow : Number of rows in the transposed convolution kernel.  nbCol : Number of columns in the transposed convolution kernel.  init : String representation of the initialization method for the weights of the layer. See  here  for available initialization strings. Default is 'glorot_uniform'.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is null.  subsample : Length 2 . The step of the convolution in the height and width dimension. Also called strides elsewhere. Default is (1, 1).  dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, Deconvolution2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Deconvolution2D(2, 2, 2, activation =  relu , inputShape = Shape(2, 2, 3)))\nval input = Tensor[Float](1, 2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-1.1157457  -0.8626509  -0.7326707\n1.8340882   -1.1647098  -1.0159439\n\n(1,2,.,.) =\n-0.13360074 0.4507607   -0.5922559\n0.15494606  0.16541296  1.6870573\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.0         0.0         0.0     0.020009547\n0.0         0.0         0.0     0.0\n0.9656998   0.0         0.0     0.5543601\n\n(1,2,.,.) =\n0.0         0.0         0.0     0.07773054\n1.4971795   0.029338006 0.0     0.0\n0.0         0.45826393  0.0     0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x3x4]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Deconvolution2D\n\nmodel = Sequential()\nmodel.add(Deconvolution2D(2, 2, 2, (2, 3, 4), input_shape=(2, 2, 3)))\ninput = np.random.random([1, 2, 2, 3])\noutput = model.forward(input)  Input is:  [[[[0.65315139 0.21904901 0.57943617]\n   [0.35141043 0.14628658 0.81862311]]\n\n  [[0.60094717 0.84649884 0.08338504]\n   [0.26753695 0.83676038 0.87466877]]]]  Output is  [[[[-0.35380065  0.22048733  0.3084591   0.23341973]\n   [-0.11611718  0.5349988  -0.26301163  1.0291481 ]\n   [ 0.00479569  0.48814884  0.00127316  0.2546792 ]]\n\n  [[-0.02683929 -0.21759698 -0.8542665  -0.25376737]\n   [ 0.04426606  0.05486238 -0.9282576  -1.1576774 ]\n   [ 0.01637976  0.1838439  -0.01419228 -0.60704494]]]]", 
            "title": "Deconvolution2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#separableconvolution2d", 
            "text": "Applies separable convolution operator for 2D inputs.  Separable convolutions consist in first performing a depthwise spatial convolution (which acts on each input channel separately) followed by a pointwise convolution which mixes together the resulting output channels. The depthMultiplier argument controls how many output channels are generated per input channel in the depthwise step.  You can also use  SeparableConv2D  as an alias of this layer.  The input of this layer should be 4D.  Scala:  SeparableConvolution2D(nbFilter, nbRow, nbCol, init =  glorot_uniform , activation = null, borderMode =  valid , subsample = (1, 1), depthMultiplier = 1, dimOrdering =  th , depthwiseRegularizer = null, pointwiseRegularizer= null, bRegularizer = null, bias = true, inputShape = null)  Python:  SeparableConvolution2D(nb_filter, nb_row, nb_col, init= glorot_uniform , activation=None, border_mode= valid , subsample=(1, 1), depth_multiplier=1, dim_ordering= th , depthwise_regularizer=None, pointwise_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)  Parameters:   nbFilter : Number of convolution filters to use.  nbRow : Number of rows in the convolution kernel.  nbCol : Number of columns in the convolution kernel.  init : String representation of the initialization method for the weights of the layer. See  here  for available initialization strings. Default is 'glorot_uniform'.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is null.  borderMode : Either 'valid' or 'same'. Default is 'valid'.  subsample : Length 2 corresponding to the step of the convolution in the height and width dimension. Also called strides elsewhere. Default is (1, 1).  depthMultiplier : How many output channel to use per input channel for the depthwise convolution step. Integer. Default is 1.  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  depthwiseRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the depthwise weights matrices. Default is null.  pointwiseRegularizer : An instance of  Regularizer , applied to the pointwise weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, SeparableConvolution2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SeparableConvolution2D(2, 2, 2, activation =  relu , inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.61846036  0.13724488     1.9047198    0.8788536\n0.74383116  -0.7590018     0.17210509   1.8095028\n-0.21476124 -0.010768774   0.5437478    0.97470677\n\n(1,2,.,.) =\n-0.22464052 -1.7141389     1.8457758    0.81563693\n-0.17250067 -1.2183974     -2.5329974   -1.3014348\n0.43760046  0.32672745     -0.6059157   0.31439257\n\n(2,1,.,.) =\n-0.32413644 -0.1871411     -0.13821407  -0.16577224\n-0.02138366 1.2260025      -0.48404458  -1.0251912\n-1.8844653  0.6796752      -0.5881143   2.1656246\n\n(2,2,.,.) =\n0.17234507  -0.6455974     1.9615031    0.6552883\n-0.05861185 1.8847446      -0.857622    -0.5949971\n-0.41135395 -0.92089206    0.13154007   -0.9326055\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.0         0.0         0.0\n0.029595211 0.0         0.34002993\n\n(1,2,.,.) =\n0.0         0.0         0.0\n0.073145226 0.0         0.5542682\n\n(2,1,.,.) =\n0.4973382   0.36478913  0.0\n0.0         0.0         0.0\n\n(2,2,.,.) =\n0.9668598   0.7102739   0.0\n0.0         0.0         0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import SeparableConvolution2D\n\nmodel = Sequential()\nmodel.add(SeparableConvolution2D(2, 2, 2, input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.39277921 0.36904141 0.16768533 0.41712068]\n   [0.62416696 0.19334139 0.83341541 0.16486488]\n   [0.57287259 0.47809379 0.11103843 0.01746644]]\n  [[0.24945342 0.05728102 0.19076369 0.70498077]\n   [0.39147172 0.08100018 0.74426575 0.74251056]\n   [0.61840056 0.00771785 0.65170218 0.04492181]]]\n\n [[[0.08337509 0.19320791 0.66757918 0.38905916]\n   [0.50237454 0.0996316  0.3981495  0.32274897]\n   [0.01598124 0.52896577 0.76068351 0.10099803]]\n  [[0.20396797 0.48682425 0.11302674 0.57491998]\n   [0.71529612 0.11720466 0.57783092 0.45790133]\n   [0.41573101 0.60269287 0.613528   0.32717263]]]]  Output is  [[[[0.15971108 0.12109925 0.17461367]\n   [0.20024002 0.13661252 0.1871847 ]]\n  [[0.47139192 0.36838844 0.45902973]\n   [0.57752806 0.41371965 0.5079273 ]]]\n\n [[[0.11111417 0.10702941 0.2030398 ]\n   [0.13108528 0.15029006 0.18544158]]\n  [[0.27002305 0.31479427 0.57750916]\n   [0.3573216  0.40100253 0.5122235 ]]]]", 
            "title": "SeparableConvolution2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#locallyconnected1d", 
            "text": "Locally-connected layer for 1D inputs which works similarly to the TemporalConvolution layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.  Border mode currently supported for this layer is 'valid'.  The input of this layer should be 3D.  Scala:  LocallyConnected1D(nbFilter, filterLength, activation = null, subsampleLength = 1, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)  Python:  LocallyConnected1D(nb_filter, filter_length, activation=None, border_mode= valid , subsample_length=1, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)  Parameters:   nbFilter : Dimensionality of the output.  filterLength : The extension (spatial or temporal) of each filter.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is null.  subsampleLength : Integer. Factor by which to subsample output.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, LocallyConnected1D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(LocallyConnected1D(6, 3, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.6755046   0.47923228  -0.41470557 -1.4644535\n-1.580751   -0.36924785 -1.1507624  0.20131736\n-0.4983051  -2.0898817  0.1623063   0.8118141\n\n(2,.,.) =\n1.5955191   -1.1017833  1.6614468   1.7959124\n1.1084127   0.528379    -1.114553   -1.030853\n0.37758648  -2.5828059  1.0172523   -1.6773314\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.20011228 0.7842446   -0.57892114 0.2405633   -0.35126245 -0.5116563\n\n(2,.,.) =\n-0.33687726 0.7863857   0.30202985  0.33251244  -0.7414977  0.14271683\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x6]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import LocallyConnected1D\n\nmodel = Sequential()\nmodel.add(LocallyConnected1D(6, 3, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  [[[0.67992353 0.88287213 0.98861104 0.17401607]\n  [0.23660068 0.02779148 0.52982599 0.19876749]\n  [0.38880073 0.6498778  0.81532701 0.91719509]]\n\n [[0.30532677 0.1574227  0.40535271 0.03174637]\n  [0.37303714 0.27821415 0.02314422 0.64516966]\n  [0.74813923 0.9884225  0.40667151 0.21894944]]]  Output is  [[[ 0.66351205 -0.03819168 -0.48071918 -0.05209085 -0.07307816  0.94942856]]\n\n [[ 0.5890693   0.0179258  -0.31232932  0.4427027  -0.30954808  0.4486028 ]]]", 
            "title": "LocallyConnected1D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#locallyconnected2d", 
            "text": "Locally-connected layer for 2D inputs that works similarly to the SpatialConvolution layer, except that weights are unshared, that is, a different set of filters is applied at each different patch of the input.  The input of this layer should be 4D.  Scala:  LocallyConnected2D(nbFilter, nbRow, nbCol, activation = null, borderMode =  valid , subsample = (1, 1), dimOrdering =  th , wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)  Python:  LocallyConnected2D(nb_filter, nb_row, nb_col, activation=None, border_mode= valid , subsample=(1, 1), dim_ordering= th , W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)  Parameters:   nbFilter : Number of convolution filters to use.  nbRow : Number of rows in the convolution kernel.  nbCol : Number of columns in the convolution kernel.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is null.  borderMode : Either 'valid' or 'same'. Default is 'valid'.  subsample : Length 2 corresponding to the step of the convolution in the height and width dimension. Also called strides elsewhere. Default is (1, 1).  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, LocallyConnected2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(LocallyConnected2D(2, 2, 2, inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n1.3119988       -1.8982307      -0.13138956     1.0872058\n-0.11329581     -0.7087005      0.085274234     -0.94051\n1.04928         2.1579344       -1.4412278      -0.90965116\n\n(1,2,.,.) =\n-0.6119555      1.2226686       -0.10441754     -1.6240023\n0.5598073       -0.099059306    -1.543586       0.72533834\n-1.6674699      -1.0901593      -0.24129404     0.30954796\n\n(2,1,.,.) =\n-0.78856885     -0.5567014      -1.1273636      -0.98069143\n-0.40949664     0.92562497      -1.3729718      0.7423901\n-0.29498738     -0.044669412    1.0937366       0.90768206\n\n(2,2,.,.) =\n1.0948726       -0.23575573     -0.051821854    -0.58692485\n1.9133459       -1.0849183      2.1423934       0.6559134\n-0.8390565      -0.27111387     -0.8439365      -1.3939567\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n-0.42428172 0.25790718  -0.5227444\n0.6963143   -0.34605533 -0.35524538\n\n(1,2,.,.) =\n0.61758286  0.8430548   0.1378907\n0.24116383  0.15782532  0.16882366\n\n(2,1,.,.) =\n-0.5603108  0.5107949   -0.112701565\n0.62288725  0.6909297   -0.9253155\n\n(2,2,.,.) =\n-0.2443612  0.9310517   -0.2417406\n-0.82973266 -1.0886648  0.19112866\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import LocallyConnected2D\n\nmodel = Sequential()\nmodel.add(LocallyConnected2D(2, 2, 2, input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.57424593 0.49505236 0.63711108 0.43693806]\n   [0.34655799 0.0058394  0.69310344 0.70403367]\n   [0.4620432  0.58679338 0.64529398 0.78130808]]\n  [[0.49651564 0.32201482 0.02470762 0.80535793]\n   [0.94485185 0.07150504 0.58789497 0.4562848 ]\n   [0.63595033 0.04600271 0.89771801 0.95419454]]]\n\n [[[0.69641827 0.21785002 0.15815588 0.8317213 ]\n   [0.84192366 0.3939658  0.64309395 0.3858968 ]\n   [0.16545408 0.58533897 0.99486481 0.84651898]]\n  [[0.05144159 0.94930242 0.26842063 0.6341632 ]\n   [0.442836   0.38544902 0.04266468 0.22600452]\n   [0.2705393  0.07313841 0.24295287 0.9573069 ]]]]  Output is  [[[[ 0.1600316   0.178018   -0.07472821]\n   [ 0.0570091  -0.19973318  0.44483435]]\n  [[-0.20258084 -0.37692443 -0.27103102]\n   [-0.624092   -0.09749079 -0.00799894]]]\n\n [[[ 0.58953685  0.35287908 -0.2203412 ]\n   [ 0.13649486 -0.29554832  0.16932982]]\n  [[-0.00787066 -0.06614903 -0.2027885 ]\n   [-0.33434835 -0.33458236 -0.15103136]]]]", 
            "title": "LocallyConnected2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#cropping1d", 
            "text": "Cropping layer for 1D input (e.g. temporal sequence).  The input of this layer should be 3D.  Scala:  Cropping1D(cropping = (1, 1), inputShape = null)  Python:  Cropping1D(cropping=(1, 1), input_shape=None, name=None)  Parameters:   cropping : Length 2. How many units should be trimmed off at the beginning and end of the cropping dimension. Default is (1, 1).  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, Cropping1D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Cropping1D((1, 1), inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-1.0038188  -0.75265634 0.7417358   1.0674809\n-1.4702164  0.64112693  0.17750219  -0.21439286\n-0.93766433 -1.0809567  0.7706962   0.16380796\n\n(2,.,.) =\n0.45019576  -0.36689326 0.08852628  -0.21602148\n0.66039973  0.11638404  0.062985964 -1.0420738\n0.46727908  -0.85894865 1.9853845   0.059447426\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-1.4702164  0.64112693  0.17750219  -0.21439286\n\n(2,.,.) =\n0.66039973  0.11638404  0.062985964 -1.0420738\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x1x4]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Cropping1D\n\nmodel = Sequential()\nmodel.add(Cropping1D(input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  [[[0.01030651 0.77603525 0.97263208 0.15933375]\n  [0.05135971 0.01139832 0.28809891 0.57260363]\n  [0.28128354 0.55290954 0.77011153 0.09879061]]\n\n [[0.75765909 0.55102462 0.42426818 0.14383546]\n  [0.85198966 0.3990277  0.13061313 0.10349525]\n  [0.69892804 0.30310119 0.2241441  0.05978997]]]  Output is  [[[0.05135971 0.01139832 0.2880989  0.57260364]]\n\n [[0.8519896  0.3990277  0.13061313 0.10349525]]]", 
            "title": "Cropping1D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#cropping2d", 
            "text": "Cropping layer for 2D input (e.g. picture).  The input of this layer should be 4D.  Scala:  Cropping2D(cropping = ((0, 0), (0, 0)), dimOrdering =  th , inputShape = null)  Python:  Cropping2D(cropping=((0, 0), (0, 0)), dim_ordering= th , input_shape=None, name=None)  Parameters:   cropping : Int tuple of tuple of length 2. How many units should be trimmed off at the beginning and end of the 2 cropping dimensions (i.e. height and width). Default is ((0, 0), (0, 0)).  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, Cropping2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Cropping2D(((0, 1), (1, 0)), inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-1.3613406  -0.03520738  -0.008660733  2.1150143\n0.18087284  1.8787018    0.30097032   -2.5634677\n-1.9463011  -0.18772388  1.5215846    -0.8047026\n\n(1,2,.,.) =\n-0.50510925 -1.1193116   0.6901347   -0.2625669\n-0.24307655 -0.77917117  -0.566465   1.0432123\n0.4877474   0.49704018   -1.5550427  1.5772455\n\n(2,1,.,.) =\n-1.6180872  0.011832007  1.2762135   0.5600022\n1.9009352   -0.11096256  1.1500957   -0.26341736\n1.0153246   0.88008636   0.0560876   -1.0235065\n\n(2,2,.,.) =\n0.1036221   1.08527      -0.52559805   -0.5091204\n1.3085281   -0.96346164  -0.09713245   -1.1010116\n0.08505145  1.9413263    2.0237558     -0.5978173\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n-0.03520738 -0.008660733  2.1150143\n1.8787018   0.30097032    -2.5634677\n\n(1,2,.,.) =\n-1.1193116   0.6901347  -0.2625669\n-0.77917117  -0.566465  1.0432123\n\n(2,1,.,.) =\n0.011832007  1.2762135  0.5600022\n-0.11096256  1.1500957  -0.26341736\n\n(2,2,.,.) =\n1.08527      -0.52559805   -0.5091204\n-0.96346164  -0.09713245   -1.1010116\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Cropping2D\n\nmodel = Sequential()\nmodel.add(Cropping2D(((0, 1), (1, 0)), input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.03691489 0.60233732 0.96327319 0.99561146]\n   [0.85728883 0.77923287 0.41328434 0.87490199]\n   [0.3389653  0.94804499 0.72922732 0.21191413]]\n  [[0.28962322 0.30133445 0.58516862 0.22476588]\n   [0.95386045 0.72488497 0.12056255 0.01265548]\n   [0.48645173 0.34426033 0.09410422 0.86815053]]]\n\n [[[0.57444115 0.79141167 0.20755353 0.38616465]\n   [0.95793123 0.22366943 0.5080078  0.27193368]\n   [0.65402317 0.1023231  0.67207896 0.2229965 ]]\n  [[0.04160647 0.55577895 0.30907277 0.42227706]\n   [0.54489229 0.90423796 0.50782414 0.51441165]\n   [0.87544565 0.47791071 0.0341273  0.14728084]]]]  Output is  [[[[0.6023373  0.96327317 0.9956115 ]\n   [0.77923286 0.41328433 0.874902  ]]\n  [[0.30133444 0.5851686  0.22476588]\n   [0.724885   0.12056255 0.01265548]]]\n\n [[[0.7914117  0.20755354 0.38616467]\n   [0.22366942 0.5080078  0.27193367]]\n\n  [[0.555779   0.30907276 0.42227706]\n   [0.904238   0.5078241  0.5144116 ]]]]", 
            "title": "Cropping2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#cropping3d", 
            "text": "Cropping layer for 3D data (e.g. spatial or spatio-temporal).  The input of this layer should be 5D.  Scala:  Cropping3D(cropping = ((1, 1), (1, 1), (1, 1)), dimOrdering =  th , inputShape = null)  Python:  Cropping3D(cropping=((1, 1), (1, 1), (1, 1)), dim_ordering= th , input_shape=None, name=None)  Parameters:   cropping : Int tuple of tuple of length 3. How many units should be trimmed off at the beginning and end of the 3 cropping dimensions (i.e. kernel_dim1, kernel_dim2 and kernel_dim3). Default is ((1, 1), (1, 1), (1, 1)).  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, Cropping3D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Cropping3D(((1, 1), (1, 1), (1, 1)), inputShape = Shape(2, 3, 4, 5)))\nval input = Tensor[Float](2, 2, 3, 4, 5).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n-0.12339484     0.25661087      0.04387503      -1.1047344      -1.1413815\n1.1830065       -0.07189157     -0.5418846      0.5576781       -0.5460917\n-0.5679186      -0.30854696     1.2614665       -0.6774269      -0.63295823\n0.5269464       -2.7981617      -0.056265026    -1.0814936      -1.0848739\n\n(1,1,2,.,.) =\n-1.9100302      0.461067        0.4014941       0.60723174      -0.40414023\n0.34300476      0.7107094       1.3142885       1.5696589       0.97591686\n0.38320687      0.07036536      -0.43628898     0.58050656      -0.57882625\n-0.43699506     -0.0094956765   0.15171598      0.038076796     -1.2433665\n\n(1,1,3,.,.) =\n0.39671394      0.880047        0.30971292      -0.3369089      0.13062176\n-0.27803114     -0.62177086     0.16659822      0.89428085      0.23684736\n1.6151237       -1.1479733      -0.2229254      1.1361892       0.79478127\n-1.8207864      1.6544164       0.07977915      -1.1316417      -0.25483203\n\n(1,2,1,.,.) =\n1.3165517       -0.9479057      -1.4662051      -0.3343554      -0.4522552\n-1.5829691      0.6378519       -0.16399206     1.4724066       1.2387054\n-1.1467208      -0.6325814      -1.2106491      -0.035734158    0.19871919\n2.285004        1.0482147       -2.0056705      -0.80917794     2.523167\n\n(1,2,2,.,.) =\n-0.57108706     -0.23606259     -0.45569882     -0.034214735    -1.9130942\n-0.2743481      1.61177         -0.7052599      0.17889105      -0.31241596\n0.22377247      1.5860337       -0.3226252      -0.1341058      0.9239994\n0.03615294      0.6233593       0.757827        -0.72271305     0.9429943\n\n(1,2,3,.,.) =\n-0.4409662      0.8867786       2.0036085       0.16242673      -0.3332395\n0.09082064      0.04958198      -0.27834833     1.8025815       -0.04848101\n0.2690667       -1.1263227      -0.95486647     0.09473259      0.98166656\n-0.9509363      -0.10084029     -0.35410827     0.29626986      0.97203517\n\n(2,1,1,.,.) =\n0.42096403      0.14016314      0.20216857      -0.678293       -1.0970931\n-0.4981112      0.12429344      1.7156922       -0.24384527     -0.010780937\n0.03672217      2.3021698       1.568247        -0.43173146     -0.5550057\n0.30469602      1.4772439       -0.21195345     0.04221814      -1.6883365\n\n(2,1,2,.,.) =\n0.22468264      0.72787744      -0.9597003      -0.28472963     -1.4575284\n1.0487963       0.4982454       -1.0186157      -1.9877508      -1.133779\n0.17539643      -0.35151628     -1.8955303      2.1854792       0.59556997\n0.6893949       -0.19556235     0.25862908      0.24450152      0.17786922\n\n(2,1,3,.,.) =\n1.147159        -0.8849993      0.9826487       0.95360875      -0.9210176\n1.3439047       0.6739913       0.06558858      0.91963255      -1.1758618\n1.747105        -0.7225308      -1.0160877      0.67554474      -0.7762811\n0.21184689      -0.43668815     -1.0738864      0.04661594      0.9613895\n\n(2,2,1,.,.) =\n-0.377159       -0.28094378     0.1081715       1.3683178       1.2572801\n0.47781375      0.4545212       0.55356956      1.0366637       -0.1962683\n-1.820227       -0.111765414    1.9194998       -1.6089902      -1.6960226\n0.14896627      0.9360371       0.49156702      0.08601956      -0.08815153\n\n(2,2,2,.,.) =\n0.056315728     -0.13061485     -0.49018836     -0.59103477     -1.6910721\n-0.023719765    -0.44977355     0.11218439      0.224829        1.400084\n0.31496882      -1.6386473      -0.6715097      0.14816228      0.3240011\n-0.80607724     -0.37951842     -0.2187672      1.1087769       0.43044603\n\n(2,2,3,.,.) =\n-1.6647842      -0.5720825      -1.5150099      0.42346838      1.495052\n-0.3567161      -1.4341534      -0.19422509     -1.2871891      -1.2758921\n-0.47077888     -0.42217267     0.67764246      1.2170314       0.8420698\n-0.4263702      1.2792329       0.38645822      -2.4653213      -1.512707\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4x5]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.7107094   1.3142885   1.5696589\n0.07036536  -0.43628898 0.58050656\n\n(1,2,1,.,.) =\n1.61177     -0.7052599  0.17889105\n1.5860337   -0.3226252  -0.1341058\n\n(2,1,1,.,.) =\n0.4982454   -1.0186157  -1.9877508\n-0.35151628 -1.8955303  2.1854792\n\n(2,2,1,.,.) =\n-0.44977355 0.11218439  0.224829\n-1.6386473  -0.6715097  0.14816228\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x2x3]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Cropping3D\n\nmodel = Sequential()\nmodel.add(Cropping3D(((1, 1), (1, 1), (1, 1)), input_shape=(2, 3, 4, 5)))\ninput = np.random.random([2, 2, 3, 4, 5])\noutput = model.forward(input)  Input is:  [[[[[0.17398425 0.68189365 0.77769123 0.53108205 0.64715435]\n    [0.14553671 0.56312657 0.68612354 0.69176945 0.30109699]\n    [0.09732807 0.37460879 0.19945361 0.86471357 0.66225896]\n    [0.23071766 0.7940814  0.20828491 0.05256511 0.39059369]]\n   [[0.61604377 0.08752888 0.0373393  0.2074062  0.60620641]\n    [0.72873275 0.86871873 0.89248703 0.9407502  0.71830713]\n    [0.23277175 0.75968678 0.2160847  0.76278034 0.27796526]\n    [0.45593022 0.31406512 0.83030059 0.17528758 0.56134316]]\n   [[0.65576189 0.41055457 0.90979203 0.76003643 0.26369912]\n    [0.20767533 0.60489496 0.44996379 0.20016757 0.39282226]\n    [0.14055952 0.15767185 0.70149107 0.88403803 0.77345544]\n    [0.34344548 0.03721154 0.86204782 0.45349481 0.69348787]]]\n  [[[0.55441874 0.59949813 0.4450893  0.2103161  0.6300366 ]\n    [0.71573331 0.32423206 0.06302588 0.91902299 0.30852669]\n    [0.73540519 0.20697542 0.20543135 0.44461869 0.89286638]\n    [0.41614996 0.48155318 0.51663767 0.23681825 0.34780746]]\n   [[0.34529962 0.81156897 0.77911935 0.65392321 0.45178564]\n    [0.39702465 0.36180668 0.37867952 0.24818676 0.84365902]\n    [0.67836434 0.24043224 0.59870659 0.81976809 0.95442206]\n    [0.15342281 0.48607751 0.11420129 0.68621285 0.09892679]]\n   [[0.61122758 0.40359022 0.99805441 0.76764677 0.6281926 ]\n    [0.44867213 0.81206033 0.40117858 0.98967612 0.76897064]\n    [0.90603977 0.17299288 0.68803644 0.75164168 0.4161878 ]\n    [0.18996933 0.93317759 0.77711184 0.50760022 0.77439241]]]]\n\n [[[[0.49974828 0.74486599 0.12447392 0.15415173 0.36715309]\n    [0.49334423 0.66699219 0.22202136 0.52689596 0.15497081]\n    [0.4117844  0.21886979 0.13096058 0.82589121 0.00621519]\n    [0.38257617 0.60924058 0.53549974 0.64299846 0.66315369]]\n   [[0.78048895 0.20350694 0.16485496 0.71243727 0.4581091 ]\n    [0.554526   0.66891789 0.90082079 0.76729771 0.40647459]\n    [0.72809646 0.68164733 0.83008334 0.90941546 0.1441997 ]\n    [0.44580521 0.78015871 0.63982938 0.26813225 0.15588673]]\n   [[0.85294056 0.0928758  0.37056251 0.82930655 0.27178195]\n    [0.95953427 0.60170629 0.69156911 0.27902576 0.55613879]\n    [0.97101437 0.49876892 0.36313494 0.11233855 0.24221145]\n    [0.28739626 0.2990425  0.68940864 0.95621615 0.6922569 ]]]\n  [[[0.90283303 0.51320503 0.78356741 0.79301195 0.17681709]\n    [0.61624755 0.95418399 0.68118889 0.69241549 0.17943311]\n    [0.71129437 0.55478761 0.34121912 0.86018439 0.03652437]\n    [0.39098173 0.87916544 0.39647239 0.00104663 0.01377085]]\n   [[0.28875017 0.03733266 0.47260498 0.2896268  0.55976704]\n    [0.08723092 0.45523634 0.98463086 0.56950302 0.98261442]\n    [0.20716971 0.52744283 0.39455719 0.57384754 0.76698272]\n    [0.3079253  0.88143353 0.85897125 0.0969679  0.43760548]]\n   [[0.44239165 0.56141652 0.30344311 0.05425044 0.34003295]\n    [0.31417344 0.39485584 0.47300811 0.38006721 0.23185974]\n    [0.06158527 0.95330693 0.63043506 0.9480669  0.93758737]\n    [0.05340179 0.2064604  0.97254971 0.60841205 0.89738937]]]]]  Output is  [[[[[0.86871874 0.89248705 0.9407502 ]\n    [0.75968677 0.2160847  0.7627803 ]]]\n  [[[0.3618067  0.3786795  0.24818675]\n    [0.24043223 0.5987066  0.8197681 ]]]]\n\n [[[[0.6689179  0.9008208  0.7672977 ]\n    [0.68164736 0.8300834  0.9094155 ]]]\n  [[[0.45523635 0.9846309  0.569503  ]\n    [0.5274428  0.39455718 0.57384753]]]]]", 
            "title": "Cropping3D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#zeropadding1d", 
            "text": "Zero-padding layer for 1D input (e.g. temporal sequence).  The input of this layer should be 3D.  Scala:  ZeroPadding1D(padding = 1, inputShape = null)  Python:  ZeroPadding1D(padding=1, input_shape=None, name=None)  Parameters:   padding : How many zeros to add at the beginning and at the end of the padding dimension.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, ZeroPadding1D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ZeroPadding1D(1, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.7421485   -0.13270181 -0.12605186 -0.7442475\n0.36977226  -0.90300065 -0.34193754 -0.035565257\n-0.23300397 0.8183156   0.7023575   -0.16938858\n\n(2,.,.) =\n-0.7785278  0.36642975  -1.0542017  -0.29036212\n-0.22632122 0.46808097  -0.68293047 1.2529073\n-0.8619831  1.3846883   1.0762612   1.1351995\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.0         0.0         0.0         0.0\n0.7421485   -0.13270181 -0.12605186 -0.7442475\n0.36977226  -0.90300065 -0.34193754 -0.035565257\n-0.23300397 0.8183156   0.7023575   -0.16938858\n0.0         0.0         0.0         0.0\n\n(2,.,.) =\n0.0         0.0         0.0         0.0\n-0.7785278  0.36642975  -1.0542017  -0.29036212\n-0.22632122 0.46808097  -0.68293047 1.2529073\n-0.8619831  1.3846883   1.0762612   1.1351995\n0.0         0.0         0.0         0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x5x4]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import ZeroPadding1D\n\nmodel = Sequential()\nmodel.add(ZeroPadding1D(1, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  [[[0.74177145 0.75805981 0.2091588  0.46929227]\n  [0.46041743 0.13213793 0.51065024 0.36081853]\n  [0.60803218 0.27764702 0.31788482 0.65445294]]\n\n [[0.96255443 0.74692762 0.50050961 0.88456158]\n  [0.55492653 0.50850271 0.17788885 0.91569285]\n  [0.27356035 0.74622588 0.39690752 0.75229177]]]  Output is  [[[0.0        0.0        0.0        0.0       ]\n  [0.74177146 0.7580598  0.2091588  0.46929225]\n  [0.46041742 0.13213794 0.5106502  0.36081854]\n  [0.60803217 0.27764702 0.31788483 0.6544529 ]\n  [0.0        0.0        0.0        0.0       ]]\n\n [[0.0        0.0        0.0        0.0       ]\n  [0.96255445 0.7469276  0.5005096  0.8845616 ]\n  [0.5549265  0.5085027  0.17788884 0.91569287]\n  [0.27356035 0.7462259  0.39690754 0.75229174]\n  [0.0        0.0        0.0        0.0       ]]]", 
            "title": "ZeroPadding1D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#zeropadding2d", 
            "text": "Zero-padding layer for 2D input (e.g. picture).  The input of this layer should be 4D.  Scala:  ZeroPadding2D(padding = (1, 1), dimOrdering =  th , inputShape = null)  Python:  ZeroPadding2D(padding=(1, 1), dim_ordering= th , input_shape=None, name=None)  Parameters:   padding : How many zeros to add at the beginning and at the end of the 2 padding dimensions (rows and cols).  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, ZeroPadding2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ZeroPadding2D((1, 1), inputShape = Shape(2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n1.7201442   -1.0197405  1.3163399\n-0.23921064 0.7732504   -0.069928266\n\n(1,2,.,.) =\n0.46323594  -1.3043984  -0.67622787\n-1.610615   -0.39253974 -0.89652705\n\n(2,1,.,.) =\n-0.3784847  -0.6738694  0.30479854\n-0.49577644 1.0704983   0.6288544\n\n(2,2,.,.) =\n0.2821439   0.790223    0.34665197\n0.24190207  0.10775433  0.46225727\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.0     0.0         0.0         0.0             0.0\n0.0     1.7201442   -1.0197405  1.3163399       0.0\n0.0     -0.23921064 0.7732504   -0.069928266    0.0\n0.0     0.0         0.0         0.0             0.0\n\n(1,2,.,.) =\n0.0     0.0         0.0         0.0             0.0\n0.0     0.46323594  -1.3043984  -0.67622787     0.0\n0.0     -1.610615   -0.39253974 -0.89652705     0.0\n0.0     0.0         0.0         0.0             0.0\n\n(2,1,.,.) =\n0.0     0.0         0.0         0.0             0.0\n0.0     -0.3784847  -0.6738694  0.30479854      0.0\n0.0     -0.49577644 1.0704983   0.6288544       0.0\n0.0     0.0         0.0         0.0             0.0\n\n(2,2,.,.) =\n0.0     0.0         0.0         0.0             0.0\n0.0     0.2821439   0.790223    0.34665197      0.0\n0.0     0.24190207  0.10775433  0.46225727      0.0\n0.0     0.0         0.0         0.0             0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x4x5]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import ZeroPadding2D\n\nmodel = Sequential()\nmodel.add(ZeroPadding2D(input_shape=(2, 2, 3)))\ninput = np.random.random([2, 2, 2, 3])\noutput = model.forward(input)  Input is:  [[[[0.44048214 0.72494886 0.96654241]\n   [0.66254801 0.37409083 0.47681466]]\n\n  [[0.23204026 0.52762765 0.15072852]\n   [0.45052127 0.29016392 0.0133929 ]]]\n\n\n [[[0.09347565 0.4754528  0.63618458]\n   [0.08016674 0.21696158 0.83892852]]\n\n  [[0.81864575 0.90813398 0.08347963]\n   [0.57234761 0.76060611 0.65707858]]]]  Output is  [[[[0.0   0.0        0.0        0.0        0.0 ]\n   [0.0   0.44048214 0.7249489  0.9665424  0.0 ]\n   [0.0   0.662548   0.37409082 0.47681466 0.0 ]\n   [0.0   0.0        0.0        0.0        0.0 ]]\n\n  [[0.0   0.0        0.0        0.0        0.0 ]\n   [0.0   0.23204026 0.52762765 0.15072852 0.0 ]\n   [0.0   0.45052126 0.29016393 0.0133929  0.0 ]\n   [0.0   0.0        0.0        0.0        0.0 ]]]\n\n\n [[[0.0   0.0        0.0        0.0        0.0 ]\n   [0.0   0.09347565 0.4754528  0.6361846  0.0 ]\n   [0.0   0.08016673 0.21696158 0.8389285  0.0 ]\n   [0.0   0.0        0.0        0.0        0.0 ]]\n\n  [[0.0   0.0        0.0        0.0        0.0 ]\n   [0.0   0.8186458  0.908134   0.08347963 0.0 ]\n   [0.0   0.5723476  0.7606061  0.65707856 0.0 ]\n   [0.0   0.0        0.0        0.0        0.0 ]]]]", 
            "title": "ZeroPadding2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#zeropadding3d", 
            "text": "Zero-padding layer for 3D data (spatial or spatio-temporal).  The input of this layer should be 5D.  Scala:  ZeroPadding3D(padding = (1, 1, 1), dimOrdering =  th , inputShape = null)  Python:  ZeroPadding3D(padding=(1, 1, 1), dim_ordering= th , input_shape=None, name=None)  Parameters:   padding : How many zeros to add at the beginning and end of the 3 padding dimensions. Symmetric padding will be applied to each dimension.  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, ZeroPadding3D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ZeroPadding3D((1, 1, 1), inputShape = Shape(1, 2, 2, 2)))\nval input = Tensor[Float](1, 1, 2, 2, 2).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n1.086798    2.162806\n-0.50501716 -0.17430544\n\n(1,1,2,.,.) =\n-1.7388326  0.27966997\n1.6211525   1.1713351\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x2x2]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.0     0.0         0.0         0.0\n0.0     0.0         0.0         0.0\n0.0     0.0         0.0         0.0\n0.0     0.0         0.0         0.0\n\n(1,1,2,.,.) =\n0.0     0.0         0.0         0.0\n0.0     1.086798    2.162806    0.0\n0.0     -0.50501716 -0.17430544 0.0\n0.0     0.0         0.0         0.0\n\n(1,1,3,.,.) =\n0.0     0.0         0.0         0.0\n0.0     -1.7388326  0.27966997  0.0\n0.0     1.6211525   1.1713351   0.0\n0.0     0.0         0.0         0.0\n\n(1,1,4,.,.) =\n0.0     0.0         0.0         0.0\n0.0     0.0         0.0         0.0\n0.0     0.0         0.0         0.0\n0.0     0.0         0.0         0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x4x4x4]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import ZeroPadding3D\n\nmodel = Sequential()\nmodel.add(ZeroPadding3D((1, 1, 1), input_shape=(1, 2, 2, 2)))\ninput = np.random.random([1, 1, 2, 2, 2])\noutput = model.forward(input)  Input is:  [[[[[0.12432462 0.19244616]\n    [0.39039533 0.88140855]]\n\n   [[0.71426182 0.86085132]\n    [0.04443494 0.679125  ]]]]]  Output is  [[[[[0.0   0.0        0.0        0.0 ]\n    [0.0   0.0        0.0        0.0 ]\n    [0.0   0.0        0.0        0.0 ]\n    [0.0   0.0        0.0        0.0 ]]\n   [[0.0   0.0        0.0        0.0 ]\n    [0.0   0.12432462 0.19244616 0.0 ]\n    [0.0   0.39039534 0.8814086  0.0 ]\n    [0.0   0.0        0.0        0.0 ]]\n   [[0.0   0.0        0.0        0.0 ]\n    [0.0   0.71426183 0.8608513  0.0 ]\n    [0.0   0.04443494 0.679125   0.0 ]\n    [0.0   0.0        0.0        0.0 ]]\n   [[0.0   0.0        0.0        0.0 ]\n    [0.0   0.0        0.0        0.0 ]\n    [0.0   0.0        0.0        0.0 ]\n    [0.0   0.0        0.0        0.0 ]]]]]", 
            "title": "ZeroPadding3D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#upsampling1d", 
            "text": "UpSampling layer for 1D inputs.  Repeats each temporal step 'length' times along the time axis.  The input of this layer should be 3D.  Scala:  UpSampling1D(length = 2, inputShape = null)  Python:  UpSampling1D(length=2, input_shape=None, name=None)  Parameters:   length : Integer. UpSampling factor. Default is 2.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, UpSampling1D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(UpSampling1D(2, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.80225134  -0.9644977   -0.71038723    -1.5673652\n0.67224514  -0.24330814  -0.082499735   0.2807591\n-0.9299857  -1.8893008   -1.1062661     -1.1637908\n\n(2,.,.) =\n-0.1831344  -0.6621819   -0.667329      -0.26960346\n-0.6601015  1.0819869    1.0307902      1.1801233\n-0.18303517 0.2565441    -0.39598823    0.23400643\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.80225134  -0.9644977   -0.71038723     -1.5673652\n0.80225134  -0.9644977   -0.71038723     -1.5673652\n0.67224514  -0.24330814  -0.082499735    0.2807591\n0.67224514  -0.24330814  -0.082499735    0.2807591\n-0.9299857  -1.8893008   -1.1062661     -1.1637908\n-0.9299857  -1.8893008   -1.1062661     -1.1637908\n\n(2,.,.) =\n-0.1831344  -0.6621819   -0.667329      -0.26960346\n-0.1831344  -0.6621819   -0.667329      -0.26960346\n-0.6601015  1.0819869    1.0307902      1.1801233\n-0.6601015  1.0819869    1.0307902      1.1801233\n-0.18303517 0.2565441    -0.39598823    0.23400643\n-0.18303517 0.2565441    -0.39598823    0.23400643\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x6x4]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import UpSampling1D\n\nmodel = Sequential()\nmodel.add(UpSampling1D(2, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  [[[0.66227662 0.00663032 0.49010329 0.26836567]\n  [0.34225774 0.26000732 0.27628499 0.49861887]\n  [0.11619066 0.28123766 0.60770962 0.80773197]]\n\n [[0.477639   0.88906297 0.38577295 0.99058504]\n  [0.50690837 0.38107999 0.05881034 0.96402145]\n  [0.42226283 0.77350512 0.54961295 0.55315271]]]  Output is  [[[0.6622766  0.00663032 0.4901033  0.26836568]\n  [0.6622766  0.00663032 0.4901033  0.26836568]\n  [0.34225774 0.26000732 0.276285   0.49861887]\n  [0.34225774 0.26000732 0.276285   0.49861887]\n  [0.11619066 0.28123766 0.60770965 0.807732  ]\n  [0.11619066 0.28123766 0.60770965 0.807732  ]]\n\n [[0.477639   0.88906294 0.38577294 0.990585  ]\n  [0.477639   0.88906294 0.38577294 0.990585  ]\n  [0.50690836 0.38107997 0.05881034 0.96402144]\n  [0.50690836 0.38107997 0.05881034 0.96402144]\n  [0.42226282 0.7735051  0.54961294 0.5531527 ]\n  [0.42226282 0.7735051  0.54961294 0.5531527 ]]]", 
            "title": "UpSampling1D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#upsampling2d", 
            "text": "UpSampling layer for 2D inputs.  Repeats the rows and columns of the data by the specified size.  The input of this layer should be 4D.  Scala:  UpSampling2D(size = (2, 2), dimOrdering =  th , inputShape = null)  Python:  UpSampling2D(size=(2, 2), dim_ordering= th , input_shape=None, name=None)  Parameters:   size : Length 2. UpSampling factors for rows and columns. Default is (2, 2).  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, UpSampling2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(UpSampling2D((2, 2), inputShape = Shape(2, 2, 2)))\nval input = Tensor[Float](1, 2, 2, 2).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.07563081 -1.921836\n-1.7368479  0.1043008\n\n(1,2,.,.) =\n-1.825055   -0.096810855\n-0.89331573 0.72812295\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x2]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n-0.07563081 -0.07563081  -1.921836   -1.921836\n-0.07563081 -0.07563081  -1.921836   -1.921836\n-1.7368479  -1.7368479   0.1043008   0.1043008\n-1.7368479  -1.7368479   0.1043008   0.1043008\n\n(1,2,.,.) =\n-1.825055    -1.825055    -0.096810855  -0.096810855\n-1.825055    -1.825055    -0.096810855  -0.096810855\n-0.89331573  -0.89331573  0.72812295    0.72812295\n-0.89331573  -0.89331573  0.72812295    0.72812295\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x4x4]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import UpSampling2D\n\nmodel = Sequential()\nmodel.add(UpSampling2D((2, 2), input_shape=(2, 2, 2)))\ninput = np.random.random([1, 2, 2, 2])\noutput = model.forward(input)  Input is:  [[[[0.55660253 0.21984387]\n   [0.36271854 0.57464162]]\n\n  [[0.55307278 0.33007518]\n   [0.31527167 0.87789644]]]]  Output is  [[[[0.55660254 0.55660254 0.21984388 0.21984388]\n   [0.55660254 0.55660254 0.21984388 0.21984388]\n   [0.36271855 0.36271855 0.57464164 0.57464164]\n   [0.36271855 0.36271855 0.57464164 0.57464164]]\n\n  [[0.55307275 0.55307275 0.33007517 0.33007517]\n   [0.55307275 0.55307275 0.33007517 0.33007517]\n   [0.31527168 0.31527168 0.8778964  0.8778964 ]\n   [0.31527168 0.31527168 0.8778964  0.8778964 ]]]]", 
            "title": "UpSampling2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/convolutional/#upsampling3d", 
            "text": "UpSampling layer for 3D inputs.  Repeats the 1st, 2nd and 3rd dimensions of the data by the specified size.  Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').  The input of this layer should be 5D.  Scala:  UpSampling3D(size = (2, 2, 2), dimOrdering =  th , inputShape = null)  Python:  UpSampling3D(size=(2, 2, 2), dim_ordering= th , input_shape=None, name=None)  Parameters:   size : Length 3. UpSampling factors for dim1, dim2 and dim3. Default is (2, 2, 2).  dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, UpSampling3D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(UpSampling3D((2, 2, 2), inputShape = Shape(1, 1, 2, 2)))\nval input = Tensor[Float](1, 1, 1, 2, 2).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n0.9906968   -0.2451235\n1.5133694   -0.34076887\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x1x2x2]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.9906968   0.9906968   -0.2451235  -0.2451235\n0.9906968   0.9906968   -0.2451235  -0.2451235\n1.5133694   1.5133694   -0.34076887 -0.34076887\n1.5133694   1.5133694   -0.34076887 -0.34076887\n\n(1,1,2,.,.) =\n0.9906968   0.9906968   -0.2451235  -0.2451235\n0.9906968   0.9906968   -0.2451235  -0.2451235\n1.5133694   1.5133694   -0.34076887 -0.34076887\n1.5133694   1.5133694   -0.34076887 -0.34076887\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x4x4]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import UpSampling3D\n\nmodel = Sequential()\nmodel.add(UpSampling3D((2, 2, 2), input_shape=(1, 1, 2, 2)))\ninput = np.random.random([1, 1, 1, 2, 2])\noutput = model.forward(input)  Input is:  [[[[[0.58361205 0.2096227 ]\n    [0.51686662 0.70260105]]]]]  Output is  [[[[[0.583612  0.583612  0.2096227 0.2096227]\n    [0.583612  0.583612  0.2096227 0.2096227]\n    [0.5168666 0.5168666 0.7026011 0.7026011]\n    [0.5168666 0.5168666 0.7026011 0.7026011]]\n\n   [[0.583612  0.583612  0.2096227 0.2096227]\n    [0.583612  0.583612  0.2096227 0.2096227]\n    [0.5168666 0.5168666 0.7026011 0.7026011]\n    [0.5168666 0.5168666 0.7026011 0.7026011]]]]]", 
            "title": "UpSampling3D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/", 
            "text": "MaxPooling1D\n\n\nMax pooling operation for temporal data.\n\n\nThe input of this layer should be 3D.\n\n\nScala:\n\n\nMaxPooling1D(poolLength = 2, stride = -1, borderMode = \nvalid\n, inputShape = null)\n\n\n\n\nPython:\n\n\nMaxPooling1D(pool_length=2, stride=None, border_mode=\nvalid\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npoolLength\n: Size of the region to which max pooling is applied. Integer. Default is 2.\n\n\nstride\n: Factor by which to downscale. 2 will halve the input. If not specified, it will default to poolLength.\n\n\nborderMode\n: Either 'valid' or 'same'. Default is 'valid'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, MaxPooling1D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(MaxPooling1D(poolLength = 3, inputShape = Shape(4, 5)))\nval input = Tensor[Float](3, 4, 5).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.32697344   -1.901702    0.9338836    0.4988416    -1.4769285\n0.82112324   -1.749153    -1.2225364   0.17479241   -0.1569928\n-1.9349245   -0.7208759   -2.6186085   0.7094514    0.02309827\n0.06299127   -0.28094748  -1.679667    -0.19593267  -0.6486389\n\n(2,.,.) =\n0.5059762    -0.27661985  1.3978469    -0.13661754  0.9121702\n1.20289      -1.2779995   -1.221474    1.6933655    0.06884759\n-0.8358409   -1.5242177   0.38067985   0.1758138    -2.0869224\n-0.052700672 -1.2065598   0.65831304   -2.7004414   -1.5840155\n\n(3,.,.) =\n-1.5877407   -0.23685509  -1.1487285   0.6082965    0.5463596\n-0.6323151   1.6099663    0.16473362   -0.6759079   -0.22952202\n0.07198518   1.0313594    1.4555247    0.7538992    -1.2048378\n1.2034347    0.11312642   -0.14845283  -1.3795642   1.1672769\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x5]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.82112324  -0.7208759  0.9338836   0.7094514   0.02309827\n\n(2,.,.) =\n1.20289     -0.27661985 1.3978469   1.6933655   0.9121702\n\n(3,.,.) =\n0.07198518  1.6099663   1.4555247   0.7538992   0.5463596\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x1x5]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import MaxPooling1D\n\nmodel = Sequential()\nmodel.add(MaxPooling1D(pool_length = 3, input_shape = (4, 5)))\ninput = np.random.random([3, 4, 5])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.40580359 0.91869648 0.52699134 0.96507862 0.45316868]\n  [0.55665601 0.91599093 0.68640946 0.55788983 0.79788871]\n  [0.63706076 0.86559853 0.2157637  0.56051023 0.48453306]\n  [0.68673896 0.35445905 0.98369363 0.05747027 0.54176785]]\n\n [[0.00154654 0.02109022 0.69103023 0.08356977 0.51230376]\n  [0.01498106 0.32251403 0.98859889 0.6393191  0.59248678]\n  [0.43467219 0.97269656 0.82172126 0.62731276 0.19477236]\n  [0.44162847 0.50752131 0.43099026 0.07546448 0.97122237]]\n\n [[0.9526254  0.82221173 0.13355431 0.19929353 0.95937559]\n  [0.53449677 0.8041899  0.45077759 0.40048272 0.31712774]\n  [0.83603459 0.72547619 0.61066729 0.09561956 0.32530191]\n  [0.10199395 0.77512743 0.69522612 0.7456257  0.73544269]]]\n\n\n\n\nOutput is:\n\n\n[[[0.63706076 0.91869646 0.6864095  0.9650786  0.7978887 ]]\n\n [[0.43467218 0.97269654 0.9885989  0.6393191  0.5924868 ]]\n\n [[0.9526254  0.82221174 0.6106673  0.4004827  0.95937556]]]\n\n\n\n\n\n\nMaxPooling2D\n\n\nMax pooling operation for spatial data.\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nMaxPooling2D(poolSize = (2, 2), strides = null, borderMode = \nvalid\n, dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nMaxPooling2D(pool_size=(2, 2), strides=None, border_mode=\nvalid\n, dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npoolSize\n: Length 2 corresponding to the downscale vertically and horizontally. Default is (2, 2), which will halve the image in each dimension.\n\n\nstrides\n: Length 2. Stride values. Default is null, and in this case it will be equal to poolSize.\n\n\nborderMode\n: Either 'valid' or 'same'. Default is 'valid'.\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, MaxPooling2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(MaxPooling2D(inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n2.5301383   0.10926374  0.6072471   0.658932\n-0.3569041  0.32731345  -1.4209954  -0.4969882\n0.70455354  -2.7349844  0.66514283  -1.0055662\n\n(1,2,.,.) =\n-0.29669985 0.054489832 -1.1771511  -0.37510478\n1.2857671   -1.1703448  0.39755398  -1.6102049\n-0.42201662 1.2561954   1.1706035   0.20676066\n\n(2,1,.,.) =\n2.2395058   0.36936793  -1.0407287  0.46479732\n0.08024679  -1.3457166  -0.7048267  -0.017787607\n-0.66454273 -1.5704913  -1.7375602  -2.417642\n\n(2,2,.,.) =\n-1.5279706  -1.0108438  1.0017345   -0.5810244\n-1.5944351  0.11111861  0.4439802   -0.48056543\n-2.4090567  -1.459287   0.67291117  0.24757418\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n2.5301383   0.658932\n\n(1,2,.,.) =\n1.2857671   0.39755398\n\n(2,1,.,.) =\n2.2395058   0.46479732\n\n(2,2,.,.) =\n0.11111861  1.0017345\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x2]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import MaxPooling2D\n\nmodel = Sequential()\nmodel.add(MaxPooling2D(input_shape = (2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.82279705 0.62487892 0.37391352 0.22834848]\n   [0.68709158 0.40902972 0.73191486 0.40095294]\n   [0.651977   0.93330601 0.45785981 0.45939351]]\n  [[0.372833   0.39871945 0.13426243 0.83083849]\n   [0.24290548 0.04446027 0.58070741 0.37752852]\n   [0.13116942 0.59339663 0.94669915 0.02460278]]]\n\n [[[0.46505904 0.96103464 0.75846419 0.77357123]\n   [0.37835688 0.88438048 0.5679742  0.74607276]\n   [0.41415466 0.73945737 0.39188398 0.52736799]]\n  [[0.51772064 0.19857965 0.15476197 0.64569767]\n   [0.21794751 0.74455093 0.48423447 0.15482331]\n   [0.38363071 0.78733222 0.2542284  0.88671892]]]]\n\n\n\n\nOutput is:\n\n\n[[[[0.82279706 0.7319149 ]]\n  [[0.39871946 0.8308385 ]]]\n\n [[[0.96103466 0.77357125]]\n  [[0.74455094 0.64569765]]]]\n\n\n\n\n\n\nMaxPooling3D\n\n\nApplies max pooling operation for 3D data (spatial or spatio-temporal).\n\n\nData format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').\n\n\nBorder mode currently supported for this layer is 'valid'.\n\n\nThe input of this layer should be 5D.\n\n\nScala:\n\n\nMaxPooling3D(poolSize = (2, 2, 2), strides = null, dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nMaxPooling3D(pool_size=(2, 2, 2), strides=None, border_mode=\nvalid\n, dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npoolSize\n: Length 3. Factors by which to downscale (dim1, dim2, dim3). Default is (2, 2, 2), which will halve the image in each dimension.\n\n\nstrides\n: Length 3. Stride values. Default is null, and in this case it will be equal to poolSize.\n\n\ndimOrdering\n: Format of input data. Only 'th' (Channel First) is supported for now.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, MaxPooling3D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(MaxPooling3D(inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n-0.5052603  0.8938585   0.44785392\n-0.48919395 0.35026026  0.541859\n\n(1,1,2,.,.) =\n1.5306468   0.24512683  1.71524\n-0.49025944 2.1886358   0.15880944\n\n(1,2,1,.,.) =\n-0.5133986  -0.16549884 -0.2971134\n1.5887301   1.8269571   1.3843931\n\n(1,2,2,.,.) =\n0.07515256  1.6993935   -0.3392596\n1.2611006   0.20215735  1.3105171\n\n(2,1,1,.,.) =\n-2.0070438  0.35554957  0.21326075\n-0.4078646  -1.5748956  -1.1007504\n\n(2,1,2,.,.) =\n1.0571382   -1.6031493  1.4638771\n-0.25891435 1.4923956   -0.24045596\n\n(2,2,1,.,.) =\n-0.57790893 0.14577095  1.3165486\n0.81937057  -0.3797079  1.2544848\n\n(2,2,2,.,.) =\n-0.42183575 -0.63774794 -2.0576336\n0.43662143  1.9010457   -0.061519064\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n2.1886358\n\n(1,2,1,.,.) =\n1.8269571\n\n(2,1,1,.,.) =\n1.4923956\n\n(2,2,1,.,.) =\n1.9010457\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x1x1]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import MaxPooling3D\n\nmodel = Sequential()\nmodel.add(MaxPooling3D(input_shape = (2, 2, 2, 3)))\ninput = np.random.random([2, 2, 2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[[0.73349746 0.9811588  0.86071417]\n    [0.33287621 0.37991739 0.87029317]]\n   [[0.62537904 0.48099174 0.06194759]\n    [0.38747972 0.05175308 0.36096032]]]\n  [[[0.63260385 0.69990236 0.63353249]\n    [0.19081261 0.56210617 0.75985185]]\n   [[0.8624058  0.47224318 0.26524027]\n    [0.75317792 0.39251436 0.98938982]]]]\n\n [[[[0.00556086 0.18833728 0.80340438]\n    [0.9317538  0.88142596 0.90724509]]\n   [[0.90243612 0.04594116 0.43662143]\n    [0.24205094 0.58687822 0.57977055]]]\n  [[[0.17240398 0.18346483 0.02520754]\n    [0.06968248 0.02442692 0.56078895]]\n   [[0.69503427 0.09528588 0.46104647]\n    [0.16752596 0.88175901 0.71032998]]]]]\n\n\n\n\nOutput is:\n\n\n[[[[[0.9811588]]]\n  [[[0.8624058]]]]\n\n [[[[0.9317538]]]\n  [[[0.881759 ]]]]]\n\n\n\n\n\n\nAveragePooling1D\n\n\nAverage pooling for temporal data.\n\n\nThe input of this layer should be 3D.\n\n\nScala:\n\n\nAveragePooling1D(poolLength = 2, stride = -1, borderMode = \nvalid\n, inputShape = null)\n\n\n\n\nPython:\n\n\nAveragePooling1D(pool_length=2, stride=None, border_mode=\nvalid\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npoolLength\n: Size of the region to which average pooling is applied. Integer. Default is 2.\n\n\nstride\n: Factor by which to downscale. 2 will halve the input. If not specified, it will default to poolLength.\n\n\nborderMode\n: Either 'valid' or 'same'. Default is 'valid'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, AveragePooling1D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AveragePooling1D(poolLength = 3, inputShape = Shape(4, 5)))\nval input = Tensor[Float](3, 4, 5).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-1.1377933   0.21371832   1.7306958    -1.9029621   -1.4344455\n0.30368176   1.4264593    -2.1044374   1.9331307    0.064429775\n-0.20389123  1.0778805    -0.6283651   1.3097609    -0.13545972\n0.2993623    0.6173592    0.36244655   0.79175955   0.79752296\n\n(2,.,.) =\n-0.2151101   -0.016314683 0.42787352   0.8266788    1.3463322\n-0.5822824   -0.80566406  1.8474609    1.0040557    0.058591228\n1.1027422    -1.3031522   -0.17601672  1.0220417    -0.26774135\n0.5274945    0.33779684   -0.85662115  0.057247106  -0.26438802\n\n(3,.,.) =\n-0.069942534 0.9225811    -0.46108767  2.4335458    0.101546675\n-0.12930758  0.7706995    -0.1920893   -0.23971881  0.72432745\n0.55851805   -0.5315623   0.7103099    -0.5954772   1.1504582\n0.6810412    2.08239      0.5578813    -0.21148366  0.6381254\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x5]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.34600094 0.9060194   -0.33403555 0.4466432   -0.50182515\n\n(2,.,.) =\n0.10178324  -0.70837694 0.69977254  0.95092535  0.37906072\n\n(3,.,.) =\n0.11975598  0.38723943  0.01904432  0.5327832   0.6587774\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x1x5]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import AveragePooling1D\n\nmodel = Sequential()\nmodel.add(AveragePooling1D(pool_length = 3, input_shape = (4, 5)))\ninput = np.random.random([3, 4, 5])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.70712635 0.03582033 0.06284402 0.32036469 0.81474437]\n  [0.79836044 0.90868531 0.28817162 0.82013972 0.31323463]\n  [0.22585456 0.36409411 0.22224669 0.93922795 0.19095179]\n  [0.39250119 0.64782355 0.85172164 0.28749378 0.1088145 ]]\n\n [[0.04373644 0.29722078 0.3117768  0.64487829 0.4810562 ]\n  [0.3168246  0.08202731 0.58480522 0.72992227 0.64433289]\n  [0.49511033 0.09427843 0.80680702 0.23613413 0.70898751]\n  [0.50461138 0.26695611 0.34203601 0.09773049 0.19039967]]\n\n [[0.75294793 0.55036481 0.26584527 0.98080601 0.43339867]\n  [0.50389323 0.07068883 0.78938881 0.96551069 0.15544646]\n  [0.12795345 0.23093578 0.22171131 0.54183322 0.39152313]\n  [0.53546306 0.66279754 0.52490436 0.14028357 0.40409458]]]\n\n\n\n\nOutput is:\n\n\n[[[0.57711375 0.4361999  0.19108744 0.69324416 0.43964362]]\n\n [[0.2852238  0.15784217 0.56779635 0.53697824 0.61145884]]\n\n [[0.4615982  0.28399646 0.42564845 0.8293833  0.3267894 ]]]\n\n\n\n\n\n\nAveragePooling2D\n\n\nAverage pooling operation for spatial data.\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nAveragePooling2D(poolSize = (2, 2), strides = null, borderMode = \nvalid\n, dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nAveragePooling2D(pool_size=(2, 2), strides=None, border_mode=\nvalid\n, dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npoolSize\n: Length 2 corresponding to the downscale vertically and horizontally. Default is (2, 2), which will halve the image in each dimension.\n\n\nstrides\n: Length 2. Stride values. Default is null, and in this case it will be equal to poolSize.\n\n\nborderMode\n: Either 'valid' or 'same'. Default is 'valid'.\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, AveragePooling2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AveragePooling2D(inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.9929163   0.73885435  -0.34893242 1.1493853\n-0.45246652 -0.32470804 1.2192643   0.30351913\n1.3251832   0.52051955  -1.1398637  -2.427732\n\n(1,2,.,.) =\n-0.5123787  -0.5055035  0.3858232   0.71986055\n0.9580216   0.36081943  1.4867425   0.9852266\n-0.6051215  -0.15555465 -1.4472512  0.51882136\n\n(2,1,.,.) =\n-1.5209191  0.006158142 1.5162845   -0.06919313\n0.56743985  -0.499725   -0.44013703 -0.12666322\n0.78009427  1.9432178   1.4082893   -0.6143322\n\n(2,2,.,.) =\n-1.387891   0.023748515 -0.8295103  -0.9282333\n1.1375008   -1.4631946  -0.67415875 -0.7773346\n-2.297338   1.0384767   1.7125391   -1.7680352\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.23864903  0.5808091\n\n(1,2,.,.) =\n0.075239725 0.89441323\n\n(2,1,.,.) =\n-0.36176154 0.22007278\n\n(2,2,.,.) =\n-0.4224591  -0.8023093\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x2]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import AveragePooling2D\n\nmodel = Sequential()\nmodel.add(AveragePooling2D(input_shape = (2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.23128514 0.69922098 0.52158685 0.43063779]\n   [0.89149649 0.33910949 0.4402748  0.08933058]\n   [0.71712488 0.21574851 0.76768248 0.57027882]]\n  [[0.08349921 0.85318742 0.49922456 0.6256355 ]\n   [0.22331336 0.78402155 0.91424506 0.18895412]\n   [0.89722286 0.31067545 0.82655572 0.37775551]]]\n\n [[[0.9706926  0.28398186 0.36623623 0.23701637]\n   [0.49936358 0.50951663 0.48116156 0.89941571]\n   [0.06519683 0.34624179 0.2462403  0.48512833]]\n  [[0.58408752 0.68318898 0.67886418 0.43403476]\n   [0.87328453 0.8412756  0.59168164 0.49972216]\n   [0.82188585 0.63685579 0.50966912 0.51439279]]]]\n\n\n\n\nOutput is:\n\n\n[[[[0.540278   0.3704575 ]]\n  [[0.48600537 0.5570148 ]]]\n\n [[[0.56588864 0.49595746]]\n  [[0.7454592  0.5510757 ]]]]\n\n\n\n\n\n\nAveragePooling3D\n\n\nApplies average pooling operation for 3D data (spatial or spatio-temporal).\n\n\nData format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').\n\n\nBorder mode currently supported for this layer is 'valid'.\n\n\nThe input of this layer should be 5D.\n\n\nScala:\n\n\nAveragePooling3D(poolSize = (2, 2, 2), strides = null, dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nAveragePooling3D(pool_size=(2, 2, 2), strides=None, border_mode=\nvalid\n, dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\npoolSize\n: Length 3. Factors by which to downscale (dim1, dim2, dim3). Default is (2, 2, 2), which will halve the image in each dimension.\n\n\nstrides\n: Length 3. Stride values. Default is null, and in this case it will be equal to poolSize.\n\n\ndimOrdering\n: Format of input data. Only 'th' (Channel First) is supported for now.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, AveragePooling3D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AveragePooling3D(inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n-1.2491689  -0.72333497 0.076971635\n-1.2854124  -0.026098572    2.1735003\n\n(1,1,2,.,.) =\n1.4519714   1.1690209   2.3558137\n0.53576165  0.544173    1.1044264\n\n(1,2,1,.,.) =\n-1.2603238  -0.5580594  -0.91401285\n-0.18393324 -0.34946147 -0.5833402\n\n(1,2,2,.,.) =\n-0.2528762  0.5091298   0.2399745\n1.4895978   -1.3734508  -1.0218369\n\n(2,1,1,.,.) =\n-1.7266496  -0.04624697 0.47165343\n0.16339892  0.9384256   1.0018257\n\n(2,1,2,.,.) =\n-0.45763373 0.41072395  0.3123065\n-1.1914686  0.90784425  -2.8544335\n\n(2,2,1,.,.) =\n0.81638193  -1.2425674  1.9570643\n1.444956    0.37828556  -1.7336447\n\n(2,2,2,.,.) =\n-0.43858975 0.91795254  0.3359727\n0.20638026  -0.07622202 -2.1452882\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.052114002\n\n(1,2,1,.,.) =\n-0.24742219\n\n(2,1,1,.,.) =\n-0.12520081\n\n(2,2,1,.,.) =\n0.25082216\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x1x1]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import AveragePooling3D\n\nmodel = Sequential()\nmodel.add(AveragePooling3D(input_shape = (2, 2, 2, 3)))\ninput = np.random.random([2, 2, 2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[[0.97536696 0.01017816 0.77256405]\n    [0.53928594 0.80710453 0.71903394]]\n   [[0.67067647 0.38680811 0.05431165]\n    [0.98320357 0.8602754  0.12535218]]]\n  [[[0.32317928 0.17129988 0.51584225]\n    [0.70060648 0.36568169 0.36353108]]\n   [[0.90675921 0.68967216 0.29854921]\n    [0.72568459 0.34304905 0.9501725 ]]]]\n\n [[[[0.96295459 0.51457555 0.15752579]\n    [0.29569757 0.73166152 0.24217882]]\n   [[0.69938844 0.98315048 0.36022304]\n    [0.97079866 0.03950786 0.18505114]]]\n  [[[0.10255992 0.87988966 0.13163776]\n    [0.286857   0.56472867 0.73914834]]\n   [[0.51970598 0.19869426 0.47845175]\n    [0.86776147 0.60381965 0.88064078]]]]]\n\n\n\n\nOutput is:\n\n\n[[[[[0.6541124 ]]]\n  [[[0.5282415 ]]]]\n\n [[[[0.64971685]]]\n  [[[0.5030021 ]]]]]\n\n\n\n\n\n\n\nGlobalMaxPooling1D\n\n\nGlobal max pooling operation for temporal data.\n\n\nThe input of this layer should be 3D.\n\n\nScala:\n\n\nGlobalMaxPooling1D(inputShape = null)\n\n\n\n\nPython:\n\n\nGlobalMaxPooling1D(input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, GlobalMaxPooling1D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalMaxPooling1D(inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-1.0603509  2.0034506   -1.9884554\n-1.187076   -1.3023934  -0.8058352\n\n(2,.,.) =\n-0.9960039  -2.5800185  -0.01848254\n-0.66063184 -1.451372   1.3490999\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-1.0603509  2.0034506   -0.8058352\n-0.66063184 -1.451372   1.3490999\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import GlobalMaxPooling1D\n\nmodel = Sequential()\nmodel.add(GlobalMaxPooling1D(input_shape = (2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.70782546 0.2064717  0.45753652]\n  [0.41262607 0.72777349 0.21662695]]\n\n [[0.0937254  0.16749913 0.65395922]\n  [0.51027108 0.67591602 0.41025529]]]\n\n\n\n\nOutput is:\n\n\n[[0.7078255  0.7277735  0.45753652]\n [0.5102711  0.675916   0.6539592 ]]\n\n\n\n\n\n\nGlobalMaxPooling2D\n\n\nGlobal max pooling operation for spatial data.\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nGlobalMaxPooling2D(dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nGlobalMaxPooling2D(dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, GlobalMaxPooling2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalMaxPooling2D(inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.33040258 -0.94677037 0.14672963   0.1252591\n-0.3141728  0.68040586  1.3511285    -0.29235613\n0.03947779  -1.1260709  0.16128083   -1.1656744\n\n(1,2,.,.) =\n1.0182372   -0.6030568  -1.5335841   0.37804475\n0.26944965  -1.6720067  0.2405665    -0.95661074\n-0.31286374 0.109459646 -1.6644431   -1.9295278\n\n(2,1,.,.) =\n1.0210015   -0.69647574 -0.629564    1.6719679\n-0.7825565  -0.48921636 0.1892077    0.17827414\n0.76913565  0.17354056  -0.5749589   -1.736962\n\n(2,2,.,.) =\n0.82071537  -0.22566034 0.12415939   0.02941268\n0.34600595  0.86877316  0.9797952    -1.7793267\n0.025843443 -1.6373945  -0.093925744 -0.22479358\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n1.3511285   1.0182372\n1.6719679   0.9797952\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import GlobalMaxPooling2D\n\nmodel = Sequential()\nmodel.add(GlobalMaxPooling2D(input_shape = (2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.4037502  0.02214535 0.83987632 0.63656679]\n   [0.57757778 0.41884406 0.94446159 0.55776242]\n   [0.40213234 0.4463349  0.04457756 0.99123233]]\n  [[0.71114675 0.88609155 0.40299526 0.01648121]\n   [0.23102758 0.89673552 0.07030409 0.79674961]\n   [0.84665248 0.18257089 0.87211872 0.22697933]]]\n\n [[[0.08033122 0.26298654 0.10863184 0.57894922]\n   [0.03999134 0.90867755 0.80473921 0.79913378]\n   [0.60443084 0.92055786 0.17994007 0.87414516]]\n  [[0.50193442 0.52639178 0.72124789 0.41776979]\n   [0.09495006 0.91797563 0.48755794 0.50458372]\n   [0.47387433 0.93445126 0.83216554 0.67275364]]]]\n\n\n\n\nOutput is:\n\n\n[[0.99123234 0.8967355]\n [0.92055786 0.9344513]]\n\n\n\n\n\n\nGlobalMaxPooling3D\n\n\nApplies global max pooling operation for 3D data.\n\n\nData format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').\n\n\nBorder mode currently supported for this layer is 'valid'.\n\n\nThe input of this layer should be 5D.\n\n\nScala:\n\n\nGlobalMaxPooling3D(dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nGlobalMaxPooling3D(dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ndimOrdering\n: Format of input data. Only 'th' (Channel First) is supported for now.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, GlobalMaxPooling3D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalMaxPooling3D(inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n0.5882856      0.6403546    -0.42084476\n-0.097307995   -0.52530056  -0.36757985\n\n(1,1,2,.,.) =\n0.60983604  -0.24730012 -0.07744695\n0.36276138  0.34722528  0.19874145\n\n(1,2,1,.,.) =\n-0.912143   0.14050196  2.1116483\n-0.67692965 -0.5708391  -2.1040971\n\n(1,2,2,.,.) =\n2.1500692   1.1697202   1.364164\n1.2241726   -0.12069768 1.2471954\n\n(2,1,1,.,.) =\n0.39550102  -0.7435119  0.47669584\n-0.17335615 0.2690476   -0.8462402\n\n(2,1,2,.,.) =\n-1.0553921  -0.35153934 0.8036665\n-1.029019   -0.64534503 0.94537926\n\n(2,2,1,.,.) =\n0.5388452   -0.27233714 1.5837694\n1.0976856   -0.20959699 1.6285672\n\n(2,2,2,.,.) =\n-0.7736055  0.58593166  -1.2158531\n1.2194971   1.4081163   1.2056179\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.6403546   2.1500692\n0.94537926  1.6285672\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import GlobalMaxPooling3D\n\nmodel = Sequential()\nmodel.add(GlobalMaxPooling3D(input_shape = (2, 2, 2, 3)))\ninput = np.random.random([2, 2, 2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[[0.35670186 0.12860978 0.99958102]\n    [0.17345679 0.19473725 0.41235665]]\n   [[0.98948429 0.26686797 0.4632353 ]\n    [0.15791828 0.07452679 0.73215605]]]\n  [[[0.80305568 0.73208753 0.31179214]\n    [0.43452576 0.563038   0.65955869]]\n   [[0.31947806 0.00899334 0.55208827]\n    [0.57471665 0.10157217 0.42698318]]]]\n\n [[[[0.59277903 0.35379325 0.5311834 ]\n    [0.91781414 0.10407255 0.58049721]]\n   [[0.14371521 0.24279466 0.26071055]\n    [0.89431752 0.66817043 0.61662462]]]\n  [[[0.6672706  0.38855847 0.88462881]\n    [0.38859986 0.80439572 0.27661295]]\n   [[0.41453042 0.11527795 0.75953012]\n    [0.77940987 0.26283438 0.97745039]]]]]\n\n\n\n\nOutput is:\n\n\n[[0.99958104 0.8030557]\n [0.91781414 0.9774504]]\n\n\n\n\n\n\nGlobalAveragePooling1D\n\n\nGlobal average pooling operation for temporal data.\n\n\nThe input of this layer should be 3D.\n\n\nScala:\n\n\nGlobalAveragePooling1D(inputShape = null)\n\n\n\n\nPython:\n\n\nGlobalAveragePooling1D(input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, GlobalAveragePooling1D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalAveragePooling1D(inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.52390736  -0.2733816  0.124149635\n-1.351596   -1.1435038  -1.5176618\n\n(2,.,.) =\n1.0428048   -0.65227276 -0.44158915\n-0.23790422 0.4179904   -0.12358317\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.41384432 -0.7084427  -0.69675606\n0.40245032  -0.11714119 -0.28258616\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import GlobalAveragePooling1D\n\nmodel = Sequential()\nmodel.add(GlobalAveragePooling1D(input_shape = (2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.93869359 0.22245741 0.9744004 ]\n  [0.89151128 0.8211663  0.73579694]]\n\n [[0.37929716 0.509159   0.21713254]\n  [0.81838451 0.72323228 0.0370643 ]]]\n\n\n\n\nOutput is:\n\n\n[[0.9151024   0.52181184 0.85509866]\n [0.59884083  0.6161956  0.12709841]]\n\n\n\n\n\n\nGlobalAveragePooling2D\n\n\nGlobal average pooling operation for spatial data.\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nGlobalAveragePooling2D(dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nGlobalAveragePooling2D(dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, GlobalAveragePooling2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalAveragePooling2D(inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.110688895    -0.95155084  1.8221924   -2.0326483\n-0.013243215   -1.2766567   -0.16704278 -0.97121066\n-2.4606674     -0.24223651  -0.5687073  0.69842345\n\n(1,2,.,.) =\n0.14165956     0.17032783   2.5329256   0.011501087\n-0.3236992     1.1332442    0.18139894  -2.3126595\n0.1546373      0.35264283   -0.04404357 -0.70906943\n\n(2,1,.,.) =\n-0.08527824    0.29270124   -0.7355773  -0.6026267\n-0.71629876    0.83938205   0.5129336   0.118145116\n0.17555784     -0.8842884   0.12628363  -0.5556226\n\n(2,2,.,.) =\n0.6230317      0.64954233   -1.3002442  -0.44802713\n-0.7294096     0.29014868   -0.55649257 2.1427174\n0.0146621745   0.67039204   0.12979278  1.8543824\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.5043883  0.10740545\n-0.12622404 0.27837467\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import GlobalAveragePooling2D\n\nmodel = Sequential()\nmodel.add(GlobalAveragePooling2D(input_shape = (2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.44851152 0.94140516 0.45500829 0.07239139]\n   [0.58724461 0.7386701  0.69641719 0.70497337]\n   [0.15950558 0.56006247 0.82534941 0.59303245]]\n  [[0.94628326 0.75747177 0.92495215 0.16233194]\n   [0.21553426 0.65968036 0.72130258 0.8929379 ]\n   [0.91295078 0.36362834 0.04734189 0.32399088]]]\n\n [[[0.74069289 0.8804913  0.38783329 0.82279268]\n   [0.29561186 0.86405938 0.21608269 0.618583  ]\n   [0.16823803 0.65690701 0.85394726 0.94541932]]\n  [[0.33876558 0.47517543 0.25908204 0.81933296]\n   [0.16176792 0.57166    0.28295922 0.95254489]\n   [0.10532106 0.98495855 0.41048516 0.86755462]]]]\n\n\n\n\nOutput is:\n\n\n[[0.5652142 0.5773672]\n [0.6208883 0.519134 ]]\n\n\n\n\n\n\nGlobalAveragePooling3D\n\n\nApplies global average pooling operation for 3D data.\n\n\nData format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').\n\n\nBorder mode currently supported for this layer is 'valid'.\n\n\nThe input of this layer should be 5D.\n\n\nScala:\n\n\nGlobalAveragePooling3D(dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nGlobalAveragePooling3D(dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ndimOrdering\n: Format of input data. Only 'th' (Channel First) is supported for now.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, GlobalAveragePooling3D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalAveragePooling3D(inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n1.8996966    -0.20018125  -0.3271749\n0.27594963   -1.0520669   0.86003053\n\n(1,1,2,.,.) =\n-0.7652662   0.72945994   0.9008456\n0.8692407    -1.1327444   2.0664887\n\n(1,2,1,.,.) =\n0.10636215   -0.812925    -0.3757974\n0.48761207   0.017417012  -2.395701\n\n(1,2,2,.,.) =\n-1.3122851   -0.5942121   -0.6180062\n-0.032230377 -0.27521232  -0.3567782\n\n(2,1,1,.,.) =\n1.8668615    -0.4244298   1.0701258\n0.63794065   -1.023562    0.16939393\n\n(2,1,2,.,.) =\n0.20582832   0.5321886    -1.5412451\n-0.38068503  1.4506307    -0.47838798\n\n(2,2,1,.,.) =\n-0.7344984   -0.28647164  2.410416\n-1.8175911   -1.1973995   1.001777\n\n(2,2,2,.,.) =\n-0.09646813  0.11988298   1.4687495\n1.493955     0.16738588   1.133337\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.34368983  -0.51347965\n0.17372166  0.30525622\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import GlobalAveragePooling3D\n\nmodel = Sequential()\nmodel.add(GlobalAveragePooling3D(input_shape = (2, 2, 2, 3)))\ninput = np.random.random([2, 2, 2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[[0.38403874 0.30696173 0.25682854]\n    [0.53124253 0.62668969 0.21927777]]\n   [[0.33040063 0.37388563 0.75210039]\n    [0.08358634 0.80063745 0.13251887]]]\n  [[[0.41724617 0.2241106  0.55527267]\n    [0.69493785 0.71098284 0.54058444]]\n   [[0.4773658  0.92236993 0.76933649]\n    [0.45217032 0.61153948 0.01976393]]]]\n\n [[[[0.27256789 0.56008397 0.19898919]\n    [0.44973465 0.66605998 0.77117999]]\n   [[0.07868799 0.94786045 0.2240451 ]\n    [0.92261946 0.4053334  0.2572511 ]]]\n  [[[0.33754374 0.28838802 0.79900278]\n    [0.26374789 0.25610211 0.9320699 ]]\n   [[0.19518511 0.80707822 0.29660536]\n    [0.56917623 0.07653736 0.77836375]]]]]\n\n\n\n\nOutput is:\n\n\n[[0.3998474  0.53297335]\n [0.47953442 0.46665   ]]", 
            "title": "Pooling Layers"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#maxpooling1d", 
            "text": "Max pooling operation for temporal data.  The input of this layer should be 3D.  Scala:  MaxPooling1D(poolLength = 2, stride = -1, borderMode =  valid , inputShape = null)  Python:  MaxPooling1D(pool_length=2, stride=None, border_mode= valid , input_shape=None, name=None)  Parameters:   poolLength : Size of the region to which max pooling is applied. Integer. Default is 2.  stride : Factor by which to downscale. 2 will halve the input. If not specified, it will default to poolLength.  borderMode : Either 'valid' or 'same'. Default is 'valid'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, MaxPooling1D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(MaxPooling1D(poolLength = 3, inputShape = Shape(4, 5)))\nval input = Tensor[Float](3, 4, 5).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.32697344   -1.901702    0.9338836    0.4988416    -1.4769285\n0.82112324   -1.749153    -1.2225364   0.17479241   -0.1569928\n-1.9349245   -0.7208759   -2.6186085   0.7094514    0.02309827\n0.06299127   -0.28094748  -1.679667    -0.19593267  -0.6486389\n\n(2,.,.) =\n0.5059762    -0.27661985  1.3978469    -0.13661754  0.9121702\n1.20289      -1.2779995   -1.221474    1.6933655    0.06884759\n-0.8358409   -1.5242177   0.38067985   0.1758138    -2.0869224\n-0.052700672 -1.2065598   0.65831304   -2.7004414   -1.5840155\n\n(3,.,.) =\n-1.5877407   -0.23685509  -1.1487285   0.6082965    0.5463596\n-0.6323151   1.6099663    0.16473362   -0.6759079   -0.22952202\n0.07198518   1.0313594    1.4555247    0.7538992    -1.2048378\n1.2034347    0.11312642   -0.14845283  -1.3795642   1.1672769\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x5]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.82112324  -0.7208759  0.9338836   0.7094514   0.02309827\n\n(2,.,.) =\n1.20289     -0.27661985 1.3978469   1.6933655   0.9121702\n\n(3,.,.) =\n0.07198518  1.6099663   1.4555247   0.7538992   0.5463596\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x1x5]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import MaxPooling1D\n\nmodel = Sequential()\nmodel.add(MaxPooling1D(pool_length = 3, input_shape = (4, 5)))\ninput = np.random.random([3, 4, 5])\noutput = model.forward(input)  Input is:  [[[0.40580359 0.91869648 0.52699134 0.96507862 0.45316868]\n  [0.55665601 0.91599093 0.68640946 0.55788983 0.79788871]\n  [0.63706076 0.86559853 0.2157637  0.56051023 0.48453306]\n  [0.68673896 0.35445905 0.98369363 0.05747027 0.54176785]]\n\n [[0.00154654 0.02109022 0.69103023 0.08356977 0.51230376]\n  [0.01498106 0.32251403 0.98859889 0.6393191  0.59248678]\n  [0.43467219 0.97269656 0.82172126 0.62731276 0.19477236]\n  [0.44162847 0.50752131 0.43099026 0.07546448 0.97122237]]\n\n [[0.9526254  0.82221173 0.13355431 0.19929353 0.95937559]\n  [0.53449677 0.8041899  0.45077759 0.40048272 0.31712774]\n  [0.83603459 0.72547619 0.61066729 0.09561956 0.32530191]\n  [0.10199395 0.77512743 0.69522612 0.7456257  0.73544269]]]  Output is:  [[[0.63706076 0.91869646 0.6864095  0.9650786  0.7978887 ]]\n\n [[0.43467218 0.97269654 0.9885989  0.6393191  0.5924868 ]]\n\n [[0.9526254  0.82221174 0.6106673  0.4004827  0.95937556]]]", 
            "title": "MaxPooling1D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#maxpooling2d", 
            "text": "Max pooling operation for spatial data.  The input of this layer should be 4D.  Scala:  MaxPooling2D(poolSize = (2, 2), strides = null, borderMode =  valid , dimOrdering =  th , inputShape = null)  Python:  MaxPooling2D(pool_size=(2, 2), strides=None, border_mode= valid , dim_ordering= th , input_shape=None, name=None)  Parameters:   poolSize : Length 2 corresponding to the downscale vertically and horizontally. Default is (2, 2), which will halve the image in each dimension.  strides : Length 2. Stride values. Default is null, and in this case it will be equal to poolSize.  borderMode : Either 'valid' or 'same'. Default is 'valid'.  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, MaxPooling2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(MaxPooling2D(inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n2.5301383   0.10926374  0.6072471   0.658932\n-0.3569041  0.32731345  -1.4209954  -0.4969882\n0.70455354  -2.7349844  0.66514283  -1.0055662\n\n(1,2,.,.) =\n-0.29669985 0.054489832 -1.1771511  -0.37510478\n1.2857671   -1.1703448  0.39755398  -1.6102049\n-0.42201662 1.2561954   1.1706035   0.20676066\n\n(2,1,.,.) =\n2.2395058   0.36936793  -1.0407287  0.46479732\n0.08024679  -1.3457166  -0.7048267  -0.017787607\n-0.66454273 -1.5704913  -1.7375602  -2.417642\n\n(2,2,.,.) =\n-1.5279706  -1.0108438  1.0017345   -0.5810244\n-1.5944351  0.11111861  0.4439802   -0.48056543\n-2.4090567  -1.459287   0.67291117  0.24757418\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n2.5301383   0.658932\n\n(1,2,.,.) =\n1.2857671   0.39755398\n\n(2,1,.,.) =\n2.2395058   0.46479732\n\n(2,2,.,.) =\n0.11111861  1.0017345\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x2]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import MaxPooling2D\n\nmodel = Sequential()\nmodel.add(MaxPooling2D(input_shape = (2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.82279705 0.62487892 0.37391352 0.22834848]\n   [0.68709158 0.40902972 0.73191486 0.40095294]\n   [0.651977   0.93330601 0.45785981 0.45939351]]\n  [[0.372833   0.39871945 0.13426243 0.83083849]\n   [0.24290548 0.04446027 0.58070741 0.37752852]\n   [0.13116942 0.59339663 0.94669915 0.02460278]]]\n\n [[[0.46505904 0.96103464 0.75846419 0.77357123]\n   [0.37835688 0.88438048 0.5679742  0.74607276]\n   [0.41415466 0.73945737 0.39188398 0.52736799]]\n  [[0.51772064 0.19857965 0.15476197 0.64569767]\n   [0.21794751 0.74455093 0.48423447 0.15482331]\n   [0.38363071 0.78733222 0.2542284  0.88671892]]]]  Output is:  [[[[0.82279706 0.7319149 ]]\n  [[0.39871946 0.8308385 ]]]\n\n [[[0.96103466 0.77357125]]\n  [[0.74455094 0.64569765]]]]", 
            "title": "MaxPooling2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#maxpooling3d", 
            "text": "Applies max pooling operation for 3D data (spatial or spatio-temporal).  Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').  Border mode currently supported for this layer is 'valid'.  The input of this layer should be 5D.  Scala:  MaxPooling3D(poolSize = (2, 2, 2), strides = null, dimOrdering =  th , inputShape = null)  Python:  MaxPooling3D(pool_size=(2, 2, 2), strides=None, border_mode= valid , dim_ordering= th , input_shape=None, name=None)  Parameters:   poolSize : Length 3. Factors by which to downscale (dim1, dim2, dim3). Default is (2, 2, 2), which will halve the image in each dimension.  strides : Length 3. Stride values. Default is null, and in this case it will be equal to poolSize.  dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, MaxPooling3D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(MaxPooling3D(inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n-0.5052603  0.8938585   0.44785392\n-0.48919395 0.35026026  0.541859\n\n(1,1,2,.,.) =\n1.5306468   0.24512683  1.71524\n-0.49025944 2.1886358   0.15880944\n\n(1,2,1,.,.) =\n-0.5133986  -0.16549884 -0.2971134\n1.5887301   1.8269571   1.3843931\n\n(1,2,2,.,.) =\n0.07515256  1.6993935   -0.3392596\n1.2611006   0.20215735  1.3105171\n\n(2,1,1,.,.) =\n-2.0070438  0.35554957  0.21326075\n-0.4078646  -1.5748956  -1.1007504\n\n(2,1,2,.,.) =\n1.0571382   -1.6031493  1.4638771\n-0.25891435 1.4923956   -0.24045596\n\n(2,2,1,.,.) =\n-0.57790893 0.14577095  1.3165486\n0.81937057  -0.3797079  1.2544848\n\n(2,2,2,.,.) =\n-0.42183575 -0.63774794 -2.0576336\n0.43662143  1.9010457   -0.061519064\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n2.1886358\n\n(1,2,1,.,.) =\n1.8269571\n\n(2,1,1,.,.) =\n1.4923956\n\n(2,2,1,.,.) =\n1.9010457\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x1x1]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import MaxPooling3D\n\nmodel = Sequential()\nmodel.add(MaxPooling3D(input_shape = (2, 2, 2, 3)))\ninput = np.random.random([2, 2, 2, 2, 3])\noutput = model.forward(input)  Input is:  [[[[[0.73349746 0.9811588  0.86071417]\n    [0.33287621 0.37991739 0.87029317]]\n   [[0.62537904 0.48099174 0.06194759]\n    [0.38747972 0.05175308 0.36096032]]]\n  [[[0.63260385 0.69990236 0.63353249]\n    [0.19081261 0.56210617 0.75985185]]\n   [[0.8624058  0.47224318 0.26524027]\n    [0.75317792 0.39251436 0.98938982]]]]\n\n [[[[0.00556086 0.18833728 0.80340438]\n    [0.9317538  0.88142596 0.90724509]]\n   [[0.90243612 0.04594116 0.43662143]\n    [0.24205094 0.58687822 0.57977055]]]\n  [[[0.17240398 0.18346483 0.02520754]\n    [0.06968248 0.02442692 0.56078895]]\n   [[0.69503427 0.09528588 0.46104647]\n    [0.16752596 0.88175901 0.71032998]]]]]  Output is:  [[[[[0.9811588]]]\n  [[[0.8624058]]]]\n\n [[[[0.9317538]]]\n  [[[0.881759 ]]]]]", 
            "title": "MaxPooling3D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#averagepooling1d", 
            "text": "Average pooling for temporal data.  The input of this layer should be 3D.  Scala:  AveragePooling1D(poolLength = 2, stride = -1, borderMode =  valid , inputShape = null)  Python:  AveragePooling1D(pool_length=2, stride=None, border_mode= valid , input_shape=None, name=None)  Parameters:   poolLength : Size of the region to which average pooling is applied. Integer. Default is 2.  stride : Factor by which to downscale. 2 will halve the input. If not specified, it will default to poolLength.  borderMode : Either 'valid' or 'same'. Default is 'valid'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, AveragePooling1D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AveragePooling1D(poolLength = 3, inputShape = Shape(4, 5)))\nval input = Tensor[Float](3, 4, 5).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-1.1377933   0.21371832   1.7306958    -1.9029621   -1.4344455\n0.30368176   1.4264593    -2.1044374   1.9331307    0.064429775\n-0.20389123  1.0778805    -0.6283651   1.3097609    -0.13545972\n0.2993623    0.6173592    0.36244655   0.79175955   0.79752296\n\n(2,.,.) =\n-0.2151101   -0.016314683 0.42787352   0.8266788    1.3463322\n-0.5822824   -0.80566406  1.8474609    1.0040557    0.058591228\n1.1027422    -1.3031522   -0.17601672  1.0220417    -0.26774135\n0.5274945    0.33779684   -0.85662115  0.057247106  -0.26438802\n\n(3,.,.) =\n-0.069942534 0.9225811    -0.46108767  2.4335458    0.101546675\n-0.12930758  0.7706995    -0.1920893   -0.23971881  0.72432745\n0.55851805   -0.5315623   0.7103099    -0.5954772   1.1504582\n0.6810412    2.08239      0.5578813    -0.21148366  0.6381254\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x4x5]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.34600094 0.9060194   -0.33403555 0.4466432   -0.50182515\n\n(2,.,.) =\n0.10178324  -0.70837694 0.69977254  0.95092535  0.37906072\n\n(3,.,.) =\n0.11975598  0.38723943  0.01904432  0.5327832   0.6587774\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 3x1x5]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import AveragePooling1D\n\nmodel = Sequential()\nmodel.add(AveragePooling1D(pool_length = 3, input_shape = (4, 5)))\ninput = np.random.random([3, 4, 5])\noutput = model.forward(input)  Input is:  [[[0.70712635 0.03582033 0.06284402 0.32036469 0.81474437]\n  [0.79836044 0.90868531 0.28817162 0.82013972 0.31323463]\n  [0.22585456 0.36409411 0.22224669 0.93922795 0.19095179]\n  [0.39250119 0.64782355 0.85172164 0.28749378 0.1088145 ]]\n\n [[0.04373644 0.29722078 0.3117768  0.64487829 0.4810562 ]\n  [0.3168246  0.08202731 0.58480522 0.72992227 0.64433289]\n  [0.49511033 0.09427843 0.80680702 0.23613413 0.70898751]\n  [0.50461138 0.26695611 0.34203601 0.09773049 0.19039967]]\n\n [[0.75294793 0.55036481 0.26584527 0.98080601 0.43339867]\n  [0.50389323 0.07068883 0.78938881 0.96551069 0.15544646]\n  [0.12795345 0.23093578 0.22171131 0.54183322 0.39152313]\n  [0.53546306 0.66279754 0.52490436 0.14028357 0.40409458]]]  Output is:  [[[0.57711375 0.4361999  0.19108744 0.69324416 0.43964362]]\n\n [[0.2852238  0.15784217 0.56779635 0.53697824 0.61145884]]\n\n [[0.4615982  0.28399646 0.42564845 0.8293833  0.3267894 ]]]", 
            "title": "AveragePooling1D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#averagepooling2d", 
            "text": "Average pooling operation for spatial data.  The input of this layer should be 4D.  Scala:  AveragePooling2D(poolSize = (2, 2), strides = null, borderMode =  valid , dimOrdering =  th , inputShape = null)  Python:  AveragePooling2D(pool_size=(2, 2), strides=None, border_mode= valid , dim_ordering= th , input_shape=None, name=None)  Parameters:   poolSize : Length 2 corresponding to the downscale vertically and horizontally. Default is (2, 2), which will halve the image in each dimension.  strides : Length 2. Stride values. Default is null, and in this case it will be equal to poolSize.  borderMode : Either 'valid' or 'same'. Default is 'valid'.  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, AveragePooling2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AveragePooling2D(inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.9929163   0.73885435  -0.34893242 1.1493853\n-0.45246652 -0.32470804 1.2192643   0.30351913\n1.3251832   0.52051955  -1.1398637  -2.427732\n\n(1,2,.,.) =\n-0.5123787  -0.5055035  0.3858232   0.71986055\n0.9580216   0.36081943  1.4867425   0.9852266\n-0.6051215  -0.15555465 -1.4472512  0.51882136\n\n(2,1,.,.) =\n-1.5209191  0.006158142 1.5162845   -0.06919313\n0.56743985  -0.499725   -0.44013703 -0.12666322\n0.78009427  1.9432178   1.4082893   -0.6143322\n\n(2,2,.,.) =\n-1.387891   0.023748515 -0.8295103  -0.9282333\n1.1375008   -1.4631946  -0.67415875 -0.7773346\n-2.297338   1.0384767   1.7125391   -1.7680352\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.23864903  0.5808091\n\n(1,2,.,.) =\n0.075239725 0.89441323\n\n(2,1,.,.) =\n-0.36176154 0.22007278\n\n(2,2,.,.) =\n-0.4224591  -0.8023093\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x2]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import AveragePooling2D\n\nmodel = Sequential()\nmodel.add(AveragePooling2D(input_shape = (2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.23128514 0.69922098 0.52158685 0.43063779]\n   [0.89149649 0.33910949 0.4402748  0.08933058]\n   [0.71712488 0.21574851 0.76768248 0.57027882]]\n  [[0.08349921 0.85318742 0.49922456 0.6256355 ]\n   [0.22331336 0.78402155 0.91424506 0.18895412]\n   [0.89722286 0.31067545 0.82655572 0.37775551]]]\n\n [[[0.9706926  0.28398186 0.36623623 0.23701637]\n   [0.49936358 0.50951663 0.48116156 0.89941571]\n   [0.06519683 0.34624179 0.2462403  0.48512833]]\n  [[0.58408752 0.68318898 0.67886418 0.43403476]\n   [0.87328453 0.8412756  0.59168164 0.49972216]\n   [0.82188585 0.63685579 0.50966912 0.51439279]]]]  Output is:  [[[[0.540278   0.3704575 ]]\n  [[0.48600537 0.5570148 ]]]\n\n [[[0.56588864 0.49595746]]\n  [[0.7454592  0.5510757 ]]]]", 
            "title": "AveragePooling2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#averagepooling3d", 
            "text": "Applies average pooling operation for 3D data (spatial or spatio-temporal).  Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').  Border mode currently supported for this layer is 'valid'.  The input of this layer should be 5D.  Scala:  AveragePooling3D(poolSize = (2, 2, 2), strides = null, dimOrdering =  th , inputShape = null)  Python:  AveragePooling3D(pool_size=(2, 2, 2), strides=None, border_mode= valid , dim_ordering= th , input_shape=None, name=None)  Parameters:   poolSize : Length 3. Factors by which to downscale (dim1, dim2, dim3). Default is (2, 2, 2), which will halve the image in each dimension.  strides : Length 3. Stride values. Default is null, and in this case it will be equal to poolSize.  dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, AveragePooling3D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(AveragePooling3D(inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n-1.2491689  -0.72333497 0.076971635\n-1.2854124  -0.026098572    2.1735003\n\n(1,1,2,.,.) =\n1.4519714   1.1690209   2.3558137\n0.53576165  0.544173    1.1044264\n\n(1,2,1,.,.) =\n-1.2603238  -0.5580594  -0.91401285\n-0.18393324 -0.34946147 -0.5833402\n\n(1,2,2,.,.) =\n-0.2528762  0.5091298   0.2399745\n1.4895978   -1.3734508  -1.0218369\n\n(2,1,1,.,.) =\n-1.7266496  -0.04624697 0.47165343\n0.16339892  0.9384256   1.0018257\n\n(2,1,2,.,.) =\n-0.45763373 0.41072395  0.3123065\n-1.1914686  0.90784425  -2.8544335\n\n(2,2,1,.,.) =\n0.81638193  -1.2425674  1.9570643\n1.444956    0.37828556  -1.7336447\n\n(2,2,2,.,.) =\n-0.43858975 0.91795254  0.3359727\n0.20638026  -0.07622202 -2.1452882\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.052114002\n\n(1,2,1,.,.) =\n-0.24742219\n\n(2,1,1,.,.) =\n-0.12520081\n\n(2,2,1,.,.) =\n0.25082216\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x1x1x1]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import AveragePooling3D\n\nmodel = Sequential()\nmodel.add(AveragePooling3D(input_shape = (2, 2, 2, 3)))\ninput = np.random.random([2, 2, 2, 2, 3])\noutput = model.forward(input)  Input is:  [[[[[0.97536696 0.01017816 0.77256405]\n    [0.53928594 0.80710453 0.71903394]]\n   [[0.67067647 0.38680811 0.05431165]\n    [0.98320357 0.8602754  0.12535218]]]\n  [[[0.32317928 0.17129988 0.51584225]\n    [0.70060648 0.36568169 0.36353108]]\n   [[0.90675921 0.68967216 0.29854921]\n    [0.72568459 0.34304905 0.9501725 ]]]]\n\n [[[[0.96295459 0.51457555 0.15752579]\n    [0.29569757 0.73166152 0.24217882]]\n   [[0.69938844 0.98315048 0.36022304]\n    [0.97079866 0.03950786 0.18505114]]]\n  [[[0.10255992 0.87988966 0.13163776]\n    [0.286857   0.56472867 0.73914834]]\n   [[0.51970598 0.19869426 0.47845175]\n    [0.86776147 0.60381965 0.88064078]]]]]  Output is:  [[[[[0.6541124 ]]]\n  [[[0.5282415 ]]]]\n\n [[[[0.64971685]]]\n  [[[0.5030021 ]]]]]", 
            "title": "AveragePooling3D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#globalmaxpooling1d", 
            "text": "Global max pooling operation for temporal data.  The input of this layer should be 3D.  Scala:  GlobalMaxPooling1D(inputShape = null)  Python:  GlobalMaxPooling1D(input_shape=None, name=None)  Parameters:   inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, GlobalMaxPooling1D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalMaxPooling1D(inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-1.0603509  2.0034506   -1.9884554\n-1.187076   -1.3023934  -0.8058352\n\n(2,.,.) =\n-0.9960039  -2.5800185  -0.01848254\n-0.66063184 -1.451372   1.3490999\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-1.0603509  2.0034506   -0.8058352\n-0.66063184 -1.451372   1.3490999\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import GlobalMaxPooling1D\n\nmodel = Sequential()\nmodel.add(GlobalMaxPooling1D(input_shape = (2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)  Input is:  [[[0.70782546 0.2064717  0.45753652]\n  [0.41262607 0.72777349 0.21662695]]\n\n [[0.0937254  0.16749913 0.65395922]\n  [0.51027108 0.67591602 0.41025529]]]  Output is:  [[0.7078255  0.7277735  0.45753652]\n [0.5102711  0.675916   0.6539592 ]]", 
            "title": "GlobalMaxPooling1D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#globalmaxpooling2d", 
            "text": "Global max pooling operation for spatial data.  The input of this layer should be 4D.  Scala:  GlobalMaxPooling2D(dimOrdering =  th , inputShape = null)  Python:  GlobalMaxPooling2D(dim_ordering= th , input_shape=None, name=None)  Parameters:   dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, GlobalMaxPooling2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalMaxPooling2D(inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n-0.33040258 -0.94677037 0.14672963   0.1252591\n-0.3141728  0.68040586  1.3511285    -0.29235613\n0.03947779  -1.1260709  0.16128083   -1.1656744\n\n(1,2,.,.) =\n1.0182372   -0.6030568  -1.5335841   0.37804475\n0.26944965  -1.6720067  0.2405665    -0.95661074\n-0.31286374 0.109459646 -1.6644431   -1.9295278\n\n(2,1,.,.) =\n1.0210015   -0.69647574 -0.629564    1.6719679\n-0.7825565  -0.48921636 0.1892077    0.17827414\n0.76913565  0.17354056  -0.5749589   -1.736962\n\n(2,2,.,.) =\n0.82071537  -0.22566034 0.12415939   0.02941268\n0.34600595  0.86877316  0.9797952    -1.7793267\n0.025843443 -1.6373945  -0.093925744 -0.22479358\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n1.3511285   1.0182372\n1.6719679   0.9797952\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import GlobalMaxPooling2D\n\nmodel = Sequential()\nmodel.add(GlobalMaxPooling2D(input_shape = (2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.4037502  0.02214535 0.83987632 0.63656679]\n   [0.57757778 0.41884406 0.94446159 0.55776242]\n   [0.40213234 0.4463349  0.04457756 0.99123233]]\n  [[0.71114675 0.88609155 0.40299526 0.01648121]\n   [0.23102758 0.89673552 0.07030409 0.79674961]\n   [0.84665248 0.18257089 0.87211872 0.22697933]]]\n\n [[[0.08033122 0.26298654 0.10863184 0.57894922]\n   [0.03999134 0.90867755 0.80473921 0.79913378]\n   [0.60443084 0.92055786 0.17994007 0.87414516]]\n  [[0.50193442 0.52639178 0.72124789 0.41776979]\n   [0.09495006 0.91797563 0.48755794 0.50458372]\n   [0.47387433 0.93445126 0.83216554 0.67275364]]]]  Output is:  [[0.99123234 0.8967355]\n [0.92055786 0.9344513]]", 
            "title": "GlobalMaxPooling2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#globalmaxpooling3d", 
            "text": "Applies global max pooling operation for 3D data.  Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').  Border mode currently supported for this layer is 'valid'.  The input of this layer should be 5D.  Scala:  GlobalMaxPooling3D(dimOrdering =  th , inputShape = null)  Python:  GlobalMaxPooling3D(dim_ordering= th , input_shape=None, name=None)  Parameters:   dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, GlobalMaxPooling3D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalMaxPooling3D(inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n0.5882856      0.6403546    -0.42084476\n-0.097307995   -0.52530056  -0.36757985\n\n(1,1,2,.,.) =\n0.60983604  -0.24730012 -0.07744695\n0.36276138  0.34722528  0.19874145\n\n(1,2,1,.,.) =\n-0.912143   0.14050196  2.1116483\n-0.67692965 -0.5708391  -2.1040971\n\n(1,2,2,.,.) =\n2.1500692   1.1697202   1.364164\n1.2241726   -0.12069768 1.2471954\n\n(2,1,1,.,.) =\n0.39550102  -0.7435119  0.47669584\n-0.17335615 0.2690476   -0.8462402\n\n(2,1,2,.,.) =\n-1.0553921  -0.35153934 0.8036665\n-1.029019   -0.64534503 0.94537926\n\n(2,2,1,.,.) =\n0.5388452   -0.27233714 1.5837694\n1.0976856   -0.20959699 1.6285672\n\n(2,2,2,.,.) =\n-0.7736055  0.58593166  -1.2158531\n1.2194971   1.4081163   1.2056179\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.6403546   2.1500692\n0.94537926  1.6285672\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import GlobalMaxPooling3D\n\nmodel = Sequential()\nmodel.add(GlobalMaxPooling3D(input_shape = (2, 2, 2, 3)))\ninput = np.random.random([2, 2, 2, 2, 3])\noutput = model.forward(input)  Input is:  [[[[[0.35670186 0.12860978 0.99958102]\n    [0.17345679 0.19473725 0.41235665]]\n   [[0.98948429 0.26686797 0.4632353 ]\n    [0.15791828 0.07452679 0.73215605]]]\n  [[[0.80305568 0.73208753 0.31179214]\n    [0.43452576 0.563038   0.65955869]]\n   [[0.31947806 0.00899334 0.55208827]\n    [0.57471665 0.10157217 0.42698318]]]]\n\n [[[[0.59277903 0.35379325 0.5311834 ]\n    [0.91781414 0.10407255 0.58049721]]\n   [[0.14371521 0.24279466 0.26071055]\n    [0.89431752 0.66817043 0.61662462]]]\n  [[[0.6672706  0.38855847 0.88462881]\n    [0.38859986 0.80439572 0.27661295]]\n   [[0.41453042 0.11527795 0.75953012]\n    [0.77940987 0.26283438 0.97745039]]]]]  Output is:  [[0.99958104 0.8030557]\n [0.91781414 0.9774504]]", 
            "title": "GlobalMaxPooling3D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#globalaveragepooling1d", 
            "text": "Global average pooling operation for temporal data.  The input of this layer should be 3D.  Scala:  GlobalAveragePooling1D(inputShape = null)  Python:  GlobalAveragePooling1D(input_shape=None, name=None)  Parameters:   inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, GlobalAveragePooling1D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalAveragePooling1D(inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.52390736  -0.2733816  0.124149635\n-1.351596   -1.1435038  -1.5176618\n\n(2,.,.) =\n1.0428048   -0.65227276 -0.44158915\n-0.23790422 0.4179904   -0.12358317\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.41384432 -0.7084427  -0.69675606\n0.40245032  -0.11714119 -0.28258616\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import GlobalAveragePooling1D\n\nmodel = Sequential()\nmodel.add(GlobalAveragePooling1D(input_shape = (2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)  Input is:  [[[0.93869359 0.22245741 0.9744004 ]\n  [0.89151128 0.8211663  0.73579694]]\n\n [[0.37929716 0.509159   0.21713254]\n  [0.81838451 0.72323228 0.0370643 ]]]  Output is:  [[0.9151024   0.52181184 0.85509866]\n [0.59884083  0.6161956  0.12709841]]", 
            "title": "GlobalAveragePooling1D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#globalaveragepooling2d", 
            "text": "Global average pooling operation for spatial data.  The input of this layer should be 4D.  Scala:  GlobalAveragePooling2D(dimOrdering =  th , inputShape = null)  Python:  GlobalAveragePooling2D(dim_ordering= th , input_shape=None, name=None)  Parameters:   dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, GlobalAveragePooling2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalAveragePooling2D(inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.110688895    -0.95155084  1.8221924   -2.0326483\n-0.013243215   -1.2766567   -0.16704278 -0.97121066\n-2.4606674     -0.24223651  -0.5687073  0.69842345\n\n(1,2,.,.) =\n0.14165956     0.17032783   2.5329256   0.011501087\n-0.3236992     1.1332442    0.18139894  -2.3126595\n0.1546373      0.35264283   -0.04404357 -0.70906943\n\n(2,1,.,.) =\n-0.08527824    0.29270124   -0.7355773  -0.6026267\n-0.71629876    0.83938205   0.5129336   0.118145116\n0.17555784     -0.8842884   0.12628363  -0.5556226\n\n(2,2,.,.) =\n0.6230317      0.64954233   -1.3002442  -0.44802713\n-0.7294096     0.29014868   -0.55649257 2.1427174\n0.0146621745   0.67039204   0.12979278  1.8543824\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.5043883  0.10740545\n-0.12622404 0.27837467\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import GlobalAveragePooling2D\n\nmodel = Sequential()\nmodel.add(GlobalAveragePooling2D(input_shape = (2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.44851152 0.94140516 0.45500829 0.07239139]\n   [0.58724461 0.7386701  0.69641719 0.70497337]\n   [0.15950558 0.56006247 0.82534941 0.59303245]]\n  [[0.94628326 0.75747177 0.92495215 0.16233194]\n   [0.21553426 0.65968036 0.72130258 0.8929379 ]\n   [0.91295078 0.36362834 0.04734189 0.32399088]]]\n\n [[[0.74069289 0.8804913  0.38783329 0.82279268]\n   [0.29561186 0.86405938 0.21608269 0.618583  ]\n   [0.16823803 0.65690701 0.85394726 0.94541932]]\n  [[0.33876558 0.47517543 0.25908204 0.81933296]\n   [0.16176792 0.57166    0.28295922 0.95254489]\n   [0.10532106 0.98495855 0.41048516 0.86755462]]]]  Output is:  [[0.5652142 0.5773672]\n [0.6208883 0.519134 ]]", 
            "title": "GlobalAveragePooling2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/pooling/#globalaveragepooling3d", 
            "text": "Applies global average pooling operation for 3D data.  Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').  Border mode currently supported for this layer is 'valid'.  The input of this layer should be 5D.  Scala:  GlobalAveragePooling3D(dimOrdering =  th , inputShape = null)  Python:  GlobalAveragePooling3D(dim_ordering= th , input_shape=None, name=None)  Parameters:   dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, GlobalAveragePooling3D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GlobalAveragePooling3D(inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n1.8996966    -0.20018125  -0.3271749\n0.27594963   -1.0520669   0.86003053\n\n(1,1,2,.,.) =\n-0.7652662   0.72945994   0.9008456\n0.8692407    -1.1327444   2.0664887\n\n(1,2,1,.,.) =\n0.10636215   -0.812925    -0.3757974\n0.48761207   0.017417012  -2.395701\n\n(1,2,2,.,.) =\n-1.3122851   -0.5942121   -0.6180062\n-0.032230377 -0.27521232  -0.3567782\n\n(2,1,1,.,.) =\n1.8668615    -0.4244298   1.0701258\n0.63794065   -1.023562    0.16939393\n\n(2,1,2,.,.) =\n0.20582832   0.5321886    -1.5412451\n-0.38068503  1.4506307    -0.47838798\n\n(2,2,1,.,.) =\n-0.7344984   -0.28647164  2.410416\n-1.8175911   -1.1973995   1.001777\n\n(2,2,2,.,.) =\n-0.09646813  0.11988298   1.4687495\n1.493955     0.16738588   1.133337\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.34368983  -0.51347965\n0.17372166  0.30525622\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import GlobalAveragePooling3D\n\nmodel = Sequential()\nmodel.add(GlobalAveragePooling3D(input_shape = (2, 2, 2, 3)))\ninput = np.random.random([2, 2, 2, 2, 3])\noutput = model.forward(input)  Input is:  [[[[[0.38403874 0.30696173 0.25682854]\n    [0.53124253 0.62668969 0.21927777]]\n   [[0.33040063 0.37388563 0.75210039]\n    [0.08358634 0.80063745 0.13251887]]]\n  [[[0.41724617 0.2241106  0.55527267]\n    [0.69493785 0.71098284 0.54058444]]\n   [[0.4773658  0.92236993 0.76933649]\n    [0.45217032 0.61153948 0.01976393]]]]\n\n [[[[0.27256789 0.56008397 0.19898919]\n    [0.44973465 0.66605998 0.77117999]]\n   [[0.07868799 0.94786045 0.2240451 ]\n    [0.92261946 0.4053334  0.2572511 ]]]\n  [[[0.33754374 0.28838802 0.79900278]\n    [0.26374789 0.25610211 0.9320699 ]]\n   [[0.19518511 0.80707822 0.29660536]\n    [0.56917623 0.07653736 0.77836375]]]]]  Output is:  [[0.3998474  0.53297335]\n [0.47953442 0.46665   ]]", 
            "title": "GlobalAveragePooling3D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/recurrent/", 
            "text": "SimpleRNN\n\n\nA fully-connected recurrent neural network cell. The output is to be fed back to input.\n\n\nThe input of this layer should be 3D, i.e. (batch, time steps, input dim).\n\n\nScala:\n\n\nSimpleRNN(outputDim, activation = \ntanh\n, returnSequences = false, goBackwards = false, wRegularizer = null, uRegularizer = null, bRegularizer = null, inputShape = null)\n\n\n\n\nPython:\n\n\nSimpleRNN(output_dim, activation=\ntanh\n, return_sequences=False, go_backwards=False, W_regularizer=None, U_regularizer=None, b_regularizer=None, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\noutputDim\n: Hidden unit size. Dimension of internal projections and final output.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is 'tanh'.\n\n\nreturnSequences\n: Whether to return the full sequence or only return the last output in the output sequence. Default is false.\n\n\ngoBackwards\n: Whether the input sequence will be processed backwards. Default is false.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nuRegularizer\n: An instance of \nRegularizer\n, applied the recurrent weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, SimpleRNN}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SimpleRNN(8, activation = \nrelu\n, inputShape = Shape(4, 5)))\nval input = Tensor[Float](2, 4, 5).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.71328646  0.24269831  -0.75013286 -1.6663225  0.35494477\n0.073439054 -1.1181073  -0.6577777  1.3154761   0.15396282\n0.41183218  -1.2667576  -0.11167632 0.946616    0.06427766\n0.013886308 -0.20620999 1.1173447   1.9083043   1.7680032\n\n(2,.,.) =\n-2.3510098  -0.8492037  0.042268332 -0.43801674 -0.010638754\n1.298793    -0.24814601 0.31325665  -0.19119295 -2.072075\n-0.11629801 0.27296612  0.94443846  0.37293285  -0.82289046\n0.6044998   0.93386084  -1.3502276  -1.7753356  1.6173482\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x5]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.0  0.020557694  0.0   0.39700085  0.622244  0.0   0.36524248  0.88961613\n0.0  1.4797685    0.0   0.0         0.0       0.0   0.0         0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import SimpleRNN\n\nmodel = Sequential()\nmodel.add(SimpleRNN(8, activation = \nrelu\n, input_shape = (4, 5)))\ninput = np.random.random([2, 4, 5])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.43400622 0.65452575 0.94952774 0.96210478 0.05286231]\n  [0.2162183  0.33225502 0.09725628 0.80813221 0.29556109]\n  [0.19720487 0.35077585 0.80904872 0.80576513 0.82035253]\n  [0.36175687 0.63291153 0.08437936 0.71581099 0.790709  ]]\n\n [[0.35387003 0.36532078 0.9834315  0.07562338 0.05600369]\n  [0.65927201 0.14652252 0.10848068 0.88225065 0.88871385]\n  [0.23627135 0.72620104 0.60391828 0.51571874 0.73550574]\n  [0.80773506 0.35121494 0.66889362 0.530684   0.52066982]]]\n\n\n\n\nOutput is:\n\n\n[[0.77534926 0.23742369 0.14946866 0.0        0.16289112 0.0  0.71689016 0.24594748]\n [0.8987881  0.06123672 0.3312829  0.29757586 0.0        0.0  1.0179179  0.23447856]]\n\n\n\n\n\n\nLSTM\n\n\nLong Short Term Memory unit architecture.\n\n\nThe input of this layer should be 3D, i.e. (batch, time steps, input dim).\n\n\nScala:\n\n\nLSTM(outputDim, activation = \ntanh\n, innerActivation = \nhard_sigmoid\n, returnSequences = false, goBackwards = false, wRegularizer = null, uRegularizer = null, bRegularizer = null, inputShape = null)\n\n\n\n\nPython:\n\n\nLSTM(output_dim, activation=\ntanh\n, inner_activation=\nhard_sigmoid\n, return_sequences=False, go_backwards=False, W_regularizer=None, U_regularizer=None, b_regularizer=None, input_shape=None, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\noutputDim\n: Hidden unit size. Dimension of internal projections and final output.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is 'tanh'.\n\n\ninnerActivation\n: String representation of the activation function for inner cells. See \nhere\n for available activation strings. Default is 'hard_sigmoid'.\n\n\nreturnSequences\n: Whether to return the full sequence or only return the last output in the output sequence. Default is false.\n\n\ngoBackwards\n: Whether the input sequence will be processed backwards. Default is false.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nuRegularizer\n: An instance of \nRegularizer\n, applied the recurrent weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, LSTM}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(LSTM(8, inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.3485646   0.38385049  0.676986\n0.13189854  0.30926105  0.4539456\n\n(2,.,.) =\n-1.7166822  -0.71257055 -0.477679\n-0.36572325 -0.5534503  -0.018431915\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.20168768 -0.20359062 -0.11801678 -0.08987579 0.20480658  -0.05170132 -0.048530716    0.08447949\n-0.07134238 -0.11233686 0.073534355 0.047955263 0.13415548  0.12862797  -0.07839044     0.28296617\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import LSTM\n\nmodel = Sequential()\nmodel.add(LSTM(8, input_shape = (2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.84004043 0.2081865  0.76093342]\n  [0.06878797 0.13804673 0.23251666]]\n\n [[0.24651173 0.5650254  0.41424478]\n  [0.49338729 0.40505622 0.01497762]]]\n\n\n\n\nOutput is:\n\n\n[[ 0.01089199  0.02563154 -0.04335827  0.03037791  0.11265078 -0.17756112\n   0.14166507  0.01017009]\n [ 0.0144811   0.03360332  0.00676281 -0.01473055  0.09639315 -0.16620669\n   0.07391933  0.01746811]]\n\n\n\n\n\n\nGRU\n\n\nGated Recurrent Unit architecture.\n\n\nThe input of this layer should be 3D, i.e. (batch, time steps, input dim).\n\n\nScala:\n\n\nGRU(outputDim, activation = \ntanh\n, innerActivation = \nhard_sigmoid\n, returnSequences = false, goBackwards = false, wRegularizer = null, uRegularizer = null, bRegularizer = null, inputShape = null)\n\n\n\n\nPython:\n\n\nGRU(output_dim, activation=\ntanh\n, inner_activation=\nhard_sigmoid\n, return_sequences=False, go_backwards=False, W_regularizer=None, U_regularizer=None, b_regularizer=None, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\noutputDim\n: Hidden unit size. Dimension of internal projections and final output.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is 'tanh'.\n\n\ninnerActivation\n: String representation of the activation function for inner cells. See \nhere\n for available activation strings. Default is 'hard_sigmoid'.\n\n\nreturnSequences\n: Whether to return the full sequence or only return the last output in the output sequence. Default is false.\n\n\ngoBackwards\n: Whether the input sequence will be processed backwards. Default is false.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nuRegularizer\n: An instance of \nRegularizer\n, applied the recurrent weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, GRU}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GRU(8, inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.010477358 -1.1201298  -0.86472356\n0.12688802   -0.6696582  0.08027417\n\n(2,.,.) =\n0.1724209    -0.52319324 -0.8808063\n0.17918338   -0.552886   -0.11891741\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.12018716  -0.31560755    0.2867627   0.6728765   0.13287778  0.2112865   0.13381396  -0.4267934\n-0.18521798  -0.30512968    0.14875418  0.63962734  0.1841841   0.25272882  0.016909363 -0.38463163\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import GRU\n\nmodel = Sequential()\nmodel.add(GRU(8, input_shape = (2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.25026651 0.35433442 0.01417391]\n  [0.77236921 0.97315472 0.66090386]]\n\n [[0.76037554 0.41029034 0.68725938]\n  [0.17888889 0.67670088 0.70580547]]]\n\n\n\n\nOutput is:\n\n\n[[-0.03584666  0.07984452 -0.06159414 -0.13331707  0.34015405 -0.07107028  0.12444386 -0.06606203]\n [ 0.02881907  0.04856917 -0.15306929 -0.24991018  0.23814955  0.0303434   0.06634206 -0.15335503]]\n\n\n\n\n\n\nHighway\n\n\nDensely connected highway network.\n\n\nHighway layers are a natural extension of LSTMs to feedforward networks.\n\n\nThe input of this layer should be 2D, i.e. (batch, input dim).\n\n\nScala:\n\n\nHighway(activation = null, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)\n\n\n\n\nPython:\n\n\nHighway(activation=None, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is null.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nbias\n: Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, Highway}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Highway(inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.26041138 0.4286919   1.723103\n1.4516269   0.5557163   -0.1149741\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.006746907    -0.109112576    1.3375516\n0.6065166   0.41575465  -0.06849813\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Highway\n\nmodel = Sequential()\nmodel.add(Highway(input_shape = (3)))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[0.5762107  0.45679288 0.00370956]\n [0.24133312 0.38104653 0.05249192]]\n\n\n\n\nOutput is:\n\n\n[[0.5762107  0.4567929  0.00370956]\n [0.24133313 0.38104653 0.05249191]]\n\n\n\n\n\n\nConvLSTM2D\n\n\nConvolutional LSTM.\n\n\nData format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').\n\n\nBorder mode currently supported for this layer is 'same'.\n\n\nThe convolution kernel for this layer is a square kernel with equal strides 'subsample'.\n\n\nThe input of this layer should be 5D.\n\n\nScala:\n\n\nConvLSTM2D(nbFilter, nbKernel, activation = \ntanh\n, innerActivation = \nhard_sigmoid\n, dimOrdering = \nth\n, subsample = 1, wRegularizer = null, uRegularizer = null, bRegularizer = null, returnSequences = false, goBackwards = false, inputShape = null)\n\n\n\n\nPython:\n\n\nConvLSTM2D(nb_filter, nb_row, nb_col, activation=\ntanh\n, inner_activation=\nhard_sigmoid\n, dim_ordering=\nth\n, border_mode=\nsame\n, subsample=(1, 1), W_regularizer=None, U_regularizer=None, b_regularizer=None, return_sequences=False, go_backwards=False, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nnbFilter\n: Number of convolution filters to use.\n\n\nnbKernel\n: Number of rows/columns in the convolution kernel. Square kernel. In Python, require nb_row==nb_col.\n\n\nactivation\n: String representation of the activation function to use. See \nhere\n for available activation strings. Default is 'tanh'.\n\n\ninnerActivation\n: String representation of the activation function to use for inner cells. See \nhere\n for available activation strings. Default is 'hard_sigmoid'.\n\n\ndimOrdering\n: Format of input data. Only 'th' (Channel First) is supported for now.\n\n\nsubsample\n: Factor by which to subsample output. Also called strides elsewhere.\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\nuRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the recurrent weights matrices. Default is null.\n\n\nbRegularizer\n: An instance of \nRegularizer\n, applied to the bias. Default is null.\n\n\nreturnSequences\n: Whether to return the full sequence or the last output in the output sequence. Default is false.\n\n\ngoBackwards\n: Whether the input sequence will be processed backwards. Default is false.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, ConvLSTM2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ConvLSTM2D(2, 2, inputShape = Shape(1, 2, 2, 2)))\nval input = Tensor[Float](1, 1, 2, 2, 2).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n-0.3935159  -2.0734277\n0.16473202  -1.0574125\n\n(1,1,2,.,.) =\n1.2325795   0.510846\n-0.4246685  -0.109434046\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x2x2]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n-0.12613402     0.035963967\n0.046498444     0.03568305\n\n(1,2,.,.) =\n-0.1547083      -0.046905644\n-0.115438126    -0.08817647\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x2]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import ConvLSTM2D\n\nmodel = Sequential()\nmodel.add(ConvLSTM2D(2, 2, 2, input_shape=(1, 2, 2, 2)))\ninput = np.random.random([1, 1, 2, 2, 2])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[[0.53293431 0.02606896]\n    [0.50916001 0.6927234 ]]\n\n   [[0.44282168 0.05963464]\n    [0.22863441 0.45312165]]]]]\n\n\n\n\nOutput is\n\n\n[[[[ 0.09322705  0.09817358]\n   [ 0.12197719  0.11264911]]\n\n  [[ -0.03922357 -0.11715978]\n   [ -0.01915754 -0.03141996]]]]", 
            "title": "Recurrent Layers"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/recurrent/#simplernn", 
            "text": "A fully-connected recurrent neural network cell. The output is to be fed back to input.  The input of this layer should be 3D, i.e. (batch, time steps, input dim).  Scala:  SimpleRNN(outputDim, activation =  tanh , returnSequences = false, goBackwards = false, wRegularizer = null, uRegularizer = null, bRegularizer = null, inputShape = null)  Python:  SimpleRNN(output_dim, activation= tanh , return_sequences=False, go_backwards=False, W_regularizer=None, U_regularizer=None, b_regularizer=None, input_shape=None, name=None)  Parameters:   outputDim : Hidden unit size. Dimension of internal projections and final output.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is 'tanh'.  returnSequences : Whether to return the full sequence or only return the last output in the output sequence. Default is false.  goBackwards : Whether the input sequence will be processed backwards. Default is false.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  uRegularizer : An instance of  Regularizer , applied the recurrent weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, SimpleRNN}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SimpleRNN(8, activation =  relu , inputShape = Shape(4, 5)))\nval input = Tensor[Float](2, 4, 5).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.71328646  0.24269831  -0.75013286 -1.6663225  0.35494477\n0.073439054 -1.1181073  -0.6577777  1.3154761   0.15396282\n0.41183218  -1.2667576  -0.11167632 0.946616    0.06427766\n0.013886308 -0.20620999 1.1173447   1.9083043   1.7680032\n\n(2,.,.) =\n-2.3510098  -0.8492037  0.042268332 -0.43801674 -0.010638754\n1.298793    -0.24814601 0.31325665  -0.19119295 -2.072075\n-0.11629801 0.27296612  0.94443846  0.37293285  -0.82289046\n0.6044998   0.93386084  -1.3502276  -1.7753356  1.6173482\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x5]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.0  0.020557694  0.0   0.39700085  0.622244  0.0   0.36524248  0.88961613\n0.0  1.4797685    0.0   0.0         0.0       0.0   0.0         0.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import SimpleRNN\n\nmodel = Sequential()\nmodel.add(SimpleRNN(8, activation =  relu , input_shape = (4, 5)))\ninput = np.random.random([2, 4, 5])\noutput = model.forward(input)  Input is:  [[[0.43400622 0.65452575 0.94952774 0.96210478 0.05286231]\n  [0.2162183  0.33225502 0.09725628 0.80813221 0.29556109]\n  [0.19720487 0.35077585 0.80904872 0.80576513 0.82035253]\n  [0.36175687 0.63291153 0.08437936 0.71581099 0.790709  ]]\n\n [[0.35387003 0.36532078 0.9834315  0.07562338 0.05600369]\n  [0.65927201 0.14652252 0.10848068 0.88225065 0.88871385]\n  [0.23627135 0.72620104 0.60391828 0.51571874 0.73550574]\n  [0.80773506 0.35121494 0.66889362 0.530684   0.52066982]]]  Output is:  [[0.77534926 0.23742369 0.14946866 0.0        0.16289112 0.0  0.71689016 0.24594748]\n [0.8987881  0.06123672 0.3312829  0.29757586 0.0        0.0  1.0179179  0.23447856]]", 
            "title": "SimpleRNN"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/recurrent/#lstm", 
            "text": "Long Short Term Memory unit architecture.  The input of this layer should be 3D, i.e. (batch, time steps, input dim).  Scala:  LSTM(outputDim, activation =  tanh , innerActivation =  hard_sigmoid , returnSequences = false, goBackwards = false, wRegularizer = null, uRegularizer = null, bRegularizer = null, inputShape = null)  Python:  LSTM(output_dim, activation= tanh , inner_activation= hard_sigmoid , return_sequences=False, go_backwards=False, W_regularizer=None, U_regularizer=None, b_regularizer=None, input_shape=None, input_shape=None, name=None)  Parameters:   outputDim : Hidden unit size. Dimension of internal projections and final output.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is 'tanh'.  innerActivation : String representation of the activation function for inner cells. See  here  for available activation strings. Default is 'hard_sigmoid'.  returnSequences : Whether to return the full sequence or only return the last output in the output sequence. Default is false.  goBackwards : Whether the input sequence will be processed backwards. Default is false.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  uRegularizer : An instance of  Regularizer , applied the recurrent weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, LSTM}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(LSTM(8, inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n1.3485646   0.38385049  0.676986\n0.13189854  0.30926105  0.4539456\n\n(2,.,.) =\n-1.7166822  -0.71257055 -0.477679\n-0.36572325 -0.5534503  -0.018431915\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.20168768 -0.20359062 -0.11801678 -0.08987579 0.20480658  -0.05170132 -0.048530716    0.08447949\n-0.07134238 -0.11233686 0.073534355 0.047955263 0.13415548  0.12862797  -0.07839044     0.28296617\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import LSTM\n\nmodel = Sequential()\nmodel.add(LSTM(8, input_shape = (2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)  Input is:  [[[0.84004043 0.2081865  0.76093342]\n  [0.06878797 0.13804673 0.23251666]]\n\n [[0.24651173 0.5650254  0.41424478]\n  [0.49338729 0.40505622 0.01497762]]]  Output is:  [[ 0.01089199  0.02563154 -0.04335827  0.03037791  0.11265078 -0.17756112\n   0.14166507  0.01017009]\n [ 0.0144811   0.03360332  0.00676281 -0.01473055  0.09639315 -0.16620669\n   0.07391933  0.01746811]]", 
            "title": "LSTM"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/recurrent/#gru", 
            "text": "Gated Recurrent Unit architecture.  The input of this layer should be 3D, i.e. (batch, time steps, input dim).  Scala:  GRU(outputDim, activation =  tanh , innerActivation =  hard_sigmoid , returnSequences = false, goBackwards = false, wRegularizer = null, uRegularizer = null, bRegularizer = null, inputShape = null)  Python:  GRU(output_dim, activation= tanh , inner_activation= hard_sigmoid , return_sequences=False, go_backwards=False, W_regularizer=None, U_regularizer=None, b_regularizer=None, input_shape=None, name=None)  Parameters:   outputDim : Hidden unit size. Dimension of internal projections and final output.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is 'tanh'.  innerActivation : String representation of the activation function for inner cells. See  here  for available activation strings. Default is 'hard_sigmoid'.  returnSequences : Whether to return the full sequence or only return the last output in the output sequence. Default is false.  goBackwards : Whether the input sequence will be processed backwards. Default is false.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  uRegularizer : An instance of  Regularizer , applied the recurrent weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, GRU}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GRU(8, inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.010477358 -1.1201298  -0.86472356\n0.12688802   -0.6696582  0.08027417\n\n(2,.,.) =\n0.1724209    -0.52319324 -0.8808063\n0.17918338   -0.552886   -0.11891741\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.12018716  -0.31560755    0.2867627   0.6728765   0.13287778  0.2112865   0.13381396  -0.4267934\n-0.18521798  -0.30512968    0.14875418  0.63962734  0.1841841   0.25272882  0.016909363 -0.38463163\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x8]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import GRU\n\nmodel = Sequential()\nmodel.add(GRU(8, input_shape = (2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)  Input is:  [[[0.25026651 0.35433442 0.01417391]\n  [0.77236921 0.97315472 0.66090386]]\n\n [[0.76037554 0.41029034 0.68725938]\n  [0.17888889 0.67670088 0.70580547]]]  Output is:  [[-0.03584666  0.07984452 -0.06159414 -0.13331707  0.34015405 -0.07107028  0.12444386 -0.06606203]\n [ 0.02881907  0.04856917 -0.15306929 -0.24991018  0.23814955  0.0303434   0.06634206 -0.15335503]]", 
            "title": "GRU"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/recurrent/#highway", 
            "text": "Densely connected highway network.  Highway layers are a natural extension of LSTMs to feedforward networks.  The input of this layer should be 2D, i.e. (batch, input dim).  Scala:  Highway(activation = null, wRegularizer = null, bRegularizer = null, bias = true, inputShape = null)  Python:  Highway(activation=None, W_regularizer=None, b_regularizer=None, bias=True, input_shape=None, name=None)  Parameters:   activation : String representation of the activation function to use. See  here  for available activation strings. Default is null.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  bias : Whether to include a bias (i.e. make the layer affine rather than linear). Default is true.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, Highway}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Highway(inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.26041138 0.4286919   1.723103\n1.4516269   0.5557163   -0.1149741\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.006746907    -0.109112576    1.3375516\n0.6065166   0.41575465  -0.06849813\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Highway\n\nmodel = Sequential()\nmodel.add(Highway(input_shape = (3)))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  [[0.5762107  0.45679288 0.00370956]\n [0.24133312 0.38104653 0.05249192]]  Output is:  [[0.5762107  0.4567929  0.00370956]\n [0.24133313 0.38104653 0.05249191]]", 
            "title": "Highway"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/recurrent/#convlstm2d", 
            "text": "Convolutional LSTM.  Data format currently supported for this layer is 'CHANNEL_FIRST' (dimOrdering='th').  Border mode currently supported for this layer is 'same'.  The convolution kernel for this layer is a square kernel with equal strides 'subsample'.  The input of this layer should be 5D.  Scala:  ConvLSTM2D(nbFilter, nbKernel, activation =  tanh , innerActivation =  hard_sigmoid , dimOrdering =  th , subsample = 1, wRegularizer = null, uRegularizer = null, bRegularizer = null, returnSequences = false, goBackwards = false, inputShape = null)  Python:  ConvLSTM2D(nb_filter, nb_row, nb_col, activation= tanh , inner_activation= hard_sigmoid , dim_ordering= th , border_mode= same , subsample=(1, 1), W_regularizer=None, U_regularizer=None, b_regularizer=None, return_sequences=False, go_backwards=False, input_shape=None, name=None)  Parameters:   nbFilter : Number of convolution filters to use.  nbKernel : Number of rows/columns in the convolution kernel. Square kernel. In Python, require nb_row==nb_col.  activation : String representation of the activation function to use. See  here  for available activation strings. Default is 'tanh'.  innerActivation : String representation of the activation function to use for inner cells. See  here  for available activation strings. Default is 'hard_sigmoid'.  dimOrdering : Format of input data. Only 'th' (Channel First) is supported for now.  subsample : Factor by which to subsample output. Also called strides elsewhere.  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  uRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the recurrent weights matrices. Default is null.  bRegularizer : An instance of  Regularizer , applied to the bias. Default is null.  returnSequences : Whether to return the full sequence or the last output in the output sequence. Default is false.  goBackwards : Whether the input sequence will be processed backwards. Default is false.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, ConvLSTM2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ConvLSTM2D(2, 2, inputShape = Shape(1, 2, 2, 2)))\nval input = Tensor[Float](1, 1, 2, 2, 2).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n-0.3935159  -2.0734277\n0.16473202  -1.0574125\n\n(1,1,2,.,.) =\n1.2325795   0.510846\n-0.4246685  -0.109434046\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x1x2x2x2]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n-0.12613402     0.035963967\n0.046498444     0.03568305\n\n(1,2,.,.) =\n-0.1547083      -0.046905644\n-0.115438126    -0.08817647\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 1x2x2x2]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import ConvLSTM2D\n\nmodel = Sequential()\nmodel.add(ConvLSTM2D(2, 2, 2, input_shape=(1, 2, 2, 2)))\ninput = np.random.random([1, 1, 2, 2, 2])\noutput = model.forward(input)  Input is:  [[[[[0.53293431 0.02606896]\n    [0.50916001 0.6927234 ]]\n\n   [[0.44282168 0.05963464]\n    [0.22863441 0.45312165]]]]]  Output is  [[[[ 0.09322705  0.09817358]\n   [ 0.12197719  0.11264911]]\n\n  [[ -0.03922357 -0.11715978]\n   [ -0.01915754 -0.03141996]]]]", 
            "title": "ConvLSTM2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/normalization/", 
            "text": "BatchNormalization\n\n\nBatch normalization layer.\n\n\nNormalize the activations of the previous layer at each batch, i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1.\n\n\nIt is a feature-wise normalization, each feature map in the input will be normalized separately.\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nBatchNormalization(epsilon = 0.001, momentum = 0.99, betaInit = \nzero\n, gammaInit = \none\n, dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nBatchNormalization(epsilon=0.001, momentum=0.99, beta_init=\nzero\n, gamma_init=\none\n, dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nepsilon\n: Fuzz parameter. Default is 0.001.\n\n\nmomentum\n: Momentum in the computation of the exponential average of the mean and standard deviation of the data, for feature-wise normalization. Default is 0.99.\n\n\nbetaInit\n: Name of initialization function for shift parameter. See \nhere\n for available initialization strings. Default is 'zero'.\n\n\ngammaInit\n: Name of initialization function for scale parameter. See \nhere\n for available initialization strings. Default is 'one'.\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. For 'th', axis along which to normalize is 1. For 'tf', axis is 3.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, BatchNormalization}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(BatchNormalization(inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.77107763    0.2937704    0.5191167    1.7458088\n0.6895759     1.1034386    0.076277375  0.73515415\n0.8190946     0.63958114   0.5226141    -0.42864776\n\n(1,2,.,.) =\n-0.121818945  0.34588146   0.055290654  -0.07994603\n0.6463561     0.13930246   1.5822772    0.5089318\n-0.21778189   -1.4048384   0.47113693   0.7929269\n\n(2,1,.,.) =\n0.6308846     -0.3855579   1.1685323    1.5646453\n0.06638282    -1.7852567   2.5698936    0.54044205\n1.020025      0.9537036    -0.95600724  2.0834947\n\n(2,2,.,.) =\n-0.5315871    -1.5204562   -0.19082998  -1.5210537\n0.35849532    0.15615761   -0.55561566  1.1889576\n-0.16226959   -2.1243215   1.1446979    -1.1057223\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.16141568    -0.3597713   -0.1137085   1.2257558\n0.07242136    0.5243313    -0.5972589   0.12218969\n0.21384695    0.017830472  -0.10988956  -1.1486028\n\n(1,2,.,.) =\n-0.03555677   0.4775637    0.15875259   0.010382571\n0.80721855    0.25092307   1.8340303    0.6564485\n-0.14083901   -1.4431748   0.6149832    0.96802336\n\n(2,1,.,.) =\n0.008334424   -1.1015517   0.5954091    1.0279375\n-0.6080631    -2.6299274   2.1256003    -0.090422675\n0.4332493     0.36083078   -1.7244436   1.5944856\n\n(2,2,.,.) =\n-0.48511901   -1.5700207   -0.11126971  -1.5706762\n0.49140254    0.26941508   -0.51148105  1.402514\n-0.07993572   -2.2325294   1.3539561    -1.1150105\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import BatchNormalization\n\nmodel = Sequential()\nmodel.add(BatchNormalization(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.01633039 0.08359466 0.31828698 0.31132638]\n   [0.82236941 0.34455877 0.40301781 0.09545177]\n   [0.32995004 0.21716768 0.40654485 0.0607145 ]]\n  [[0.04502162 0.90428985 0.54087212 0.78525733]\n   [0.02355475 0.86309013 0.25354746 0.88168388]\n   [0.77375427 0.74295181 0.43970331 0.07890251]]]\n\n [[[0.87290131 0.15790927 0.25248005 0.56290773]\n   [0.47154244 0.98287739 0.59877866 0.3287331 ]\n   [0.0048165  0.47392756 0.32070177 0.51298559]]\n  [[0.89172586 0.68240756 0.86829594 0.79287212]\n   [0.13308157 0.04279427 0.59920687 0.26807939]\n   [0.42409288 0.54029318 0.65308363 0.90739643]]]]\n\n\n\n\nOutput is\n\n\n[[[[-1.3824786   -1.1216924   -0.21178117  -0.2387677 ]\n   [ 1.7425659   -0.10992443  0.11672354   -1.075722  ]\n   [-0.16656308  -0.6038247   0.13039804   -1.2103996 ]]\n  [[-1.6169451   1.149055     -0.02079336  0.7658872 ]\n   [-1.6860473   1.0164324    -0.9456966   1.076286  ]\n   [ 0.7288585   0.6297049    -0.3464575   -1.5078819 ]]]\n\n [[[ 1.93848     -0.8335718   -0.4669172   0.73662305]\n   [ 0.3823962   2.3648615    0.87569594   -0.17128123]\n   [-1.4271184   0.39164335   -0.20241894  0.5430728 ]]\n  [[ 1.1086112   0.43481186   1.0331899    0.7903993 ]\n   [-1.3334786   -1.6241149   0.16698733   -0.89891803]\n   [-0.39670774  -0.02265698  0.3404176    1.1590551 ]]]]", 
            "title": "Normalization Layers"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/normalization/#batchnormalization", 
            "text": "Batch normalization layer.  Normalize the activations of the previous layer at each batch, i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1.  It is a feature-wise normalization, each feature map in the input will be normalized separately.  The input of this layer should be 4D.  Scala:  BatchNormalization(epsilon = 0.001, momentum = 0.99, betaInit =  zero , gammaInit =  one , dimOrdering =  th , inputShape = null)  Python:  BatchNormalization(epsilon=0.001, momentum=0.99, beta_init= zero , gamma_init= one , dim_ordering= th , input_shape=None, name=None)  Parameters:   epsilon : Fuzz parameter. Default is 0.001.  momentum : Momentum in the computation of the exponential average of the mean and standard deviation of the data, for feature-wise normalization. Default is 0.99.  betaInit : Name of initialization function for shift parameter. See  here  for available initialization strings. Default is 'zero'.  gammaInit : Name of initialization function for scale parameter. See  here  for available initialization strings. Default is 'one'.  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'. For 'th', axis along which to normalize is 1. For 'tf', axis is 3.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, BatchNormalization}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(BatchNormalization(inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n0.77107763    0.2937704    0.5191167    1.7458088\n0.6895759     1.1034386    0.076277375  0.73515415\n0.8190946     0.63958114   0.5226141    -0.42864776\n\n(1,2,.,.) =\n-0.121818945  0.34588146   0.055290654  -0.07994603\n0.6463561     0.13930246   1.5822772    0.5089318\n-0.21778189   -1.4048384   0.47113693   0.7929269\n\n(2,1,.,.) =\n0.6308846     -0.3855579   1.1685323    1.5646453\n0.06638282    -1.7852567   2.5698936    0.54044205\n1.020025      0.9537036    -0.95600724  2.0834947\n\n(2,2,.,.) =\n-0.5315871    -1.5204562   -0.19082998  -1.5210537\n0.35849532    0.15615761   -0.55561566  1.1889576\n-0.16226959   -2.1243215   1.1446979    -1.1057223\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.16141568    -0.3597713   -0.1137085   1.2257558\n0.07242136    0.5243313    -0.5972589   0.12218969\n0.21384695    0.017830472  -0.10988956  -1.1486028\n\n(1,2,.,.) =\n-0.03555677   0.4775637    0.15875259   0.010382571\n0.80721855    0.25092307   1.8340303    0.6564485\n-0.14083901   -1.4431748   0.6149832    0.96802336\n\n(2,1,.,.) =\n0.008334424   -1.1015517   0.5954091    1.0279375\n-0.6080631    -2.6299274   2.1256003    -0.090422675\n0.4332493     0.36083078   -1.7244436   1.5944856\n\n(2,2,.,.) =\n-0.48511901   -1.5700207   -0.11126971  -1.5706762\n0.49140254    0.26941508   -0.51148105  1.402514\n-0.07993572   -2.2325294   1.3539561    -1.1150105\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import BatchNormalization\n\nmodel = Sequential()\nmodel.add(BatchNormalization(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.01633039 0.08359466 0.31828698 0.31132638]\n   [0.82236941 0.34455877 0.40301781 0.09545177]\n   [0.32995004 0.21716768 0.40654485 0.0607145 ]]\n  [[0.04502162 0.90428985 0.54087212 0.78525733]\n   [0.02355475 0.86309013 0.25354746 0.88168388]\n   [0.77375427 0.74295181 0.43970331 0.07890251]]]\n\n [[[0.87290131 0.15790927 0.25248005 0.56290773]\n   [0.47154244 0.98287739 0.59877866 0.3287331 ]\n   [0.0048165  0.47392756 0.32070177 0.51298559]]\n  [[0.89172586 0.68240756 0.86829594 0.79287212]\n   [0.13308157 0.04279427 0.59920687 0.26807939]\n   [0.42409288 0.54029318 0.65308363 0.90739643]]]]  Output is  [[[[-1.3824786   -1.1216924   -0.21178117  -0.2387677 ]\n   [ 1.7425659   -0.10992443  0.11672354   -1.075722  ]\n   [-0.16656308  -0.6038247   0.13039804   -1.2103996 ]]\n  [[-1.6169451   1.149055     -0.02079336  0.7658872 ]\n   [-1.6860473   1.0164324    -0.9456966   1.076286  ]\n   [ 0.7288585   0.6297049    -0.3464575   -1.5078819 ]]]\n\n [[[ 1.93848     -0.8335718   -0.4669172   0.73662305]\n   [ 0.3823962   2.3648615    0.87569594   -0.17128123]\n   [-1.4271184   0.39164335   -0.20241894  0.5430728 ]]\n  [[ 1.1086112   0.43481186   1.0331899    0.7903993 ]\n   [-1.3334786   -1.6241149   0.16698733   -0.89891803]\n   [-0.39670774  -0.02265698  0.3404176    1.1590551 ]]]]", 
            "title": "BatchNormalization"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/embedding/", 
            "text": "Embedding\n\n\nTurn positive integers (indexes) into dense vectors of fixed size.\n\n\nThe input of this layer should be 2D.\n\n\nScala:\n\n\nEmbedding(inputDim, outputDim, init = \nuniform\n, wRegularizer = null, inputShape = null)\n\n\n\n\nPython:\n\n\nEmbedding(input_dim, output_dim, init=\nuniform\n, W_regularizer=None, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ninputDim\n: Int \n 0. Size of the vocabulary.\n\n\noutputDim\n: Int \n= 0. Dimension of the dense embedding.\n\n\ninit\n: String representation of the initialization method for the weights of the layer. See \nhere\n for available initialization strings. Default is \"uniform\".\n\n\nwRegularizer\n: An instance of \nRegularizer\n, (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, Embedding}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Embedding(8, 2, inputShape = Shape(4)))\nval input = Tensor[Float](2, 4)\ninput(Array(1, 1)) = 1\ninput(Array(1, 2)) = 2\ninput(Array(1, 3)) = 4\ninput(Array(1, 4)) = 5\ninput(Array(2, 1)) = 4\ninput(Array(2, 2)) = 3\ninput(Array(2, 3)) = 2\ninput(Array(2, 4)) = 6\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0 2.0 4.0 5.0\n4.0 3.0 2.0 6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.03256504      -0.043232664\n-0.044753443    0.026075097\n0.045668535     0.02456015\n0.021222712     -0.04373116\n\n(2,.,.) =\n0.045668535     0.02456015\n0.03761902      -0.0014174521\n-0.044753443    0.026075097\n-0.030343587    -0.0015718295\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x2]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Embedding\n\nmodel = Sequential()\nmodel.add(Embedding(8, 2, input_shape=(4,)))\ninput = np.random.randint(4, size=(2, 4))\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[0 2 2 2]\n [2 1 1 0]]\n\n\n\n\nOutput is\n\n\n[[[ 0.0094721  -0.01927968]\n  [-0.00483634 -0.03992473]\n  [-0.00483634 -0.03992473]\n  [-0.00483634 -0.03992473]]\n\n [[-0.00483634 -0.03992473]\n  [-0.03603687 -0.03708585]\n  [-0.03603687 -0.03708585]\n  [ 0.0094721  -0.01927968]]]", 
            "title": "Embedding Layers"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/embedding/#embedding", 
            "text": "Turn positive integers (indexes) into dense vectors of fixed size.  The input of this layer should be 2D.  Scala:  Embedding(inputDim, outputDim, init =  uniform , wRegularizer = null, inputShape = null)  Python:  Embedding(input_dim, output_dim, init= uniform , W_regularizer=None, input_shape=None, name=None)  Parameters:   inputDim : Int   0. Size of the vocabulary.  outputDim : Int  = 0. Dimension of the dense embedding.  init : String representation of the initialization method for the weights of the layer. See  here  for available initialization strings. Default is \"uniform\".  wRegularizer : An instance of  Regularizer , (eg. L1 or L2 regularization), applied to the input weights matrices. Default is null.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, Embedding}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Embedding(8, 2, inputShape = Shape(4)))\nval input = Tensor[Float](2, 4)\ninput(Array(1, 1)) = 1\ninput(Array(1, 2)) = 2\ninput(Array(1, 3)) = 4\ninput(Array(1, 4)) = 5\ninput(Array(2, 1)) = 4\ninput(Array(2, 2)) = 3\ninput(Array(2, 3)) = 2\ninput(Array(2, 4)) = 6\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n1.0 2.0 4.0 5.0\n4.0 3.0 2.0 6.0\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.03256504      -0.043232664\n-0.044753443    0.026075097\n0.045668535     0.02456015\n0.021222712     -0.04373116\n\n(2,.,.) =\n0.045668535     0.02456015\n0.03761902      -0.0014174521\n-0.044753443    0.026075097\n-0.030343587    -0.0015718295\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x4x2]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Embedding\n\nmodel = Sequential()\nmodel.add(Embedding(8, 2, input_shape=(4,)))\ninput = np.random.randint(4, size=(2, 4))\noutput = model.forward(input)  Input is:  [[0 2 2 2]\n [2 1 1 0]]  Output is  [[[ 0.0094721  -0.01927968]\n  [-0.00483634 -0.03992473]\n  [-0.00483634 -0.03992473]\n  [-0.00483634 -0.03992473]]\n\n [[-0.00483634 -0.03992473]\n  [-0.03603687 -0.03708585]\n  [-0.03603687 -0.03708585]\n  [ 0.0094721  -0.01927968]]]", 
            "title": "Embedding"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/dropout/", 
            "text": "Dropout\n\n\nApplies Dropout to the input by randomly setting a fraction 'p' of input units to 0 at each update during training time in order to prevent overfitting.\n\n\nScala:\n\n\nDropout(p, inputShape = null)\n\n\n\n\nPython:\n\n\nDropout(p, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\np\n: Fraction of the input units to drop. Between 0 and 1.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, Dropout}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Dropout(0.3, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-1.1256621     2.5402398    -1.1346831   0.50337905\n-1.3835752     0.9513693    -0.24547328  -0.28897092\n-0.0302343     -0.4106753   0.46467322   -0.7328933\n\n(2,.,.) =\n1.2569109      0.16947697   -0.5000246   2.0856402\n-0.04246076    1.5827807    -1.0235463   1.7278075\n-0.0035352164  -1.2579697   0.206815     -0.053890422\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.0           0.0        -1.620976  0.0\n-1.976536     1.359099   0.0        -0.4128156\n-0.043191858  -0.586679  0.6638189  -1.0469904\n\n(2,.,.) =\n0.0            0.0         -0.7143209  2.979486\n-0.060658228   2.2611153   0.0         0.0\n-0.0050503095  -1.7970997  0.0         0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Dropout\n\nmodel = Sequential()\nmodel.add(Dropout(0.3, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.61976372 0.36074095 0.59003926 0.75373888]\n  [0.2390103  0.93491731 0.89078166 0.93083315]\n  [0.62360382 0.73646417 0.32886041 0.25372008]]\n\n [[0.10235195 0.7782206  0.54940485 0.41757437]\n  [0.94804637 0.04642807 0.17194449 0.2675274 ]\n  [0.89322413 0.3301816  0.49910094 0.00819342]]]\n\n\n\n\nOutput is\n\n\n[[[0.88537675 0.51534426 0.0        0.0       ]\n  [0.0        1.3355962  1.2725452  1.3297616 ]\n  [0.89086264 1.0520917  0.4698006  0.0       ]]\n\n [[0.14621708 1.1117437  0.7848641  0.59653485]\n  [1.354352   0.06632582 0.24563499 0.382182  ]\n  [1.2760345  0.471688   0.7130013  0.01170488]]]\n\n\n\n\n\n\nGaussianDropout\n\n\nApply multiplicative 1-centered Gaussian noise.\n\n\nAs it is a regularization layer, it is only active at training time.\n\n\nScala:\n\n\nGaussianDropout(p, inputShape = null)\n\n\n\n\nPython:\n\n\nGaussianDropout(p, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\np\n: Drop probability (as with 'Dropout'). The multiplicative noise will have standard deviation 'sqrt(p/(1-p))'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, GaussianDropout}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GaussianDropout(0.45, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.14522108 0.27993536  -0.38809696 0.26372102\n-0.5572615  0.091684595 0.27881327  -1.6235427\n-0.32884964 -0.46456075 1.6169231   0.31943536\n\n(2,.,.) =\n-1.813811   1.1577623   -0.8995344  -1.0607182\n-0.3952898  -2.3437335  -0.6608733  1.1752778\n-1.3373735  -1.7404749  0.82832927  0.3053458\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.27553135  0.15290284   -0.23144199  0.619676\n-0.6648747   0.053253293  -0.08241931  -0.47651786\n-0.46381548  -1.0048811   1.5911313    0.39929882\n\n(2,.,.) =\n-0.43828326  0.4397059    -0.7071283   -1.440457\n-0.27415445  -1.6525689   -0.14050363  0.8728552\n-2.0516112   -2.1537325   1.4714862    0.29218474\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import GaussianDropout\n\nmodel = Sequential()\nmodel.add(GaussianDropout(0.45, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.87208899 0.1353189  0.325058   0.63174633]\n  [0.20479221 0.29774652 0.42038452 0.23819006]\n  [0.07608872 0.91696766 0.245824   0.84324374]]\n\n [[0.26268714 0.76275494 0.63620997 0.15049668]\n  [0.54144135 0.70412821 0.05555471 0.72317157]\n  [0.32796076 0.26804862 0.80775221 0.46948471]]]\n\n\n\n\nOutput is\n\n\n[[[ 2.1392     -0.16185573 -0.18517245 -0.36539674]\n  [ 0.15324984  0.17320508  0.82520926  0.21734479]\n  [ 0.17601383  0.24906069  0.15664667  0.12675671]]\n\n [[ 0.49689308  1.8231225   1.0023257   0.37604305]\n  [ 1.2827866  -0.08726044  0.01333602  0.8518126 ]\n  [ 0.20021693  0.31828243  1.0940336   0.00866747]]]\n\n\n\n\n\n\nGaussianNoise\n\n\nApply additive zero-centered Gaussian noise.\n\n\nThis is useful to mitigate overfitting (you could see it as a form of random data augmentation).\n\n\nGaussian Noise is a natural choice as corruption process for real valued inputs.\n\n\nAs it is a regularization layer, it is only active at training time.\n\n\nScala:\n\n\nGaussianNoise(sigma, inputShape = null)\n\n\n\n\nPython:\n\n\nGaussianNoise(sigma, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nsigma\n: Standard deviation of the noise distribution.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, GaussianNoise}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GaussianNoise(0.6, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.4226985   -0.010519333  -0.49748304   -0.3176052\n0.52444375  0.31100306    1.0308859     2.0337727\n0.21513703  -0.396619     -0.055275716  -0.40603992\n\n(2,.,.) =\n-1.2393064  -0.536477     -0.35633054   -0.09068655\n-1.7297741  -0.5812992    -1.2833812    -0.7185058\n0.13474904  0.06468039    -0.6630115    1.2471422\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.72299504   0.7733576    -0.13965577   0.72079915\n0.20137814    0.6300731    2.5559645     2.3056328\n-0.19732013   -0.482926    -0.22114205   -0.88772345\n\n(2,.,.) =\n-1.4293398    -1.0870209   -0.5509953    -0.31268832\n-2.244024     -0.23773572  -3.022697     -0.65151817\n-0.035656676  -0.7470889   -0.8566216    1.1347939\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import GaussianNoise\n\nmodel = Sequential()\nmodel.add(GaussianNoise(0.6, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.61699657 0.9759922  0.62898391 0.57265605]\n  [0.88815108 0.9484446  0.0300381  0.54114527]\n  [0.94046216 0.05998474 0.24860526 0.82020617]]\n\n [[0.87308242 0.24780141 0.73385444 0.40836049]\n  [0.33166358 0.74540915 0.28333526 0.08263288]\n  [0.17527315 0.79798327 0.49351559 0.13895365]]]\n\n\n\n\nOutput is\n\n\n[[[ 1.5833025   1.1431103   0.14338043  1.634818  ]\n  [ 0.01713479  1.1608562   0.222246    0.40559798]\n  [ 0.9930201   0.1187391   -0.35643864 -0.7164774 ]]\n\n [[ 1.0105296   1.423961    0.90040827  1.3460591 ]\n  [ 0.943779    -0.48430538 0.20670155  -0.50143087]\n  [ -0.29849088 0.12774569  -0.16126743 -0.011041  ]]]\n\n\n\n\n\n\nSpatialDropout1D\n\n\nSpatial 1D version of Dropout.\n\n\nThis version performs the same function as Dropout, however it drops entire 1D feature maps instead of individual elements. If adjacent frames within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout1D will help promote independence between feature maps and should be used instead.\n\n\nThe input of this layer should be 3D.\n\n\nScala:\n\n\nSpatialDropout1D(p = 0.5, inputShape = null)\n\n\n\n\nPython:\n\n\nSpatialDropout1D(p=0.5, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\np\n: Fraction of the input units to drop. Between 0 and 1.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, SpatialDropout1D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SpatialDropout1D(inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.41961443 -0.3900255  -0.11937201 1.2904007\n-1.7623849  -1.6778483  -0.30053464 0.33295104\n-0.29824665 -0.25474855 -2.1878588  1.2741995\n\n(2,.,.) =\n0.24517925  2.0451863   -0.4281332  -1.2022524\n-0.7767442  0.24794191  -0.5614063  0.14720131\n-1.4832486  0.59478635  -0.13351384 -0.8799204\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.41961443 -0.0   -0.11937201  1.2904007\n-1.7623849  -0.0   -0.30053464  0.33295104\n-0.29824665 -0.0   -2.1878588   1.2741995\n\n(2,.,.) =\n0.24517925  0.0    -0.4281332   -0.0\n-0.7767442  0.0    -0.5614063   0.0\n-1.4832486  0.0    -0.13351384  -0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import SpatialDropout1D\n\nmodel = Sequential()\nmodel.add(SpatialDropout1D(input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.67162434 0.91104925 0.66869854 0.17295748]\n  [0.78326617 0.27447329 0.18051406 0.24230118]\n  [0.7098933  0.32496974 0.00517668 0.21293476]]\n\n [[0.26932307 0.33496273 0.71258256 0.15464896]\n  [0.75286915 0.210486   0.91826256 0.81379954]\n  [0.11960744 0.37420041 0.03886506 0.22882457]]]\n\n\n\n\nOutput is\n\n\n[[[0.0        0.0        0.0        0.0       ]\n  [0.0        0.0        0.0        0.0       ]\n  [0.0        0.0        0.0        0.0       ]]\n\n [[0.0        0.33496273 0.0        0.15464896]\n  [0.0        0.210486   0.0        0.81379956]\n  [0.0        0.3742004  0.0        0.22882457]]]\n\n\n\n\n\n\nSpatialDropout2D\n\n\nSpatial 2D version of Dropout.\n\n\nThis version performs the same function as Dropout, however it drops entire 2D feature maps instead of individual elements. If adjacent pixels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout2D will help promote independence between feature maps and should be used instead.\n\n\nThe input of this layer should be 4D.\n\n\nScala:\n\n\nSpatialDropout2D(p = 0.5, dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nSpatialDropout2D(p=0.5, dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\np\n: Fraction of the input units to drop. Between 0 and 1.\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, SpatialDropout2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SpatialDropout2D(inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n1.1651757   1.0867785   -0.56122786 -0.542156\n-0.79321486 0.64733976  -0.7040698  -0.8619171\n-0.61122066 -1.9640825  -1.0078672  -0.12195914\n\n(1,2,.,.) =\n-0.24738677 -0.9351172  -0.11694977 0.8657273\n-0.4773825  -1.6853696  -1.4906564  -0.06981948\n-0.8184341  -1.3537912  1.2442955   -0.0071462104\n\n(2,1,.,.) =\n1.8801081   0.44946647  0.47776535  0.036228795\n-1.2122079  0.41413695  -0.691067   2.6273472\n1.4293005   -1.2627622  -1.8263477  0.015581204\n\n(2,2,.,.) =\n2.0050068   -0.32893315 0.19670151  0.8031714\n0.16645809  -0.68172836 0.5169275   -0.83938134\n0.1789333   2.1845143   1.3843338   -0.8283524\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.0         0.0         -0.0        -0.0\n-0.0        0.0         -0.0        -0.0\n-0.0        -0.0        -0.0        -0.0\n\n(1,2,.,.) =\n-0.0        -0.0        -0.0        0.0\n-0.0        -0.0        -0.0        -0.0\n-0.0        -0.0        0.0         -0.0\n\n(2,1,.,.) =\n1.8801081   0.44946647  0.47776535  0.036228795\n-1.2122079  0.41413695  -0.691067   2.6273472\n1.4293005   -1.2627622  -1.8263477  0.015581204\n\n(2,2,.,.) =\n2.0050068   -0.32893315 0.19670151  0.8031714\n0.16645809  -0.68172836 0.5169275   -0.83938134\n0.1789333   2.1845143   1.3843338   -0.8283524\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import SpatialDropout2D\n\nmodel = Sequential()\nmodel.add(SpatialDropout2D(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[0.21864846 0.43531162 0.23078088 0.81122115]\n   [0.19442596 0.11110444 0.533805   0.68291312]\n   [0.40738259 0.05448269 0.04647733 0.41683944]]\n  [[0.23354645 0.46005503 0.87695602 0.13318982]\n   [0.2596346  0.67654484 0.79389709 0.50408343]\n   [0.50043622 0.28028835 0.81897585 0.01629935]]]\n\n [[[0.32173241 0.38367311 0.10315543 0.22691558]\n   [0.41640003 0.45932496 0.70795718 0.67185326]\n   [0.11911477 0.90231481 0.49881045 0.74297438]]\n  [[0.48873758 0.53475116 0.06801025 0.50640297]\n   [0.95740488 0.14928652 0.10466387 0.29040436]\n   [0.44062539 0.36983024 0.35326756 0.60592402]]]]\n\n\n\n\nOutput is\n\n\n[[[[0.21864846 0.43531162 0.23078088 0.8112211 ]\n   [0.19442596 0.11110444 0.533805   0.6829131 ]\n   [0.4073826  0.05448269 0.04647733 0.41683942]]\n  [[0.23354645 0.46005502 0.87695605 0.13318983]\n   [0.2596346  0.67654485 0.7938971  0.50408345]\n   [0.50043625 0.28028834 0.81897587 0.01629935]]]\n\n [[[0.0        0.0        0.0        0.0       ]\n   [0.0        0.0        0.0        0.0       ]\n   [0.0        0.0        0.0        0.0       ]]\n  [[0.48873758 0.5347512  0.06801025 0.50640297]\n   [0.95740485 0.14928652 0.10466387 0.29040435]\n   [0.4406254  0.36983025 0.35326755 0.605924  ]]]]\n\n\n\n\n\n\nSpatialDropout3D\n\n\nSpatial 3D version of Dropout.\n\n\nThis version performs the same function as Dropout, however it drops entire 3D feature maps instead of individual elements. If adjacent voxels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout3D will help promote independence between feature maps and should be used instead.\n\n\nThe input of this layer should be 5D.\n\n\nScala:\n\n\nSpatialDropout3D(p = 0.5, dimOrdering = \nth\n, inputShape = null)\n\n\n\n\nPython:\n\n\nSpatialDropout3D(p=0.5, dim_ordering=\nth\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\np\n: Fraction of the input units to drop. Between 0 and 1.\n\n\ndimOrdering\n: Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, SpatialDropout3D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SpatialDropout3D(inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n0.28834015    -0.74598366  0.16951436\n0.17009573    0.3626017    -0.24652131\n\n(1,1,2,.,.) =\n1.3008109     0.37243804   0.073205866\n1.0715603     0.02033514   -1.7862324\n\n(1,2,1,.,.) =\n-0.5285066    -1.3859391   -1.0543352\n0.7904896     0.7473174    -0.5941196\n\n(1,2,2,.,.) =\n-0.060706574  -2.4405587    1.5963978\n-0.33285397   -0.48576602   0.8121179\n\n(2,1,1,.,.) =\n-0.7060156    0.31667668    -0.28765643\n-1.3115436    -1.7266335    1.0080509\n\n(2,1,2,.,.) =\n1.2365453     -0.13272893   -1.2130978\n0.26921487    -0.66259027   0.5537464\n\n(2,2,1,.,.) =\n1.6578121     -0.09890133   0.4794677\n1.5102282     0.067802615   0.76998603\n\n(2,2,2,.,.) =\n-0.47348467   0.19535838    0.62601316\n-2.4771519    -0.40744382   0.04029308\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.0             -0.0        0.0\n0.0             0.0         -0.0\n\n(1,1,2,.,.) =\n0.0             0.0         0.0\n0.0             0.0         -0.0\n\n(1,2,1,.,.) =\n-0.5285066      -1.3859391  -1.0543352\n0.7904896       0.7473174   -0.5941196\n\n(1,2,2,.,.) =\n-0.060706574    -2.4405587  1.5963978\n-0.33285397     -0.48576602 0.8121179\n\n(2,1,1,.,.) =\n-0.0            0.0         -0.0\n-0.0            -0.0        0.0\n\n(2,1,2,.,.) =\n0.0             -0.0        -0.0\n0.0             -0.0        0.0\n\n(2,2,1,.,.) =\n0.0             -0.0        0.0\n0.0             0.0         0.0\n\n(2,2,2,.,.) =\n-0.0            0.0         0.0\n-0.0            -0.0        0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import SpatialDropout3D\n\nmodel = Sequential()\nmodel.add(SpatialDropout3D(input_shape=(2, 2, 2, 2)))\ninput = np.random.random([2, 2, 2, 2, 2])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[[[0.68128454 0.57379206]\n    [0.19533742 0.19906853]]\n   [[0.21527836 0.79586573]\n    [0.51065215 0.94422278]]]\n  [[[0.95178211 0.50359204]\n    [0.0306965  0.92563536]]\n   [[0.33744311 0.58750719]\n    [0.45437398 0.7081438 ]]]]\n\n [[[[0.00235233 0.8092749 ]\n    [0.65525661 0.01079958]]\n   [[0.29877429 0.42090468]\n    [0.28265598 0.81520172]]]\n  [[[0.91811333 0.3275563 ]\n    [0.66125455 0.15555596]]\n   [[0.53651033 0.66013486]\n    [0.45874838 0.7613676 ]]]]]\n\n\n\n\nOutput is\n\n\n[[[[[0.68128455 0.57379204]\n    [0.19533743 0.19906853]]\n   [[0.21527836 0.7958657 ]\n    [0.5106521  0.94422275]]]\n  [[[0.0        0.0       ]\n    [0.0        0.0       ]]\n   [[0.0        0.0       ]\n    [0.0        0.0       ]]]]\n\n [[[[0.0        0.0       ]\n    [0.0        0.0       ]]\n   [[0.0        0.0       ]\n    [0.0        0.0       ]]]\n  [[[0.91811335 0.3275563 ]\n    [0.6612545  0.15555596]]\n   [[0.53651035 0.66013485]\n    [0.45874837 0.7613676 ]]]]]", 
            "title": "Dropout Layers"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/dropout/#dropout", 
            "text": "Applies Dropout to the input by randomly setting a fraction 'p' of input units to 0 at each update during training time in order to prevent overfitting.  Scala:  Dropout(p, inputShape = null)  Python:  Dropout(p, input_shape=None, name=None)  Parameters:   p : Fraction of the input units to drop. Between 0 and 1.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, Dropout}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Dropout(0.3, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-1.1256621     2.5402398    -1.1346831   0.50337905\n-1.3835752     0.9513693    -0.24547328  -0.28897092\n-0.0302343     -0.4106753   0.46467322   -0.7328933\n\n(2,.,.) =\n1.2569109      0.16947697   -0.5000246   2.0856402\n-0.04246076    1.5827807    -1.0235463   1.7278075\n-0.0035352164  -1.2579697   0.206815     -0.053890422\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.0           0.0        -1.620976  0.0\n-1.976536     1.359099   0.0        -0.4128156\n-0.043191858  -0.586679  0.6638189  -1.0469904\n\n(2,.,.) =\n0.0            0.0         -0.7143209  2.979486\n-0.060658228   2.2611153   0.0         0.0\n-0.0050503095  -1.7970997  0.0         0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Dropout\n\nmodel = Sequential()\nmodel.add(Dropout(0.3, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  [[[0.61976372 0.36074095 0.59003926 0.75373888]\n  [0.2390103  0.93491731 0.89078166 0.93083315]\n  [0.62360382 0.73646417 0.32886041 0.25372008]]\n\n [[0.10235195 0.7782206  0.54940485 0.41757437]\n  [0.94804637 0.04642807 0.17194449 0.2675274 ]\n  [0.89322413 0.3301816  0.49910094 0.00819342]]]  Output is  [[[0.88537675 0.51534426 0.0        0.0       ]\n  [0.0        1.3355962  1.2725452  1.3297616 ]\n  [0.89086264 1.0520917  0.4698006  0.0       ]]\n\n [[0.14621708 1.1117437  0.7848641  0.59653485]\n  [1.354352   0.06632582 0.24563499 0.382182  ]\n  [1.2760345  0.471688   0.7130013  0.01170488]]]", 
            "title": "Dropout"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/dropout/#gaussiandropout", 
            "text": "Apply multiplicative 1-centered Gaussian noise.  As it is a regularization layer, it is only active at training time.  Scala:  GaussianDropout(p, inputShape = null)  Python:  GaussianDropout(p, input_shape=None, name=None)  Parameters:   p : Drop probability (as with 'Dropout'). The multiplicative noise will have standard deviation 'sqrt(p/(1-p))'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, GaussianDropout}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GaussianDropout(0.45, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.14522108 0.27993536  -0.38809696 0.26372102\n-0.5572615  0.091684595 0.27881327  -1.6235427\n-0.32884964 -0.46456075 1.6169231   0.31943536\n\n(2,.,.) =\n-1.813811   1.1577623   -0.8995344  -1.0607182\n-0.3952898  -2.3437335  -0.6608733  1.1752778\n-1.3373735  -1.7404749  0.82832927  0.3053458\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.27553135  0.15290284   -0.23144199  0.619676\n-0.6648747   0.053253293  -0.08241931  -0.47651786\n-0.46381548  -1.0048811   1.5911313    0.39929882\n\n(2,.,.) =\n-0.43828326  0.4397059    -0.7071283   -1.440457\n-0.27415445  -1.6525689   -0.14050363  0.8728552\n-2.0516112   -2.1537325   1.4714862    0.29218474\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import GaussianDropout\n\nmodel = Sequential()\nmodel.add(GaussianDropout(0.45, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  [[[0.87208899 0.1353189  0.325058   0.63174633]\n  [0.20479221 0.29774652 0.42038452 0.23819006]\n  [0.07608872 0.91696766 0.245824   0.84324374]]\n\n [[0.26268714 0.76275494 0.63620997 0.15049668]\n  [0.54144135 0.70412821 0.05555471 0.72317157]\n  [0.32796076 0.26804862 0.80775221 0.46948471]]]  Output is  [[[ 2.1392     -0.16185573 -0.18517245 -0.36539674]\n  [ 0.15324984  0.17320508  0.82520926  0.21734479]\n  [ 0.17601383  0.24906069  0.15664667  0.12675671]]\n\n [[ 0.49689308  1.8231225   1.0023257   0.37604305]\n  [ 1.2827866  -0.08726044  0.01333602  0.8518126 ]\n  [ 0.20021693  0.31828243  1.0940336   0.00866747]]]", 
            "title": "GaussianDropout"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/dropout/#gaussiannoise", 
            "text": "Apply additive zero-centered Gaussian noise.  This is useful to mitigate overfitting (you could see it as a form of random data augmentation).  Gaussian Noise is a natural choice as corruption process for real valued inputs.  As it is a regularization layer, it is only active at training time.  Scala:  GaussianNoise(sigma, inputShape = null)  Python:  GaussianNoise(sigma, input_shape=None, name=None)  Parameters:   sigma : Standard deviation of the noise distribution.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, GaussianNoise}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(GaussianNoise(0.6, inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.4226985   -0.010519333  -0.49748304   -0.3176052\n0.52444375  0.31100306    1.0308859     2.0337727\n0.21513703  -0.396619     -0.055275716  -0.40603992\n\n(2,.,.) =\n-1.2393064  -0.536477     -0.35633054   -0.09068655\n-1.7297741  -0.5812992    -1.2833812    -0.7185058\n0.13474904  0.06468039    -0.6630115    1.2471422\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.72299504   0.7733576    -0.13965577   0.72079915\n0.20137814    0.6300731    2.5559645     2.3056328\n-0.19732013   -0.482926    -0.22114205   -0.88772345\n\n(2,.,.) =\n-1.4293398    -1.0870209   -0.5509953    -0.31268832\n-2.244024     -0.23773572  -3.022697     -0.65151817\n-0.035656676  -0.7470889   -0.8566216    1.1347939\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import GaussianNoise\n\nmodel = Sequential()\nmodel.add(GaussianNoise(0.6, input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  [[[0.61699657 0.9759922  0.62898391 0.57265605]\n  [0.88815108 0.9484446  0.0300381  0.54114527]\n  [0.94046216 0.05998474 0.24860526 0.82020617]]\n\n [[0.87308242 0.24780141 0.73385444 0.40836049]\n  [0.33166358 0.74540915 0.28333526 0.08263288]\n  [0.17527315 0.79798327 0.49351559 0.13895365]]]  Output is  [[[ 1.5833025   1.1431103   0.14338043  1.634818  ]\n  [ 0.01713479  1.1608562   0.222246    0.40559798]\n  [ 0.9930201   0.1187391   -0.35643864 -0.7164774 ]]\n\n [[ 1.0105296   1.423961    0.90040827  1.3460591 ]\n  [ 0.943779    -0.48430538 0.20670155  -0.50143087]\n  [ -0.29849088 0.12774569  -0.16126743 -0.011041  ]]]", 
            "title": "GaussianNoise"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/dropout/#spatialdropout1d", 
            "text": "Spatial 1D version of Dropout.  This version performs the same function as Dropout, however it drops entire 1D feature maps instead of individual elements. If adjacent frames within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout1D will help promote independence between feature maps and should be used instead.  The input of this layer should be 3D.  Scala:  SpatialDropout1D(p = 0.5, inputShape = null)  Python:  SpatialDropout1D(p=0.5, input_shape=None, name=None)  Parameters:   p : Fraction of the input units to drop. Between 0 and 1.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, SpatialDropout1D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SpatialDropout1D(inputShape = Shape(3, 4)))\nval input = Tensor[Float](2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.41961443 -0.3900255  -0.11937201 1.2904007\n-1.7623849  -1.6778483  -0.30053464 0.33295104\n-0.29824665 -0.25474855 -2.1878588  1.2741995\n\n(2,.,.) =\n0.24517925  2.0451863   -0.4281332  -1.2022524\n-0.7767442  0.24794191  -0.5614063  0.14720131\n-1.4832486  0.59478635  -0.13351384 -0.8799204\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n-0.41961443 -0.0   -0.11937201  1.2904007\n-1.7623849  -0.0   -0.30053464  0.33295104\n-0.29824665 -0.0   -2.1878588   1.2741995\n\n(2,.,.) =\n0.24517925  0.0    -0.4281332   -0.0\n-0.7767442  0.0    -0.5614063   0.0\n-1.4832486  0.0    -0.13351384  -0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3x4]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import SpatialDropout1D\n\nmodel = Sequential()\nmodel.add(SpatialDropout1D(input_shape=(3, 4)))\ninput = np.random.random([2, 3, 4])\noutput = model.forward(input)  Input is:  [[[0.67162434 0.91104925 0.66869854 0.17295748]\n  [0.78326617 0.27447329 0.18051406 0.24230118]\n  [0.7098933  0.32496974 0.00517668 0.21293476]]\n\n [[0.26932307 0.33496273 0.71258256 0.15464896]\n  [0.75286915 0.210486   0.91826256 0.81379954]\n  [0.11960744 0.37420041 0.03886506 0.22882457]]]  Output is  [[[0.0        0.0        0.0        0.0       ]\n  [0.0        0.0        0.0        0.0       ]\n  [0.0        0.0        0.0        0.0       ]]\n\n [[0.0        0.33496273 0.0        0.15464896]\n  [0.0        0.210486   0.0        0.81379956]\n  [0.0        0.3742004  0.0        0.22882457]]]", 
            "title": "SpatialDropout1D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/dropout/#spatialdropout2d", 
            "text": "Spatial 2D version of Dropout.  This version performs the same function as Dropout, however it drops entire 2D feature maps instead of individual elements. If adjacent pixels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout2D will help promote independence between feature maps and should be used instead.  The input of this layer should be 4D.  Scala:  SpatialDropout2D(p = 0.5, dimOrdering =  th , inputShape = null)  Python:  SpatialDropout2D(p=0.5, dim_ordering= th , input_shape=None, name=None)  Parameters:   p : Fraction of the input units to drop. Between 0 and 1.  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, SpatialDropout2D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SpatialDropout2D(inputShape = Shape(2, 3, 4)))\nval input = Tensor[Float](2, 2, 3, 4).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,.,.) =\n1.1651757   1.0867785   -0.56122786 -0.542156\n-0.79321486 0.64733976  -0.7040698  -0.8619171\n-0.61122066 -1.9640825  -1.0078672  -0.12195914\n\n(1,2,.,.) =\n-0.24738677 -0.9351172  -0.11694977 0.8657273\n-0.4773825  -1.6853696  -1.4906564  -0.06981948\n-0.8184341  -1.3537912  1.2442955   -0.0071462104\n\n(2,1,.,.) =\n1.8801081   0.44946647  0.47776535  0.036228795\n-1.2122079  0.41413695  -0.691067   2.6273472\n1.4293005   -1.2627622  -1.8263477  0.015581204\n\n(2,2,.,.) =\n2.0050068   -0.32893315 0.19670151  0.8031714\n0.16645809  -0.68172836 0.5169275   -0.83938134\n0.1789333   2.1845143   1.3843338   -0.8283524\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,.,.) =\n0.0         0.0         -0.0        -0.0\n-0.0        0.0         -0.0        -0.0\n-0.0        -0.0        -0.0        -0.0\n\n(1,2,.,.) =\n-0.0        -0.0        -0.0        0.0\n-0.0        -0.0        -0.0        -0.0\n-0.0        -0.0        0.0         -0.0\n\n(2,1,.,.) =\n1.8801081   0.44946647  0.47776535  0.036228795\n-1.2122079  0.41413695  -0.691067   2.6273472\n1.4293005   -1.2627622  -1.8263477  0.015581204\n\n(2,2,.,.) =\n2.0050068   -0.32893315 0.19670151  0.8031714\n0.16645809  -0.68172836 0.5169275   -0.83938134\n0.1789333   2.1845143   1.3843338   -0.8283524\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3x4]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import SpatialDropout2D\n\nmodel = Sequential()\nmodel.add(SpatialDropout2D(input_shape=(2, 3, 4)))\ninput = np.random.random([2, 2, 3, 4])\noutput = model.forward(input)  Input is:  [[[[0.21864846 0.43531162 0.23078088 0.81122115]\n   [0.19442596 0.11110444 0.533805   0.68291312]\n   [0.40738259 0.05448269 0.04647733 0.41683944]]\n  [[0.23354645 0.46005503 0.87695602 0.13318982]\n   [0.2596346  0.67654484 0.79389709 0.50408343]\n   [0.50043622 0.28028835 0.81897585 0.01629935]]]\n\n [[[0.32173241 0.38367311 0.10315543 0.22691558]\n   [0.41640003 0.45932496 0.70795718 0.67185326]\n   [0.11911477 0.90231481 0.49881045 0.74297438]]\n  [[0.48873758 0.53475116 0.06801025 0.50640297]\n   [0.95740488 0.14928652 0.10466387 0.29040436]\n   [0.44062539 0.36983024 0.35326756 0.60592402]]]]  Output is  [[[[0.21864846 0.43531162 0.23078088 0.8112211 ]\n   [0.19442596 0.11110444 0.533805   0.6829131 ]\n   [0.4073826  0.05448269 0.04647733 0.41683942]]\n  [[0.23354645 0.46005502 0.87695605 0.13318983]\n   [0.2596346  0.67654485 0.7938971  0.50408345]\n   [0.50043625 0.28028834 0.81897587 0.01629935]]]\n\n [[[0.0        0.0        0.0        0.0       ]\n   [0.0        0.0        0.0        0.0       ]\n   [0.0        0.0        0.0        0.0       ]]\n  [[0.48873758 0.5347512  0.06801025 0.50640297]\n   [0.95740485 0.14928652 0.10466387 0.29040435]\n   [0.4406254  0.36983025 0.35326755 0.605924  ]]]]", 
            "title": "SpatialDropout2D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/dropout/#spatialdropout3d", 
            "text": "Spatial 3D version of Dropout.  This version performs the same function as Dropout, however it drops entire 3D feature maps instead of individual elements. If adjacent voxels within feature maps are strongly correlated (as is normally the case in early convolution layers) then regular dropout will not regularize the activations and will otherwise just result in an effective learning rate decrease. In this case, SpatialDropout3D will help promote independence between feature maps and should be used instead.  The input of this layer should be 5D.  Scala:  SpatialDropout3D(p = 0.5, dimOrdering =  th , inputShape = null)  Python:  SpatialDropout3D(p=0.5, dim_ordering= th , input_shape=None, name=None)  Parameters:   p : Fraction of the input units to drop. Between 0 and 1.  dimOrdering : Format of input data. Either 'th' (Channel First) or 'tf' (Channel Last). Default is 'th'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, SpatialDropout3D}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SpatialDropout3D(inputShape = Shape(2, 2, 2, 3)))\nval input = Tensor[Float](2, 2, 2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,1,1,.,.) =\n0.28834015    -0.74598366  0.16951436\n0.17009573    0.3626017    -0.24652131\n\n(1,1,2,.,.) =\n1.3008109     0.37243804   0.073205866\n1.0715603     0.02033514   -1.7862324\n\n(1,2,1,.,.) =\n-0.5285066    -1.3859391   -1.0543352\n0.7904896     0.7473174    -0.5941196\n\n(1,2,2,.,.) =\n-0.060706574  -2.4405587    1.5963978\n-0.33285397   -0.48576602   0.8121179\n\n(2,1,1,.,.) =\n-0.7060156    0.31667668    -0.28765643\n-1.3115436    -1.7266335    1.0080509\n\n(2,1,2,.,.) =\n1.2365453     -0.13272893   -1.2130978\n0.26921487    -0.66259027   0.5537464\n\n(2,2,1,.,.) =\n1.6578121     -0.09890133   0.4794677\n1.5102282     0.067802615   0.76998603\n\n(2,2,2,.,.) =\n-0.47348467   0.19535838    0.62601316\n-2.4771519    -0.40744382   0.04029308\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,1,1,.,.) =\n0.0             -0.0        0.0\n0.0             0.0         -0.0\n\n(1,1,2,.,.) =\n0.0             0.0         0.0\n0.0             0.0         -0.0\n\n(1,2,1,.,.) =\n-0.5285066      -1.3859391  -1.0543352\n0.7904896       0.7473174   -0.5941196\n\n(1,2,2,.,.) =\n-0.060706574    -2.4405587  1.5963978\n-0.33285397     -0.48576602 0.8121179\n\n(2,1,1,.,.) =\n-0.0            0.0         -0.0\n-0.0            -0.0        0.0\n\n(2,1,2,.,.) =\n0.0             -0.0        -0.0\n0.0             -0.0        0.0\n\n(2,2,1,.,.) =\n0.0             -0.0        0.0\n0.0             0.0         0.0\n\n(2,2,2,.,.) =\n-0.0            0.0         0.0\n-0.0            -0.0        0.0\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x2x2x3]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import SpatialDropout3D\n\nmodel = Sequential()\nmodel.add(SpatialDropout3D(input_shape=(2, 2, 2, 2)))\ninput = np.random.random([2, 2, 2, 2, 2])\noutput = model.forward(input)  Input is:  [[[[[0.68128454 0.57379206]\n    [0.19533742 0.19906853]]\n   [[0.21527836 0.79586573]\n    [0.51065215 0.94422278]]]\n  [[[0.95178211 0.50359204]\n    [0.0306965  0.92563536]]\n   [[0.33744311 0.58750719]\n    [0.45437398 0.7081438 ]]]]\n\n [[[[0.00235233 0.8092749 ]\n    [0.65525661 0.01079958]]\n   [[0.29877429 0.42090468]\n    [0.28265598 0.81520172]]]\n  [[[0.91811333 0.3275563 ]\n    [0.66125455 0.15555596]]\n   [[0.53651033 0.66013486]\n    [0.45874838 0.7613676 ]]]]]  Output is  [[[[[0.68128455 0.57379204]\n    [0.19533743 0.19906853]]\n   [[0.21527836 0.7958657 ]\n    [0.5106521  0.94422275]]]\n  [[[0.0        0.0       ]\n    [0.0        0.0       ]]\n   [[0.0        0.0       ]\n    [0.0        0.0       ]]]]\n\n [[[[0.0        0.0       ]\n    [0.0        0.0       ]]\n   [[0.0        0.0       ]\n    [0.0        0.0       ]]]\n  [[[0.91811335 0.3275563 ]\n    [0.6612545  0.15555596]]\n   [[0.53651035 0.66013485]\n    [0.45874837 0.7613676 ]]]]]", 
            "title": "SpatialDropout3D"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/advanced-activation/", 
            "text": "ELU\n\n\nExponential Linear Unit.\n\n\nIt follows: f(x) =  alpha * (exp(x) - 1.) for x \n 0, f(x) = x for x \n= 0.\n\n\nScala:\n\n\nELU(alpha = 1.0, inputShape = null)\n\n\n\n\nPython:\n\n\nELU(alpha=1.0, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nalpha\n: Scale for the negative factor. Default is 1.0.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, ELU}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ELU(inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.13405465 0.05160992  -1.4711418\n1.5808829   -1.3145303  0.6709266\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.1254577  0.05160992  -0.77033687\n1.5808829   -0.73139954 0.6709266\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import ELU\n\nmodel = Sequential()\nmodel.add(ELU(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[0.90404922 0.23530925 0.49711093]\n [0.43009161 0.22446032 0.90144771]]\n\n\n\n\nOutput is\n\n\n[[0.9040492  0.23530924 0.49711093]\n [0.43009162 0.22446032 0.9014477 ]]\n\n\n\n\n\n\nLeakyReLU\n\n\nLeaky version of a Rectified Linear Unit.\n\n\nIt allows a small gradient when the unit is not active: f(x) = alpha * x for x \n 0, f(x) = x for x \n= 0.\n\n\nScala:\n\n\nLeakyReLU(alpha = 0.3, inputShape = null)\n\n\n\n\nPython:\n\n\nLeakyReLU(alpha=0.3, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nalpha\n: Negative slope coefficient. Default is 0.3.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, LeakyReLU}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(LeakyReLU(inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.8846715    -0.5720033  -0.8220917\n-0.51755846  1.099684    2.6011446\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.8846715       -0.005720033   -0.008220917\n-0.0051755845   1.099684       2.6011446\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import LeakyReLU\n\nmodel = Sequential()\nmodel.add(LeakyReLU(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[0.14422043 0.38066946 0.55092494]\n [0.60075682 0.53505094 0.78330962]]\n\n\n\n\nOutput is\n\n\n[[0.14422044 0.38066944 0.55092496]\n [0.6007568  0.5350509  0.78330964]]\n\n\n\n\n\n\nSReLU\n\n\nS-shaped Rectified Linear Unit.\n\n\nIt follows: f(x) = t^r + a^r(x - t^r) for x \n= t^r, f(x) = x for t^r \n x \n t^l, f(x) = t^l + a^l(x - t^l) for x \n= t^l.\n\n\nScala:\n\n\nSReLU(tLeftInit = \nzero\n, aLeftInit = \nglorot_uniform\n, tRightInit = \nglorot_uniform\n, aRightInit = \none\n, sharedAxes = null, inputShape = null)\n\n\n\n\nPython:\n\n\nSReLU(t_left_init=\nzero\n, a_left_init=\nglorot_uniform\n, t_right_init=\nglorot_uniform\n, a_right_init=\none\n, shared_axes=None, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ntLeftInit\n: String representation of the initialization method for the left part intercept. See \nhere\n for available initialization strings. Default is 'zero'.\n\n\naLeftInit\n: String representation of the initialization method for the left part slope. See \nhere\n for available initialization strings. Default is 'glorot_uniform'.\n\n\ntRightInit\n: String representation of ithe nitialization method for the right part intercept. See \nhere\n for available initialization strings. Default is 'glorot_uniform'.\n\n\naRightInit\n: String representation of the initialization method for the right part slope. See \nhere\n for available initialization strings. Default is 'one'.\n\n\nsharedAxes\n: The axes along which to share learnable parameters for the activation function. Default is null.\nFor example, if the incoming feature maps are from a 2D convolution with output shape (batch, height, width, channels), and you wish to share parameters across space so that each filter only has one set of parameters, set 'sharedAxes = Array(1,2)'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, SReLU}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SReLU(inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.5599429   0.22811626  -0.027771426\n-0.56582874 1.9261217   1.2686813\n\n(2,.,.) =\n0.7538568   0.8725621   0.19803657\n0.49057     0.0537252   0.8684544\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.5599429   0.22811626  -0.009864618\n0.07011698  1.9261217   1.2686813\n\n(2,.,.) =\n0.7538568   0.87256205  0.19803657\n0.49057     0.0537252   0.8684544\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import SReLU\n\nmodel = Sequential()\nmodel.add(SReLU(input_shape=(2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.42998132 0.47736492 0.9554154 ]\n  [0.93264942 0.56851545 0.39508313]]\n\n [[0.5164102  0.22304862 0.44380779]\n  [0.69137804 0.26413953 0.60638032]]]\n\n\n\n\nOutput is\n\n\n[[[0.42998132 0.47736493 0.9554154 ]\n  [0.93264943 0.5685154  0.39508313]]\n\n [[0.5164102  0.22304863 0.44380778]\n  [0.69137806 0.26413953 0.60638034]]]\n\n\n\n\n\n\nThresholdedReLU\n\n\nThresholded Rectified Linear Unit.\n\n\nIt follows: f(x) = x for x \n theta, f(x) = 0 otherwise.\n\n\nScala:\n\n\nThresholdedReLU(theta = 1.0, inputShape = null)\n\n\n\n\nPython:\n\n\nThresholdedReLU(theta=1.0, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\ntheta\n: Threshold location of activation. Default is 1.0.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, ThresholdedReLU}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ThresholdedReLU(inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n2.220999    1.2022058   -1.0015608\n0.6532913   0.31831574  1.6747104\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n2.220999    1.2022058   0.0\n0.0         0.0         1.6747104\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import ThresholdedReLU\n\nmodel = Sequential()\nmodel.add(ThresholdedReLU(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[0.91854565 0.58317415 0.33089385]\n [0.82472184 0.70572913 0.32803604]]\n\n\n\n\nOutput is\n\n\n[[0.0   0.0   0.0]\n [0.0   0.0   0.0]]", 
            "title": "Advanced Activations"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/advanced-activation/#elu", 
            "text": "Exponential Linear Unit.  It follows: f(x) =  alpha * (exp(x) - 1.) for x   0, f(x) = x for x  = 0.  Scala:  ELU(alpha = 1.0, inputShape = null)  Python:  ELU(alpha=1.0, input_shape=None, name=None)  Parameters:   alpha : Scale for the negative factor. Default is 1.0.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, ELU}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ELU(inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n-0.13405465 0.05160992  -1.4711418\n1.5808829   -1.3145303  0.6709266\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n-0.1254577  0.05160992  -0.77033687\n1.5808829   -0.73139954 0.6709266\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import ELU\n\nmodel = Sequential()\nmodel.add(ELU(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  [[0.90404922 0.23530925 0.49711093]\n [0.43009161 0.22446032 0.90144771]]  Output is  [[0.9040492  0.23530924 0.49711093]\n [0.43009162 0.22446032 0.9014477 ]]", 
            "title": "ELU"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/advanced-activation/#leakyrelu", 
            "text": "Leaky version of a Rectified Linear Unit.  It allows a small gradient when the unit is not active: f(x) = alpha * x for x   0, f(x) = x for x  = 0.  Scala:  LeakyReLU(alpha = 0.3, inputShape = null)  Python:  LeakyReLU(alpha=0.3, input_shape=None, name=None)  Parameters:   alpha : Negative slope coefficient. Default is 0.3.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, LeakyReLU}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(LeakyReLU(inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n0.8846715    -0.5720033  -0.8220917\n-0.51755846  1.099684    2.6011446\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n0.8846715       -0.005720033   -0.008220917\n-0.0051755845   1.099684       2.6011446\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import LeakyReLU\n\nmodel = Sequential()\nmodel.add(LeakyReLU(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  [[0.14422043 0.38066946 0.55092494]\n [0.60075682 0.53505094 0.78330962]]  Output is  [[0.14422044 0.38066944 0.55092496]\n [0.6007568  0.5350509  0.78330964]]", 
            "title": "LeakyReLU"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/advanced-activation/#srelu", 
            "text": "S-shaped Rectified Linear Unit.  It follows: f(x) = t^r + a^r(x - t^r) for x  = t^r, f(x) = x for t^r   x   t^l, f(x) = t^l + a^l(x - t^l) for x  = t^l.  Scala:  SReLU(tLeftInit =  zero , aLeftInit =  glorot_uniform , tRightInit =  glorot_uniform , aRightInit =  one , sharedAxes = null, inputShape = null)  Python:  SReLU(t_left_init= zero , a_left_init= glorot_uniform , t_right_init= glorot_uniform , a_right_init= one , shared_axes=None, input_shape=None, name=None)  Parameters:   tLeftInit : String representation of the initialization method for the left part intercept. See  here  for available initialization strings. Default is 'zero'.  aLeftInit : String representation of the initialization method for the left part slope. See  here  for available initialization strings. Default is 'glorot_uniform'.  tRightInit : String representation of ithe nitialization method for the right part intercept. See  here  for available initialization strings. Default is 'glorot_uniform'.  aRightInit : String representation of the initialization method for the right part slope. See  here  for available initialization strings. Default is 'one'.  sharedAxes : The axes along which to share learnable parameters for the activation function. Default is null.\nFor example, if the incoming feature maps are from a 2D convolution with output shape (batch, height, width, channels), and you wish to share parameters across space so that each filter only has one set of parameters, set 'sharedAxes = Array(1,2)'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, SReLU}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(SReLU(inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.5599429   0.22811626  -0.027771426\n-0.56582874 1.9261217   1.2686813\n\n(2,.,.) =\n0.7538568   0.8725621   0.19803657\n0.49057     0.0537252   0.8684544\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.5599429   0.22811626  -0.009864618\n0.07011698  1.9261217   1.2686813\n\n(2,.,.) =\n0.7538568   0.87256205  0.19803657\n0.49057     0.0537252   0.8684544\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import SReLU\n\nmodel = Sequential()\nmodel.add(SReLU(input_shape=(2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)  Input is:  [[[0.42998132 0.47736492 0.9554154 ]\n  [0.93264942 0.56851545 0.39508313]]\n\n [[0.5164102  0.22304862 0.44380779]\n  [0.69137804 0.26413953 0.60638032]]]  Output is  [[[0.42998132 0.47736493 0.9554154 ]\n  [0.93264943 0.5685154  0.39508313]]\n\n [[0.5164102  0.22304863 0.44380778]\n  [0.69137806 0.26413953 0.60638034]]]", 
            "title": "SReLU"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/advanced-activation/#thresholdedrelu", 
            "text": "Thresholded Rectified Linear Unit.  It follows: f(x) = x for x   theta, f(x) = 0 otherwise.  Scala:  ThresholdedReLU(theta = 1.0, inputShape = null)  Python:  ThresholdedReLU(theta=1.0, input_shape=None, name=None)  Parameters:   theta : Threshold location of activation. Default is 1.0.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, ThresholdedReLU}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(ThresholdedReLU(inputShape = Shape(3)))\nval input = Tensor[Float](2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n2.220999    1.2022058   -1.0015608\n0.6532913   0.31831574  1.6747104\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n2.220999    1.2022058   0.0\n0.0         0.0         1.6747104\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x3]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import ThresholdedReLU\n\nmodel = Sequential()\nmodel.add(ThresholdedReLU(input_shape=(3, )))\ninput = np.random.random([2, 3])\noutput = model.forward(input)  Input is:  [[0.91854565 0.58317415 0.33089385]\n [0.82472184 0.70572913 0.32803604]]  Output is  [[0.0   0.0   0.0]\n [0.0   0.0   0.0]]", 
            "title": "ThresholdedReLU"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/wrappers/", 
            "text": "TimeDistributed\n\n\nTimeDistributed wrapper. Apply a layer to every temporal slice of an input.\n\n\nThe input should be at least 3D, and the dimension of index one will be considered to be the temporal dimension.\n\n\nScala:\n\n\nTimeDistributed(layer, inputShape = null)\n\n\n\n\nPython:\n\n\nTimeDistributed(layer, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nlayer\n: A layer instance.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, TimeDistributed, Dense}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(TimeDistributed(Dense(8, activation = \nrelu\n), inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.15650798 -0.60011286 -0.0883946\n-0.8020574  -2.0070791  0.58417106\n\n(2,.,.) =\n1.1210757   0.061217457 0.37585327\n0.11572507  0.045938224 -1.1890792\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.35345355  0.019948795 0.0         0.22901565   0.0  0.035260748  0.0          0.40403664\n1.4793522   0.803728    0.0         0.93547887   0.0  0.097175285  0.0          1.2386305\n\n(2,.,.) =\n0.06176605  0.0         0.051847294 0.76588714   0.0  0.67298067   0.10942559   0.0\n0.0         0.0         0.0         0.0          0.0  0.0          0.4285032    0.3072814\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x8]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import TimeDistributed, Dense\n\nmodel = Sequential()\nmodel.add(TimeDistributed(Dense(8, activation = \nrelu\n), input_shape = (2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.37107995 0.16777911 0.07691505]\n  [0.42678424 0.53602176 0.01580607]]\n\n [[0.31664302 0.03947526 0.1556008 ]\n  [0.2834384  0.68845104 0.23020768]]]\n\n\n\n\nOutput is:\n\n\n[[[0.09678233 0.21351711 0.0   0.07420383 0.09885262 0.0 0.13514107 0.0 ]\n  [0.06882857 0.18277436 0.0   0.1371126  0.00853634 0.0 0.1224944  0.0 ]]\n\n [[0.11387025 0.20642482 0.0   0.04896355 0.11478973 0.0 0.12610494 0.0 ]\n  [0.08322716 0.08292685 0.0   0.14674747 0.0        0.0 0.05299555 0.0 ]]]\n\n\n\n\n\n\nBidirectional\n\n\nBidirectional wrapper for RNNs.\n\n\nBidirectional currently requires RNNs to return the full sequence, i.e. returnSequences = true.\n\n\nScala:\n\n\nBidirectional(layer, mergeMode = \nconcat\n, inputShape = null)\n\n\n\n\nPython:\n\n\nBidirectional(layer, merge_mode=\nconcat\n, input_shape=None, name=None)\n\n\n\n\nParameters:\n\n\n\n\nlayer\n: An instance of a recurrent layer.\n\n\nmergeMode\n: Mode by which outputs of the forward and backward RNNs will be combined. Must be one of: 'sum', 'mul', 'concat', 'ave'. Default is 'concat'.\n\n\ninputShape\n: Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a \nShape\n object. For Python API, it should be a shape tuple. Batch dimension should be excluded.\n\n\n\n\nScala example:\n\n\nimport com.intel.analytics.bigdl.nn.keras.{Sequential, Bidirectional, SimpleRNN}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Bidirectional(SimpleRNN(4, returnSequences = true), inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)\n\n\n\n\nInput is:\n\n\ninput: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.6564635   1.525706    -0.54619956\n0.67109746  -0.45657027 -0.5378798\n\n(2,.,.) =\n0.19413045  -0.08337678 -0.0016114949\n0.6112209   0.7706432   1.3831\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]\n\n\n\n\nOutput is:\n\n\noutput: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.7013748   0.4841168     0.10397806 0.3799655   0.6934304  0.27561978  0.44025457  0.44310626\n0.4784317   -0.040266205  0.6599038  -0.29032442 0.55478245 0.061714854 0.5239438   -0.2890968\n\n(2,.,.) =\n0.32227796  0.23023699  0.34051302  -0.18683606 0.38275728  0.49924713  0.3152017   -0.14768216\n0.1766845   0.39446256  -0.12303881 0.08089487  0.08701726  0.46380803  -0.3540904  -0.0030886582\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x8]\n\n\n\n\nPython example:\n\n\nimport numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Bidirectional, LSTM\n\nmodel = Sequential()\nmodel.add(Bidirectional(LSTM(4, return_sequences = True), merge_mode = \nsum\n, input_shape = (3, 3)))\ninput = np.random.random([2, 3, 3])\noutput = model.forward(input)\n\n\n\n\nInput is:\n\n\n[[[0.95180543 0.87111702 0.08901385]\n  [0.77432517 0.27843224 0.83308397]\n  [0.9140173  0.28253884 0.01381966]]\n\n [[0.12674146 0.74173106 0.86059416]\n  [0.40666387 0.85293504 0.9403338 ]\n  [0.42748364 0.14310765 0.98098256]]]\n\n\n\n\nOutput is:\n\n\n[[[ 0.11651072  0.07040063  0.53200144 -0.37872505]\n  [ 0.03238479  0.15081021  0.55530167 -0.3390156 ]\n  [ 0.18388109  0.02891854  0.5591757  -0.28601688]]\n\n [[-0.17779878 -0.02685877  0.244566   -0.34734237]\n  [-0.17816684  0.077871    0.3195565  -0.40989208]\n  [-0.13442594  0.08941883  0.3418655  -0.29824993]]]", 
            "title": "Layer Wrappers"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/wrappers/#timedistributed", 
            "text": "TimeDistributed wrapper. Apply a layer to every temporal slice of an input.  The input should be at least 3D, and the dimension of index one will be considered to be the temporal dimension.  Scala:  TimeDistributed(layer, inputShape = null)  Python:  TimeDistributed(layer, input_shape=None, name=None)  Parameters:   layer : A layer instance.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, TimeDistributed, Dense}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(TimeDistributed(Dense(8, activation =  relu ), inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n-0.15650798 -0.60011286 -0.0883946\n-0.8020574  -2.0070791  0.58417106\n\n(2,.,.) =\n1.1210757   0.061217457 0.37585327\n0.11572507  0.045938224 -1.1890792\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.35345355  0.019948795 0.0         0.22901565   0.0  0.035260748  0.0          0.40403664\n1.4793522   0.803728    0.0         0.93547887   0.0  0.097175285  0.0          1.2386305\n\n(2,.,.) =\n0.06176605  0.0         0.051847294 0.76588714   0.0  0.67298067   0.10942559   0.0\n0.0         0.0         0.0         0.0          0.0  0.0          0.4285032    0.3072814\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x8]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import TimeDistributed, Dense\n\nmodel = Sequential()\nmodel.add(TimeDistributed(Dense(8, activation =  relu ), input_shape = (2, 3)))\ninput = np.random.random([2, 2, 3])\noutput = model.forward(input)  Input is:  [[[0.37107995 0.16777911 0.07691505]\n  [0.42678424 0.53602176 0.01580607]]\n\n [[0.31664302 0.03947526 0.1556008 ]\n  [0.2834384  0.68845104 0.23020768]]]  Output is:  [[[0.09678233 0.21351711 0.0   0.07420383 0.09885262 0.0 0.13514107 0.0 ]\n  [0.06882857 0.18277436 0.0   0.1371126  0.00853634 0.0 0.1224944  0.0 ]]\n\n [[0.11387025 0.20642482 0.0   0.04896355 0.11478973 0.0 0.12610494 0.0 ]\n  [0.08322716 0.08292685 0.0   0.14674747 0.0        0.0 0.05299555 0.0 ]]]", 
            "title": "TimeDistributed"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Layers/wrappers/#bidirectional", 
            "text": "Bidirectional wrapper for RNNs.  Bidirectional currently requires RNNs to return the full sequence, i.e. returnSequences = true.  Scala:  Bidirectional(layer, mergeMode =  concat , inputShape = null)  Python:  Bidirectional(layer, merge_mode= concat , input_shape=None, name=None)  Parameters:   layer : An instance of a recurrent layer.  mergeMode : Mode by which outputs of the forward and backward RNNs will be combined. Must be one of: 'sum', 'mul', 'concat', 'ave'. Default is 'concat'.  inputShape : Only need to specify this argument when you use this layer as the first layer of a model. For Scala API, it should be a  Shape  object. For Python API, it should be a shape tuple. Batch dimension should be excluded.   Scala example:  import com.intel.analytics.bigdl.nn.keras.{Sequential, Bidirectional, SimpleRNN}\nimport com.intel.analytics.bigdl.utils.Shape\nimport com.intel.analytics.bigdl.tensor.Tensor\n\nval model = Sequential[Float]()\nmodel.add(Bidirectional(SimpleRNN(4, returnSequences = true), inputShape = Shape(2, 3)))\nval input = Tensor[Float](2, 2, 3).randn()\nval output = model.forward(input)  Input is:  input: com.intel.analytics.bigdl.tensor.Tensor[Float] =\n(1,.,.) =\n0.6564635   1.525706    -0.54619956\n0.67109746  -0.45657027 -0.5378798\n\n(2,.,.) =\n0.19413045  -0.08337678 -0.0016114949\n0.6112209   0.7706432   1.3831\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x3]  Output is:  output: com.intel.analytics.bigdl.nn.abstractnn.Activity =\n(1,.,.) =\n0.7013748   0.4841168     0.10397806 0.3799655   0.6934304  0.27561978  0.44025457  0.44310626\n0.4784317   -0.040266205  0.6599038  -0.29032442 0.55478245 0.061714854 0.5239438   -0.2890968\n\n(2,.,.) =\n0.32227796  0.23023699  0.34051302  -0.18683606 0.38275728  0.49924713  0.3152017   -0.14768216\n0.1766845   0.39446256  -0.12303881 0.08089487  0.08701726  0.46380803  -0.3540904  -0.0030886582\n\n[com.intel.analytics.bigdl.tensor.DenseTensor of size 2x2x8]  Python example:  import numpy as np\nfrom bigdl.nn.keras.topology import Sequential\nfrom bigdl.nn.keras.layer import Bidirectional, LSTM\n\nmodel = Sequential()\nmodel.add(Bidirectional(LSTM(4, return_sequences = True), merge_mode =  sum , input_shape = (3, 3)))\ninput = np.random.random([2, 3, 3])\noutput = model.forward(input)  Input is:  [[[0.95180543 0.87111702 0.08901385]\n  [0.77432517 0.27843224 0.83308397]\n  [0.9140173  0.28253884 0.01381966]]\n\n [[0.12674146 0.74173106 0.86059416]\n  [0.40666387 0.85293504 0.9403338 ]\n  [0.42748364 0.14310765 0.98098256]]]  Output is:  [[[ 0.11651072  0.07040063  0.53200144 -0.37872505]\n  [ 0.03238479  0.15081021  0.55530167 -0.3390156 ]\n  [ 0.18388109  0.02891854  0.5591757  -0.28601688]]\n\n [[-0.17779878 -0.02685877  0.244566   -0.34734237]\n  [-0.17816684  0.077871    0.3195565  -0.40989208]\n  [-0.13442594  0.08941883  0.3418655  -0.29824993]]]", 
            "title": "Bidirectional"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/training/", 
            "text": "This page shows how to train, evaluate or predict a model using the Keras-Style API.\n\n\nYou may refer to the \nUser Guide\n page to see how to define a model in \nPython\n or \nScala\n correspondingly.\n\n\nYou may refer to \nLayers\n section to find all the available layers.\n\n\nAfter defining a model with the Keras-Style API, you can call the following \nmethods\n on the model:\n\n\n\n\nCompile\n\n\nConfigure the learning process. Must be called before \nfit\n or \nevaluate\n.\n\n\nScala:\n\n\ncompile(optimizer, loss, metrics = null)\n\n\n\n\nPython\n\n\ncompile(optimizer, loss, metrics=None)\n\n\n\n\nParameters:\n\n\n\n\noptimizer\n: Optimization method to be used. Can either use the string representation of an optimization method (see \nhere\n) or an instance of \nOptimMethod\n. \n\n\nloss\n: Criterion to be used. Can either use the string representation of a criterion (see \nhere\n) or an instance of \nLoss\n.\n\n\nmetrics\n: One or more validation methods to be used. Default is null if no validation needs to be configured. Can either use the string representation \nArray(\"accuracy\")\n(Scala) \n[\"accuracy\"]\n(Python) or instances of \nValidationMethod\n.\n\n\n\n\n\n\nFit\n\n\nTrain a model for a fixed number of epochs on a dataset. Need to first \ncompile\n the model beforehand.\n\n\nScala:\n\n\nfit(x, nbEpoch = 10, validationData = null)\n\n\n\n\nPython\n\n\nfit(x, y=None, batch_size=32, nb_epoch=10, validation_data=None, distributed=True)\n\n\n\n\nParameters:\n\n\n\n\nx\n: Training dataset.\n\n\nbatchSize\n: Number of samples per gradient update.\n\n\nnbEpoch\n: Number of iterations to train.\n\n\nvalidationData\n: Dataset for validation. Default is null if validation is not configured.\n\n\n\n\nRemark\n\n\n\n\nFor \nScala\n, x can either be RDD of \nSample\n (specifying \nbatchSize\n) or an instance of \nDataSet\n.\n\n\nFor \nPython\n, you can use x (a Numpy array) as features with y (a Numpy array) as labels; or only x (RDD of \nSample\n) without specifying y.\n\n\nThe parameter \ndistributed\n is to choose whether to train the model using distributed mode or local mode in \nPython\n. Default is true. If in local mode, x and y must both be Numpy arrays.\n\n\n\n\n\n\nEvaluate\n\n\nEvaluate a model on a given dataset using the metrics specified when you \ncompile\n the model.\n\n\nScala:\n\n\nevaluate(x)\n\n\n\n\nPython\n\n\nevaluate(x, y=None, batch_size=32)\n\n\n\n\nParameters:\n\n\n\n\nx\n: Evaluation dataset.\n\n\nbatchSize\n: Number of samples per batch.\n\n\n\n\nRemark\n\n\n\n\nFor \nScala\n, x can either be RDD of \nSample\n (specifying \nbatchSize\n) or an instance of \nDataSet\n.\n\n\nFor \nPython\n, you can use x (a Numpy array) as features with y (a Numpy array) as labels; or only x (RDD of \nSample\n) without specifying y. Currently only evaluation in distributed mode is supported in Python.\n\n\n\n\n\n\nPredict\n\n\nUse a model to do prediction.\n\n\nScala:\n\n\npredict(x)\n\n\n\n\nPython\n\n\npredict(x, distributed=True)\n\n\n\n\nParameters:\n\n\n\n\nx\n: Prediction data.\n\n\n\n\nRemark\n\n\n\n\nFor \nScala\n, x can either be RDD of \nSample\n (specifying \nbatchSize\n) or an instance of \nLocalDataSet\n.\n\n\nFor \nPython\n, x can either be a Numpy array representing labels or RDD of \nSample\n.\n\n\nThe parameter \ndistributed\n is to choose whether to do prediction using distributed mode or local mode in \nPython\n. Default is true. If in local mode, x must be a Numpy array.", 
            "title": "Train, evaluate or predict a model"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/training/#compile", 
            "text": "Configure the learning process. Must be called before  fit  or  evaluate .  Scala:  compile(optimizer, loss, metrics = null)  Python  compile(optimizer, loss, metrics=None)  Parameters:   optimizer : Optimization method to be used. Can either use the string representation of an optimization method (see  here ) or an instance of  OptimMethod .   loss : Criterion to be used. Can either use the string representation of a criterion (see  here ) or an instance of  Loss .  metrics : One or more validation methods to be used. Default is null if no validation needs to be configured. Can either use the string representation  Array(\"accuracy\") (Scala)  [\"accuracy\"] (Python) or instances of  ValidationMethod .", 
            "title": "Compile"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/training/#fit", 
            "text": "Train a model for a fixed number of epochs on a dataset. Need to first  compile  the model beforehand.  Scala:  fit(x, nbEpoch = 10, validationData = null)  Python  fit(x, y=None, batch_size=32, nb_epoch=10, validation_data=None, distributed=True)  Parameters:   x : Training dataset.  batchSize : Number of samples per gradient update.  nbEpoch : Number of iterations to train.  validationData : Dataset for validation. Default is null if validation is not configured.   Remark   For  Scala , x can either be RDD of  Sample  (specifying  batchSize ) or an instance of  DataSet .  For  Python , you can use x (a Numpy array) as features with y (a Numpy array) as labels; or only x (RDD of  Sample ) without specifying y.  The parameter  distributed  is to choose whether to train the model using distributed mode or local mode in  Python . Default is true. If in local mode, x and y must both be Numpy arrays.", 
            "title": "Fit"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/training/#evaluate", 
            "text": "Evaluate a model on a given dataset using the metrics specified when you  compile  the model.  Scala:  evaluate(x)  Python  evaluate(x, y=None, batch_size=32)  Parameters:   x : Evaluation dataset.  batchSize : Number of samples per batch.   Remark   For  Scala , x can either be RDD of  Sample  (specifying  batchSize ) or an instance of  DataSet .  For  Python , you can use x (a Numpy array) as features with y (a Numpy array) as labels; or only x (RDD of  Sample ) without specifying y. Currently only evaluation in distributed mode is supported in Python.", 
            "title": "Evaluate"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/training/#predict", 
            "text": "Use a model to do prediction.  Scala:  predict(x)  Python  predict(x, distributed=True)  Parameters:   x : Prediction data.   Remark   For  Scala , x can either be RDD of  Sample  (specifying  batchSize ) or an instance of  LocalDataSet .  For  Python , x can either be a Numpy array representing labels or RDD of  Sample .  The parameter  distributed  is to choose whether to do prediction using distributed mode or local mode in  Python . Default is true. If in local mode, x must be a Numpy array.", 
            "title": "Predict"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/optimizer/", 
            "text": "An optimizer, specified when you \ncompile\n the model, is used to update model gradient parameters in the process of training.\n\n\nSee \nhere\n for available optimizer objects.\n\n\nFor the sake of convenience, you can also use the corresponding string representation of an optimizer. In this case, the default parameters of an optimizer will be applied.\n\n\n\n\nAvailable Optimizers\n\n\n\n\nsgd\n\n\nadam\n\n\nadamax\n\n\nadadelta\n\n\nadagrad\n\n\nrmsprop", 
            "title": "Optimizers"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/optimizer/#available-optimizers", 
            "text": "sgd  adam  adamax  adadelta  adagrad  rmsprop", 
            "title": "Available Optimizers"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/loss/", 
            "text": "A loss function (or objective function), specified when you \ncompile\n the model, is the function that the model intends to optimize in the process of training.\n\n\nSee \nhere\n for available loss objects.\n\n\nFor the sake of convenience, you can also use the corresponding string representation of a loss.\n\n\n\n\nAvailable Losses\n\n\n\n\nmean_squared_error\n or \nmse\n\n\nmean_absolute_error\n or \nmae\n\n\ncategorical_crossentropy\n\n\nsparse_categorical_crossentropy\n\n\nbinary_crossentropy\n\n\nmean_absolute_percentage_error\n or \nmape\n\n\nmean_squared_logarithmic_error\n or \nmsle\n\n\nkullback_leibler_divergence\n or \nkld\n\n\nhinge\n\n\nsquared_hinge\n\n\npoisson\n\n\ncosine_proximity", 
            "title": "Losses"
        }, 
        {
            "location": "/KerasStyleAPIGuide/Optimization/loss/#available-losses", 
            "text": "mean_squared_error  or  mse  mean_absolute_error  or  mae  categorical_crossentropy  sparse_categorical_crossentropy  binary_crossentropy  mean_absolute_percentage_error  or  mape  mean_squared_logarithmic_error  or  msle  kullback_leibler_divergence  or  kld  hinge  squared_hinge  poisson  cosine_proximity", 
            "title": "Available Losses"
        }, 
        {
            "location": "/powered-by/", 
            "text": "Cray\n: \nCray Urika-XC Analytics Suite\n uses BigDL to provide AI support\n\n\nDatabricks\n: \nIntel\u2019s BigDL on Databricks\n\n\nAzure\n: \nUse BigDL on AZure HDInsight\n\n\nA more detailed post for \nHow to use BigDL on Apache Spark for Azure HDInsight\n\n\n\n\n\n\nAliCloud\n: \nBigDL on AliCloud E-MapReduce (in Chinese)\n\n\nAWS\n: \nRunning BigDL, Deep Learning for Apache Spark, on AWS\n\n\nCloudera\n: \nBigDL on CDH and Cloudera Data Science Workbench\n\n\nMicrosoft\n: \nRunning BigDL on Microsoft Data Science Virtual Machine\n\n\nLightbend\n: \nUsing Apache Spark with Intel BigDL on Mesosphere DC/OS\n\n\nQubole\n: Deep Learning on Qubole Using BigDL for Apache Spark (\nPart 1\n and \nPart 2\n)\n\n\nTelefonica Open Cloud\n: \nUsing BigDL in Telefonica Open Cloud", 
            "title": "Powered by"
        }, 
        {
            "location": "/known-issues/", 
            "text": "Currently, BigDL uses synchronous mini-batch SGD in model training. The mini-batch size is\nexpected to be a multiple of \ntotal cores\n used in the job.\n\n\n\n\n\n\nYou may observe very poor performance when running BigDL for Spark 2.0 with Java 7; it is highly\nrecommended to use Java 8 when building and running BigDL for Spark 2.0.\n\n\n\n\n\n\nOn Spark 2.0, please use default Java serializer instead of Kryo because of\n\nKryo Issue 341\n. The issue has been fixed in\nKryo 4.0. However, Spark 2.0 uses Kryo 3.0.3. Spark 1.5 and 1.6 do not have this problem.\n\n\n\n\n\n\nOn CentOS 6 and 7, please increase the max user processes to a larger value (e.g., 514585);\notherwise, you may see errors like \"unable to create new native thread\".\n\n\n\n\n\n\nCurrently, BigDL will load all the training and validation data into memory during training.\nYou may encounter errors if it runs out of memory.\n\n\n\n\n\n\nIf you meet the program stuck after \nSave model...\n on Mesos, check the \nspark.driver.memory\n\nand increase the value. Eg, VGG on Cifar10 may need 20G+.\n\n\n\n\n\n\nIf you meet \ncan't find executor core number\n on Mesos, you should pass the executor cores\nthrough \n--conf spark.executor.cores=xxx\n\n\n\n\n\n\nOn Windows, if you meet \"Could not locate executable null\\bin\\winutils.exe\" error, you need to\ninstall winutils.exe. Please refer this\n\npost\n.\n\n\n\n\n\n\nIf the training data are cached before all the executor resources are allocated(this sometimes\nhappens when the data set is too small), we find Spark may not distribute the training data\npartitions evenly on each executor. So the training tasks will be unbalanced allocated among\nexecutors. To solve this problem, you can increase the\n\nspark.scheduler.maxRegisteredResourcesWaitingTime\n property(default is 30s).", 
            "title": "Known Issues"
        }, 
        {
            "location": "/presentations/", 
            "text": "Talks:\n\n\n\n\n\n\nAI Conference 2017 San Francisco\n:Very large-scale distributed deep learning with BigDL \n[Slides]\n\n\n\n\n\n\n Strata 2017 NY:\nBuilding advanced analytics and deep learning on Apache Spark with BigDL\n[Slides]\n\n\n\n\n\n\n Strata 2017 London:\nDistributed deep learning at scale on Apache Spark with BigDL\n[Slides]\n\n\n\n\n\n\nStrata 2017 Beijing:\nBuilding deep learning power big data analytics on Apache Spark using BigDL\n[Slides]\n\n\n\n\n\n\nStrata 2017 Beijing:\n Distributed deep learning at scale on Apache Spark with BigDL \n[Slides]\n\n\n\n\n\n\nSpark Summit East 2017:\nBuilding Deep Learning Powered Big Data \n[Slides]\n\n\n\n\n\n\nSpark Summit East 2017:\n BigDL: A Distributed Deep Learning Library on Spark \n[Slides]\n\n\n\n\n\n\nSpark Summit 2017:\nBigDL: Bringing Ease of Use of Deep Learning for Apache Spark\n\n[Slides]\n\n\n\n\n\n\nSpark Summit 2017:\nDeep Learning to Big Data Analytics on Apache Spark Using BigDL \n[Slides]\n\n\n\n\n\n\n\n\n Others:\n \n\n\n\n\n\n\nBigDL Overview\n \n\n\n\n\n\n\nIntroduction to BigDL on Apache Spark* :\n\n\n\n\n\n\nPart1\n \n\n\n\n\n\n\nPart2 \n\n\n\n\n\n\nPart3", 
            "title": "Presentations"
        }
    ]
}