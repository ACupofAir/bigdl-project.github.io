<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    
    <link rel="shortcut icon" href="/img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>Transformer - BigDL Project</title>
    <link href="/css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="/css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="/css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="/css/highlight.css">
    <link href="../../extra.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="/js/jquery-3.2.1.min.js"></script>
    <script src="/js/bootstrap-3.3.7.min.js"></script>
    <script src="/js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "Transformer", url: "#transformer", children: [
          ]},
          {title: "FeatureTransformer", url: "#featuretransformer", children: [
          ]},
          {title: "Brightness", url: "#brightness", children: [
          ]},
          {title: "Hue", url: "#hue", children: [
          ]},
          {title: "Saturation", url: "#saturation", children: [
          ]},
          {title: "Contrast", url: "#contrast", children: [
          ]},
          {title: "ChannelOrder", url: "#channelorder", children: [
          ]},
          {title: "ColorJitter", url: "#colorjitter", children: [
          ]},
          {title: "Resize", url: "#resize", children: [
          ]},
          {title: "AspectScale", url: "#aspectscale", children: [
          ]},
          {title: "RandomAspectScale", url: "#randomaspectscale", children: [
          ]},
          {title: "ChannelNormalize", url: "#channelnormalize", children: [
          ]},
          {title: "PixelNormalizer", url: "#pixelnormalizer", children: [
          ]},
          {title: "CenterCrop", url: "#centercrop", children: [
          ]},
          {title: "RandomCrop", url: "#randomcrop", children: [
          ]},
          {title: "FixedCrop", url: "#fixedcrop", children: [
          ]},
          {title: "DetectionCrop", url: "#detectioncrop", children: [
          ]},
          {title: "Expand", url: "#expand", children: [
          ]},
          {title: "Filler", url: "#filler", children: [
          ]},
          {title: "HFlip", url: "#hflip", children: [
          ]},
          {title: "RandomTransformer", url: "#randomtransformer", children: [
          ]},
          {title: "BytesToMat", url: "#bytestomat", children: [
          ]},
          {title: "MatToFloats", url: "#mattofloats", children: [
          ]},
          {title: "MatToTensor", url: "#mattotensor", children: [
          ]},
          {title: "ImageFrameToSample", url: "#imageframetosample", children: [
          ]},
        ];

    </script>
    <script src="/js/base.js"></script>
      <script src="../../search/require.js"></script>
      <script src="../../search/search.js"></script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
    

    <h2 id="transformer"><strong>Transformer</strong></h2>
<p>Transformer is for pre-processing. In many deep learning workload, input data need to be pre-processed before fed into   model. For example, in CNN, the image file need to be decoded from some compressed format(e.g. jpeg) to float arrays,    normalized and cropped to some fixed shape. You can also find pre-processing in other types of deep learning work        load(e.g. NLP, speech recognition). In BigDL, we provide many pre-process procedures for user. They're implemented as    Transformer.</p>
<p>The transformer interface is</p>
<pre><code class="scala">
trait Transformer[A, B] extends Serializable {
   def apply(prev: Iterator[A]): Iterator[B]
 }
</code></pre>

<p>It's simple, right? What a transformer do is convert a sequence of objects of Class A to a sequence of objects of Class  B.</p>
<p>Transformer is flexible. You can chain them together to do pre-processing. Let's still use the CNN example, say first    we need read image files from given paths, then extract the image binaries to array of float, then normalized the image  content and crop a fixed size from the image at a random position. Here we need 4 transformers, <code>PathToImage</code>,           <code>ImageToArray</code>, <code>Normalizor</code> and <code>Cropper</code>. And then chain them together.</p>
<h2 id="featuretransformer"><strong>FeatureTransformer</strong></h2>
<p><code>FeatureTransformer</code> is the transformer that transforms from <code>ImageFeature</code> to <code>ImageFeature</code>.
<code>FeatureTransformer</code> extends 'Transformer[ImageFeature, ImageFeature]'.</p>
<p>FeatureTransformer can be chained with FeatureTransformer with the</p>
<p>The key function in <code>FeatureTransformer</code> is <code>transform</code>, which does the ImageFeature transformation
and exception control.
While <code>transformMat</code> is called by <code>transform</code>,
and it is expected to contain the actual transformation of an ImageFeature.
It is advised to override <code>transformMat</code> when you implement your own FeatureTransformer.</p>
<hr />
<h2 id="brightness"><strong>Brightness</strong></h2>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val brightness = Brightness(deltaLow: Double, deltaHigh: Double)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">brightness = Brightness(delta_low, delta_high)
</code></pre>

<p>Adjust the image brightness.
<em> <code>deltaLow</code> brightness parameter: low bound
</em> <code>deltaHigh</code> brightness parameter: high bound</p>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.bigdl.transform.vision.image.augmentation._
val data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
val transformer = Brightness(0, 32)
val transformed = transformer(data)
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">from bigdl.transform.vision.image import *
brightness = Brightness(0.0, 32.0)
local_image_frame = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
transformed = brightness(local_image_frame)
</code></pre>

<hr />
<h2 id="hue"><strong>Hue</strong></h2>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val transformer = Hue(deltaLow: Double, deltaHigh: Double)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">transformer = Hue(delta_low, delta_high)
</code></pre>

<p>Adjust the image hue.
<em> <code>deltaLow</code> Hue parameter: low bound
</em> <code>deltaHigh</code> Hue parameter: high bound</p>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.bigdl.transform.vision.image.augmentation._
val data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
val transformer = Hue(-18, 18)
val transformed = transformer(data)
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">from bigdl.transform.vision.image import *
transformer = Hue(-18.0, 18.0)
local_image_frame = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
transformed = transformer(local_image_frame)
</code></pre>

<hr />
<h2 id="saturation"><strong>Saturation</strong></h2>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val transformer = Saturation(deltaLow: Double, deltaHigh: Double)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">transformer = Saturation(delta_low, delta_high)
</code></pre>

<p>Adjust the image Saturation.
<em> <code>deltaLow</code> Saturation parameter: low bound
</em> <code>deltaHigh</code> Saturation parameter: high bound</p>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.bigdl.transform.vision.image.augmentation._
val data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
val transformer = Saturation(10, 20)
val transformed = transformer(data)
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">from bigdl.transform.vision.image import *
transformer = Saturation(10.0, 20.0)
local_image_frame = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
transformed = transformer(local_image_frame)
</code></pre>

<hr />
<h2 id="contrast"><strong>Contrast</strong></h2>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val transformer = Contrast(deltaLow: Double, deltaHigh: Double)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">transformer = Contrast(delta_low, delta_high)
</code></pre>

<p>Adjust the image Contrast.
<em> <code>deltaLow</code> Contrast parameter: low bound
</em> <code>deltaHigh</code> Contrast parameter: high bound</p>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.bigdl.transform.vision.image.augmentation._
val data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
val transformer = Contrast(0.5, 1.5)
val transformed = transformer(data)
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">from bigdl.transform.vision.image import *
transformer = Hue(0.5, 1.5)
local_image_frame = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
transformed = transformer(local_image_frame)
</code></pre>

<hr />
<h2 id="channelorder"><strong>ChannelOrder</strong></h2>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val transformer = ChannelOrder()
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">transformer = ChannelOrder()
</code></pre>

<p>Random change the channel order of an image</p>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.bigdl.transform.vision.image.augmentation._
val data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
val transformer = ChannelOrder()
val transformed = transformer(data)
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">from bigdl.transform.vision.image import *
transformer = ChannelOrder()
local_image_frame = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
transformed = transformer(local_image_frame)
</code></pre>

<hr />
<h2 id="colorjitter"><strong>ColorJitter</strong></h2>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val transformer = ColorJitter(brightnessProb: Double = 0.5,
                              brightnessDelta: Double = 32,
                              contrastProb: Double = 0.5,
                              contrastLower: Double = 0.5,
                              contrastUpper: Double = 1.5,
                              hueProb: Double = 0.5,
                              hueDelta: Double = 18,
                              saturationProb: Double = 0.5,
                              saturationLower: Double = 0.5,
                              saturationUpper: Double = 1.5,
                              randomOrderProb: Double = 0,
                              shuffle: Boolean = false)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">transformer = ColorJitter(brightness_prob = 0.5,
                           brightness_delta = 32.0,
                           contrast_prob = 0.5,
                           contrast_lower = 0.5,
                           contrast_upper = 1.5,
                           hue_prob = 0.5,
                           hue_delta = 18.0,
                           saturation_prob = 0.5,
                           saturation_lower = 0.5,
                           saturation_upper = 1.5,
                           random_order_prob = 0.0,
                           shuffle = False)
</code></pre>

<p>Random adjust brightness, contrast, hue, saturation</p>
<ul>
<li><code>brightnessProb</code>: probability to adjust brightness</li>
<li><code>brightnessDelta</code>: brightness parameter</li>
<li><code>contrastProb</code>: probability to adjust contrast</li>
<li><code>contrastLower</code>: contrast lower parameter</li>
<li><code>contrastUpper</code>: contrast upper parameter</li>
<li><code>hueProb</code>: probability to adjust hue</li>
<li><code>hueDelta</code>: hue parameter</li>
<li><code>saturationProb</code>: probability to adjust saturation</li>
<li><code>saturationLower</code>: saturation lower parameter</li>
<li><code>saturationUpper</code>: saturation upper parameter</li>
<li><code>randomChannelOrderProb</code>: random order for different operation</li>
<li><code>shuffle</code>: shuffle the transformers</li>
</ul>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.bigdl.transform.vision.image.augmentation._
val data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
val transformer = ColorJitter()
val transformed = transformer(data)
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">from bigdl.transform.vision.image import *
transformer = ColorJitter()
local_image_frame = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
transformed = transformer(local_image_frame)
</code></pre>

<hr />
<h2 id="resize"><strong>Resize</strong></h2>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val transformer = Resize(resizeH: Int, resizeW: Int,
                    resizeMode: Int = Imgproc.INTER_LINEAR,
                    useScaleFactor: Boolean = true)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">transformer = Resize(resize_h, resize_w, resize_mode = 1, use_scale_factor=True)
</code></pre>

<p>Resize image
 * <code>resizeH</code> height after resize
 * <code>resizeW</code> width after resize
 * <code>resizeMode</code> if resizeMode = -1, random select a mode from
(Imgproc.INTER_LINEAR, Imgproc.INTER_CUBIC, Imgproc.INTER_AREA,
                   Imgproc.INTER_NEAREST, Imgproc.INTER_LANCZOS4)
 * <code>useScaleFactor</code> if true, scale factor fx and fy is used, fx = fy = 0
 note that the result of the following are different:</p>
<pre><code class="python">Imgproc.resize(mat, mat, new Size(resizeWH, resizeWH), 0, 0, Imgproc.INTER_LINEAR)
Imgproc.resize(mat, mat, new Size(resizeWH, resizeWH))
</code></pre>

<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.bigdl.transform.vision.image.augmentation._
val data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
val transformer = Resize(300, 300)
val transformed = transformer(data)
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">from bigdl.transform.vision.image import *
transformer = Resize(300, 300)
local_image_frame = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
transformed = transformer(local_image_frame)
</code></pre>

<hr />
<h2 id="aspectscale"><strong>AspectScale</strong></h2>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val transformer = AspectScale(scale: Int, scaleMultipleOf: Int = 1,
                    maxSize: Int = 1000)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">transformer = AspectScale(scale, scale_multiple_of = 1, max_size = 1000)
</code></pre>

<p>Resize the image, keep the aspect ratio. scale according to the short edge
 * <code>scale</code> scale size, apply to short edge
 * <code>scaleMultipleOf</code> make the scaled size multiple of some value
 * <code>maxSize</code> max size after scale</p>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.bigdl.transform.vision.image.augmentation._
val data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
val transformer = AspectScale(750, maxSize = 3000)
val transformed = transformer(data)
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">from bigdl.transform.vision.image import *
transformer = AspectScale(750, max_size = 3000)
local_image_frame = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
transformed = transformer(local_image_frame)
</code></pre>

<hr />
<h2 id="randomaspectscale"><strong>RandomAspectScale</strong></h2>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val transformer = AspectScale(scale: Int, scaleMultipleOf: Int = 1,
                    maxSize: Int = 1000)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">transformer = AspectScale(scale, scale_multiple_of = 1, max_size = 1000)
</code></pre>

<p>resize the image by randomly choosing a scale
 * <code>scales</code> array of scale options that for random choice
 * <code>scaleMultipleOf</code> Resize test images so that its width and height are multiples of
 * <code>maxSize</code> Max pixel size of the longest side of a scaled input image</p>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.bigdl.transform.vision.image.augmentation._
val data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
val transformer = RandomAspectScale(Array(750, 600), maxSize = 3000)
val transformed = transformer(data)
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">from bigdl.transform.vision.image import *
transformer = RandomAspectScale([750, 600], max_size = 3000)
local_image_frame = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
transformed = transformer(local_image_frame)
</code></pre>

<hr />
<h2 id="channelnormalize"><strong>ChannelNormalize</strong></h2>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val transformer = ChannelNormalize(meanR: Float, meanG: Float, meanB: Float,
                                         stdR: Float = 1, stdG: Float = 1, stdB: Float = 1)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">transformer = ChannelNormalize(mean_r, mean_b, mean_g, std_r=1.0, std_g=1.0, std_b=1.0)
</code></pre>

<p>image channel normalize
 * <code>meanR</code> mean value in R channel
 * <code>meanG</code> mean value in G channel
 * <code>meanB</code> mean value in B channel
 * <code>stdR</code> std value in R channel
 * <code>stdG</code> std value in G channel
 * <code>stdB</code> std value in B channel</p>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.bigdl.transform.vision.image.augmentation._
val data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
val transformer = ChannelNormalize(100f, 200f, 300f, 2f, 3f, 4f)
val transformed = transformer(data)
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">from bigdl.transform.vision.image import *
transformer = ChannelNormalize(100.0, 200.0, 300.0, 2.0, 3.0, 4.0)
local_image_frame = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
transformed = transformer(local_image_frame)
</code></pre>

<hr />
<h2 id="pixelnormalizer"><strong>PixelNormalizer</strong></h2>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val transformer = PixelNormalizer(means: Array[Float])
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">transformer = PixelNormalizer(means)
</code></pre>

<p>Pixel level normalizer, data(i) = data(i) - mean(i)</p>
<ul>
<li><code>means</code> pixel level mean, following H * W * C order</li>
</ul>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.bigdl.transform.vision.image.augmentation._
val data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
// Assume the image pixels length is 375 * 500 * 3
val means = new Array[Float](375 * 500 * 3)
val transformer = PixelNormalizer(means)
val transformed = transformer(data)
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">from bigdl.transform.vision.image import *
means = [2.0] * 3 * 500 * 375
transformer = PixelNormalize(means)
local_image_frame = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
transformed = transformer(local_image_frame)
</code></pre>

<hr />
<h2 id="centercrop"><strong>CenterCrop</strong></h2>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val transformer = CenterCrop(cropWidth: Int, cropHeight: Int, isClip: Boolean = true)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">transformer = CenterCrop(crop_width, crop_height, is_clip=True)
</code></pre>

<p>Crop a <code>cropWidth</code> x <code>cropHeight</code> patch from center of image.
The patch size should be less than the image size.</p>
<ul>
<li><code>cropWidth</code> width after crop</li>
<li><code>cropHeight</code> height after crop</li>
<li><code>isClip</code> whether to clip the roi to image boundaries</li>
</ul>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.bigdl.transform.vision.image.augmentation._
val data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
val transformer = CenterCrop(200, 200)
val transformed = transformer(data)
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">from bigdl.transform.vision.image import *
transformer = CenterCrop(200, 200)
local_image_frame = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
transformed = transformer(local_image_frame)
</code></pre>

<hr />
<h2 id="randomcrop"><strong>RandomCrop</strong></h2>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val transformer = RandomCrop(cropWidth: Int, cropHeight: Int, isClip: Boolean = true)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">transformer = RandomCrop(crop_width, crop_height, is_clip=True)
</code></pre>

<p>Random crop a <code>cropWidth</code> x <code>cropHeight</code> patch from an image.
The patch size should be less than the image size.</p>
<ul>
<li><code>cropWidth</code> width after crop</li>
<li><code>cropHeight</code> height after crop</li>
<li><code>isClip</code> whether to clip the roi to image boundaries</li>
</ul>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.bigdl.transform.vision.image.augmentation._
val data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
val transformer = RandomCrop(200, 200)
val transformed = transformer(data)
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">from bigdl.transform.vision.image import *
transformer = RandomCrop(200, 200)
local_image_frame = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
transformed = transformer(local_image_frame)
</code></pre>

<hr />
<h2 id="fixedcrop"><strong>FixedCrop</strong></h2>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val transformer = FixedCrop(x1: Float, y1: Float, x2: Float, y2: Float, normalized: Boolean,
                      isClip: Boolean = true)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">transformer = FixedCrop(x1, y1, x2, y2, normalized=True, is_clip=True)
</code></pre>

<p>Crop a fixed area of image</p>
<ul>
<li><code>x1</code> start in width</li>
<li><code>y1</code> start in height</li>
<li><code>x2</code> end in width</li>
<li><code>y2</code> end in height</li>
<li><code>normalized</code> whether args are normalized, i.e. in range [0, 1]</li>
<li><code>isClip</code> whether to clip the roi to image boundaries</li>
</ul>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.bigdl.transform.vision.image.augmentation._
val data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
val transformer = FixedCrop(0, 0, 50, 50, false)
val transformed = transformer(data)

val transformer2 = FixedCrop(0, 0, 0.1f, 0.1333f, true)
val transformed2 = transformer(data)
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">from bigdl.transform.vision.image import *
local_image_frame = ImageFrame.read(&quot;/tmp/test.jpg&quot;)

transformer = FixedCrop(0.0, 0.0, 50.0, 50.0, False)
transformed = transformer(local_image_frame)

transformer2 = FixedCrop(0.0, 0.0, 0.1, 0.1333, True)
transformed2 = transformer(local_image_frame)
</code></pre>

<hr />
<h2 id="detectioncrop"><strong>DetectionCrop</strong></h2>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val transformer = DetectionCrop(roiKey: String, normalized: Boolean = true)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">transformer = DetectionCrop(roi_key, normalized=True)
</code></pre>

<p>Crop from object detections, each image should has a tensor detection,
which is stored in ImageFeature</p>
<ul>
<li><code>roiKey</code> roiKey that map a tensor detection</li>
<li><code>normalized</code> whether is detection is normalized, i.e. in range [0, 1]</li>
</ul>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.bigdl.transform.vision.image.augmentation._
import com.intel.analytics.bigdl.utils.T
import com.intel.analytics.bigdl.tensor.Tensor

val data = ImageFrame.read(&quot;/tmp/test.jpg&quot;).toLocal()
val imf = data.array(0)
imf(&quot;roi&quot;) = Tensor[Float](T(1, 1, 0.2, 0, 0, 0.5, 0.5))
val transformer = DetectionCrop(&quot;roi&quot;)
val transformed = transformer(data)
</code></pre>

<hr />
<h2 id="expand"><strong>Expand</strong></h2>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val transformer = Expand(meansR: Int = 123, meansG: Int = 117, meansB: Int = 104,
                    minExpandRatio: Double = 1, maxExpandRatio: Double = 4.0)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">transformer = Expand(means_r=123, means_g=117, means_b=104,
                                      min_expand_ratio=1.0,
                                      max_expand_ratio=4.0)
</code></pre>

<p>expand image, fill the blank part with the meanR, meanG, meanB</p>
<ul>
<li><code>meansR</code> means in R channel</li>
<li><code>meansG</code> means in G channel</li>
<li><code>meansB</code> means in B channel</li>
<li><code>minExpandRatio</code> min expand ratio</li>
<li><code>maxExpandRatio</code> max expand ratio</li>
</ul>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.bigdl.transform.vision.image.augmentation._

val data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
val transformer = Expand(minExpandRatio = 2, maxExpandRatio = 2)
val transformed = transformer(data)
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">from bigdl.transform.vision.image import *
data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
transformer = Expand(min_expand_ratio = 2.0, max_expand_ratio = 2.0)
transformed = transformer(data)
</code></pre>

<hr />
<h2 id="filler"><strong>Filler</strong></h2>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val transformer = Filler(startX: Float, startY: Float, endX: Float, endY: Float, value: Int = 255)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">transformer = Filler(start_x, start_y, end_x, end_y, value = 255)
</code></pre>

<p>Fill part of image with certain pixel value</p>
<ul>
<li><code>startX</code> start x ratio</li>
<li><code>startY</code> start y ratio</li>
<li><code>endX</code> end x ratio</li>
<li><code>endY</code> end y ratio</li>
<li><code>value</code> filling value</li>
</ul>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.bigdl.transform.vision.image.augmentation._

val data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
val transformer = Filler(0, 0, 1, 0.5f, 255)
val transformed = transformer(data)
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">from bigdl.transform.vision.image import *
data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
transformer = Filler(0.0, 0.0, 1.0, 0.5, 255)
transformed = transformer(data)
</code></pre>

<hr />
<h2 id="hflip"><strong>HFlip</strong></h2>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val transformer = HFlip()
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">transformer = HFlip()
</code></pre>

<p>Flip the image horizontally</p>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.bigdl.transform.vision.image.augmentation._

val data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
val transformer = HFlip()
val transformed = transformer(data)
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">from bigdl.transform.vision.image import *
data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
transformer = HFlip()
transformed = transformer(data)
</code></pre>

<hr />
<h2 id="randomtransformer"><strong>RandomTransformer</strong></h2>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val transformer = RandomTransformer(transformer: FeatureTransformer, maxProb: Double)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">transformer = RandomTransformer(transformer, maxProb)
</code></pre>

<p>It is a wrapper for transformers to control the transform probability
 * <code>transformer</code> transformer to apply randomness
 * <code>maxProb</code> max prob</p>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.bigdl.transform.vision.image.augmentation._

val data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
val transformer = RandomTransformer(HFlip(), 0.5)
val transformed = transformer(data)
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">from bigdl.transform.vision.image import *
data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
transformer = RandomTransformer(HFlip(), 0.5)
transformed = transformer(data)
</code></pre>

<hr />
<h2 id="bytestomat"><strong>BytesToMat</strong></h2>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val transformer = BytesToMat(byteKey: String = ImageFeature.bytes)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">transformer = BytesToMat(byte_key=&quot;bytes&quot;)
</code></pre>

<p>Transform byte array(original image file in byte) to OpenCVMat
* <code>byteKey</code>: key that maps byte array</p>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.bigdl.transform.vision.image.BytesToMat

val data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
val transformer = BytesToMat()
val transformed = transformer(data)
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">from bigdl.transform.vision.image import *
data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
transformer = BytesToMat()
transformed = transformer(data)
</code></pre>

<hr />
<h2 id="mattofloats"><strong>MatToFloats</strong></h2>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val transformer = MatToFloats(validHeight: Int, validWidth: Int, validChannels: Int,
                    outKey: String = ImageFeature.floats, shareBuffer: Boolean = true)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">transformer = MatToFloats(valid_height=300, valid_width=300, valid_channel=300,
                                          out_key = &quot;floats&quot;, share_buffer=True)
</code></pre>

<p>Transform OpenCVMat to float array, note that in this transformer, the mat is released.
 * <code>validHeight</code> valid height in case the mat is invalid
 * <code>validWidth</code> valid width in case the mat is invalid
 * <code>validChannels</code> valid channel in case the mat is invalid
 * <code>outKey</code> key to store float array
 * <code>shareBuffer</code> share buffer of output</p>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.bigdl.transform.vision.image.MatToFloats

val data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
val transformer = MatToFloats()
val transformed = transformer(data)
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">from bigdl.transform.vision.image import *
data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
transformer = MatToFloats()
transformed = transformer(data)
</code></pre>

<hr />
<h2 id="mattotensor"><strong>MatToTensor</strong></h2>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val transformer = MatToFloats(toRGB: Boolean = false,
                               tensorKey: String = ImageFeature.imageTensor)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">transformer = MatToFloats(to_rgb=False, tensor_key=&quot;imageTensor&quot;)
</code></pre>

<p>Transform opencv mat to tensor, note that in this transformer, the mat is released.
 * <code>toRGB</code> BGR to RGB (default is BGR)
 * <code>tensorKey</code> key to store transformed tensor</p>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.bigdl.transform.vision.image.MatToTensor

val data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
val transformer = MatToTensor[Float]()
val transformed = transformer(data)
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">from bigdl.transform.vision.image import *
data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
transformer = MatToTensor()
transformed = transformer(data)
</code></pre>

<hr />
<h2 id="imageframetosample"><strong>ImageFrameToSample</strong></h2>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val transformer = ImageFrameToSample(inputKeys: Array[String] = Array(ImageFeature.imageTensor),
                               targetKeys: Array[String] = null,
                               sampleKey: String = ImageFeature.sample)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">transformer = ImageFrameToSample(input_keys=[&quot;imageTensor&quot;], target_keys=None,
                                           sample_key=&quot;sample&quot;)
</code></pre>

<p>Transforms tensors that map inputKeys and targetKeys to sample,
note that in this transformer, the mat has been released.
  * <code>inputKeys</code> keys that maps inputs (each input should be a tensor)
  * <code>targetKeys</code> keys that maps targets (each target should be a tensor)
  * <code>sampleKey</code> key to store sample</p>
<p>Note that you may need to chain <code>MatToTensor</code> before <code>ImageFrameToSample</code>,
since <code>ImageFrameToSample</code> requires all inputkeys map Tensor type</p>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.bigdl.transform.vision.image._

val data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
val transformer = MatToTensor[Float]()
val toSample = ImageFrameToSample[Float]()
val transformed = transformer(data)
toSample(transformed)
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">from bigdl.transform.vision.image import *
data = ImageFrame.read(&quot;/tmp/test.jpg&quot;)
transformer = MatToTensor()
to_sample = ImageFrameToSample()
transformed = transformer(data)
to_sample(transformed)
</code></pre>

  <br>
</div>

<footer class="col-md-12 wm-page-content">
  <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>