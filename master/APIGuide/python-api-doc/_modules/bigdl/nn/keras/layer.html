
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>bigdl.nn.keras.layer &#8212; BigDL  documentation</title>
    <link rel="stylesheet" href="../../../../_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    <script type="text/javascript" src="../../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../../index.html">BigDL  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../../index.html" accesskey="U">Module code</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <h1>Source code for bigdl.nn.keras.layer</h1><div class="highlight"><pre>
<span></span><span class="c1">#</span>
<span class="c1"># Copyright 2016 The BigDL Authors.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1">#</span>

<span class="kn">import</span> <span class="nn">sys</span>

<span class="kn">from</span> <span class="nn">bigdl.nn.layer</span> <span class="k">import</span> <span class="n">Layer</span><span class="p">,</span> <span class="n">Sequential</span> <span class="k">as</span> <span class="n">TSequential</span><span class="p">,</span> <span class="n">Model</span> <span class="k">as</span> <span class="n">TModel</span>
<span class="kn">from</span> <span class="nn">bigdl.util.common</span> <span class="k">import</span> <span class="n">callBigDlFunc</span><span class="p">,</span> <span class="n">JTensor</span><span class="p">,</span> <span class="n">JavaValue</span><span class="p">,</span> <span class="n">to_list</span>

<span class="k">if</span> <span class="n">sys</span><span class="o">.</span><span class="n">version</span> <span class="o">&gt;=</span> <span class="s1">&#39;3&#39;</span><span class="p">:</span>
    <span class="n">long</span> <span class="o">=</span> <span class="nb">int</span>
    <span class="n">unicode</span> <span class="o">=</span> <span class="nb">str</span>


<div class="viewcode-block" id="InferShape"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.InferShape">[docs]</a><span class="k">class</span> <span class="nc">InferShape</span><span class="p">(</span><span class="n">JavaValue</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bigdl_type</span> <span class="o">=</span> <span class="n">bigdl_type</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">__to_keras_shape</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">([</span><span class="kc">None</span><span class="p">]</span> <span class="o">+</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>

    <span class="k">def</span> <span class="nf">__process_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__to_keras_shape</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">__to_keras_shape</span><span class="p">(</span><span class="n">s</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">shape</span><span class="p">]</span>

<div class="viewcode-block" id="InferShape.get_input_shape"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.InferShape.get_input_shape">[docs]</a>    <span class="k">def</span> <span class="nf">get_input_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return a list of shape tuples if there are multiple inputs.</span>
<span class="sd">        Return one shape tuple otherwise.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">input</span> <span class="o">=</span> <span class="n">callBigDlFunc</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bigdl_type</span><span class="p">,</span> <span class="s2">&quot;getInputShape&quot;</span><span class="p">,</span>
                              <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">)</span></div>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__process_shape</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>

<div class="viewcode-block" id="InferShape.get_output_shape"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.InferShape.get_output_shape">[docs]</a>    <span class="k">def</span> <span class="nf">get_output_shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return a list of shape tuples if there are multiple outputs.</span>
<span class="sd">        Return one shape tuple otherwise.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">callBigDlFunc</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bigdl_type</span><span class="p">,</span> <span class="s2">&quot;getOutputShape&quot;</span><span class="p">,</span>
                               <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">)</span></div></div>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">__process_shape</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>


<div class="viewcode-block" id="KerasLayer"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.KerasLayer">[docs]</a><span class="k">class</span> <span class="nc">KerasLayer</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
<div class="viewcode-block" id="KerasLayer.jvm_class_constructor"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.KerasLayer.jvm_class_constructor">[docs]</a>    <span class="k">def</span> <span class="nf">jvm_class_constructor</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;createKeras&quot;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;creating: &quot;</span> <span class="o">+</span> <span class="n">name</span><span class="p">)</span></div></div>
        <span class="k">return</span> <span class="n">name</span>


<div class="viewcode-block" id="Sequential"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.Sequential">[docs]</a><span class="k">class</span> <span class="nc">Sequential</span><span class="p">(</span><span class="n">TSequential</span><span class="p">,</span> <span class="n">InferShape</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Container for a Sequential model.</span>

<span class="sd">    &gt;&gt;&gt; sequential = Sequential()</span>
<span class="sd">    creating: createSequential</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span></div>
        <span class="nb">super</span><span class="p">(</span><span class="n">Sequential</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">bigdl_type</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>


<div class="viewcode-block" id="Model"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.Model">[docs]</a><span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">TModel</span><span class="p">,</span> <span class="n">InferShape</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">to_list</span><span class="p">(</span><span class="nb">input</span><span class="p">),</span>
                                    <span class="n">to_list</span><span class="p">(</span><span class="n">output</span><span class="p">),</span>
                                    <span class="n">is_keras</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span></div>
                                    <span class="n">bigdl_type</span><span class="o">=</span><span class="n">bigdl_type</span><span class="p">)</span>


<div class="viewcode-block" id="Input"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.Input">[docs]</a><span class="k">class</span> <span class="nc">Input</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Input</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                    <span class="n">name</span><span class="p">,</span></div>
                                    <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="InputLayer"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.InputLayer">[docs]</a><span class="k">class</span> <span class="nc">InputLayer</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Layer to be used as an entry point into a model.</span>

<span class="sd">    # Arguments</span>
<span class="sd">    input_shape: A shape tuple, not including the batch axis.</span>

<span class="sd">    &gt;&gt;&gt; inputlayer = InputLayer(input_shape=(3, 5))</span>
<span class="sd">    creating: createKerasInputLayer</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">InputLayer</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span></div>
                                         <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="Dense"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.Dense">[docs]</a><span class="k">class</span> <span class="nc">Dense</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A densely-connected NN layer.</span>
<span class="sd">    The most common input is 2D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    output_dim: The size of output dimension.</span>
<span class="sd">    init: String representations of initialization method for the weights of the layer.</span>
<span class="sd">          Default is &#39;glorot_uniform&#39;.</span>
<span class="sd">    activation: String representations of activation function to use (such as &#39;relu&#39; or &#39;sigmoid&#39;).</span>
<span class="sd">                Default is None.</span>
<span class="sd">    W_regularizer: An instance of [[Regularizer]], (eg. L1 or L2 regularization),</span>
<span class="sd">                   applied to the input weights matrices. Default is None.</span>
<span class="sd">    b_regularizer: An instance of [[Regularizer]], applied to the bias. Default is None.</span>
<span class="sd">    bias: Whether to include a bias (i.e. make the layer affine rather than linear). Default is True.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; dense = Dense(10, input_shape=(3, 4))</span>
<span class="sd">    creating: createKerasDense</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s2">&quot;glorot_uniform&quot;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">W_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">b_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Dense</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                    <span class="n">output_dim</span><span class="p">,</span>
                                    <span class="n">init</span><span class="p">,</span>
                                    <span class="n">activation</span><span class="p">,</span>
                                    <span class="n">W_regularizer</span><span class="p">,</span>
                                    <span class="n">b_regularizer</span><span class="p">,</span>
                                    <span class="n">bias</span><span class="p">,</span></div>
                                    <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="MaxoutDense"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.MaxoutDense">[docs]</a><span class="k">class</span> <span class="nc">MaxoutDense</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A dense maxout layer that takes the element-wise maximum of nbFeature, Dense(inputDim, outputDim) linear layers.</span>
<span class="sd">    This allows the layer to learn a convex, piecewise linear activation function over the inputs.</span>
<span class="sd">    The input of this layer should be 2D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    output_dim: The size of output dimension.</span>
<span class="sd">    nb_feature: Number of Dense layers to use internally. Int. Default is 4.</span>
<span class="sd">    W_regularizer: An instance of [[Regularizer]], (eg. L1 or L2 regularization),</span>
<span class="sd">                   applied to the input weights matrices. Default is None.</span>
<span class="sd">    b_regularizer: An instance of [[Regularizer]], applied to the bias. Default is None.</span>
<span class="sd">    bias: Whether to include a bias (i.e. make the layer affine rather than linear). Default is True.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; maxoutdense = MaxoutDense(6, input_shape=(10, ))</span>
<span class="sd">    creating: createKerasMaxoutDense</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">nb_feature</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">W_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">b_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MaxoutDense</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                          <span class="n">output_dim</span><span class="p">,</span>
                                          <span class="n">nb_feature</span><span class="p">,</span>
                                          <span class="n">W_regularizer</span><span class="p">,</span>
                                          <span class="n">b_regularizer</span><span class="p">,</span>
                                          <span class="n">bias</span><span class="p">,</span></div>
                                          <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="Embedding"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.Embedding">[docs]</a><span class="k">class</span> <span class="nc">Embedding</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Turn positive integers (indexes) into dense vectors of fixed size.</span>
<span class="sd">    The input of this layer should be 2D.</span>

<span class="sd">    This layer can only be used as the first layer in a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    input_dim: Size of the vocabulary. Int &gt; 0.</span>
<span class="sd">    output_dim: Dimension of the dense embedding. Int &gt;= 0.</span>
<span class="sd">    init: String representations of initialization method for the weights of the layer.</span>
<span class="sd">          Default is &#39;uniform&#39;.</span>
<span class="sd">    W_regularizer: An instance of [[Regularizer]], (eg. L1 or L2 regularization),</span>
<span class="sd">                   applied to the embedding matrix. Default is None.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; embedding = Embedding(1000, 32, input_shape=(10, ))</span>
<span class="sd">    creating: createKerasEmbedding</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s2">&quot;uniform&quot;</span><span class="p">,</span>
                 <span class="n">W_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Embedding</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                        <span class="n">input_dim</span><span class="p">,</span>
                                        <span class="n">output_dim</span><span class="p">,</span>
                                        <span class="n">init</span><span class="p">,</span>
                                        <span class="n">W_regularizer</span><span class="p">,</span></div>
                                        <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="BatchNormalization"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.BatchNormalization">[docs]</a><span class="k">class</span> <span class="nc">BatchNormalization</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Batch normalization layer.</span>
<span class="sd">    Normalize the activations of the previous layer at each batch, i.e. applies a transformation</span>
<span class="sd">    that maintains the mean activation close to 0 and the activation standard deviation close to 1.</span>
<span class="sd">    It is a feature-wise normalization, each feature map in the input will be normalized separately.</span>
<span class="sd">    The input of this layer should be 4D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    epsilon: Small float &gt; 0. Fuzz parameter. Default is 0.001.</span>
<span class="sd">    momentum: Float. Momentum in the computation of the exponential average of the mean and</span>
<span class="sd">              standard deviation of the data, for feature-wise normalization. Default is 0.99.</span>
<span class="sd">    beta_init: Name of initialization function for shift parameter. Default is &#39;zero&#39;.</span>
<span class="sd">    gamma_init: Name of initialization function for scale parameter. Default is &#39;one&#39;.</span>
<span class="sd">    dim_ordering: Format of input data. Either &#39;th&#39; (Channel First) or &#39;tf&#39; (Channel Last). Default is &#39;th&#39;.</span>
<span class="sd">                  For &#39;th&#39;, axis along which to normalize is 1. For &#39;tf&#39;, axis is 3.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; batchnormalization = BatchNormalization(input_shape=(3, 12, 12))</span>
<span class="sd">    creating: createKerasBatchNormalization</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epsilon</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">beta_init</span><span class="o">=</span><span class="s2">&quot;zero&quot;</span><span class="p">,</span> <span class="n">gamma_init</span><span class="o">=</span><span class="s2">&quot;one&quot;</span><span class="p">,</span>
                 <span class="n">dim_ordering</span><span class="o">=</span><span class="s2">&quot;th&quot;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BatchNormalization</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                 <span class="nb">float</span><span class="p">(</span><span class="n">epsilon</span><span class="p">),</span>
                                                 <span class="nb">float</span><span class="p">(</span><span class="n">momentum</span><span class="p">),</span>
                                                 <span class="n">beta_init</span><span class="p">,</span>
                                                 <span class="n">gamma_init</span><span class="p">,</span>
                                                 <span class="n">dim_ordering</span><span class="p">,</span>
                                                 <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>

<div class="viewcode-block" id="BatchNormalization.set_running_mean"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.BatchNormalization.set_running_mean">[docs]</a>    <span class="k">def</span> <span class="nf">set_running_mean</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">running_mean</span><span class="p">):</span>
        <span class="n">callBigDlFunc</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bigdl_type</span><span class="p">,</span> <span class="s2">&quot;setKerasRunningMean&quot;</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">JTensor</span><span class="o">.</span><span class="n">from_ndarray</span><span class="p">(</span><span class="n">running_mean</span><span class="p">))</span></div>
        <span class="k">return</span> <span class="bp">self</span>

<div class="viewcode-block" id="BatchNormalization.set_running_std"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.BatchNormalization.set_running_std">[docs]</a>    <span class="k">def</span> <span class="nf">set_running_std</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">running_std</span><span class="p">):</span>
        <span class="n">callBigDlFunc</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bigdl_type</span><span class="p">,</span> <span class="s2">&quot;setKerasRunningStd&quot;</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">,</span> <span class="n">JTensor</span><span class="o">.</span><span class="n">from_ndarray</span><span class="p">(</span><span class="n">running_std</span><span class="p">))</span></div>
        <span class="k">return</span> <span class="bp">self</span>

<div class="viewcode-block" id="BatchNormalization.get_running_mean"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.BatchNormalization.get_running_mean">[docs]</a>    <span class="k">def</span> <span class="nf">get_running_mean</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">callBigDlFunc</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bigdl_type</span><span class="p">,</span> <span class="s2">&quot;getKerasRunningMean&quot;</span><span class="p">,</span></div>
                             <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">)</span><span class="o">.</span><span class="n">to_ndarray</span><span class="p">()</span>

<div class="viewcode-block" id="BatchNormalization.get_running_std"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.BatchNormalization.get_running_std">[docs]</a>    <span class="k">def</span> <span class="nf">get_running_std</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">callBigDlFunc</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">bigdl_type</span><span class="p">,</span> <span class="s2">&quot;getKerasRunningStd&quot;</span><span class="p">,</span></div></div>
                             <span class="bp">self</span><span class="o">.</span><span class="n">value</span><span class="p">)</span><span class="o">.</span><span class="n">to_ndarray</span><span class="p">()</span>


<div class="viewcode-block" id="Merge"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.Merge">[docs]</a><span class="k">class</span> <span class="nc">Merge</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Used to merge a list of tensors into a single tensor, following some merge mode.</span>
<span class="sd">    Merge must have at least two input layers.</span>

<span class="sd">    When using this layer as the first layer in a model, you need to provide the argument</span>
<span class="sd">    input_shape for input layers (a list of shape tuples, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    layers: A list of layer instances. Must be more than one layer.</span>
<span class="sd">    mode: Merge mode. String, must be one of: &#39;sum&#39;, &#39;mul&#39;, &#39;concat&#39;, &#39;ave&#39;, &#39;cos&#39;,</span>
<span class="sd">          &#39;dot&#39;, &#39;max&#39;. Default is &#39;sum&#39;.</span>
<span class="sd">    concat_axis: Int, axis to use in mode concat. Only specify this when mode is &#39;concat&#39;.</span>
<span class="sd">                 Default is -1, meaning the last axis of the input.</span>
<span class="sd">    input_shape: A list of shape tuples, each not including batch.</span>

<span class="sd">    &gt;&gt;&gt; l1 = InputLayer(input_shape=(3, 5))</span>
<span class="sd">    creating: createKerasInputLayer</span>
<span class="sd">    &gt;&gt;&gt; l2 = InputLayer(input_shape=(3, 5))</span>
<span class="sd">    creating: createKerasInputLayer</span>
<span class="sd">    &gt;&gt;&gt; merge = Merge(layers=[l1, l2], mode=&#39;sum&#39;)</span>
<span class="sd">    creating: createKerasMerge</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layers</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span><span class="p">,</span> <span class="n">concat_axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Merge</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                    <span class="nb">list</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span> <span class="k">if</span> <span class="n">layers</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
                                    <span class="n">mode</span><span class="p">,</span>
                                    <span class="n">concat_axis</span><span class="p">,</span></div>
                                    <span class="n">input_shape</span><span class="p">)</span>


<div class="viewcode-block" id="Dropout"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.Dropout">[docs]</a><span class="k">class</span> <span class="nc">Dropout</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies Dropout to the input by randomly setting a fraction &#39;p&#39; of input units to 0 at each</span>
<span class="sd">    update during training time in order to prevent overfitting.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    p: Fraction of the input units to drop. Float between 0 and 1.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; dropout = Dropout(0.25, input_shape=(2, 3))</span>
<span class="sd">    creating: createKerasDropout</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Dropout</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                      <span class="nb">float</span><span class="p">(</span><span class="n">p</span><span class="p">),</span></div>
                                      <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="Flatten"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.Flatten">[docs]</a><span class="k">class</span> <span class="nc">Flatten</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Flattens the input without affecting the batch size.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; flatten = Flatten(input_shape=(3, 10, 2))</span>
<span class="sd">    creating: createKerasFlatten</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Flatten</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span></div>
                                      <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="Reshape"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.Reshape">[docs]</a><span class="k">class</span> <span class="nc">Reshape</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Reshapes an output to a certain shape.</span>
<span class="sd">    Supports shape inference by allowing one -1 in the target shape.</span>
<span class="sd">    For example, if input_shape = (2, 3, 4), target_shape = (3, -1),</span>
<span class="sd">    then output_shape will be (3, 8).</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    target_shape: A shape tuple. The target shape that you desire to have. Batch dimension should be excluded.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; reshape = Reshape((2, 10), input_shape=(5, 4))</span>
<span class="sd">    creating: createKerasReshape</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target_shape</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Reshape</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                      <span class="n">target_shape</span><span class="p">,</span></div>
                                      <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="Activation"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.Activation">[docs]</a><span class="k">class</span> <span class="nc">Activation</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Simple activation function to be applied to the output.</span>
<span class="sd">    Available activations: &#39;tanh&#39;, &#39;relu&#39;, &#39;sigmoid&#39;, &#39;softmax&#39;, &#39;softplus&#39;, &#39;softsign&#39;, &#39;hard_sigmoid&#39;.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    activation: Name of the activation function as string.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; activation = Activation(&quot;relu&quot;, input_shape=(3, 4))</span>
<span class="sd">    creating: createKerasActivation</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">activation</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Activation</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                         <span class="n">activation</span><span class="p">,</span></div>
                                         <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="RepeatVector"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.RepeatVector">[docs]</a><span class="k">class</span> <span class="nc">RepeatVector</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Repeats the input n times.</span>
<span class="sd">    The input of this layer should be 2D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    n: Repetition factor. Int.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; repeatvector = RepeatVector(5, input_shape=(3, ))</span>
<span class="sd">    creating: createKerasRepeatVector</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">RepeatVector</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                           <span class="n">n</span><span class="p">,</span></div>
                                           <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="Permute"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.Permute">[docs]</a><span class="k">class</span> <span class="nc">Permute</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Permutes the dimensions of the input according to a given pattern.</span>
<span class="sd">    Useful for connecting RNNs and convnets together.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    dims: Tuple of int. Permutation pattern, does not include the samples dimension. Indexing starts at 1.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; permute = Permute((2, 1, 3), input_shape=(3, 4, 5))</span>
<span class="sd">    creating: createKerasPermute</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dims</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Permute</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                      <span class="n">dims</span><span class="p">,</span></div>
                                      <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="Highway"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.Highway">[docs]</a><span class="k">class</span> <span class="nc">Highway</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Densely connected highway network. Highway layers are a natural extension of LSTMs to feedforward networks.</span>
<span class="sd">    The input of this layer should be 2D, i.e. (batch, input dim).</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    activation: String representations of activation function to use (such as &#39;relu&#39; or &#39;sigmoid&#39;).</span>
<span class="sd">                Default is None.</span>
<span class="sd">    W_regularizer: An instance of [[Regularizer]], (eg. L1 or L2 regularization),</span>
<span class="sd">                   applied to the input weights matrices. Default is None.</span>
<span class="sd">    b_regularizer: An instance of [[Regularizer]], applied to the bias. Default is None.</span>
<span class="sd">    bias: Whether to include a bias (i.e. make the layer affine rather than linear).</span>
<span class="sd">          Default is True.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; highway = Highway(activation=&#39;relu&#39;, input_shape=(8, ))</span>
<span class="sd">    creating: createKerasHighway</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">W_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">b_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Highway</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                      <span class="n">activation</span><span class="p">,</span>
                                      <span class="n">W_regularizer</span><span class="p">,</span>
                                      <span class="n">b_regularizer</span><span class="p">,</span>
                                      <span class="n">bias</span><span class="p">,</span></div>
                                      <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="Convolution1D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.Convolution1D">[docs]</a><span class="k">class</span> <span class="nc">Convolution1D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies convolution operator for filtering neighborhoods of 1D inputs.</span>
<span class="sd">    You can also use Conv1D as an alias of this layer.</span>
<span class="sd">    The input of this layer should be 3D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    nb_filter: Number of convolution filters to use.</span>
<span class="sd">    filter_length: The extension (spatial or temporal) of each filter.</span>
<span class="sd">    init: String representations of initialization method for the weights of the layer.</span>
<span class="sd">          Default is &#39;glorot_uniform&#39;.</span>
<span class="sd">    activation: String representations of activation function to use (such as &#39;relu&#39; or &#39;sigmoid&#39;).</span>
<span class="sd">                Default is None.</span>
<span class="sd">    border_mode: Either &#39;valid&#39; or &#39;same&#39;. Default is &#39;valid&#39;.</span>
<span class="sd">    subsample_length: Factor by which to subsample output. Int. Default is 1.</span>
<span class="sd">    W_regularizer: An instance of [[Regularizer]], (eg. L1 or L2 regularization),</span>
<span class="sd">                   applied to the input weights matrices. Default is None.</span>
<span class="sd">    b_regularizer: An instance of [[Regularizer]], applied to the bias. Default is None.</span>
<span class="sd">    bias: Whether to include a bias (i.e. make the layer affine rather than linear).</span>
<span class="sd">          Default is True.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; conv1d = Convolution1D(12, 4, input_shape=(3, 16))</span>
<span class="sd">    creating: createKerasConvolution1D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nb_filter</span><span class="p">,</span> <span class="n">filter_length</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s2">&quot;glorot_uniform&quot;</span><span class="p">,</span>
                 <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">border_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span> <span class="n">subsample_length</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">W_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">b_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Convolution1D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                            <span class="n">nb_filter</span><span class="p">,</span>
                                            <span class="n">filter_length</span><span class="p">,</span>
                                            <span class="n">init</span><span class="p">,</span>
                                            <span class="n">activation</span><span class="p">,</span>
                                            <span class="n">border_mode</span><span class="p">,</span>
                                            <span class="n">subsample_length</span><span class="p">,</span>
                                            <span class="n">W_regularizer</span><span class="p">,</span>
                                            <span class="n">b_regularizer</span><span class="p">,</span>
                                            <span class="n">bias</span><span class="p">,</span></div>
                                            <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="Convolution2D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.Convolution2D">[docs]</a><span class="k">class</span> <span class="nc">Convolution2D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies a 2D convolution over an input image composed of several input planes.</span>
<span class="sd">    You can also use Conv2D as an alias of this layer.</span>
<span class="sd">    The input of this layer should be 4D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>
<span class="sd">    e.g. input_shape=(3, 128, 128) for 128x128 RGB pictures.</span>

<span class="sd">    # Arguments</span>
<span class="sd">    nb_filter: Number of convolution filters to use.</span>
<span class="sd">    nb_row: Number of rows in the convolution kernel.</span>
<span class="sd">    nb_col: Number of cols in the convolution kernel.</span>
<span class="sd">    init: String representations of initialization method for the weights of the layer.</span>
<span class="sd">          Default is &#39;glorot_uniform&#39;.</span>
<span class="sd">    activation: String representations of activation function to use (such as &#39;relu&#39; or &#39;sigmoid&#39;).</span>
<span class="sd">                Default is None.</span>
<span class="sd">    border_mode: Either &#39;valid&#39; or &#39;same&#39;. Default is &#39;valid&#39;.</span>
<span class="sd">    subsample: Int tuple of length 2 corresponding to the step of the convolution in the</span>
<span class="sd">               height and width dimension. Also called strides elsewhere. Default is (1, 1).</span>
<span class="sd">    dim_ordering: Format of input data. Either &#39;th&#39; (Channel First) or &#39;tf&#39; (Channel Last). Default is &#39;th&#39;.</span>
<span class="sd">    W_regularizer: An instance of [[Regularizer]], (eg. L1 or L2 regularization),</span>
<span class="sd">                   applied to the input weights matrices. Default is None.</span>
<span class="sd">    b_regularizer: An instance of [[Regularizer]], applied to the bias. Default is None.</span>
<span class="sd">    bias: Whether to include a bias (i.e. make the layer affine rather than linear).</span>
<span class="sd">          Default is True.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; conv2d = Convolution2D(32, 3, 3, input_shape=(3, 128, 128))</span>
<span class="sd">    creating: createKerasConvolution2D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nb_filter</span><span class="p">,</span> <span class="n">nb_row</span><span class="p">,</span> <span class="n">nb_col</span><span class="p">,</span>
                 <span class="n">init</span><span class="o">=</span><span class="s2">&quot;glorot_uniform&quot;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">border_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dim_ordering</span><span class="o">=</span><span class="s2">&quot;th&quot;</span><span class="p">,</span>
                 <span class="n">W_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">b_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Convolution2D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                            <span class="n">nb_filter</span><span class="p">,</span>
                                            <span class="n">nb_row</span><span class="p">,</span>
                                            <span class="n">nb_col</span><span class="p">,</span>
                                            <span class="n">init</span><span class="p">,</span>
                                            <span class="n">activation</span><span class="p">,</span>
                                            <span class="n">border_mode</span><span class="p">,</span>
                                            <span class="n">subsample</span><span class="p">,</span>
                                            <span class="n">dim_ordering</span><span class="p">,</span>
                                            <span class="n">W_regularizer</span><span class="p">,</span>
                                            <span class="n">b_regularizer</span><span class="p">,</span>
                                            <span class="n">bias</span><span class="p">,</span></div>
                                            <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="Convolution3D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.Convolution3D">[docs]</a><span class="k">class</span> <span class="nc">Convolution3D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies convolution operator for filtering windows of three-dimensional inputs.</span>
<span class="sd">    You can also use Conv3D as an alias of this layer.</span>
<span class="sd">    Data format currently supported for this layer is dim_ordering=&#39;th&#39; (Channel First).</span>
<span class="sd">    The input of this layer should be 5D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    nb_filter: Number of convolution filters to use.</span>
<span class="sd">    kernel_dim1: Length of the first dimension in the convolution kernel.</span>
<span class="sd">    kernel_dim2: Length of the second dimension in the convolution kernel.</span>
<span class="sd">    kernel_dim3: Length of the third dimension in the convolution kernel.</span>
<span class="sd">    init: String representations of initialization method for the weights of the layer.</span>
<span class="sd">          Default is &#39;glorot_uniform&#39;.</span>
<span class="sd">    activation: String representations of activation function to use (such as &#39;relu&#39; or &#39;sigmoid&#39;).</span>
<span class="sd">                Default is None.</span>
<span class="sd">    border_mode: Either &#39;valid&#39; or &#39;same&#39;. Default is &#39;valid&#39;.</span>
<span class="sd">    subsample: Int tuple of length 3. Factor by which to subsample output.</span>
<span class="sd">               Also called strides elsewhere. Default is (1, 1, 1).</span>
<span class="sd">    dim_ordering: Format of input data. Only &#39;th&#39; (Channel First) is supported for now.</span>
<span class="sd">    W_regularizer: An instance of [[Regularizer]], (eg. L1 or L2 regularization),</span>
<span class="sd">                   applied to the input weights matrices. Default is None.</span>
<span class="sd">    b_regularizer: An instance of [[Regularizer]], applied to the bias. Default is None.</span>
<span class="sd">    bias: Whether to include a bias (i.e. make the layer affine rather than linear).</span>
<span class="sd">          Default is True.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; conv3d = Convolution3D(32, 3, 4, 5, input_shape=(3, 64, 64, 64))</span>
<span class="sd">    creating: createKerasConvolution3D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nb_filter</span><span class="p">,</span> <span class="n">kernel_dim1</span><span class="p">,</span> <span class="n">kernel_dim2</span><span class="p">,</span> <span class="n">kernel_dim3</span><span class="p">,</span>
                 <span class="n">init</span><span class="o">=</span><span class="s2">&quot;glorot_uniform&quot;</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">border_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span>
                 <span class="n">subsample</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dim_ordering</span><span class="o">=</span><span class="s2">&quot;th&quot;</span><span class="p">,</span> <span class="n">W_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">b_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Convolution3D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                            <span class="n">nb_filter</span><span class="p">,</span>
                                            <span class="n">kernel_dim1</span><span class="p">,</span>
                                            <span class="n">kernel_dim2</span><span class="p">,</span>
                                            <span class="n">kernel_dim3</span><span class="p">,</span>
                                            <span class="n">init</span><span class="p">,</span>
                                            <span class="n">activation</span><span class="p">,</span>
                                            <span class="n">border_mode</span><span class="p">,</span>
                                            <span class="n">subsample</span><span class="p">,</span>
                                            <span class="n">dim_ordering</span><span class="p">,</span>
                                            <span class="n">W_regularizer</span><span class="p">,</span>
                                            <span class="n">b_regularizer</span><span class="p">,</span>
                                            <span class="n">bias</span><span class="p">,</span></div>
                                            <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="AtrousConvolution1D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.AtrousConvolution1D">[docs]</a><span class="k">class</span> <span class="nc">AtrousConvolution1D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies an atrous convolution operator for filtering neighborhoods of 1D inputs.</span>
<span class="sd">    A.k.a dilated convolution or convolution with holes.</span>
<span class="sd">    Border mode currently supported for this layer is &#39;valid&#39;.</span>
<span class="sd">    Bias will be included in this layer.</span>
<span class="sd">    You can also use AtrousConv1D as an alias of this layer.</span>
<span class="sd">    The input of this layer should be 3D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    nb_filter: Number of convolution filters to use.</span>
<span class="sd">    filter_length: The extension (spatial or temporal) of each filter.</span>
<span class="sd">    init: String representations of initialization method for the weights of the layer.</span>
<span class="sd">          Default is &#39;glorot_uniform&#39;.</span>
<span class="sd">    activation: String representations of activation function to use (such as &#39;relu&#39; or &#39;sigmoid&#39;).</span>
<span class="sd">                Default is None.</span>
<span class="sd">    border_mode: Only &#39;valid&#39; is supported for now.</span>
<span class="sd">    subsample_length: Factor by which to subsample output. Int. Default is 1.</span>
<span class="sd">    atrous_rate: Factor for kernel dilation. Also called filter_dilation elsewhere. Int. Default is 1.</span>
<span class="sd">    W_regularizer: An instance of [[Regularizer]], (eg. L1 or L2 regularization),</span>
<span class="sd">                   applied to the input weights matrices. Default is None.</span>
<span class="sd">    b_regularizer: An instance of [[Regularizer]], applied to the bias. Default is None.</span>
<span class="sd">    bias: Only &#39;True&#39; is supported for now.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; atrousconv1d = AtrousConvolution1D(8, 3, input_shape=(3, 12))</span>
<span class="sd">    creating: createKerasAtrousConvolution1D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nb_filter</span><span class="p">,</span> <span class="n">filter_length</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s2">&quot;glorot_uniform&quot;</span><span class="p">,</span>
                 <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">border_mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">,</span> <span class="n">subsample_length</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">atrous_rate</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">W_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">b_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">border_mode</span> <span class="o">!=</span> <span class="s2">&quot;valid&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;For AtrousConvolution1D, only border_mode=&#39;valid&#39; is supported for now&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">bias</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;For AtrousConvolution1D, only bias=True is supported for now&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AtrousConvolution1D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                  <span class="n">nb_filter</span><span class="p">,</span>
                                                  <span class="n">filter_length</span><span class="p">,</span>
                                                  <span class="n">init</span><span class="p">,</span>
                                                  <span class="n">activation</span><span class="p">,</span>
                                                  <span class="n">subsample_length</span><span class="p">,</span>
                                                  <span class="n">atrous_rate</span><span class="p">,</span>
                                                  <span class="n">W_regularizer</span><span class="p">,</span>
                                                  <span class="n">b_regularizer</span><span class="p">,</span></div>
                                                  <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="AtrousConvolution2D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.AtrousConvolution2D">[docs]</a><span class="k">class</span> <span class="nc">AtrousConvolution2D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies an atrous Convolution operator for filtering windows of 2D inputs.</span>
<span class="sd">    A.k.a dilated convolution or convolution with holes.</span>
<span class="sd">    Data format currently supported for this layer is dim_ordering=&#39;th&#39; (Channel First).</span>
<span class="sd">    Border mode currently supported for this layer is &#39;valid&#39;.</span>
<span class="sd">    Bias will be included in this layer.</span>
<span class="sd">    You can also use AtrousConv2D as an alias of this layer.</span>
<span class="sd">    The input of this layer should be 4D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>
<span class="sd">    e.g. input_shape=(3, 128, 128) for 128x128 RGB pictures.</span>

<span class="sd">    # Arguments</span>
<span class="sd">    nb_filter: Number of convolution filters to use.</span>
<span class="sd">    nb_row: Number of rows in the convolution kernel.</span>
<span class="sd">    nb_col: Number of cols in the convolution kernel.</span>
<span class="sd">    init: String representations of initialization method for the weights of the layer.</span>
<span class="sd">          Default is &#39;glorot_uniform&#39;.</span>
<span class="sd">    activation: String representations of activation function to use (such as &#39;relu&#39; or &#39;sigmoid&#39;).</span>
<span class="sd">                Default is None.</span>
<span class="sd">    border_mode: Only &#39;valid&#39; is supported for now.</span>
<span class="sd">    subsample: Int tuple of length 2 corresponding to the step of the convolution in the</span>
<span class="sd">               height and width dimension. Also called strides elsewhere. Default is (1, 1).</span>
<span class="sd">    atrous_rate: Int tuple of length 2. Factor for kernel dilation.</span>
<span class="sd">                 Also called filter_dilation elsewhere. Default is (1, 1).</span>
<span class="sd">    dim_ordering: Format of input data. Only &#39;th&#39; (Channel First) is supported for now.</span>
<span class="sd">    W_regularizer: An instance of [[Regularizer]], (eg. L1 or L2 regularization),</span>
<span class="sd">                   applied to the input weights matrices. Default is None.</span>
<span class="sd">    b_regularizer: An instance of [[Regularizer]], applied to the bias. Default is None.</span>
<span class="sd">    bias: Only &#39;True&#39; is supported for now.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; atrousconv2d = AtrousConvolution2D(12, 4, 3, input_shape=(3, 64, 64))</span>
<span class="sd">    creating: createKerasAtrousConvolution2D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nb_filter</span><span class="p">,</span> <span class="n">nb_row</span><span class="p">,</span> <span class="n">nb_col</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s2">&quot;glorot_uniform&quot;</span><span class="p">,</span>
                 <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">border_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                 <span class="n">atrous_rate</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dim_ordering</span><span class="o">=</span><span class="s2">&quot;th&quot;</span><span class="p">,</span> <span class="n">W_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">b_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">border_mode</span> <span class="o">!=</span> <span class="s2">&quot;valid&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;For AtrousConvolution2D, only border_mode=&#39;valid&#39; is supported for now&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">bias</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;For AtrousConvolution2D, only bias=True is supported for now&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AtrousConvolution2D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                  <span class="n">nb_filter</span><span class="p">,</span>
                                                  <span class="n">nb_row</span><span class="p">,</span>
                                                  <span class="n">nb_col</span><span class="p">,</span>
                                                  <span class="n">init</span><span class="p">,</span>
                                                  <span class="n">activation</span><span class="p">,</span>
                                                  <span class="n">subsample</span><span class="p">,</span>
                                                  <span class="n">atrous_rate</span><span class="p">,</span>
                                                  <span class="n">dim_ordering</span><span class="p">,</span>
                                                  <span class="n">W_regularizer</span><span class="p">,</span>
                                                  <span class="n">b_regularizer</span><span class="p">,</span></div>
                                                  <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="Deconvolution2D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.Deconvolution2D">[docs]</a><span class="k">class</span> <span class="nc">Deconvolution2D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Transposed convolution operator for filtering windows of 2D inputs.</span>
<span class="sd">    The need for transposed convolutions generally arises from the desire to use a transformation</span>
<span class="sd">    going in the opposite direction of a normal convolution, i.e., from something that has</span>
<span class="sd">    the shape of the output of some convolution to something that has the shape of its input</span>
<span class="sd">    while maintaining a connectivity pattern that is compatible with said convolution.</span>
<span class="sd">    Data format currently supported for this layer is dim_ordering=&#39;th&#39; (Channel First).</span>
<span class="sd">    Border mode currently supported for this layer is &#39;valid&#39;.</span>
<span class="sd">    You can also use Deconv2D as an alias of this layer.</span>
<span class="sd">    The input of this layer should be 4D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>
<span class="sd">    e.g. input_shape=(3, 128, 128) for 128x128 RGB pictures.</span>

<span class="sd">    # Arguments</span>
<span class="sd">    nb_filter: Number of transposed convolution filters to use.</span>
<span class="sd">    nb_row: Number of rows in the convolution kernel.</span>
<span class="sd">    nb_col: Number of cols in the convolution kernel.</span>
<span class="sd">    output_shape: Output shape of the transposed convolution operation. Tuple of int.</span>
<span class="sd">    init: String representations of initialization method for the weights of the layer.</span>
<span class="sd">          Default is &#39;glorot_uniform&#39;.</span>
<span class="sd">    activation: String representations of activation function to use (such as &#39;relu&#39; or &#39;sigmoid&#39;).</span>
<span class="sd">                Default is None.</span>
<span class="sd">    border_mode: Only &#39;valid&#39; is supported for now.</span>
<span class="sd">    subsample: Int tuple of length 2 corresponding to the step of the convolution in the</span>
<span class="sd">               height and width dimension. Also called strides elsewhere. Default is (1, 1).</span>
<span class="sd">    dim_ordering: Format of input data. Only &#39;th&#39; (Channel First) is supported for now.</span>
<span class="sd">    W_regularizer: An instance of [[Regularizer]], (eg. L1 or L2 regularization),</span>
<span class="sd">                   applied to the input weights matrices. Default is None.</span>
<span class="sd">    b_regularizer: An instance of [[Regularizer]], applied to the bias. Default is None.</span>
<span class="sd">    bias: Whether to include a bias (i.e. make the layer affine rather than linear).</span>
<span class="sd">          Default is True.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; deconv2d = Deconvolution2D(3, 3, 3, output_shape=(None, 3, 14, 14), input_shape=(3, 12, 12))</span>
<span class="sd">    creating: createKerasDeconvolution2D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nb_filter</span><span class="p">,</span> <span class="n">nb_row</span><span class="p">,</span> <span class="n">nb_col</span><span class="p">,</span> <span class="n">output_shape</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s2">&quot;glorot_uniform&quot;</span><span class="p">,</span>
                 <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">border_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dim_ordering</span><span class="o">=</span><span class="s2">&quot;th&quot;</span><span class="p">,</span>
                 <span class="n">W_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">b_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">border_mode</span> <span class="o">!=</span> <span class="s2">&quot;valid&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;For Deconvolution2D, only border_mode=&#39;valid&#39; is supported for now&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Deconvolution2D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                              <span class="n">nb_filter</span><span class="p">,</span>
                                              <span class="n">nb_row</span><span class="p">,</span>
                                              <span class="n">nb_col</span><span class="p">,</span>
                                              <span class="n">init</span><span class="p">,</span>
                                              <span class="n">activation</span><span class="p">,</span>
                                              <span class="n">subsample</span><span class="p">,</span>
                                              <span class="n">dim_ordering</span><span class="p">,</span>
                                              <span class="n">W_regularizer</span><span class="p">,</span>
                                              <span class="n">b_regularizer</span><span class="p">,</span>
                                              <span class="n">bias</span><span class="p">,</span></div>
                                              <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="SeparableConvolution2D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.SeparableConvolution2D">[docs]</a><span class="k">class</span> <span class="nc">SeparableConvolution2D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies separable convolution operator for 2D inputs.</span>
<span class="sd">    Separable convolutions consist in first performing a depthwise spatial convolution (which acts</span>
<span class="sd">    on each input channel separately) followed by a pointwise convolution which mixes together the</span>
<span class="sd">    resulting output channels. The depthMultiplier argument controls how many output channels are</span>
<span class="sd">    generated per input channel in the depthwise step.</span>
<span class="sd">    You can also use SeparableConv2D as an alias of this layer.</span>
<span class="sd">    The input of this layer should be 4D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>
<span class="sd">    e.g. input_shape=(3, 128, 128) for 128x128 RGB pictures.</span>

<span class="sd">    # Arguments</span>
<span class="sd">    nb_filter: Number of convolution filters to use.</span>
<span class="sd">    nb_row: Number of rows in the convolution kernel.</span>
<span class="sd">    nb_col: Number of cols in the convolution kernel.</span>
<span class="sd">    init: String representations of initialization method for the weights of the layer.</span>
<span class="sd">          Default is &#39;glorot_uniform&#39;.</span>
<span class="sd">    activation: String representations of activation function to use (such as &#39;relu&#39; or &#39;sigmoid&#39;).</span>
<span class="sd">                Default is None.</span>
<span class="sd">    border_mode: Either &#39;valid&#39; or &#39;same&#39;. Default is &#39;valid&#39;.</span>
<span class="sd">    subsample: Int tuple of length 2 corresponding to the step of the convolution in the</span>
<span class="sd">               height and width dimension. Also called strides elsewhere. Default is (1, 1).</span>
<span class="sd">    depth_multiplier: How many output channel to use per input channel for the depthwise convolution step.</span>
<span class="sd">                      Int. Default is 1.</span>
<span class="sd">    dim_ordering: Format of input data. Either &#39;th&#39; (Channel First) or &#39;tf&#39; (Channel Last). Default is &#39;th&#39;.</span>
<span class="sd">    depthwise_regularizer: An instance of [[Regularizer]], (eg. L1 or L2 regularization),</span>
<span class="sd">                           applied to the depthwise weights matrices. Default is None.</span>
<span class="sd">    pointwise_regularizer: An instance of [[Regularizer]], applied to the pointwise weights matrices.</span>
<span class="sd">                           Default is None.</span>
<span class="sd">    b_regularizer: An instance of [[Regularizer]], applied to the bias. Default is None.</span>
<span class="sd">    bias: Whether to include a bias (i.e. make the layer affine rather than linear).</span>
<span class="sd">          Default is True.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; separableconv2d = SeparableConvolution2D(12, 3, 4, input_shape=(3, 32, 32))</span>
<span class="sd">    creating: createKerasSeparableConvolution2D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nb_filter</span><span class="p">,</span> <span class="n">nb_row</span><span class="p">,</span> <span class="n">nb_col</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s2">&quot;glorot_uniform&quot;</span><span class="p">,</span>
                 <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">border_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">depth_multiplier</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                 <span class="n">dim_ordering</span><span class="o">=</span><span class="s2">&quot;th&quot;</span><span class="p">,</span> <span class="n">depthwise_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">pointwise_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">b_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SeparableConvolution2D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                     <span class="n">nb_filter</span><span class="p">,</span>
                                                     <span class="n">nb_row</span><span class="p">,</span>
                                                     <span class="n">nb_col</span><span class="p">,</span>
                                                     <span class="n">init</span><span class="p">,</span>
                                                     <span class="n">activation</span><span class="p">,</span>
                                                     <span class="n">border_mode</span><span class="p">,</span>
                                                     <span class="n">subsample</span><span class="p">,</span>
                                                     <span class="n">depth_multiplier</span><span class="p">,</span>
                                                     <span class="n">dim_ordering</span><span class="p">,</span>
                                                     <span class="n">depthwise_regularizer</span><span class="p">,</span>
                                                     <span class="n">pointwise_regularizer</span><span class="p">,</span>
                                                     <span class="n">b_regularizer</span><span class="p">,</span>
                                                     <span class="n">bias</span><span class="p">,</span></div>
                                                     <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<span class="n">Conv1D</span> <span class="o">=</span> <span class="n">Convolution1D</span>
<span class="n">Conv2D</span> <span class="o">=</span> <span class="n">Convolution2D</span>
<span class="n">Conv3D</span> <span class="o">=</span> <span class="n">Convolution3D</span>
<span class="n">Deconv2D</span> <span class="o">=</span> <span class="n">Deconvolution2D</span>
<span class="n">AtrousConv1D</span> <span class="o">=</span> <span class="n">AtrousConvolution1D</span>
<span class="n">AtrousConv2D</span> <span class="o">=</span> <span class="n">AtrousConvolution2D</span>
<span class="n">SeparableConv2D</span> <span class="o">=</span> <span class="n">SeparableConvolution2D</span>


<div class="viewcode-block" id="Cropping1D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.Cropping1D">[docs]</a><span class="k">class</span> <span class="nc">Cropping1D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Cropping layer for 1D input (e.g. temporal sequence).</span>
<span class="sd">    The input of this layer should be 3D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    cropping: Int tuple of length 2. How many units should be trimmed off at the beginning and</span>
<span class="sd">              end of the cropping dimension. Default is (1, 1).</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; cropping1d = Cropping1D(cropping=(1, 2), input_shape=(8, 8))</span>
<span class="sd">    creating: createKerasCropping1D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cropping</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Cropping1D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                         <span class="n">cropping</span><span class="p">,</span></div>
                                         <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="Cropping2D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.Cropping2D">[docs]</a><span class="k">class</span> <span class="nc">Cropping2D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Cropping layer for 2D input (e.g. picture).</span>
<span class="sd">    The input of this layer should be 4D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    cropping: Int tuple of tuple of length 2. How many units should be trimmed off at the beginning and</span>
<span class="sd">              end of the 2 cropping dimensions (i.e. height and width). Default is ((0, 0), (0, 0)).</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; cropping2d = Cropping2D(cropping=((1, 2), (0, 1)), input_shape=(12, 12, 12))</span>
<span class="sd">    creating: createKerasCropping2D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cropping</span><span class="o">=</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">)),</span> <span class="n">dim_ordering</span><span class="o">=</span><span class="s2">&quot;th&quot;</span><span class="p">,</span>
                 <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Cropping2D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                         <span class="n">cropping</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                         <span class="n">cropping</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                         <span class="n">dim_ordering</span><span class="p">,</span></div>
                                         <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="Cropping3D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.Cropping3D">[docs]</a><span class="k">class</span> <span class="nc">Cropping3D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Cropping layer for 3D data (e.g. spatial or spatio-temporal).</span>
<span class="sd">    The input of this layer should be 5D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    cropping: Int tuple of tuple of length 3. How many units should be trimmed off at the beginning and</span>
<span class="sd">              end of the 3 cropping dimensions (i.e. kernel_dim1, kernel_dim2 and kernel_dim3).</span>
<span class="sd">              Default is ((1, 1), (1, 1), (1, 1)).</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; cropping3d = Cropping3D(cropping=((0, 2), (1, 1), (3, 1)), input_shape=(4, 12, 12, 16))</span>
<span class="sd">    creating: createKerasCropping3D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cropping</span><span class="o">=</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">dim_ordering</span><span class="o">=</span><span class="s2">&quot;th&quot;</span><span class="p">,</span>
                 <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Cropping3D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                         <span class="n">cropping</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                         <span class="n">cropping</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                         <span class="n">cropping</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                                         <span class="n">dim_ordering</span><span class="p">,</span></div>
                                         <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="UpSampling1D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.UpSampling1D">[docs]</a><span class="k">class</span> <span class="nc">UpSampling1D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    UpSampling layer for 1D inputs.</span>
<span class="sd">    Repeats each temporal step &#39;length&#39; times along the time axis.</span>
<span class="sd">    The input of this layer should be 3D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    length: Int. UpSampling factor. Default is 2.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; upsampling1d = UpSampling1D(length=3, input_shape=(3, 12))</span>
<span class="sd">    creating: createKerasUpSampling1D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">UpSampling1D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                           <span class="n">length</span><span class="p">,</span></div>
                                           <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="UpSampling2D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.UpSampling2D">[docs]</a><span class="k">class</span> <span class="nc">UpSampling2D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    UpSampling layer for 2D inputs.</span>
<span class="sd">    Repeats the rows and columns of the data by size[0] and size[1] respectively.</span>
<span class="sd">    The input of this layer should be 4D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    size: Int tuple of length 2. UpSampling factors for rows and columns. Default is (2, 2).</span>
<span class="sd">    dim_ordering: Format of input data. Either &#39;th&#39; (Channel First) or &#39;tf&#39; (Channel Last). Default is &#39;th&#39;.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; upsampling2d = UpSampling2D(size=(1, 3), input_shape=(3, 16, 16))</span>
<span class="sd">    creating: createKerasUpSampling2D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dim_ordering</span><span class="o">=</span><span class="s2">&quot;th&quot;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">UpSampling2D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                           <span class="n">size</span><span class="p">,</span>
                                           <span class="n">dim_ordering</span><span class="p">,</span></div>
                                           <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="UpSampling3D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.UpSampling3D">[docs]</a><span class="k">class</span> <span class="nc">UpSampling3D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    UpSampling layer for 2D inputs.</span>
<span class="sd">    Repeats the 1st, 2nd and 3rd dimensions of the data by size[0], size[1] and size[2] respectively.</span>
<span class="sd">    Data format currently supported for this layer is dim_ordering=&#39;th&#39; (Channel First).</span>
<span class="sd">    The input of this layer should be 5D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    size: Int tuple of length 3. UpSampling factors for dim1, dim2 and dim3. Default is (2, 2, 2).</span>
<span class="sd">    dim_ordering: Format of input data. Only &#39;th&#39; (Channel First) is supported for now.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; upsampling3d = UpSampling3D(size=(1, 2, 3), input_shape=(3, 16, 16, 16))</span>
<span class="sd">    creating: createKerasUpSampling3D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dim_ordering</span><span class="o">=</span><span class="s2">&quot;th&quot;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">UpSampling3D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                           <span class="n">size</span><span class="p">,</span>
                                           <span class="n">dim_ordering</span><span class="p">,</span></div>
                                           <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="ZeroPadding1D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.ZeroPadding1D">[docs]</a><span class="k">class</span> <span class="nc">ZeroPadding1D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Zero-padding layer for 1D input (e.g. temporal sequence).</span>
<span class="sd">    The input of this layer should be 3D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    padding: Int or int tuple of length 2.</span>
<span class="sd">             If int, how many zeros to add both at the beginning and at the end of the padding dimension.</span>
<span class="sd">             If tuple of length 2, how many zeros to add in the order &#39;(left_pad, right_pad)&#39;.</span>
<span class="sd">             Default is 1.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; zeropadding1d = ZeroPadding1D(padding=2, input_shape=(3, 6))</span>
<span class="sd">    creating: createKerasZeroPadding1D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">padding</span> <span class="o">=</span> <span class="p">(</span><span class="n">padding</span><span class="p">,</span> <span class="n">padding</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ZeroPadding1D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                            <span class="n">padding</span><span class="p">,</span></div>
                                            <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="ZeroPadding2D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.ZeroPadding2D">[docs]</a><span class="k">class</span> <span class="nc">ZeroPadding2D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Zero-padding layer for 2D input (e.g. picture).</span>
<span class="sd">    The input of this layer should be 4D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    padding: Int tuple of length 2 or length 4.</span>
<span class="sd">             If tuple of length 2, how many zeros to add both at the beginning and at the end of rows and cols.</span>
<span class="sd">             If tuple of length 4, how many zeros to add in the order &#39;(top_pad, bottom_pad, left_pad, right_pad)&#39;.</span>
<span class="sd">             Default is (1, 1).</span>
<span class="sd">    dim_ordering: Format of input data. Either &#39;th&#39; (Channel First) or &#39;tf&#39; (Channel Last). Default is &#39;th&#39;.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; zeropadding2d = ZeroPadding2D(padding=(2, 1), input_shape=(2, 8, 8))</span>
<span class="sd">    creating: createKerasZeroPadding2D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dim_ordering</span><span class="o">=</span><span class="s2">&quot;th&quot;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">padding</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">padding</span> <span class="o">=</span> <span class="p">(</span><span class="n">padding</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">padding</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">padding</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">padding</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ZeroPadding2D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                            <span class="n">padding</span><span class="p">,</span>
                                            <span class="n">dim_ordering</span><span class="p">,</span></div>
                                            <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="ZeroPadding3D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.ZeroPadding3D">[docs]</a><span class="k">class</span> <span class="nc">ZeroPadding3D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Zero-padding layer for 3D data (spatial or spatio-temporal).</span>
<span class="sd">    The input of this layer should be 5D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    padding: Int tuple of length 3. How many zeros to add at the beginning and at the end of the 3 padding dimensions.</span>
<span class="sd">             Symmetric padding will be applied to each dimension. Default is (1, 1, 1).</span>
<span class="sd">    dim_ordering: Format of input data. Either &#39;th&#39; (Channel First) or &#39;tf&#39; (Channel Last). Default is &#39;th&#39;.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; zeropadding3d = ZeroPadding3D(padding=(2, 1, 2), input_shape=(2, 8, 8, 10))</span>
<span class="sd">    creating: createKerasZeroPadding3D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dim_ordering</span><span class="o">=</span><span class="s2">&quot;th&quot;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ZeroPadding3D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                            <span class="n">padding</span><span class="p">,</span>
                                            <span class="n">dim_ordering</span><span class="p">,</span></div>
                                            <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="MaxPooling1D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.MaxPooling1D">[docs]</a><span class="k">class</span> <span class="nc">MaxPooling1D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies max pooling operation for temporal data.</span>
<span class="sd">    The input of this layer should be 3D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    pool_length: Size of the region to which max pooling is applied.</span>
<span class="sd">    strides: Factor by which to downscale. 2 will halve the input.</span>
<span class="sd">             Default is None, and in this case it will be equal to pool_length..</span>
<span class="sd">    border_mode: Either &#39;valid&#39; or &#39;same&#39;. Default is &#39;valid&#39;.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; maxpooling1d = MaxPooling1D(3, input_shape=(3, 24))</span>
<span class="sd">    creating: createKerasMaxPooling1D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pool_length</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">border_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span>
                 <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">stride</span><span class="p">:</span>
            <span class="n">stride</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MaxPooling1D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                           <span class="n">pool_length</span><span class="p">,</span>
                                           <span class="n">stride</span><span class="p">,</span>
                                           <span class="n">border_mode</span><span class="p">,</span></div>
                                           <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="MaxPooling2D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.MaxPooling2D">[docs]</a><span class="k">class</span> <span class="nc">MaxPooling2D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies max pooling operation for spatial data.</span>
<span class="sd">    The input of this layer should be 4D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    pool_size: Int tuple of length 2 corresponding to the downscale vertically and horizontally.</span>
<span class="sd">               Default is (2, 2), which will halve the image in each dimension.</span>
<span class="sd">    strides: Int tuple of length 2. Stride values. Default is None, and in this case it will be equal to pool_size.</span>
<span class="sd">    border_mode: Either &#39;valid&#39; or &#39;same&#39;. Default is &#39;valid&#39;.</span>
<span class="sd">    dim_ordering: Format of input data. Either &#39;th&#39; (Channel First) or &#39;tf&#39; (Channel Last). Default is &#39;th&#39;.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; maxpooling2d = MaxPooling2D((2, 2), input_shape=(3, 32, 32))</span>
<span class="sd">    creating: createKerasMaxPooling2D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">border_mode</span><span class="o">=</span><span class="s1">&#39;valid&#39;</span><span class="p">,</span> <span class="n">dim_ordering</span><span class="o">=</span><span class="s1">&#39;th&#39;</span><span class="p">,</span>
                 <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MaxPooling2D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                           <span class="n">pool_size</span><span class="p">,</span>
                                           <span class="n">strides</span><span class="p">,</span>
                                           <span class="n">border_mode</span><span class="p">,</span>
                                           <span class="n">dim_ordering</span><span class="p">,</span></div>
                                           <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="MaxPooling3D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.MaxPooling3D">[docs]</a><span class="k">class</span> <span class="nc">MaxPooling3D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies max pooling operation for 3D data (spatial or spatio-temporal).</span>
<span class="sd">    Data format currently supported for this layer is dim_ordering=&#39;th&#39; (Channel First).</span>
<span class="sd">    Border mode currently supported for this layer is &#39;valid&#39;.</span>
<span class="sd">    The input of this layer should be 5D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    pool_size: Int tuple of length 3. Factors by which to downscale (dim1, dim2, dim3).</span>
<span class="sd">               Default is (2, 2, 2), which will halve the image in each dimension.</span>
<span class="sd">    strides: Int tuple of length 3. Stride values. Default is None, and in this case it will be equal to pool_size.</span>
<span class="sd">    border_mode: Only &#39;valid&#39; is supported for now.</span>
<span class="sd">    dim_ordering: Format of input data. Only &#39;th&#39; (Channel First) is supported for now.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; maxpooling3d = MaxPooling3D((2, 1, 3), input_shape=(3, 32, 32, 32))</span>
<span class="sd">    creating: createKerasMaxPooling3D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">border_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span>
                 <span class="n">dim_ordering</span><span class="o">=</span><span class="s2">&quot;th&quot;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">border_mode</span> <span class="o">!=</span> <span class="s2">&quot;valid&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;For MaxPooling3D, only border_mode=&#39;valid&#39; is supported for now&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MaxPooling3D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                           <span class="n">pool_size</span><span class="p">,</span>
                                           <span class="n">strides</span><span class="p">,</span>
                                           <span class="n">dim_ordering</span><span class="p">,</span></div>
                                           <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="AveragePooling1D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.AveragePooling1D">[docs]</a><span class="k">class</span> <span class="nc">AveragePooling1D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies average pooling operation for temporal data.</span>
<span class="sd">    The input of this layer should be 3D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    pool_length: Size of the region to which max pooling is applied.</span>
<span class="sd">    strides: Factor by which to downscale. 2 will halve the input.</span>
<span class="sd">             Default is None, and in this case it will be equal to pool_length..</span>
<span class="sd">    border_mode: Either &#39;valid&#39; or &#39;same&#39;. Default is &#39;valid&#39;.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; averagepooling1d = AveragePooling1D(input_shape=(3, 24))</span>
<span class="sd">    creating: createKerasAveragePooling1D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pool_length</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">border_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span>
                 <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">stride</span><span class="p">:</span>
            <span class="n">stride</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AveragePooling1D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                               <span class="n">pool_length</span><span class="p">,</span>
                                               <span class="n">stride</span><span class="p">,</span>
                                               <span class="n">border_mode</span><span class="p">,</span></div>
                                               <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="AveragePooling2D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.AveragePooling2D">[docs]</a><span class="k">class</span> <span class="nc">AveragePooling2D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies average pooling operation for spatial data.</span>
<span class="sd">    The input of this layer should be 4D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    pool_size: Int tuple of length 2 corresponding to the downscale vertically and horizontally.</span>
<span class="sd">               Default is (2, 2), which will halve the image in each dimension.</span>
<span class="sd">    strides: Int tuple of length 2. Stride values. Default is None, and in this case it will be equal to pool_size.</span>
<span class="sd">    border_mode: Either &#39;valid&#39; or &#39;same&#39;. Default is &#39;valid&#39;.</span>
<span class="sd">    dim_ordering: Format of input data. Either &#39;th&#39; (Channel First) or &#39;tf&#39; (Channel Last). Default is &#39;th&#39;.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; averagepooling2d = AveragePooling2D((1, 2), input_shape=(2, 28, 32))</span>
<span class="sd">    creating: createKerasAveragePooling2D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">border_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span>
                 <span class="n">dim_ordering</span><span class="o">=</span><span class="s2">&quot;th&quot;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AveragePooling2D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                               <span class="n">pool_size</span><span class="p">,</span>
                                               <span class="n">strides</span><span class="p">,</span>
                                               <span class="n">border_mode</span><span class="p">,</span>
                                               <span class="n">dim_ordering</span><span class="p">,</span></div>
                                               <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="AveragePooling3D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.AveragePooling3D">[docs]</a><span class="k">class</span> <span class="nc">AveragePooling3D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies average pooling operation for 3D data (spatial or spatio-temporal).</span>
<span class="sd">    Data format currently supported for this layer is dim_ordering=&#39;th&#39; (Channel First).</span>
<span class="sd">    Border mode currently supported for this layer is &#39;valid&#39;.</span>
<span class="sd">    The input of this layer should be 5D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    pool_size: Int tuple of length 3. Factors by which to downscale (dim1, dim2, dim3).</span>
<span class="sd">               Default is (2, 2, 2), which will halve the image in each dimension.</span>
<span class="sd">    strides: Int tuple of length 3. Stride values. Default is None, and in this case it will be equal to pool_size.</span>
<span class="sd">    border_mode: Only &#39;valid&#39; is supported for now.</span>
<span class="sd">    dim_ordering: Format of input data. Only &#39;th&#39; (Channel First) is supported for now.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; averagepooling3d = AveragePooling3D((1, 1, 2), input_shape=(3, 28, 32, 36))</span>
<span class="sd">    creating: createKerasAveragePooling3D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pool_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">strides</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">border_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span>
                 <span class="n">dim_ordering</span><span class="o">=</span><span class="s2">&quot;th&quot;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">border_mode</span> <span class="o">!=</span> <span class="s2">&quot;valid&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;For AveragePooling3D, only border_mode=&#39;valid&#39; is supported for now&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">AveragePooling3D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                               <span class="n">pool_size</span><span class="p">,</span>
                                               <span class="n">strides</span><span class="p">,</span>
                                               <span class="n">dim_ordering</span><span class="p">,</span></div>
                                               <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="GlobalMaxPooling1D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.GlobalMaxPooling1D">[docs]</a><span class="k">class</span> <span class="nc">GlobalMaxPooling1D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies global max pooling operation for temporal data.</span>
<span class="sd">    The input of this layer should be 3D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; globalmaxpooling1d = GlobalMaxPooling1D(input_shape=(4, 8))</span>
<span class="sd">    creating: createKerasGlobalMaxPooling1D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GlobalMaxPooling1D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span></div>
                                                 <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="GlobalAveragePooling1D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.GlobalAveragePooling1D">[docs]</a><span class="k">class</span> <span class="nc">GlobalAveragePooling1D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies global average pooling operation for temporal data.</span>
<span class="sd">    The input of this layer should be 3D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; globalaveragepooling1d = GlobalAveragePooling1D(input_shape=(12, 12))</span>
<span class="sd">    creating: createKerasGlobalAveragePooling1D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GlobalAveragePooling1D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span></div>
                                                     <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="GlobalMaxPooling2D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.GlobalMaxPooling2D">[docs]</a><span class="k">class</span> <span class="nc">GlobalMaxPooling2D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies global max pooling operation for spatial data.</span>
<span class="sd">    The input of this layer should be 4D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    dim_ordering: Format of input data. Either &#39;th&#39; (Channel First) or &#39;tf&#39; (Channel Last). Default is &#39;th&#39;.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; globalmaxpooling2d = GlobalMaxPooling2D(input_shape=(4, 32, 32))</span>
<span class="sd">    creating: createKerasGlobalMaxPooling2D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim_ordering</span><span class="o">=</span><span class="s2">&quot;th&quot;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GlobalMaxPooling2D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                 <span class="n">dim_ordering</span><span class="p">,</span></div>
                                                 <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="GlobalAveragePooling2D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.GlobalAveragePooling2D">[docs]</a><span class="k">class</span> <span class="nc">GlobalAveragePooling2D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies global average pooling operation for spatial data.</span>
<span class="sd">    The input of this layer should be 4D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    dim_ordering: Format of input data. Either &#39;th&#39; (Channel First) or &#39;tf&#39; (Channel Last). Default is &#39;th&#39;.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; globalaveragepooling2d = GlobalAveragePooling2D(input_shape=(4, 32, 32))</span>
<span class="sd">    creating: createKerasGlobalAveragePooling2D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim_ordering</span><span class="o">=</span><span class="s2">&quot;th&quot;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GlobalAveragePooling2D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                     <span class="n">dim_ordering</span><span class="p">,</span></div>
                                                     <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="GlobalMaxPooling3D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.GlobalMaxPooling3D">[docs]</a><span class="k">class</span> <span class="nc">GlobalMaxPooling3D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies global max pooling operation for 3D data.</span>
<span class="sd">    Data format currently supported for this layer is dim_ordering=&#39;th&#39; (Channel First).</span>
<span class="sd">    Border mode currently supported for this layer is &#39;valid&#39;.</span>
<span class="sd">    The input of this layer should be 5D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    dim_ordering: Format of input data. Only &#39;th&#39; (Channel First) is supported for now.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; globalmaxpooling3d = GlobalMaxPooling3D(input_shape=(4, 32, 32, 32))</span>
<span class="sd">    creating: createKerasGlobalMaxPooling3D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim_ordering</span><span class="o">=</span><span class="s2">&quot;th&quot;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GlobalMaxPooling3D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                 <span class="n">dim_ordering</span><span class="p">,</span></div>
                                                 <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="GlobalAveragePooling3D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.GlobalAveragePooling3D">[docs]</a><span class="k">class</span> <span class="nc">GlobalAveragePooling3D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies global average pooling operation for 3D data.</span>
<span class="sd">    Data format currently supported for this layer is dim_ordering=&#39;th&#39; (Channel First).</span>
<span class="sd">    Border mode currently supported for this layer is &#39;valid&#39;.</span>
<span class="sd">    The input of this layer should be 5D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    dim_ordering: Format of input data. Only &#39;th&#39; (Channel First) is supported for now.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; globalaveragepooling3d = GlobalAveragePooling3D(input_shape=(4, 16, 16, 20))</span>
<span class="sd">    creating: createKerasGlobalAveragePooling3D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dim_ordering</span><span class="o">=</span><span class="s2">&quot;th&quot;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GlobalAveragePooling3D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                     <span class="n">dim_ordering</span><span class="p">,</span></div>
                                                     <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="SimpleRNN"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.SimpleRNN">[docs]</a><span class="k">class</span> <span class="nc">SimpleRNN</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A fully-connected recurrent neural network cell. The output is to be fed back to input.</span>
<span class="sd">    The input of this layer should be 3D, i.e. (batch, time steps, input dim).</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    output_dim: Hidden unit size. Dimension of internal projections and final output.</span>
<span class="sd">    activation: String representations of activation function to use (such as &#39;relu&#39; or &#39;sigmoid&#39;).</span>
<span class="sd">                Default is &#39;tanh&#39;.</span>
<span class="sd">    return_sequences: Whether to return the full sequence or only return the last output in the output sequence.</span>
<span class="sd">                      Default is False.</span>
<span class="sd">    go_backwards: Whether the input sequence will be processed backwards. Default is False.</span>
<span class="sd">    W_regularizer: An instance of [[Regularizer]], (eg. L1 or L2 regularization),</span>
<span class="sd">                   applied to the input weights matrices. Default is None.</span>
<span class="sd">    U_regularizer: An instance of [[Regularizer]], applied the recurrent weights matrices. Default is None.</span>
<span class="sd">    b_regularizer: An instance of [[Regularizer]], applied to the bias. Default is None.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; simplernn = SimpleRNN(16, input_shape=(3, 32))</span>
<span class="sd">    creating: createKerasSimpleRNN</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;tanh&quot;</span><span class="p">,</span> <span class="n">return_sequences</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                 <span class="n">go_backwards</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">W_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">U_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">b_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SimpleRNN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                        <span class="n">output_dim</span><span class="p">,</span>
                                        <span class="n">activation</span><span class="p">,</span>
                                        <span class="n">return_sequences</span><span class="p">,</span>
                                        <span class="n">go_backwards</span><span class="p">,</span>
                                        <span class="n">W_regularizer</span><span class="p">,</span>
                                        <span class="n">U_regularizer</span><span class="p">,</span>
                                        <span class="n">b_regularizer</span><span class="p">,</span></div>
                                        <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="LSTM"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.LSTM">[docs]</a><span class="k">class</span> <span class="nc">LSTM</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Long Short Term Memory unit architecture.</span>
<span class="sd">    The input of this layer should be 3D, i.e. (batch, time steps, input dim).</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    output_dim: Hidden unit size. Dimension of internal projections and final output.</span>
<span class="sd">    activation: String representations of activation function to use (such as &#39;relu&#39; or &#39;sigmoid&#39;).</span>
<span class="sd">                Default is &#39;tanh&#39;.</span>
<span class="sd">    inner_activation: String representations of activation function for inner cells. Default is &#39;hard_sigmoid&#39;.</span>
<span class="sd">    return_sequences: Whether to return the full sequence or only return the last output in the output sequence.</span>
<span class="sd">                      Default is False.</span>
<span class="sd">    go_backwards: Whether the input sequence will be processed backwards. Default is False.</span>
<span class="sd">    W_regularizer: An instance of [[Regularizer]], (eg. L1 or L2 regularization),</span>
<span class="sd">                   applied to the input weights matrices. Default is None.</span>
<span class="sd">    U_regularizer: An instance of [[Regularizer]], applied the recurrent weights matrices. Default is None.</span>
<span class="sd">    b_regularizer: An instance of [[Regularizer]], applied to the bias. Default is None.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; lstm = LSTM(32, input_shape=(8, 16))</span>
<span class="sd">    creating: createKerasLSTM</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;tanh&quot;</span><span class="p">,</span> <span class="n">inner_activation</span><span class="o">=</span><span class="s2">&quot;hard_sigmoid&quot;</span><span class="p">,</span>
                 <span class="n">return_sequences</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">go_backwards</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">W_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">U_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">b_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LSTM</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                   <span class="n">output_dim</span><span class="p">,</span>
                                   <span class="n">activation</span><span class="p">,</span>
                                   <span class="n">inner_activation</span><span class="p">,</span>
                                   <span class="n">return_sequences</span><span class="p">,</span>
                                   <span class="n">go_backwards</span><span class="p">,</span>
                                   <span class="n">W_regularizer</span><span class="p">,</span>
                                   <span class="n">U_regularizer</span><span class="p">,</span>
                                   <span class="n">b_regularizer</span><span class="p">,</span></div>
                                   <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="GRU"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.GRU">[docs]</a><span class="k">class</span> <span class="nc">GRU</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Gated Recurrent Unit architecture.</span>
<span class="sd">    The input of this layer should be 3D, i.e. (batch, time steps, input dim).</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    output_dim: Hidden unit size. Dimension of internal projections and final output.</span>
<span class="sd">    activation: String representations of activation function to use (such as &#39;relu&#39; or &#39;sigmoid&#39;).</span>
<span class="sd">                Default is &#39;tanh&#39;.</span>
<span class="sd">    inner_activation: String representations of activation function for inner cells. Default is &#39;hard_sigmoid&#39;.</span>
<span class="sd">    return_sequences: Whether to return the full sequence or only return the last output in the output sequence.</span>
<span class="sd">                      Default is False.</span>
<span class="sd">    go_backwards: Whether the input sequence will be processed backwards. Default is False.</span>
<span class="sd">    W_regularizer: An instance of [[Regularizer]], (eg. L1 or L2 regularization),</span>
<span class="sd">                   applied to the input weights matrices. Default is None.</span>
<span class="sd">    U_regularizer: An instance of [[Regularizer]], applied the recurrent weights matrices. Default is None.</span>
<span class="sd">    b_regularizer: An instance of [[Regularizer]], applied to the bias. Default is None.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; gru = GRU(24, input_shape=(32, 32))</span>
<span class="sd">    creating: createKerasGRU</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;tanh&quot;</span><span class="p">,</span> <span class="n">inner_activation</span><span class="o">=</span><span class="s2">&quot;hard_sigmoid&quot;</span><span class="p">,</span>
                 <span class="n">return_sequences</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">go_backwards</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">W_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">U_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">b_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GRU</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                  <span class="n">output_dim</span><span class="p">,</span>
                                  <span class="n">activation</span><span class="p">,</span>
                                  <span class="n">inner_activation</span><span class="p">,</span>
                                  <span class="n">return_sequences</span><span class="p">,</span>
                                  <span class="n">go_backwards</span><span class="p">,</span>
                                  <span class="n">W_regularizer</span><span class="p">,</span>
                                  <span class="n">U_regularizer</span><span class="p">,</span>
                                  <span class="n">b_regularizer</span><span class="p">,</span></div>
                                  <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="ConvLSTM2D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.ConvLSTM2D">[docs]</a><span class="k">class</span> <span class="nc">ConvLSTM2D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Convolutional LSTM.</span>
<span class="sd">    Data format currently supported for this layer is dim_ordering=&#39;th&#39; (Channel First).</span>
<span class="sd">    Border mode currently supported for this layer is &#39;same&#39;.</span>
<span class="sd">    The convolution kernel for this layer is a square kernel with equal strides &#39;subsample&#39;.</span>
<span class="sd">    The input of this layer should be 5D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    nb_filter: Number of convolution filters to use.</span>
<span class="sd">    nb_row: Number of rows in the convolution kernel.</span>
<span class="sd">    nb_col: Number of cols in the convolution kernel. Should be equal to nb_row as for a square kernel.</span>
<span class="sd">    activation: String representations of activation function to use (such as &#39;relu&#39; or &#39;sigmoid&#39;).</span>
<span class="sd">                Default is &#39;tanh&#39;.</span>
<span class="sd">    inner_activation: String representations of activation function for inner cells. Default is &#39;hard_sigmoid&#39;.</span>
<span class="sd">    dim_ordering: Format of input data. Only &#39;th&#39; (Channel First) is supported for now.</span>
<span class="sd">    border_mode: Only &#39;same&#39; is supported for now.</span>
<span class="sd">    subsample: Tuple of length 2. Factor by which to subsample output. Also called strides elsewhere.</span>
<span class="sd">               Only support subsample[0] equal to subsample[1] for now. Default is (1, 1).</span>
<span class="sd">    W_regularizer: An instance of [[Regularizer]], (eg. L1 or L2 regularization),</span>
<span class="sd">                   applied to the input weights matrices. Default is None.</span>
<span class="sd">    U_regularizer: An instance of [[Regularizer]], applied the recurrent weights matrices. Default is None.</span>
<span class="sd">    b_regularizer: An instance of [[Regularizer]], applied to the bias. Default is None.</span>
<span class="sd">    return_sequences: Whether to return the full sequence or only return the last output in the output sequence.</span>
<span class="sd">                      Default is False.</span>
<span class="sd">    go_backwards: Whether the input sequence will be processed backwards. Default is False.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; convlstm2d = ConvLSTM2D(24, 3, 3, input_shape=(4, 32, 32, 32))</span>
<span class="sd">    creating: createKerasConvLSTM2D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nb_filter</span><span class="p">,</span> <span class="n">nb_row</span><span class="p">,</span> <span class="n">nb_col</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;tanh&quot;</span><span class="p">,</span>
                 <span class="n">inner_activation</span><span class="o">=</span><span class="s2">&quot;hard_sigmoid&quot;</span><span class="p">,</span> <span class="n">dim_ordering</span><span class="o">=</span><span class="s2">&quot;th&quot;</span><span class="p">,</span> <span class="n">border_mode</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span>
                 <span class="n">subsample</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">W_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">U_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">b_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">return_sequences</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">go_backwards</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">nb_row</span> <span class="o">!=</span> <span class="n">nb_col</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;For ConvLSTM2D, only square kernel is supported for now&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">border_mode</span> <span class="o">!=</span> <span class="s2">&quot;same&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;For ConvLSTM2D, only border_mode=&#39;same&#39; is supported for now&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">subsample</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="n">subsample</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;For ConvLSTM2D, only equal strides is supported for now&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ConvLSTM2D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                         <span class="n">nb_filter</span><span class="p">,</span>
                                         <span class="n">nb_row</span><span class="p">,</span>
                                         <span class="n">activation</span><span class="p">,</span>
                                         <span class="n">inner_activation</span><span class="p">,</span>
                                         <span class="n">dim_ordering</span><span class="p">,</span>
                                         <span class="n">subsample</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                                         <span class="n">W_regularizer</span><span class="p">,</span>
                                         <span class="n">U_regularizer</span><span class="p">,</span>
                                         <span class="n">b_regularizer</span><span class="p">,</span>
                                         <span class="n">return_sequences</span><span class="p">,</span>
                                         <span class="n">go_backwards</span><span class="p">,</span></div>
                                         <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="LocallyConnected1D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.LocallyConnected1D">[docs]</a><span class="k">class</span> <span class="nc">LocallyConnected1D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Locally-connected layer for 1D inputs which works similarly to the TemporalConvolution layer, except that</span>
<span class="sd">    weights are unshared, that is, a different set of filters is applied at each different patch of the input.</span>
<span class="sd">    Border mode currently supported for this layer is &#39;valid&#39;.</span>
<span class="sd">    The input of this layer should be 3D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    nb_filter: Dimensionality of the output.</span>
<span class="sd">    filter_length: The extension (spatial or temporal) of each filter.</span>
<span class="sd">    activation: String representations of activation function to use (such as &#39;relu&#39; or &#39;sigmoid&#39;).</span>
<span class="sd">                Default is None.</span>
<span class="sd">    border_mode: Only &#39;valid&#39; is supported for now.</span>
<span class="sd">    subsample_length: Factor by which to subsample output. Int. Default is 1.</span>
<span class="sd">    W_regularizer: An instance of [[Regularizer]], (eg. L1 or L2 regularization),</span>
<span class="sd">                   applied to the input weights matrices. Default is None.</span>
<span class="sd">    b_regularizer: An instance of [[Regularizer]], applied to the bias. Default is None.</span>
<span class="sd">    bias: Whether to include a bias (i.e. make the layer affine rather than linear).</span>
<span class="sd">          Default is True.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; locallyconnected1d = LocallyConnected1D(6, 3, input_shape=(8, 12))</span>
<span class="sd">    creating: createKerasLocallyConnected1D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nb_filter</span><span class="p">,</span> <span class="n">filter_length</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">border_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span>
                 <span class="n">subsample_length</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">W_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">b_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">border_mode</span> <span class="o">!=</span> <span class="s2">&quot;valid&quot;</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;For LocallyConnected1D, only border_mode=&#39;valid&#39; is supported for now&quot;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LocallyConnected1D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                 <span class="n">nb_filter</span><span class="p">,</span>
                                                 <span class="n">filter_length</span><span class="p">,</span>
                                                 <span class="n">activation</span><span class="p">,</span>
                                                 <span class="n">subsample_length</span><span class="p">,</span>
                                                 <span class="n">W_regularizer</span><span class="p">,</span>
                                                 <span class="n">b_regularizer</span><span class="p">,</span>
                                                 <span class="n">bias</span><span class="p">,</span></div>
                                                 <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="LocallyConnected2D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.LocallyConnected2D">[docs]</a><span class="k">class</span> <span class="nc">LocallyConnected2D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Locally-connected layer for 2D inputs that works similarly to the SpatialConvolution layer, except that</span>
<span class="sd">    weights are unshared, that is, a different set of filters is applied at each different patch of the input.</span>
<span class="sd">    The input of this layer should be 4D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    nb_filter: Number of convolution filters to use.</span>
<span class="sd">    nb_row: Number of rows in the convolution kernel.</span>
<span class="sd">    nb_col: Number of cols in the convolution kernel.</span>
<span class="sd">    activation: String representations of activation function to use (such as &#39;relu&#39; or &#39;sigmoid&#39;).</span>
<span class="sd">                Default is None.</span>
<span class="sd">    border_mode: Either &#39;valid&#39; or &#39;same&#39;. Default is &#39;valid&#39;.</span>
<span class="sd">    subsample: Int tuple of length 2 corresponding to the step of the convolution in the</span>
<span class="sd">               height and width dimension. Also called strides elsewhere. Default is (1, 1).</span>
<span class="sd">    dim_ordering: Format of input data. Either &#39;th&#39; (Channel First) or &#39;tf&#39; (Channel Last). Default is &#39;th&#39;.</span>
<span class="sd">    W_regularizer: An instance of [[Regularizer]], (eg. L1 or L2 regularization),</span>
<span class="sd">                   applied to the input weights matrices. Default is None.</span>
<span class="sd">    b_regularizer: An instance of [[Regularizer]], applied to the bias. Default is None.</span>
<span class="sd">    bias: Whether to include a bias (i.e. make the layer affine rather than linear).</span>
<span class="sd">          Default is True.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; locallyconnected2d = LocallyConnected2D(12, 3, 4, input_shape=(3, 128, 128))</span>
<span class="sd">    creating: createKerasLocallyConnected2D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">nb_filter</span><span class="p">,</span> <span class="n">nb_row</span><span class="p">,</span> <span class="n">nb_col</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">border_mode</span><span class="o">=</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span> <span class="n">subsample</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">dim_ordering</span><span class="o">=</span><span class="s2">&quot;th&quot;</span><span class="p">,</span>
                 <span class="n">W_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">b_regularizer</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                 <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LocallyConnected2D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                                 <span class="n">nb_filter</span><span class="p">,</span>
                                                 <span class="n">nb_row</span><span class="p">,</span>
                                                 <span class="n">nb_col</span><span class="p">,</span>
                                                 <span class="n">activation</span><span class="p">,</span>
                                                 <span class="n">border_mode</span><span class="p">,</span>
                                                 <span class="n">subsample</span><span class="p">,</span>
                                                 <span class="n">dim_ordering</span><span class="p">,</span>
                                                 <span class="n">W_regularizer</span><span class="p">,</span>
                                                 <span class="n">b_regularizer</span><span class="p">,</span>
                                                 <span class="n">bias</span><span class="p">,</span></div>
                                                 <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="SpatialDropout1D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.SpatialDropout1D">[docs]</a><span class="k">class</span> <span class="nc">SpatialDropout1D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Spatial 1D version of Dropout.</span>
<span class="sd">    This version performs the same function as Dropout, however it drops entire 1D feature maps</span>
<span class="sd">    instead of individual elements. If adjacent frames within feature maps are strongly correlated</span>
<span class="sd">    (as is normally the case in early convolution layers) then regular dropout will not regularize the</span>
<span class="sd">    activations and will otherwise just result in an effective learning rate decrease.</span>
<span class="sd">    In this case, SpatialDropout1D will help promote independence between feature maps and should be used instead.</span>
<span class="sd">    The input of this layer should be 3D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    p: Fraction of the input units to drop. Float between 0 and 1.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; spatialdropout1d = SpatialDropout1D(0.4, input_shape=(10, 12))</span>
<span class="sd">    creating: createKerasSpatialDropout1D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SpatialDropout1D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                               <span class="nb">float</span><span class="p">(</span><span class="n">p</span><span class="p">),</span></div>
                                               <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="SpatialDropout2D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.SpatialDropout2D">[docs]</a><span class="k">class</span> <span class="nc">SpatialDropout2D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Spatial 2D version of Dropout.</span>
<span class="sd">    This version performs the same function as Dropout, however it drops entire 2D feature maps</span>
<span class="sd">    instead of individual elements. If adjacent pixels within feature maps are strongly correlated</span>
<span class="sd">    (as is normally the case in early convolution layers) then regular dropout will not regularize the</span>
<span class="sd">    activations and will otherwise just result in an effective learning rate decrease.</span>
<span class="sd">    In this case, SpatialDropout2D will help promote independence between feature maps and should be used instead.</span>
<span class="sd">    The input of this layer should be 4D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    p: Fraction of the input units to drop. Float between 0 and 1.</span>
<span class="sd">    dim_ordering: Format of input data. Either &#39;th&#39; (Channel First) or &#39;tf&#39; (Channel Last). Default is &#39;th&#39;.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; spatialdropout2d = SpatialDropout2D(0.25, input_shape=(5, 12, 12))</span>
<span class="sd">    creating: createKerasSpatialDropout2D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dim_ordering</span><span class="o">=</span><span class="s2">&quot;th&quot;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SpatialDropout2D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                               <span class="nb">float</span><span class="p">(</span><span class="n">p</span><span class="p">),</span>
                                               <span class="n">dim_ordering</span><span class="p">,</span></div>
                                               <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="SpatialDropout3D"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.SpatialDropout3D">[docs]</a><span class="k">class</span> <span class="nc">SpatialDropout3D</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Spatial 3D version of Dropout.</span>
<span class="sd">    This version performs the same function as Dropout, however it drops entire 3D feature maps</span>
<span class="sd">    instead of individual elements. If adjacent voxels within feature maps are strongly correlated</span>
<span class="sd">    (as is normally the case in early convolution layers) then regular dropout will not regularize the</span>
<span class="sd">    activations and will otherwise just result in an effective learning rate decrease.</span>
<span class="sd">    In this case, SpatialDropout3D will help promote independence between feature maps and should be used instead.</span>
<span class="sd">    The input of this layer should be 5D.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    p: Fraction of the input units to drop. Float between 0 and 1.</span>
<span class="sd">    dim_ordering: Format of input data. Either &#39;th&#39; (Channel First) or &#39;tf&#39; (Channel Last). Default is &#39;th&#39;.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; spatialdropout3d = SpatialDropout3D(0.6, input_shape=(4, 12, 12, 16))</span>
<span class="sd">    creating: createKerasSpatialDropout3D</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">dim_ordering</span><span class="o">=</span><span class="s2">&quot;th&quot;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SpatialDropout3D</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                               <span class="nb">float</span><span class="p">(</span><span class="n">p</span><span class="p">),</span>
                                               <span class="n">dim_ordering</span><span class="p">,</span></div>
                                               <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="GaussianDropout"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.GaussianDropout">[docs]</a><span class="k">class</span> <span class="nc">GaussianDropout</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply multiplicative 1-centered Gaussian noise.</span>
<span class="sd">    As it is a regularization layer, it is only active at training time.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    p: Drop probability. Float between 0 and 1.</span>
<span class="sd">       The multiplicative noise will have standard deviation &#39;sqrt(p/(1-p))&#39;.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; gaussiandropout = GaussianDropout(0.45, input_shape=(4, 8))</span>
<span class="sd">    creating: createKerasGaussianDropout</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GaussianDropout</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                              <span class="nb">float</span><span class="p">(</span><span class="n">p</span><span class="p">),</span></div>
                                              <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="GaussianNoise"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.GaussianNoise">[docs]</a><span class="k">class</span> <span class="nc">GaussianNoise</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Apply additive zero-centered Gaussian noise.</span>
<span class="sd">    This is useful to mitigate overfitting (you could see it as a form of random data augmentation).</span>
<span class="sd">    Gaussian Noise is a natural choice as corruption process for real valued inputs.</span>
<span class="sd">    As it is a regularization layer, it is only active at training time.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    sigma: Float, standard deviation of the noise distribution.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; gaussiannoise = GaussianNoise(0.45, input_shape=(3, 4, 5))</span>
<span class="sd">    creating: createKerasGaussianNoise</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sigma</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">GaussianNoise</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                            <span class="nb">float</span><span class="p">(</span><span class="n">sigma</span><span class="p">),</span></div>
                                            <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="Masking"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.Masking">[docs]</a><span class="k">class</span> <span class="nc">Masking</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Use a mask value to skip timesteps for a sequence.</span>
<span class="sd">    Masks a sequence by using a mask value to skip timesteps.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    mask_value: Float, mask value. For each timestep in the input tensor (dimension #1 in the tensor),</span>
<span class="sd">                if all values in the input tensor at that timestep are equal to `mask_value`,</span>
<span class="sd">                then the timestep will masked (skipped) in all downstream layers.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; masking = Masking(0.3, input_shape=(6, 8))</span>
<span class="sd">    creating: createKerasMasking</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mask_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Masking</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                      <span class="nb">float</span><span class="p">(</span><span class="n">mask_value</span><span class="p">),</span></div>
                                      <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="SReLU"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.SReLU">[docs]</a><span class="k">class</span> <span class="nc">SReLU</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    S-shaped Rectified Linear Unit.</span>
<span class="sd">    It follows:</span>
<span class="sd">    f(x) = t^r + a^r(x - t^r) for x &gt;= t^r</span>
<span class="sd">    f(x) = x for t^r &gt; x &gt; t^l,</span>
<span class="sd">    f(x) = t^l + a^l(x - t^l) for x &lt;= t^l</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    t_left_init: String representations of initialization method for the left part intercept.</span>
<span class="sd">                 Default is &#39;zero&#39;.</span>
<span class="sd">    a_left_init: String representations of initialization method for the left part slope.</span>
<span class="sd">                 Default is &#39;glorot_uniform&#39;.</span>
<span class="sd">    t_right_init: String representations of initialization method for the right part intercept.</span>
<span class="sd">                  Default is &#39;glorot_uniform&#39;.</span>
<span class="sd">    a_right_init: String representations of initialization method for the right part slope.</span>
<span class="sd">                  Default is &#39;one&#39;.</span>
<span class="sd">    shared_axes: Int tuple. The axes along which to share learnable parameters for the activation function.</span>
<span class="sd">                 Default is None.</span>
<span class="sd">                 For example, if the incoming feature maps are from a 2D convolution with output shape</span>
<span class="sd">                 (batch, height, width, channels), and you wish to share parameters across space so that</span>
<span class="sd">                 each filter only has one set of parameters, set &#39;SharedAxes=(1,2)&#39;.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; srelu = SReLU(input_shape=(4, 5))</span>
<span class="sd">    creating: createKerasSReLU</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">t_left_init</span><span class="o">=</span><span class="s1">&#39;zero&#39;</span><span class="p">,</span> <span class="n">a_left_init</span><span class="o">=</span><span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span>
                 <span class="n">t_right_init</span><span class="o">=</span><span class="s1">&#39;glorot_uniform&#39;</span><span class="p">,</span> <span class="n">a_right_init</span><span class="o">=</span><span class="s1">&#39;one&#39;</span><span class="p">,</span>
                 <span class="n">shared_axes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SReLU</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                    <span class="n">t_left_init</span><span class="p">,</span>
                                    <span class="n">a_left_init</span><span class="p">,</span>
                                    <span class="n">t_right_init</span><span class="p">,</span>
                                    <span class="n">a_right_init</span><span class="p">,</span>
                                    <span class="n">shared_axes</span><span class="p">,</span></div>
                                    <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="ELU"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.ELU">[docs]</a><span class="k">class</span> <span class="nc">ELU</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Exponential Linear Unit.</span>
<span class="sd">    It follows:</span>
<span class="sd">    f(x) =  alpha * (exp(x) - 1.) for x &lt; 0,</span>
<span class="sd">    f(x) = x for x &gt;= 0.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    alpha: Float, scale for the negative factor.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; elu = ELU(1.2, input_shape=(4, 5))</span>
<span class="sd">    creating: createKerasELU</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ELU</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                  <span class="nb">float</span><span class="p">(</span><span class="n">alpha</span><span class="p">),</span></div>
                                  <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="LeakyReLU"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.LeakyReLU">[docs]</a><span class="k">class</span> <span class="nc">LeakyReLU</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Leaky version of a Rectified Linear Unit.</span>
<span class="sd">    It allows a small gradient when the unit is not active:</span>
<span class="sd">    f(x) = alpha * x for x &lt; 0,</span>
<span class="sd">    f(x) = x for x &gt;= 0.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    alpha: Float &gt;= 0. Negative slope coefficient.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; leakyrelu = LeakyReLU(0.02, input_shape=(4, 5))</span>
<span class="sd">    creating: createKerasLeakyReLU</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LeakyReLU</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                        <span class="nb">float</span><span class="p">(</span><span class="n">alpha</span><span class="p">),</span></div>
                                        <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="ThresholdedReLU"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.ThresholdedReLU">[docs]</a><span class="k">class</span> <span class="nc">ThresholdedReLU</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Thresholded Rectified Linear Unit.</span>
<span class="sd">    It follows:</span>
<span class="sd">    f(x) = x for x &gt; theta,</span>
<span class="sd">    f(x) = 0 otherwise.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    theta: Float &gt;= 0. Threshold location of activation.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; thresholdedrelu = ThresholdedReLU(input_shape=(10, 12))</span>
<span class="sd">    creating: createKerasThresholdedReLU</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">theta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ThresholdedReLU</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                              <span class="nb">float</span><span class="p">(</span><span class="n">theta</span><span class="p">),</span></div>
                                              <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="TimeDistributed"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.TimeDistributed">[docs]</a><span class="k">class</span> <span class="nc">TimeDistributed</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    TimeDistributed wrapper.</span>
<span class="sd">    Apply a layer to every temporal slice of an input.</span>
<span class="sd">    The input should be at least 3D, and the dimension of index one will be considered to be the temporal dimension.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    # Arguments</span>
<span class="sd">    layer: A layer instance.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; timedistributed = TimeDistributed(Dense(8), input_shape=(10, 12))</span>
<span class="sd">    creating: createKerasDense</span>
<span class="sd">    creating: createKerasTimeDistributed</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">TimeDistributed</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                              <span class="n">layer</span><span class="p">,</span></div>
                                              <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>


<div class="viewcode-block" id="Bidirectional"><a class="viewcode-back" href="../../../../bigdl.nn.keras.html#bigdl.nn.keras.layer.Bidirectional">[docs]</a><span class="k">class</span> <span class="nc">Bidirectional</span><span class="p">(</span><span class="n">KerasLayer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Bidirectional wrapper for RNNs.</span>
<span class="sd">    Bidirectional currently requires RNNs to return the full sequence, i.e. return_sequences = True.</span>

<span class="sd">    When you use this layer as the first layer of a model, you need to provide the argument</span>
<span class="sd">    input_shape (a shape tuple, does not include the batch dimension).</span>

<span class="sd">    Example of creating a bidirectional LSTM:</span>
<span class="sd">    Bidirectiona(LSTM(12, return_sequences=True), merge_mode=&quot;sum&quot;, input_shape=(32, 32))</span>

<span class="sd">    # Arguments</span>
<span class="sd">    layer: An instance of a recurrent layer.</span>
<span class="sd">    merge_mode: Mode by which outputs of the forward and backward RNNs will be combined.</span>
<span class="sd">                Must be one of: &#39;sum&#39;, &#39;mul&#39;, &#39;concat&#39;, &#39;ave&#39;. Default is &#39;concat&#39;.</span>
<span class="sd">    input_shape: A shape tuple, not including batch.</span>

<span class="sd">    &gt;&gt;&gt; bidiretional = Bidirectional(LSTM(10, return_sequences=True), input_shape=(12, 16))</span>
<span class="sd">    creating: createKerasLSTM</span>
<span class="sd">    creating: createKerasBidirectional</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layer</span><span class="p">,</span> <span class="n">merge_mode</span><span class="o">=</span><span class="s2">&quot;concat&quot;</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="o">=</span><span class="s2">&quot;float&quot;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Bidirectional</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">bigdl_type</span><span class="p">,</span>
                                            <span class="n">layer</span><span class="p">,</span>
                                            <span class="n">merge_mode</span><span class="p">,</span></div>
                                            <span class="nb">list</span><span class="p">(</span><span class="n">input_shape</span><span class="p">)</span> <span class="k">if</span> <span class="n">input_shape</span> <span class="k">else</span> <span class="kc">None</span><span class="p">)</span>
</pre></div>

          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="nav-item nav-item-0"><a href="../../../../index.html">BigDL  documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="../../../index.html" >Module code</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2018, Intel.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.7.1.
    </div>
  </body>
</html>