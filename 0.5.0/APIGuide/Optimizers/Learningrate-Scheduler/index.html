<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    
    <link rel="shortcut icon" href="/img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>LearningRate Scheduler - BigDL Project</title>
    <link href="/css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="/css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="/css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="/css/highlight.css">
    <link href="../../../extra.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="/js/jquery-3.2.1.min.js"></script>
    <script src="/js/bootstrap-3.3.7.min.js"></script>
    <script src="/js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "Poly", url: "#poly", children: [
          ]},
          {title: "Default", url: "#default", children: [
          ]},
          {title: "NaturalExp", url: "#naturalexp", children: [
          ]},
          {title: "Exponential", url: "#exponential", children: [
          ]},
          {title: "Plateau", url: "#plateau", children: [
          ]},
          {title: "Warmup", url: "#warmup", children: [
          ]},
          {title: "SequentialSchedule", url: "#sequentialschedule", children: [
          ]},
          {title: "EpochDecay", url: "#epochdecay", children: [
          ]},
          {title: "Regime", url: "#regime", children: [
          ]},
          {title: "EpochSchedule", url: "#epochschedule", children: [
          ]},
          {title: "EpochStep", url: "#epochstep", children: [
          ]},
        ];

    </script>
    <script src="/js/base.js"></script>
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-60548202-2', 'bigdl-project.github.io');
        ga('send', 'pageview');
    </script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
    
    <h1><strong>LearningRate Scheduler</strong></h1>
    <hr>
    <h2 id="poly">Poly</h2>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val lrScheduler = Poly(power=0.5, maxIteration=1000)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">lr_scheduler = Poly(power=0.5, max_iteration=1000, bigdl_type=&quot;float&quot;)
</code></pre>

<p>A learning rate decay policy, where the effective learning rate follows a polynomial decay, to be zero by the max_iteration. Calculation: base_lr (1 - iter/maxIteration) <code>^</code> (power)</p>
<p><code>power</code> coeffient of decay, refer to calculation formula</p>
<p><code>maxIteration</code> max iteration when lr becomes zero</p>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">import com.intel.analytics.bigdl.optim._
import com.intel.analytics.bigdl.tensor.Tensor
import com.intel.analytics.bigdl.tensor.TensorNumericMath.TensorNumeric.NumericFloat
import com.intel.analytics.bigdl.utils.T

val optimMethod = new SGD[Double](0.1)
optimMethod.learningRateSchedule = Poly(3, 100)
def feval(x: Tensor[Double]): (Double, Tensor[Double]) = {
  return (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))
}
val x = Tensor[Double](Storage(Array(10.0, 10.0)))
optimMethod.optimize(feval, x)
&gt; print(optimMethod.learningRateSchedule.currentRate)
-0.1
optimMethod.optimize(feval, x)
&gt; print(optimMethod.learningRateSchedule.currentRate)
-0.0970299
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">optim_method = SGD(0.1)
optimMethod.learningRateSchedule = Poly(3, 100)
</code></pre>

<h2 id="default">Default</h2>
<p>It is the default learning rate schedule. For each iteration, the learning rate would update with the following formula:
 l_{n + 1} = l / (1 + n * learning_rate_decay) where <code>l</code> is the initial learning rate</p>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val lrScheduler = Default()
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">lr_scheduler = Default()
</code></pre>

<p><strong>Scala example:</strong></p>
<pre><code class="scala">val optimMethod = new SGD[Double](0.1, 0.1)
def feval(x: Tensor[Double]): (Double, Tensor[Double]) = {
  return (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))
}
val x = Tensor[Double](Storage(Array(10.0, 10.0)))
optimMethod.optimize(feval, x)
&gt; print(optimMethod.learningRateSchedule.currentRate)
-0.1
optimMethod.optimize(feval, x)
&gt; print(optimMethod.learningRateSchedule.currentRate)
-0.09090909090909091
optimMethod.optimize(feval, x)
&gt; print(optimMethod.learningRateSchedule.currentRate)
-0.08333333333333334
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">optimMethod = SGD(leaningrate_schedule=Default())
</code></pre>

<h2 id="naturalexp">NaturalExp</h2>
<p>A learning rate schedule, which rescale the learning rate by exp ( -decay_rate * iter / decay_step ) referring to tensorflow's learning rate decay # natural_exp_decay</p>
<p><code>decay_step</code> how often to apply decay</p>
<p><code>gamma</code> the decay rate. e.g. 0.96</p>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val learningRateScheduler = NaturalExp(1, 1)
</code></pre>

<p><strong>Scala example:</strong></p>
<pre><code class="scala">val optimMethod = new SGD[Double](0.1)
optimMethod.learningRateSchedule = NaturalExp(1, 1)
def feval(x: Tensor[Double]): (Double, Tensor[Double]) = {
  (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))
}
val x = Tensor[Double](Storage(Array(10.0, 10.0)))
val state = T(&quot;epoch&quot; -&gt; 0, &quot;evalCounter&quot; -&gt; 0)
optimMethod.state = state
optimMethod.optimize(feval, x)
&gt; print(optimMethod.learningRateSchedule.currentRate)
-0.1

optimMethod.optimize(feval, x)
&gt; print(optimMethod.learningRateSchedule.currentRate)
-0.036787944117144235

optimMethod.optimize(feval, x)
&gt; print(optimMethod.learningRateSchedule.currentRate)
-0.013533528323661271
</code></pre>

<h2 id="exponential">Exponential</h2>
<p>A learning rate schedule, which rescale the learning rate by lr_{n + 1} = lr * decayRate <code>^</code> (iter / decayStep)</p>
<p><code>decayStep</code> the inteval for lr decay</p>
<p><code>decayRate</code> decay rate</p>
<p><code>stairCase</code> if true, iter / decayStep is an integer division and the decayed learning rate follows a staircase function.</p>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val learningRateSchedule = Exponential(10, 0.96)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">exponential = Exponential(100, 0.1)
</code></pre>

<p><strong>Scala example:</strong></p>
<pre><code class="scala">val optimMethod = new SGD[Double](0.05)
optimMethod.learningRateSchedule = Exponential(10, 0.96)
def feval(x: Tensor[Double]): (Double, Tensor[Double]) = {
  (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))
}
val x = Tensor[Double](Storage(Array(10.0, 10.0)))
val state = T(&quot;epoch&quot; -&gt; 0, &quot;evalCounter&quot; -&gt; 0)
optimMethod.state = state
optimMethod.optimize(feval, x)
&gt; print(optimMethod.learningRateSchedule.currentRate)
-0.05

optimMethod.optimize(feval, x)
&gt; print(optimMethod.learningRateSchedule.currentRate)
-0.049796306069892535
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">optimMethod = SGD(leaningrate_schedule=Exponential(100, 0.1))
</code></pre>

<h2 id="plateau">Plateau</h2>
<p>Plateau is the learning rate schedule when a metric has stopped improving. Models often benefit from reducing the learning rate by a factor of 2-10 once learning stagnates. It monitors a quantity and if no improvement is seen for a 'patience' number of epochs, the learning rate is reduced.</p>
<p><code>monitor</code> quantity to be monitored, can be Loss or score</p>
<p><code>factor</code> factor by which the learning rate will be reduced. new_lr = lr * factor</p>
<p><code>patience</code> number of epochs with no improvement after which learning rate will be reduced.</p>
<p><code>mode</code> one of {min, max}. In min mode, lr will be reduced when the quantity monitored has stopped decreasing;
 in max mode it will be reduced when the quantity monitored has stopped increasing</p>
<p><code>epsilon</code> threshold for measuring the new optimum, to only focus on significant changes.</p>
<p><code>cooldown</code> number of epochs to wait before resuming normal operation after lr has been reduced.</p>
<p><code>minLr</code> lower bound on the learning rate.</p>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val learningRateSchedule = Plateau(monitor=&quot;score&quot;, factor=0.1, patience=10, mode=&quot;min&quot;, epsilon=1e-4f, cooldown=0, minLr=0)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">plateau = Plateau(&quot;score&quot;, factor=0.1, patience=10, mode=&quot;min&quot;, epsilon=1e-4, cooldown=0, minLr=0)
</code></pre>

<p><strong>Scala example:</strong></p>
<pre><code class="scala">val optimMethod = new SGD[Double](0.05)
optimMethod.learningRateSchedule = Plateau(monitor=&quot;score&quot;, factor=0.1, patience=10, mode=&quot;min&quot;, epsilon=1e-4f, cooldown=0, minLr=0)
def feval(x: Tensor[Double]): (Double, Tensor[Double]) = {
  (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))
}
val x = Tensor[Double](Storage(Array(10.0, 10.0)))
val state = T(&quot;epoch&quot; -&gt; 0, &quot;evalCounter&quot; -&gt; 0)
optimMethod.state = state
optimMethod.optimize(feval, x)
&gt; print(optimMethod.learningRateSchedule.currentRate)


optimMethod.optimize(feval, x)
&gt; print(optimMethod.learningRateSchedule.currentRate)

</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">optimMethod = SGD(leaningrate_schedule=Plateau(&quot;score&quot;))
</code></pre>

<h2 id="warmup">Warmup</h2>
<p>A learning rate gradual increase policy, where the effective learning rate increase delta after each iteration. Calculation: base_lr + delta * iteration</p>
<p><code>delta</code> increase amount after each iteration</p>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val learningRateSchedule = Warmup(delta = 0.05)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">warmup = Warmup(delta=0.05)
</code></pre>

<p><strong>Scala example:</strong></p>
<pre><code class="scala">val lrSchedules = new SequentialSchedule(100)
lrSchedules.add(Warmup(0.3), 3).add(Poly(3, 100), 100)
val optimMethod = new SGD[Double](learningRate = 0.1, learningRateSchedule = lrSchedules)

def feval(x: Tensor[Double]): (Double, Tensor[Double]) = {
  return (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))
}
val x = Tensor[Double](Storage(Array(10.0, 10.0)))
optimMethod.optimize(feval, x)
&gt; print(optimMethod.learningRateSchedule.currentRate)
-0.1

optimMethod.optimize(feval, x)
&gt; print(optimMethod.learningRateSchedule.currentRate)
-0.4
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">optimMethod = SGD(leaningrate_schedule=Warmup(0.05))
</code></pre>

<h2 id="sequentialschedule">SequentialSchedule</h2>
<p>A learning rate scheduler which can stack several learning rate schedulers.</p>
<p><code>iterationPerEpoch</code> iteration numbers per epoch</p>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val learningRateSchedule = SequentialSchedule(iterationPerEpoch=100)
</code></pre>

<p><strong>Python:</strong></p>
<pre><code class="python">sequentialSchedule = SequentialSchedule(iteration_per_epoch=5)
</code></pre>

<p><strong>Scala example:</strong></p>
<pre><code class="scala">val lrSchedules = new SequentialSchedule(100)
lrSchedules.add(Warmup(0.3), 3).add(Poly(3, 100), 100)
val optimMethod = new SGD[Double](learningRate = 0.1, learningRateSchedule = lrSchedules)

def feval(x: Tensor[Double]): (Double, Tensor[Double]) = {
  return (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))
}
val x = Tensor[Double](Storage(Array(10.0, 10.0)))
optimMethod.optimize(feval, x)
&gt; print(optimMethod.learningRateSchedule.currentRate)
-0.1

optimMethod.optimize(feval, x)
&gt; print(optimMethod.learningRateSchedule.currentRate)
-0.4

optimMethod.optimize(feval, x)
&gt; print(optimMethod.learningRateSchedule.currentRate)
-0.7

optimMethod.optimize(feval, x)
&gt; print(optimMethod.learningRateSchedule.currentRate)
-1.0

optimMethod.optimize(feval, x)
&gt; print(optimMethod.learningRateSchedule.currentRate)
-0.9702989999999999
</code></pre>

<p><strong>Python example:</strong></p>
<pre><code class="python">sequentialSchedule = SequentialSchedule(5)
poly = Poly(0.5, 2)
sequentialSchedule.add(poly, 5)
</code></pre>

<h2 id="epochdecay">EpochDecay</h2>
<p><strong>Scala:</strong></p>
<pre><code class="scala">def decay(epoch: Int): Double =
  if (epoch &gt;= 1) 2.0 else if (epoch &gt;= 2) 1.0 else 0.0

val learningRateSchedule = EpochDecay(decay)
</code></pre>

<p>It is an epoch decay learning rate schedule. The learning rate decays through a function argument on number of run epochs l_{n + 1} = l_{n} * 0.1 <code>^</code> decayType(epoch)</p>
<p><code>decayType</code> is a function with number of run epochs as the argument</p>
<p><strong>Scala example:</strong></p>
<pre><code class="scala">def decay(epoch: Int): Double =
  if (epoch == 1) 2.0 else if (epoch == 2) 1.0 else 0.0

val optimMethod = new SGD[Double](1000)
optimMethod.learningRateSchedule = EpochDecay(decay)
def feval(x: Tensor[Double]): (Double, Tensor[Double]) = {
  return (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))
}
val x = Tensor[Double](Storage(Array(10.0, 10.0)))
val state = T(&quot;epoch&quot; -&gt; 0)
for(e &lt;- 1 to 3) {
  state(&quot;epoch&quot;) = e
  optimMethod.state = state
  optimMethod.optimize(feval, x)
  if(e &lt;= 1) {
    assert(optimMethod.learningRateSchedule.currentRate==10)
  } else if (e &lt;= 2) {
    assert(optimMethod.learningRateSchedule.currentRate==100)
  } else {
    assert(optimMethod.learningRateSchedule.currentRate==1000)
  }
}
</code></pre>

<h2 id="regime">Regime</h2>
<p>A structure to specify hyper parameters by start epoch and end epoch. Usually work with [[EpochSchedule]].</p>
<p><code>startEpoch</code> start epoch</p>
<p><code>endEpoch</code> end epoch</p>
<p><code>config</code> config table contains hyper parameters</p>
<h2 id="epochschedule">EpochSchedule</h2>
<p>A learning rate schedule which configure the learning rate according to some pre-defined [[Regime]]. If the running epoch is within the interval of a regime <code>r</code> [r.startEpoch, r.endEpoch], then the learning
 rate will take the "learningRate" in r.config.</p>
<p><code>regimes</code> an array of pre-defined [[Regime]].</p>
<p><strong>Scala:</strong></p>
<pre><code class="scala">val regimes: Array[Regime] = Array(
  Regime(1, 3, T(&quot;learningRate&quot; -&gt; 1e-2, &quot;weightDecay&quot; -&gt; 2e-4)),
  Regime(4, 7, T(&quot;learningRate&quot; -&gt; 5e-3, &quot;weightDecay&quot; -&gt; 2e-4)),
  Regime(8, 10, T(&quot;learningRate&quot; -&gt; 1e-3, &quot;weightDecay&quot; -&gt; 0.0))
)
val learningRateScheduler = EpochSchedule(regimes)
</code></pre>

<p><strong>Scala example:</strong></p>
<pre><code class="scala">val regimes: Array[Regime] = Array(
  Regime(1, 3, T(&quot;learningRate&quot; -&gt; 1e-2, &quot;weightDecay&quot; -&gt; 2e-4)),
  Regime(4, 7, T(&quot;learningRate&quot; -&gt; 5e-3, &quot;weightDecay&quot; -&gt; 2e-4)),
  Regime(8, 10, T(&quot;learningRate&quot; -&gt; 1e-3, &quot;weightDecay&quot; -&gt; 0.0))
)

val state = T(&quot;epoch&quot; -&gt; 0)
val optimMethod = new SGD[Double](0.1)
optimMethod.learningRateSchedule = EpochSchedule(regimes)
def feval(x: Tensor[Double]): (Double, Tensor[Double]) = {
  return (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))
}
val x = Tensor[Double](Storage(Array(10.0, 10.0)))
for(e &lt;- 1 to 10) {
  state(&quot;epoch&quot;) = e
  optimMethod.state = state
  optimMethod.optimize(feval, x)
  if(e &lt;= 3) {
    assert(optimMethod.learningRateSchedule.currentRate==-1e-2)
    assert(optimMethod.weightDecay==2e-4)
  } else if (e &lt;= 7) {
    assert(optimMethod.learningRateSchedule.currentRate==-5e-3)
    assert(optimMethod.weightDecay==2e-4)
  } else if (e &lt;= 10) {
    assert(optimMethod.learningRateSchedule.currentRate==-1e-3)
    assert(optimMethod.weightDecay==0.0)
  }
}
</code></pre>

<h2 id="epochstep">EpochStep</h2>
<p>A learning rate schedule which rescale the learning rate by <code>gamma</code> for each <code>stepSize</code> epochs.</p>
<p><code>stepSize</code> For how many epochs to update the learning rate once</p>
<p><code>gamma</code> the rescale factor</p>
<p><strong>Scala:</strong>
 <code>scala
 val learningRateScheduler = EpochStep(1, 0.5)</code></p>
<p><strong>Scala example:</strong>
 <code>scala
 val optimMethod = new SGD[Double](0.1)
 optimMethod.learningRateSchedule = EpochStep(1, 0.5)
 def feval(x: Tensor[Double]): (Double, Tensor[Double]) = {
   (0.1, Tensor[Double](Storage(Array(1.0, 1.0))))
 }
 val x = Tensor[Double](Storage(Array(10.0, 10.0)))
 val state = T("epoch" -&gt; 0)
 for(e &lt;- 1 to 10) {
   state("epoch") = e
   optimMethod.state = state
   optimMethod.optimize(feval, x)
   assert(optimMethod.learningRateSchedule.currentRate==(-0.1 * Math.pow(0.5, e)))
 }</code></p>

  <br>
</div>

<footer class="col-md-12 wm-page-content">
  <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>